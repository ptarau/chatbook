Amazon Elastic Compute Cloud User Guide for Linux Instances Amazon Elastic Compute Cloud User Guide for Linux Instances Amazon Elastic Compute Cloud : User Guide for Linux Instances Copyright © 2020 Amazon Web Services , Inc. and/or its aﬃliates .
Amazon 's trademarks and trade dress may not be used in connection with any product or service that is not Amazon 's , in any manner that is likely to cause confusion among customers , or in any manner that disparages or discredits Amazon .
All other trademarks not owned by Amazon are the property of their respective owners , who may or may not be aﬃliated with , connected to , or sponsored by Amazon .
Amazon Elastic Compute Cloud User Guide for Linux Instances Table of Contents What is Amazon EC2 ?
55 iii Amazon Elastic Compute Cloud User Guide for Linux Instances Install WordPress .
My Public DNS Name Changed and now my Blog is Broken .
101 Finding the latest Amazon Linux AMI using Systems Manager .
120 iv Amazon Elastic Compute Cloud User Guide for Linux Instances Setting up the AMI tools .
Platform details and usage operation values .
Viewing platform details and usage operation values .
Conﬁrm billing information on your bill .
Connecting to an Amazon Linux instance .
Instances built on the Nitro System .
Monitoring the Status of Your Instances .
Logging API Calls with AWS CloudTrail .
Working with IP Addresses for Your Instance .
Prepare to Bring Your Address Range to Your AWS Account .
Provision the Address Range for use with AWS .
Advertise the Address Range through AWS .
Using reverse DNS for email applications .
IP Addresses Per Network Interface Per Instance Type .
Best Practices for Conﬁguring Network Interfaces .
Enabling enhanced networking on your instance .
Getting Started with EFA and MPI .
Getting Started with EFA and NCCL .
Changing the Placement Group for an Instance .
801 Check and Set the MTU on Your Linux Instance .
901 Retrieving the public key for your key pair through instance metadata .
903 Connecting to your Linux instance if you lose your private key .
1026 viii Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Performance .
Controlling access to longer ID settings .
Listing and ﬁltering using the CLI and API .
Working with tags using the console .
Working with tags using the CLI or API .
Error : Server refused our key or No supported authentication methods available .
Can not connect using my browser .
fsck : No such ﬁle or directory while trying to open .
1177 xi Amazon Elastic Compute Cloud User Guide for Linux Instances Features of Amazon EC2 What is Amazon EC2 ?
Using Amazon EC2 eliminates your need to invest in hardware up front , so you can develop and deploy applications faster .
You can use Amazon EC2 to launch as many or as few virtual servers as you need , conﬁgure security and networking , and manage storage .
Amazon EC2 enables you to scale up or down to handle changes in requirements or spikes in popularity , reducing your need to forecast traﬃc .
For more information about cloud computing , see What is Cloud Computing ?
For more information about running your website on AWS , see Web Hosting .
How to get started with Amazon EC2 First , you need to get set up to use Amazon EC2 .
After you are set up , you are ready to complete the Getting Started tutorial for Amazon EC2 .
Whenever you need more information about an Amazon EC2 feature , you can read the technical documentation .
You can also provision Amazon EC2 resources using other services in AWS .
For more information , see the following documentation : • Amazon EC2 Auto Scaling User Guide • AWS CloudFormation User Guide • AWS Elastic Beanstalk Developer Guide • AWS OpsWorks User Guide To automatically distribute incoming application traﬃc across multiple instances , use Elastic Load Balancing .
For more information , see Elastic Load Balancing User Guide .
To monitor basic statistics for your instances and Amazon EBS volumes , use Amazon CloudWatch .
For more information , see the Amazon CloudWatch User Guide .
For more information , see the Amazon CloudWatch Events User Guide .
2 Amazon Elastic Compute Cloud User Guide for Linux Instances Accessing Amazon EC2 To monitor the calls made to the Amazon EC2 API for your account , including calls made by the AWS Management Console , command line tools , and other services , use AWS CloudTrail .
For more information , see the AWS CloudTrail User Guide .
Although you can set up a database on an EC2 instance , Amazon RDS oﬀers the advantage of handling your database management tasks , such as patching the software , backing up , and storing the backups .
For more information , see Amazon Relational Database Service Developer Guide .
To import virtual machine ( VM ) images from your local environment into AWS and convert them into ready-to-use AMIs or instances , use VM Import/Export .
If you 've signed up for an AWS account , you can access the Amazon EC2 console by signing into the AWS Management Console and selecting EC2 from the console home page .
If you prefer to use a command line interface , you have the following options : AWS Command Line Interface ( CLI ) Provides commands for a broad set of AWS products , and is supported on Windows , Mac , and Linux .
To get started , see AWS Command Line Interface User Guide .
For more information about the commands for Amazon EC2 , see ec2 in the AWS CLI Command Reference .
AWS Tools for Windows PowerShell Provides commands for a broad set of AWS products for those who script in the PowerShell environment .
To get started , see the AWS Tools for Windows PowerShell User Guide .
For more information about the cmdlets for Amazon EC2 , see the AWS Tools for PowerShell Cmdlet Reference .
These requests are HTTP or HTTPS requests that use the HTTP verbs GET or POST and a Query parameter named Action .
For more information about the API actions for Amazon EC2 , see Actions in the Amazon EC2 API Reference .
If you prefer to build applications using language-speciﬁc APIs instead of submitting a request over HTTP or HTTPS , AWS provides libraries , sample code , tutorials , and other resources for software developers .
These libraries provide basic functions that automate tasks such as cryptographically signing your requests , retrying requests , and handling error responses , making it is easier for you to get started .
Pricing for Amazon EC2 When you sign up for AWS , you can get started with Amazon EC2 for free using the AWS Free Tier .
Amazon EC2 provides the following purchasing options for instances : On-Demand Instances Pay for the instances that you use by the second , with no long-term commitments or upfront payments .
3 Amazon Elastic Compute Cloud User Guide for Linux Instances PCI DSS compliance Savings Plans You can reduce your Amazon EC2 costs by making a commitment to a consistent amount of usage , in USD per hour , for a term of 1 or 3 years .
To calculate the cost of a sample provisioned environment , see Cloud Economics Center .
To see your bill , go to the Billing and Cost Management Dashboard in the AWS Billing and Cost Management console .
Your bill contains links to usage reports that provide details about your bill .
To learn more about AWS account billing , see AWS Account Billing .
For an overview of Trusted Advisor , a service that helps you optimize the costs , security , and performance of your AWS environment , see AWS Trusted Advisor .
PCI DSS compliance Amazon EC2 supports the processing , storage , and transmission of credit card data by a merchant or service provider , and has been validated as being compliant with Payment Card Industry ( PCI ) Data Security Standard ( DSS ) .
For more information about PCI DSS , including how to request a copy of the AWS PCI Compliance Package , see PCI DSS Level 1 .
From an AMI , you launch an instance , which is a copy of the AMI running as a virtual server in the cloud .
You can launch multiple instances of an AMI , as shown in the following ﬁgure .
4 Amazon Elastic Compute Cloud User Guide for Linux Instances Instances Your instances keep running until you stop or terminate them , or until they fail .
If an instance fails , you can launch a new one from the AMI .
Instances An instance is a virtual server in the cloud .
Its conﬁguration at launch is a copy of the AMI that you speciﬁed when you launched the instance .
You can launch diﬀerent types of instances from a single AMI .
An instance type essentially determines the hardware of the host computer used for your instance .
Each instance type oﬀers diﬀerent compute and memory capabilities .
Select an instance type based on the amount of memory and computing power that you need for the application or software that you plan to run on the instance .
For more information about the hardware speciﬁcations for each Amazon EC2 instance type , see Amazon EC2 Instance Types .
After you launch an instance , it looks like a traditional host , and you can interact with it as you would any computer .
You have complete control of your instances ; you can use sudo to run commands that require root privileges .
Your AWS account has a limit on the number of instances that you can have running .
For more information about this limit , and how to request an increase , see How many instances can I run in Amazon EC2 in the Amazon EC2 General FAQ .
Storage for your instance The root device for your instance contains the image used to boot the instance .
Your instance may include local storage volumes , known as instance store volumes , which you can conﬁgure at launch time with block device mapping .
After these volumes have been added to and mapped on your instance , they are available for you to mount and use .
If your instance fails , or if your instance is stopped or terminated , the data on these volumes is lost ; therefore , these volumes are best used for temporary data .
To keep important data safe , you should use a replication strategy across multiple instances , or store your persistent data in Amazon S3 or Amazon EBS volumes .
5 Amazon Elastic Compute Cloud User Guide for Linux Instances AMIs Security best practices • Use AWS Identity and Access Management ( IAM ) to control access to your AWS resources , including your instances .
You can create IAM users and groups under your AWS account , assign security credentials to each , and control the access that each has to resources and services in AWS .
• Restrict access by only allowing trusted hosts or networks to access ports on your instance .
For example , you can restrict SSH access by restricting incoming traﬃc on port 22 .
• Review the rules in your security groups regularly , and ensure that you apply the principle of least privilege—only open up permissions that you require .
You can also create diﬀerent security groups to deal with instances that have diﬀerent security requirements .
Consider creating a bastion security group that allows external logins , and keep the remainder of your instances in a group that does not allow external logins .
Stopping , starting , and terminating instances Stopping an instance When an instance is stopped , the instance performs a normal shutdown , and then transitions to a stopped state .
All of its Amazon EBS volumes remain attached , and you can start the instance again at a later time .
You are not charged for additional instance usage while the instance is in a stopped state .
A minimum of one minute is charged for every transition from a stopped state to a running state .
If the instance type was changed while the instance was stopped , you will be charged the rate for the new instance type after the instance is started .
All of the associated Amazon EBS usage of your instance , including root device usage , is billed using typical Amazon EBS prices .
When an instance is in a stopped state , you can attach or detach Amazon EBS volumes .
You can also create an AMI from the instance , and you can change the kernel , RAM disk , and instance type .
Terminating an instance When an instance is terminated , the instance performs a normal shutdown .
The root device volume is deleted by default , but any attached Amazon EBS volumes are preserved by default , determined by each volume 's deleteOnTermination attribute setting .
The instance itself is also deleted , and you can't start the instance again at a later time .
To prevent accidental termination , you can disable instance termination .
If you do so , ensure that the disableApiTermination attribute is set to true for the instance .
To control the behavior of an instance shutdown , such as shutdown -h in Linux or shutdown in Windows , set the instanceInitiatedShutdownBehavior instance attribute to stop or terminate as desired .
Instances with Amazon EBS volumes for the root device default to stop , and instances with instancestore root devices are always terminated as the result of an instance shutdown .
In addition , members of the AWS developer community 6 Amazon Elastic Compute Cloud User Guide for Linux Instances Regions , Availability Zones , and Local Zones have published their own custom AMIs .
You can also create your own custom AMI or AMIs ; doing so enables you to quickly and easily start new instances that have everything you need .
For example , if your application is a website or a web service , your AMI could include a web server , the associated static content , and the code for the dynamic pages .
As a result , after you launch an instance from this AMI , your web server starts , and your application is ready to accept requests .
All AMIs are categorized as either backed by Amazon EBS , which means that the root device for an instance launched from the AMI is an Amazon EBS volume , or backed by instance store , which means that the root device for an instance launched from the AMI is an instance store volume created from a template stored in Amazon S3 .
The description of an AMI indicates the type of root device ( either ebs or instance store ) .
This is important because there are signiﬁcant diﬀerences in what you can do with each type of AMI .
Each Region has multiple , isolated locations known as Availability Zones .
Local Zones provide you the ability to place resources , such as compute and storage , in multiple locations closer to your end users .
Resources are n't replicated across Regions unless you speciﬁcally choose to do so .
Although rare , failures can occur that aﬀect the availability of instances that are in the same location .
If you host all of your instances in a single location that is aﬀected by a failure , none of your instances would be available .
Each Availability Zone is isolated , but the Availability Zones in a Region are connected through low-latency links .
A Local Zone is an AWS infrastructure deployment that places select services closer to your end users .
A Local Zone is an extension of a Region that is in a diﬀerent location from your Region .
The following diagram illustrates the relationship between Regions , Availability Zones , and Local Zones .
This achieves the greatest possible fault tolerance and stability .
When you view your resources , you see only the resources that are tied to the Region that you speciﬁed .
This is because Regions are isolated from each other , and we do n't automatically replicate resources across Regions .
When you launch an instance , you must select an AMI that 's in the same Region .
If the AMI is in another Region , you can copy the AMI to the Region you 're using .
Note that there is a charge for data transfer between Regions .
Availability Zones When you launch an instance , you can select an Availability Zone or let us choose one for you .
If you distribute your instances across multiple Availability Zones and one instance fails , you can design your application so that an instance in another Availability Zone can handle requests .
You can also use Elastic IP addresses to mask the failure of an instance in one Availability Zone by rapidly remapping the address to an instance in another Availability Zone .
8 Amazon Elastic Compute Cloud User Guide for Linux Instances Concepts An Availability Zone is represented by a Region code followed by a letter identiﬁer ; for example , us-east-1a .
To ensure that resources are distributed across the Availability Zones for a Region , we independently map Availability Zones to names for each AWS account .
For example , the Availability Zone us-east-1a for your AWS account might not be the same location as us-east-1a for another AWS account .
To coordinate Availability Zones across accounts , you must use the AZ ID , which is a unique and consistent identiﬁer for an Availability Zone .
For example , use1-az1 is an AZ ID for the us-east-1 Region and it has the same location in every AWS account .
Viewing AZ IDs enables you to determine the location of resources in one account relative to the resources in another account .
For example , if you share a subnet in the Availability Zone with the AZ ID use-az2 with another account , this subnet is available to that account in the Availability Zone whose AZ ID is also use-az2 .
The AZ ID for each VPC and subnet is displayed in the Amazon VPC console .
For more information , see Working with VPC Sharing in the Amazon VPC User Guide .
As Availability Zones grow over time , our ability to expand them can become constrained .
If this happens , we might restrict you from launching an instance in a constrained Availability Zone unless you already have an instance in that Availability Zone .
Eventually , we might also remove the constrained Availability Zone from the list of Availability Zones for new accounts .
Therefore , your account might have a diﬀerent number of available Availability Zones in a Region than another account .
You can list the Availability Zones that are available to your account .
Local Zones A Local Zone is an extension of an AWS Region in geographic proximity to your users .
Local Zones have their own connections to the internet and support AWS Direct Connect , so resources created in a Local Zone can serve local users with very low-latency communications .
Finally , launch any of the following resources in the Local Zone subnet , so that your applications are closer to your end users : • Amazon EC2 instances • Amazon EBS volumes • Amazon FSx ﬁle servers • Application Load Balancer • Dedicated Hosts Local Zones are not available in every Region .
You can list the Local Zones that are available to your account .
Network border groups A network border group is a unique set of Availability Zones or Local Zones from where AWS advertises IP addresses .
You can allocate the following resources from a network border group : 9 Amazon Elastic Compute Cloud User Guide for Linux Instances Available Regions • Elastic IPv4 addresses that Amazon provides • IPv6 Amazon-provided VPC addresses A network border group limits the addresses to the group .
IP addresses can not move between network border groups .
Available Regions Your account determines the Regions that are available to you .
For example : • An AWS account provides multiple Regions so that you can launch Amazon EC2 instances in locations that meet your requirements .
For example , you might want to launch instances in Europe to be closer to your European customers or to meet legal requirements .
The following table lists the Regions provided by an AWS account .
For more information , see Managing AWS Regions in the AWS General Reference .
The number and mapping of Availability Zones per Region may vary between AWS accounts .
To get a list of the Availability Zones that are available to your account , you can use the Amazon EC2 console or the command line interface .
Regions and endpoints When you work with an instance using the command line interface or API actions , you must specify its Regional endpoint .
For more information about the Regions and endpoints for Amazon EC2 , see Amazon EC2 endpoints adn quotas in the Amazon Web Services General Reference .
Describing your Regions , Availability Zones , and Local Zones You can use the Amazon EC2 console or the command line interface to determine which Regions , Availability Zones , and Local Zones are available for your account .
From the navigation bar , view the options in the Region selector .
The Availability Zones and Local Zones are listed under Service Health , Availability Zone Status .
12 Amazon Elastic Compute Cloud User Guide for Linux Instances Specifying the Region for a resource To ﬁnd your Regions , Availability Zones , and Local Zones using the AWS CLI 1 .
Use the describe-regions command as follows to describe the Regions that are enabled for your account .
Use the describe-availability-zones command as follows to describe the Availability Zones and Local Zones within the speciﬁed Region .
Use the describe-availability-zones command as follows to describe the Availability Zones and Local Zones regardless of the opt-in status .
Use the Get-EC2Region command as follows to describe the Regions for your account .
Use the Get-EC2AvailabilityZone command as follows to describe the Availability Zones within the speciﬁed Region .
You can specify the Region for a resource using the AWS Management Console or the command line .
Note Some AWS resources might not be available in all Regions , Availability Zones , and Local Zones .
Ensure that you can create the resources that you need in the desired Regions or Availability Zones before launching an instance in a speciﬁc Availability Zone .
Use the Region selector in the navigation bar .
13 Amazon Elastic Compute Cloud User Guide for Linux Instances Specifying the Region for a resource To specify the default Region using the command line You can set the value of an environment variable to the desired Regional endpoint ( for example , https : //ec2.us-east-2.amazonaws.com ) : 14 Amazon Elastic Compute Cloud User Guide for Linux Instances Enabling Local Zones • AWS_DEFAULT_REGION ( AWS CLI ) • Set-AWSDefaultRegion ( AWS Tools for Windows PowerShell ) Alternatively , you can use the -- region ( AWS CLI ) or -Region ( AWS Tools for Windows PowerShell ) command line option with each individual command .
For more information about the endpoints for Amazon EC2 , see Amazon Elastic Compute Cloud Endpoints .
Enabling Local Zones Before you specify a Local Zone for a resource or service , you must enable the zone .
You can enable Local Zones using the AWS Management Console or the AWS CLI .
Note We enable all Availability Zones by default and you can not disable them .
Some AWS resources might not be available in all Regions .
Make sure that you can create the resources that you need in the desired Regions or Local Zones before launching an instance in a speciﬁc Local Zone .
Use the Region selector in the navigation bar , and select your Region .
Under Availability Zone status , choose Enable additional Local Zones .
Under Local Zone Groups , turn on each Local Zone that you want to enable .
In the Enable conﬁrmation dialog box , enter Enable , and then choose OK. 15 Amazon Elastic Compute Cloud User Guide for Linux Instances Disabling Local Zones To enable Local Zones using the AWS CLI • Use the modify-availability-zone-group command .
Disabling Local Zones You must contact AWS Support to disable a Local Zone .
Important Remove all resources before you disable a Local Zone .
Any resources that are left in the Local Zone incur charges .
After you remove the resources , create a case with AWS Support with the title Disable Zone Group .
Launching instances in an Availability Zone or a Local Zone When you launch an instance , select a Region that puts your instances closer to speciﬁc customers , or meets the legal or other requirements that you have .
By launching your instances in separate Availability Zones , you can protect your applications from the failure of a single location .
By launching an instance in a Local Zone , you can run latency-sensitive applications close to your end users while having the beneﬁts of the AWS infrastructure .
When you launch an instance , you can optionally specify an Availability Zone or Local Zone in the Region that you are using .
If you do not specify an Availability Zone or Local Zone , we select an Availability Zone for you .
When you launch your initial instances , we recommend that you accept the default Availability Zone , because this enables us to select the best Availability Zone for you based on system health and available capacity .
If you launch additional instances , specify an Availability Zone only if your new instances must be close to , or separated from , your running instances .
Migrating an instance to another Availability Zone If necessary , you can migrate an instance from one Availability Zone to another .
For example , let 's say you are trying to modify the instance type of your instance and we ca n't launch an instance of the new instance type in the current Availability Zone .
In this case , you can migrate the instance to an Availability Zone where we are able to launch an instance of that instance type .
The migration process involves : • Creating an AMI from the original instance • Launching an instance in the new Availability Zone • Updating the conﬁguration of the new instance , as shown in the following procedure To migrate an instance to another Availability Zone 1 .
Create an AMI from the instance .
The procedure depends on your operating system and the type of root device volume for the instance .
• Creating an Amazon EBS-Backed Windows AMI If you need to preserve the private IPv4 address of the instance , you must delete the subnet in the current Availability Zone and then create a subnet in the new Availability Zone with the same IPv4 16 Amazon Elastic Compute Cloud User Guide for Linux Instances Root device volume address range as the original subnet .
Note that you must terminate all instances in a subnet before you can delete it .
Therefore , you should create AMIs from all of the instances in your subnet so that you can move all instances from the current subnet to the new subnet .
Launch an instance from the AMI that you just created , specifying the new Availability Zone or subnet .
You can use the same instance type as the original instance , or select a new instance type .
If the original instance has an associated Elastic IP address , associate it with the new instance .
If the original instance is a Reserved Instance , change the Availability Zone for your reservation .
( If you also changed the instance type , you can also change the instance type for your reservation . ) .
Amazon EC2 root device volume When you launch an instance , the root device volume contains the image used to boot the instance .
When we introduced Amazon EC2 , all AMIs were backed by Amazon EC2 instance store , which means the root device for an instance launched from the AMI is an instance store volume created from a template stored in Amazon S3 .
After we introduced Amazon EBS , we introduced AMIs that are backed by Amazon EBS .
This means that the root device for an instance launched from the AMI is an Amazon EBS volume created from an Amazon EBS snapshot .
You can choose between AMIs backed by Amazon EC2 instance store and AMIs backed by Amazon EBS .
We recommend that you use AMIs backed by Amazon EBS , because they launch faster and use persistent storage .
The description of an AMI includes which type of AMI it is ; you 'll see the root device referred to in some places as either ebs ( for Amazon EBS-backed ) or instance store ( for instance store-backed ) .
This is important because there are signiﬁcant diﬀerences between what you can do with each type of AMI .
Instance store-backed instances Instances that use instance stores for the root device automatically have one or more instance store volumes available , with one volume serving as the root device volume .
When an instance is launched , the image that is used to boot the instance is copied to the root volume .
Note that you can optionally use additional instance store volumes , depending on the instance type .
Any data on the instance store volumes persists as long as the instance is running , but this data is deleted when the instance is terminated ( instance store-backed instances do not support the Stop action ) or if it fails ( such as if an underlying drive has issues ) .
17 Amazon Elastic Compute Cloud User Guide for Linux Instances Root device storage concepts After an instance store-backed instance fails or terminates , it can not be restored .
If you plan to use Amazon EC2 instance store-backed instances , we highly recommend that you distribute the data on your instance stores across multiple Availability Zones .
You should also back up critical data from your instance store volumes to persistent storage on a regular basis .
Amazon EBS-backed instances Instances that use Amazon EBS for the root device automatically have an Amazon EBS volume attached .
When you launch an Amazon EBS-backed instance , we create an Amazon EBS volume for each Amazon EBS snapshot referenced by the AMI you use .
You can optionally use other Amazon EBS volumes or instance store volumes , depending on the instance type .
An Amazon EBS-backed instance can be stopped and later restarted without aﬀecting data stored in the attached volumes .
For example , you can modify the properties of the instance , change its size , or update the kernel it is using , or you can attach your root volume to a diﬀerent running instance for debugging or any other purpose .
If an Amazon EBS-backed instance fails , you can restore your session by following one of these methods : • Stop and then start again ( try this method ﬁrst ) .
18 Amazon Elastic Compute Cloud User Guide for Linux Instances Choosing an AMI by root device type • Attach the volume to the new instance by following these steps : 1 .
Detach the remaining Amazon EBS volumes from the old instance .
Reattach the Amazon EBS volumes to the new instance .
Choosing an AMI by root device type The AMI that you specify when you launch your instance determines the type of root device volume that your instance has .
In the search bar choose Platform to select the operating system ( such as Amazon Linux ) , and Root Device Type to select EBS images .
Choose an AMI and write down its AMI ID .
In the search bar , choose Platform to select the operating system ( such as Amazon Linux ) , and Root Device Type to select Instance store .
Choose an AMI and write down its AMI ID .
To verify the type of the root device volume of an AMI using the command line You can use one of the following commands .
19 Amazon Elastic Compute Cloud User Guide for Linux Instances Changing the root volume to persist 3 .
Check the value of Root device type in the Description tab as follows : • If the value is ebs , this is an Amazon EBS-backed instance .
To determine the root device type of an instance using the command line You can use one of the following commands .
You can change the default behavior to ensure that the volume persists after the instance terminates .
To change the default behavior , set the DeleteOnTermination attribute to false using a block device mapping .
Topics • Conﬁguring the root volume to persist during instance launch ( p. 20 ) • Conﬁguring the root volume to persist for an existing instance ( p. 21 ) • Conﬁrming that a root volume is conﬁgured to persist ( p. 21 ) Conﬁguring the root volume to persist during instance launch You can conﬁgure the root volume to persist when you launch an instance using the Amazon EC2 console or the command line tools .
To conﬁgure the root volume to persist when you launch an instance using the console 1 .
In the navigation pane , choose Instances and then choose Launch Instance .
On the Choose an Amazon Machine Image ( AMI ) page , select the AMI to use and choose Select .
Follow the wizard to complete the Choose an Instance Type and Conﬁgure Instance Details pages .
On the Add Storage page , deselect Delete On Termination for the root volume .
Complete the remaining wizard pages , and then choose Launch .
To conﬁgure the root volume to persist when you launch an instance using the AWS CLI Use the run-instances command and include a block device mapping that sets the DeleteOnTermination attribute to false .
Conﬁguring the root volume to persist for an existing instance You can conﬁgure the root volume to persist for a running instance using the command line tools only .
If the instance is running , you must stop it ﬁrst .
To conﬁgure the root volume to persist for an existing instance using the AWS CLI If the instance is running , use the stop-instances command to stop it .
After the instance is stopped , use the modify-instance-attribute command with a block device mapping that sets the DeleteOnTermination attribute to false .
After the instance is stopped , use the Edit-EC2InstanceAttribute command with a block device mapping that sets the DeleteOnTermination attribute to false .
In the navigation pane , choose Instances and then select the instance .
21 Amazon Elastic Compute Cloud User Guide for Linux Instances Changing the root volume to persist 3 .
In the Description tab , choose the entry for Root device .
If Delete on termination is set to false , the volume is conﬁgured to persist .
To conﬁrm that a root volume is conﬁgured to persist using the AWS CLI Use the describe-instances command and verify that the DeleteOnTermination attribute in the BlockDeviceMappings response element is set to false .
You can open the Amazon EC2 console , choose Launch Instance , and follow the steps in the launch wizard to launch your ﬁrst instance .
If you have n't signed up for AWS yet , or if you need assistance launching your ﬁrst instance , complete the following tasks to get set up to use Amazon EC2 : 1 .
You are charged only for the services that you use .
If you have an AWS account already , skip to the next task .
If you do n't have an AWS account , use the following procedure to create one .
Part of the sign-up procedure involves receiving a phone call and entering a veriﬁcation code on the phone keypad .
Create a key pair AWS uses public-key cryptography to secure the login information for your instance .
A Linux instance has no password ; you use a key pair to log in to your instance securely .
You specify the name of the key pair when you launch your instance , then provide the private key when you log in using SSH .
Note that if you plan to launch instances in multiple Regions , you 'll need to create a key pair in each Region .
You can select any Region that 's available to you , regardless of your location .
However , key pairs are speciﬁc to a region ; for example , if you plan to launch an instance in the US East ( Ohio ) Region , you must create a key pair for the instance in the US East ( Ohio ) Region .
For File format , choose the format in which to save the private key .
• Choose pem to save the private key in a format that is used with OpenSSH .
• Choose ppk to save the private key in a format that is used with PuTTY , a tool that enables you to connect to a Linux instance from Windows .
The private key ﬁle is automatically downloaded by your browser .
The base ﬁle name is the name you speciﬁed as the name of your key pair , and the ﬁle name extension is .pem .
Important This is the only chance for you to save the private key ﬁle .
You 'll need to provide the name of your key pair when you launch an instance and the corresponding private key each time you connect to the instance .
If you will use an SSH client on a Mac or Linux computer to connect to your Linux instance , use the following command to set the permissions of your private key ﬁle so that only you can read it .
chmod 400 your_user_name-key-pair-region_name.pem If you do not set these permissions , then you can not connect to your instance using this key pair .
Create a security group Security groups act as a ﬁrewall for associated instances , controlling both inbound and outbound traﬃc at the instance level .
You must add rules to a security group that enable you to connect to your instance from your IP address using SSH .
You can also add rules that allow inbound and outbound HTTP and HTTPS access from anywhere .
Note that if you plan to launch instances in multiple Regions , you 'll need to create a security group in each Region .
The security group editor in the Amazon EC2 console can automatically detect the public IPv4 address for you .
Alternatively , you can use the search phrase `` what is my IP address '' in an Internet browser , or use the following service : Check IP .
If you are connecting through an Internet service provider ( ISP ) or from behind a ﬁrewall without a static IP address , you need to ﬁnd out the range of IP addresses used by client computers .
Tip Alternatively , you can use the Amazon VPC console to create a security group .
However , the instructions in this procedure do n't match the Amazon VPC console .
Therefore , if you switched to the Amazon VPC console in the previous section , either switch back to the 25 Amazon Elastic Compute Cloud User Guide for Linux Instances Create a security group Amazon EC2 console and use these instructions , or use the instructions in Set Up a Security Group for Your VPC in the Amazon VPC Getting Started Guide .
Security groups are speciﬁc to a Region , so you should select the same Region in which you created your key pair .
Choose Security Groups in the navigation pane .
In the VPC list , select your default VPC for the Region .
In the Source box , choose My IP to automatically populate the ﬁeld with the public IPv4 address of your local computer .
Alternatively , choose Custom and specify the public IPv4 address of your computer or network in CIDR notation .
27 Amazon Elastic Compute Cloud User Guide for Linux Instances Overview Getting started with Amazon EC2 Linux instances Let 's get started with Amazon Elastic Compute Cloud ( Amazon EC2 ) by launching , connecting to , and using a Linux instance .
An instance is a virtual server in the AWS cloud .
With Amazon EC2 , you can set up and conﬁgure the operating system and applications that run on your instance .
When you sign up for AWS , you can get started with Amazon EC2 using the AWS Free Tier .
If you created your AWS account less than 12 months ago , and have not already exceeded the free tier beneﬁts for Amazon EC2 , it will not cost you anything to complete this tutorial , because we help you select options that are within the free tier beneﬁts .
Otherwise , you 'll incur the standard Amazon EC2 usage fees from the time that you launch the instance until you terminate the instance ( which is the ﬁnal task of this tutorial ) , even if it remains idle .
You can either specify the Availability Zone in which your instance runs , or let Amazon EC2 select an Availability Zone for you .
When you launch your instance , you secure it by specifying a key pair and security group .
When you connect to your instance , you must specify the private key of the key pair that you speciﬁed when launching your instance .
28 Amazon Elastic Compute Cloud User Guide for Linux Instances Prerequisites Tasks To complete this tutorial , perform the following tasks : 1 .
• If you 'd prefer to use the command line , see this tutorial in the AWS Command Line Interface User Guide : Using Amazon EC2 through the AWS CLI .
Step 1 : Launch an instance You can launch a Linux instance using the AWS Management Console as described in the following procedure .
This tutorial is intended to help you launch your ﬁrst instance quickly , so it does n't cover all possible options .
For more information about the advanced options , see Launching an Instance .
On the Choose an Instance Type page , you can select the hardware conﬁguration of your instance .
Notice that this instance type is eligible for the free tier .
Choose Review and Launch to let the wizard complete the other conﬁguration settings for you .
On the Review Instance Launch page , under Security Groups , you 'll see that the wizard created and selected a security group for you .
You can use this security group , or alternatively you can select the security group that you created when getting set up using the following steps : a. b .
On the Conﬁgure Security Group page , ensure that Select an existing security group is selected .
Select your security group from the list of existing security groups , and then choose Review and Launch .
When prompted for a key pair , select Choose an existing key pair , then select the key pair that you created when getting set up .
This is the only chance for you to save the private key ﬁle , 29 Amazon Elastic Compute Cloud User Guide for Linux Instances Step 2 : Connect to your instance so be sure to download it .
You 'll need to provide the name of your key pair when you launch an instance and the corresponding private key each time you connect to the instance .
When you are ready , select the acknowledgement check box , and then choose Launch Instances .
A conﬁrmation page lets you know that your instance is launching .
Choose View Instances to close the conﬁrmation page and return to the console .
On the Instances screen , you can view the status of the launch .
It takes a short time for an instance to launch .
When you launch an instance , its initial state is pending .
After the instance starts , its state changes to running and it receives a public DNS name .
It can take a few minutes for the instance to be ready so that you can connect to it .
Check that your instance has passed its status checks ; you can view this information in the Status Checks column .
Step 2 : Connect to your instance There are several ways to connect to your Linux instance .
Important You ca n't connect to your instance unless you launched it with a key pair for which you have the .pem ﬁle and you launched it with a security group that allows SSH access from your computer .
Step 3 : Clean up your instance After you 've ﬁnished with the instance that you created for this tutorial , you should clean up by terminating the instance .
Important Terminating an instance eﬀectively deletes it ; you ca n't reconnect to an instance after you've terminated it .
If you launched an instance that is not within the AWS Free Tier , you 'll stop incurring charges for that instance as soon as the instance status changes to shutting down or terminated .
If you 'd like to keep your instance for later , but not incur charges , you can stop the instance now and then start it again later .
After your instance is terminated , it remains visible on the console for a short while , and then the entry is deleted .
30 Amazon Elastic Compute Cloud User Guide for Linux Instances Next steps Next steps After you start your instance , you might want to try some of the following exercises : • Learn how to remotely manage your EC2 instance using Run Command .
For more information , see AWS Systems Manager Run Command in the AWS Systems Manager User Guide .
• Conﬁgure a CloudWatch alarm to notify you if your usage exceeds the Free Tier .
For more information , see Create a Billing Alarm in the AWS Billing and Cost Management User Guide .
31 Amazon Elastic Compute Cloud User Guide for Linux Instances Best practices for Amazon EC2 This list of practices will help you get the maximum beneﬁt from Amazon EC2 .
Security • Manage access to AWS resources and APIs using identity federation , IAM users , and IAM roles .
Establish credential management policies and procedures for creating , distributing , rotating , and revoking AWS access credentials .
For more information , see IAM Best Practices in the IAM User Guide .
• Implement the least permissive rules for your security group .
For more information about updating Amazon Linux 2 or the Amazon Linux AMI , see Managing Software on Your Linux Instance in the Amazon EC2 User Guide for Linux Instances .
Storage • Understand the implications of the root device type for data persistence , backup , and recovery .
• Use separate Amazon EBS volumes for the operating system versus your data .
Ensure that the volume with your data persists after instance termination .
• Use the instance store available for your instance to store temporary data .
Remember that the data stored in instance store is deleted when you stop or terminate your instance .
If you use instance store for database storage , ensure that you have a cluster with a replication factor that ensures fault tolerance .
Resource management • Use instance metadata and custom resource tags to track and identify your AWS resources .
Plan to request any limit increases in advance of the time that you 'll need them .
• Deploy critical components of your application across multiple Availability Zones , and replicate your data appropriately .
• Design your applications to handle dynamic IP addressing when your instance restarts .
32 Amazon Elastic Compute Cloud User Guide for Linux Instances • Regularly test the process of recovering your instances and Amazon EBS volumes if they fail .
33 Amazon Elastic Compute Cloud User Guide for Linux Instances Install a LAMP Server ( Amazon Linux 2 ) Tutorials for Amazon EC2 Instances Running Linux The following tutorials show you how to perform common tasks using EC2 instances running Linux .
You can use this server to host a static website or deploy a dynamic PHP application that reads and writes information to a database .
If you are trying to set up a LAMP web server on an Ubuntu or Red Hat Enterprise Linux instance , this tutorial will not work for you .
For more information about other distributions , see their speciﬁc documentation .
For information about LAMP web servers on Ubuntu , see the Ubuntu community documentation ApacheMySQLPHP topic .
Option : Complete this tutorial using automation To complete this tutorial using AWS Systems Manager Automation instead of the following tasks , run the AWSDocs-InstallALAMPServer-AL2 Automation document .
Note The following procedure installs the latest PHP version available on Amazon Linux 2 , currently PHP 7.2 .
If you plan to use PHP applications other than those described in this tutorial , you should check their compatibility with PHP 7.2 .
To ensure that all of your software packages are up to date , perform a quick software update on your instance .
This process may take a few minutes , but it is important to make sure that you have the latest security updates and bug ﬁxes .
The -y option installs the updates without asking for conﬁrmation .
If you would like to examine the updates before installing , you can omit this option .
Install the lamp-mariadb10.2-php7.2 and php7.2 Amazon Linux Extras repositories to get the latest versions of the LAMP MariaDB and PHP packages for Amazon Linux 2 .
You can view your version of Amazon Linux with the following command .
Now that your instance is current , you can install the Apache web server , MariaDB , and PHP software packages .
Use the yum install command to install multiple software packages and all related dependencies at the same time .
Use the systemctl command to conﬁgure the Apache web server to start at each system boot .
Add a security rule to allow inbound HTTP ( port 80 ) connections to your instance if you have not already done so .
This group contains a single rule to allow SSH connections .
Choose Instances and select your instance .
If there is no content in /var/www/html , you should see the Apache test page .
If you are unable to see the Apache test page , check that the security group you are using contains a rule to allow HTTP ( port 80 ) traﬃc .
Important If you are not using Amazon Linux , you may also need to conﬁgure the ﬁrewall on your instance to allow these connections .
For more information about how to conﬁgure the ﬁrewall , see the documentation for your speciﬁc distribution .
36 Amazon Elastic Compute Cloud User Guide for Linux Instances Step 1 : Prepare the LAMP Server Apache httpd serves ﬁles that are kept in a directory called the Apache document root .
The Amazon Linux Apache document root is /var/www/html , which by default is owned by root .
To allow the ec2-user account to manipulate ﬁles in this directory , you must modify the ownership and permissions of the directory .
There are many ways to accomplish this task .
In this tutorial , you add ec2user to the apache group , to give the apache group ownership of the /var/www directory and assign write permissions to the group .
Log out and then log back in again to pick up the new group , and then verify your membership .
Change the group ownership of /var/www and its contents to the apache group .
To add group write permissions and to set the group ID on future subdirectories , change the directory permissions of /var/www and its subdirectories .
To secure your web server ( Optional ) A web server running the HTTP protocol provides no transport security for the data that it sends or receives .
When you connect to an HTTP server using a web browser , the URLs that you visit , the content of webpages that you receive , and the contents ( including passwords ) of any HTML forms that you submit are all visible to eavesdroppers anywhere along the network pathway .
The best practice for securing your web server is to install support for HTTPS ( HTTP Secure ) , which protects your data with SSL/TLS encryption .
Step 2 : Test Your LAMP Server If your server is installed and running , and your ﬁle permissions are set correctly , your ec2-user account should be able to create a PHP ﬁle in the /var/www/html directory that is available from the internet .
In a web browser , type the URL of the ﬁle that you just created .
This URL is the public DNS address of your instance followed by a forward slash and the ﬁle name .
For example : http : //my.public.dns.amazonaws.com/phpinfo.php You should see the PHP information page : 38 Amazon Elastic Compute Cloud User Guide for Linux Instances Step 3 : Secure the Database Server Note If you do not see this page , verify that the /var/www/html/phpinfo.php ﬁle was created properly in the previous step .
You can also verify that all of the required packages were installed with the following command .
Although this can be useful information , it should not be broadcast to the internet for security reasons .
If you add content to the Apache document root at /var/www/html , you should be able to view that content at the public DNS address for your instance .
Step 3 : Secure the Database Server The default installation of the MariaDB server has several features that are great for testing and development , but they should be disabled or removed for production servers .
The mysql_secure_installation command walks you through the process of setting a root password and removing the insecure features from your installation .
Even if you are not planning on using the MariaDB server , we recommend performing this procedure .
Make sure to store this password in a safe place .
Note Setting a root password for MariaDB is only the most basic measure for securing your database .
When you build or install a database-driven application , you typically create a database service user for that application and avoid using the root account for anything but database administration .
( Optional ) If you do not plan to use the MariaDB server right away , stop it .
You can restart it when you need it again .
( Optional ) If you want the MariaDB server to start at every boot , type the following command .
Follow the steps below to install and conﬁgure phpMyAdmin on your Amazon Linux instance .
Important We do not recommend using phpMyAdmin to access a LAMP server unless you have enabled SSL/TLS in Apache ; otherwise , your database administrator password and other data are transmitted insecurely across the internet .
For security recommendations from the developers , see Securing your phpMyAdmin installation .
Create a phpMyAdmin folder and extract the package into it with the following command .
This URL is the public DNS address ( or the public IP address ) of your instance followed by a forward slash and the name of your installation directory .
Log in to your phpMyAdmin installation with the root user name and the MySQL root password you created earlier .
Your installation must still be conﬁgured before you put it into service .
For information about using phpMyAdmin , see the phpMyAdmin User Guide .
42 Amazon Elastic Compute Cloud User Guide for Linux Instances Troubleshooting Troubleshooting This section oﬀers suggestions for resolving common problems you may encounter while setting up a new LAMP server .
Perform the following checks to see if your Apache web server is running and accessible .
If you are unable to see the Apache test page , check that the security group you are using contains a rule to allow HTTP ( port 80 ) traﬃc .
43 Amazon Elastic Compute Cloud User Guide for Linux Instances Install a LAMP Server ( Amazon Linux AMI ) Tutorial : Install a LAMP Web Server with the Amazon Linux AMI The following procedures help you install an Apache web server with PHP and MySQL support on your Amazon Linux instance ( sometimes called a LAMP web server or LAMP stack ) .
You can use this server to host a static website or deploy a dynamic PHP application that reads and writes information to a database .
If you are trying to set up a LAMP web server on an Ubuntu or Red Hat Enterprise Linux instance , this tutorial will not work for you .
For more information about other distributions , see their speciﬁc documentation .
For information about LAMP web servers on Ubuntu , see the Ubuntu community documentation ApacheMySQLPHP topic .
Option : Complete this tutorial using automation To complete this tutorial using AWS Systems Manager Automation instead of the following tasks , run the AWSDocs-InstallALAMPServer-AL Automation document .
To install and start the LAMP web server with the Amazon Linux AMI 1 .
To ensure that all of your software packages are up to date , perform a quick software update on your instance .
This process may take a few minutes , but it is important to make sure that you have the latest security updates and bug ﬁxes .
The -y option installs the updates without asking for conﬁrmation .
If you would like to examine the updates before installing , you can omit this option .
Now that your instance is current , you can install the Apache web server , MySQL , and PHP software packages .
44 Amazon Elastic Compute Cloud User Guide for Linux Instances Step 1 : Prepare the LAMP Server Note Some applications may not be compatible with the following recommended software environment .
Before installing these packages , check whether your LAMP applications are compatible with them .
If there is a problem , you may need to install an alternative environment .
For more information , see The application software I want to run on my server is incompatible with the installed PHP version or other software ( p. 53 ) Use the yum install command to install multiple software packages and all related dependencies at the same time .
You can view your version of Amazon Linux with the following command .
[ OK ] Use the chkconﬁg command to conﬁgure the Apache web server to start at each system boot .
Add a security rule to allow inbound HTTP ( port 80 ) connections to your instance if you have not already done so .
This group contains a single rule to allow SSH connections .
Choose Instances and select your instance .
If there is no content in /var/www/html , you should see the Apache test page .
If you are unable to see the Apache test page , check that the security group you are using contains a rule to allow HTTP ( port 80 ) traﬃc .
Important If you are not using Amazon Linux , you may also need to conﬁgure the ﬁrewall on your instance to allow these connections .
For more information about how to conﬁgure the ﬁrewall , see the documentation for your speciﬁc distribution .
Note This test page appears only when there is no content in /var/www/html .
When you add content to the document root , your content appears at the public DNS address of your instance instead of this test page .
46 Amazon Elastic Compute Cloud User Guide for Linux Instances Step 1 : Prepare the LAMP Server Apache httpd serves ﬁles that are kept in a directory called the Apache document root .
The Amazon Linux Apache document root is /var/www/html , which by default is owned by root .
There are many ways to accomplish this task .
In this tutorial , you add ec2user to the apache group , to give the apache group ownership of the /var/www directory and assign write permissions to the group .
Log out and then log back in again to pick up the new group , and then verify your membership .
Change the group ownership of /var/www and its contents to the apache group .
To add group write permissions and to set the group ID on future subdirectories , change the directory permissions of /var/www and its subdirectories .
( Optional ) Secure your web server A web server running the HTTP protocol provides no transport security for the data that it sends or receives .
When you connect to an HTTP server using a web browser , the URLs that you visit , the content 47 Amazon Elastic Compute Cloud User Guide for Linux Instances Step 2 : Test Your Lamp Server of webpages that you receive , and the contents ( including passwords ) of any HTML forms that you submit are all visible to eavesdroppers anywhere along the network pathway .
The best practice for securing your web server is to install support for HTTPS ( HTTP Secure ) , which protects your data with SSL/TLS encryption .
Step 2 : Test Your Lamp Server If your server is installed and running , and your ﬁle permissions are set correctly , your ec2-user account should be able to create a PHP ﬁle in the /var/www/html directory that is available from the internet .
In a web browser , type the URL of the ﬁle that you just created .
This URL is the public DNS address of your instance followed by a forward slash and the ﬁle name .
For example : http : //my.public.dns.amazonaws.com/phpinfo.php You should see the PHP information page : 48 Amazon Elastic Compute Cloud User Guide for Linux Instances Step 3 : Secure the Database Server If you do not see this page , verify that the /var/www/html/phpinfo.php ﬁle was created properly in the previous step .
You can also verify that all of the required packages were installed with the following command .
The package versions in the second column do not need to match this example output .
Although this can be useful information , it should not be broadcast to the internet for security reasons .
[ ec2-user ~ ] $ rm /var/www/html/phpinfo.php Step 3 : Secure the Database Server The default installation of the MySQL server has several features that are great for testing and development , but they should be disabled or removed for production servers .
The mysql_secure_installation command walks you through the process of setting a root password and removing the insecure features from your installation .
Even if you are not planning on using the MySQL server , we recommend performing this procedure .
PLEASE REMEMBER TO SET A PASSWORD FOR THE MySQL root USER !
Make sure to store this password in a safe place .
Note Setting a root password for MySQL is only the most basic measure for securing your database .
When you build or install a database-driven application , you typically create a database service user for that application and avoid using the root account for anything but database administration .
( Optional ) If you do not plan to use the MySQL server right away , stop it .
You can restart it when you need it again .
If you add content to the Apache document root at /var/www/html , you should be able to view that content at the public DNS address for your instance .
Follow the steps below to install and conﬁgure phpMyAdmin on your Amazon Linux instance .
Important We do not recommend using phpMyAdmin to access a LAMP server unless you have enabled SSL/TLS in Apache ; otherwise , your database administrator password and other data are transmitted insecurely across the internet .
For security recommendations from the developers , see Securing your phpMyAdmin installation .
Note The Amazon Linux package management system does not currently support the automatic installation of phpMyAdmin in a PHP 7 environment .
This tutorial describes how to install phpMyAdmin manually .
Create a phpMyAdmin folder and extract the package into it using the following command .
This URL is the public DNS address ( or the public IP address ) of your instance followed by a forward slash and the name of your installation directory .
Log in to your phpMyAdmin installation with the root user name and the MySQL root password you created earlier .
Your installation must still be conﬁgured before you put it into service .
For information about using phpMyAdmin , see the phpMyAdmin User Guide .
52 Amazon Elastic Compute Cloud User Guide for Linux Instances Troubleshooting Troubleshooting This section oﬀers suggestions for resolving common problems you may encounter while setting up a new LAMP server .
Perform the following checks to see if your Apache web server is running and accessible .
If you are unable to see the Apache test page , check that the security group you are using contains a rule to allow HTTP ( port 80 ) traﬃc .
The application software I want to run on my server is incompatible with the installed PHP version or other software This tutorial recommends installing the most up-to-date versions of Apache HTTP Server , PHP , and MySQL .
Before installing an additional LAMP application , check its requirements to conﬁrm that it is compatible with your installed environment .
If the latest version of PHP is not supported , it is possible ( and entirely safe ) to downgrade to an earlier supported conﬁguration .
You can also install more than one version of PHP in parallel , which solves certain compatibility problems with a minimum of eﬀort .
For information about conﬁguring a preference among multiple installed PHP versions , see Amazon Linux AMI 2016.09 Release Notes .
Tutorial : Hosting a WordPress Blog with Amazon Linux The following procedures will help you install , conﬁgure , and secure a WordPress blog on your Amazon Linux instance .
This tutorial is a good introduction to using Amazon EC2 in that you have full control over a web server that hosts your WordPress blog , which is not typical with a traditional hosting service .
You are responsible for updating the software packages and maintaining security patches for your server .
For a more automated WordPress installation that does not require direct interaction with the web server conﬁguration , the AWS CloudFormation service provides a WordPress template that can also get you started quickly .
For more information , see Getting Started in the AWS CloudFormation User Guide .
If you 'd prefer to host your WordPress blog on a Windows instance , see Deploying a WordPress Blog on Your Amazon EC2 Windows Instance in the Amazon EC2 User Guide for Windows Instances .
Important These procedures are intended for use with Amazon Linux .
For more information about other distributions , see their speciﬁc documentation .
Many steps in this tutorial do not work on 54 Amazon Elastic Compute Cloud User Guide for Linux Instances Prerequisites Ubuntu instances .
For help installing WordPress on an Ubuntu instance , see WordPress in the Ubuntu documentation .
Prerequisites This tutorial assumes that you have launched an Amazon Linux instance with a functional web server with PHP and database ( either MySQL or MariaDB ) support by following all of the steps in Tutorial : Install a LAMP Web Server with the Amazon Linux AMI ( p. 44 ) for Amazon Linux AMI or Tutorial : Install a LAMP Web Server on Amazon Linux 2 ( p. 34 ) for Amazon Linux 2 .
This tutorial also has steps for conﬁguring a security group to allow HTTP and HTTPS traﬃc , as well as several steps to ensure that ﬁle permissions are set properly for your web server .
We strongly recommend that you associate an Elastic IP address ( EIP ) to the instance you are using to host a WordPress blog .
This prevents the public DNS address for your instance from changing and breaking your installation .
If you own a domain name and you want to use it for your blog , you can update the DNS record for the domain name to point to your EIP address ( for help with this , contact your domain name registrar ) .
You can have one EIP address associated with a running instance at no charge .
If you do n't already have a domain name for your blog , you can register a domain name with Route 53 and associate your instance 's EIP address with your domain name .
For more information , see Registering Domain Names Using Amazon Route 53 in the Amazon Route 53 Developer Guide .
Install WordPress Connect to your instance , and download the WordPress installation package .
Download the latest WordPress installation package with the wget command .
The following command should always download the latest release .
Unzip and unarchive the installation package .
The installation folder is unzipped to a folder called wordpress .
This procedure helps you create your blog 's database and a user that is authorized to read and save information to it .
Log in to the database server as the root user .
Enter your database root password when prompted ; this may be diﬀerent than your root system password , or it may even be empty if you have not secured your database server .
If you have not secured your database server yet , it is important that you do so .
Your WordPress installation uses these values to communicate with your MySQL database .
Make sure that you create a strong password for your user .
Do not reuse an existing password , and make sure to store this password in a safe place .
Note The punctuation marks surrounding the database name in the command below are called backticks .
Backticks are not always required , but they allow you to use otherwise illegal characters , such as hyphens , in database names .
Grant full privileges for your database to the WordPress user that you created earlier .
Flush the database privileges to pick up all of your changes .
exit To create and edit the wp-conﬁg.php ﬁle The WordPress installation folder contains a sample conﬁguration ﬁle called wp-config-sample.php .
In this procedure , you copy this ﬁle and edit it to ﬁt your speciﬁc conﬁguration .
This creates a new conﬁguration ﬁle and keeps the original sample ﬁle intact as a backup .
Edit the wp-config.php ﬁle with your favorite text editor ( such as nano or vim ) and enter values for your installation .
If you do not have a favorite text editor , nano is suitable for beginners .
These KEY and SALT values provide a layer of encryption to the browser cookies that WordPress users store on their local machines .
Visit https : //api.wordpress.org/secret-key/1.1/salt/ to randomly generate a set of key values that you can copy and paste into your wp-config.php ﬁle .
To paste text into a PuTTY terminal , place the cursor where you want to paste the text and right-click your mouse inside the PuTTY terminal .
Note The values below are for example purposes only ; do not use these values for your installation .
57 Amazon Elastic Compute Cloud User Guide for Linux Instances Install WordPress To install your WordPress ﬁles under the Apache document root • Now that you 've unzipped the installation folder , created a MySQL database and user , and customized the WordPress conﬁguration ﬁle , you are ready to copy your installation ﬁles to your web server document root so you can run the installation script that completes your installation .
The location of these ﬁles depends on whether you want your WordPress blog to be available at the actual root of your web server ( for example , my.public.dns.amazonaws.com ) or in a subdirectory or folder under the root ( for example , my.public.dns.amazonaws.com/blog ) .
After you move your installation under the Apache document root , the WordPress installation script is unprotected and an attacker could gain access to your blog if the Apache web server were running .
To stop the Apache web server , enter the command sudo service httpd stop .
If you are moving on to the next procedure , you do not need to stop the Apache web server .
To allow WordPress to use permalinks WordPress permalinks need to use Apache .htaccess ﬁles to work properly , but this is not enabled by default on Amazon Linux .
Use this procedure to allow all overrides in the Apache document root .
If you do not have a favorite text editor , nano is suitable for beginners .
Change the AllowOverride None line in the above section to read AllowOverride All .
Save the ﬁle and exit your text editor .
To install the PHP graphics drawing library The GD library for PHP enables you to modify images .
Install this library as follows if you need to crop the header image for your blog .
[ ec2-user ~ ] $ sudo yum install php72-gd To ﬁx ﬁle permissions for the Apache web server Some of the available features in WordPress require write access to the Apache document root ( such as uploading media though the Administration screens ) .
Grant ﬁle ownership of /var/www and its contents to the apache user .
Grant group ownership of /var/www and its contents to the apache group .
Change the directory permissions of /var/www and its subdirectories to add group write permissions and to set the group ID on future subdirectories .
Recursively change the ﬁle permissions of /var/www and its subdirectories to add group write permissions .
Restart the Apache web server to pick up the new group and permissions .
The commands that you use depend on the operating system .
The commands in this procedure are for use with Amazon Linux 2 .
Use the procedure that follows this one with Amazon Linux AMI .
Use the systemctl command to ensure that the httpd and database services start at every system boot .
Verify that the database server is running .
In a web browser , type the URL of your WordPress blog ( either the public DNS address for your instance , or that address followed by the blog folder ) .
You should see the WordPress installation script .
Provide the information required by the WordPress installation .
Choose Install WordPress to complete the installation .
For more information , see Run the Install Script on the WordPress website .
To run the WordPress installation script with Amazon Linux AMI 1 .
Use the chkconﬁg command to ensure that the httpd and database services start at every system boot .
Verify that the database server is running .
In a web browser , type the URL of your WordPress blog ( either the public DNS address for your instance , or that address followed by the blog folder ) .
You should see the WordPress installation script .
Provide the information required by the WordPress installation .
Choose Install WordPress to complete the installation .
For more information , see Run the Install Script on the WordPress website .
Next Steps After you have tested your WordPress blog , consider updating its conﬁguration .
Use a Custom Domain Name If you have a domain name associated with your EC2 instance 's EIP address , you can conﬁgure your blog to use that name instead of the EC2 public DNS address .
Conﬁgure Your Blog You can conﬁgure your blog to use diﬀerent themes and plugins to oﬀer a more personalized experience for your readers .
However , sometimes the installation process can backﬁre , causing you to lose your entire blog .
We strongly recommend that you create a backup Amazon Machine Image ( AMI ) of your instance before attempting to install any themes or plugins so you can restore your blog if anything goes wrong during installation .
Increase Capacity If your WordPress blog becomes popular and you need more compute power or storage , consider the following steps : • Expand the storage space on your instance .
• Move your MySQL database to Amazon RDS to take advantage of the service 's ability to scale easily .
61 Amazon Elastic Compute Cloud User Guide for Linux Instances Help !
My Public DNS Name Changed and now my Blog is Broken Help !
My Public DNS Name Changed and now my Blog is Broken Your WordPress installation is automatically conﬁgured using the public DNS address for your EC2 instance .
If you stop and restart the instance , the public DNS address changes ( unless it is associated with an Elastic IP address ) and your blog will not work anymore because it references resources at an address that no longer exists ( or is assigned to another EC2 instance ) .
If this has happened to your WordPress installation , you may be able to recover your blog with the procedure below , which uses the wp-cli command line interface for WordPress .
Note the old site URL and the new site URL for your instance .
The old site URL is likely the public DNS name for your EC2 instance when you installed WordPress .
The new site URL is the current public DNS name for your EC2 instance .
If you are not sure of your old site URL , you can use curl to ﬁnd it with the following command .
Search and replace the old site URL in your WordPress installation with the following command .
In a web browser , enter the new site URL of your WordPress blog to verify that the site is working properly again .
This tutorial explains how to add support manually for SSL/TLS on an EC2 instance with Amazon Linux 2 and Apache web server .
62 Amazon Elastic Compute Cloud User Guide for Linux Instances Prerequisites For historical reasons , web encryption is often referred to simply as SSL .
While web browsers still support SSL , its successor protocol TLS is less vulnerable to attack .
Amazon Linux 2 disables serverside support for all versions of SSL by default .
Security standards bodies consider TLS 1.0 to be unsafe , and both TLS 1.0 and TLS 1.1 are on track to be formally deprecated by the IETF .
This tutorial contains guidance based exclusively on enabling TLS 1.2 .
This tutorial refers to modern web encryption simply as TLS .
Important These procedures are intended for use with Amazon Linux 2 .
If you are trying to set up a LAMP web server on an instance with a diﬀerent distribution , or if you are resuing an older , existing instance , some procedures in this tutorial might not work for you .
For information about LAMP web servers on Ubuntu , see the Ubuntu community documentation ApacheMySQLPHP .
For information about Red Hat Enterprise Linux , see the Customer Portal topic Web Servers .
Only the httpd package and its dependencies are needed , so you can ignore the instructions involving PHP and MariaDB .
To use your EC2 instance to host a public website , you need to register a domain name for your web server or transfer an existing domain name to your Amazon EC2 host .
Numerous third-party domain registration and DNS hosting services are available for this , or you can use Amazon Route 53 .
Step 1 : Enable TLS on the Server This procedure takes you through the process of setting up TLS on Amazon Linux 2 with a self-signed digital certiﬁcate .
63 Amazon Elastic Compute Cloud User Guide for Linux Instances Step 1 : Enable TLS on the Server Note A self-signed certiﬁcate is acceptable for testing but not production .
If you expose your selfsigned certiﬁcate to the internet , visitors to your site are greeted by security warnings .
To ensure that all of your software packages are up to date , perform a quick software update on your instance .
This process may take a few minutes , but it is important to make sure that you have the latest security updates and bug ﬁxes .
Note The -y option installs the updates without asking for conﬁrmation .
If you would like to examine the updates before installing , you can omit this option .
Now that your instance is current , add TLS support by installing the Apache module mod_ssl .
It contains directives telling Apache where to ﬁnd encryption keys and certiﬁcates , the TLS protocol versions to allow , and the encryption ciphers to accept .
This certiﬁcate is useful for testing that Apache is properly set up to use TLS .
Because it oﬀers no proof of identity , it should not be used in production .
If used in production , it triggers warnings in Web browsers .
The speciﬁed ﬁle name matches the default that is assigned in the SSLCertiﬁcateFile directive in /etc/httpd/ conf.d/ssl.conf .
Apache requires the certiﬁcate and key to be in PEM format , which consists of Base64-encoded ASCII characters framed by `` BEGIN '' and `` END '' lines , as in the following abbreviated example .
Note When you replace the default TLS ﬁles with your own customized ﬁles , be sure that they are in PEM format .
Open the /etc/httpd/conf.d/ssl.conf ﬁle and comment out the following line , because the self-signed dummy certiﬁcate also contains the key .
If you do not comment out this line before you complete the next step , the Apache service fails to start .
Test it by entering the IP address or fully qualiﬁed domain name of your EC2 instance into a browser URL bar with the preﬁx https : // .
Override the warnings and proceed to the site .
If the default Apache test page opens , it means that you have successfully conﬁgured TLS on your server .
All data passing between the browser and server is now encrypted .
Note To prevent site visitors from encountering warning screens , you must obtain a trusted , CAsigned certiﬁcate that not only encrypts , but also publicly authenticates you as the owner of the site .
Each web browser contains a list of CAs trusted by the browser vendor to do this .
An X.509 certiﬁcate consists primarily of a public key that corresponds to your private server key , and a signature by the CA that is cryptographically tied to the public key .
When a browser connects to a web server over HTTPS , the server presents a certiﬁcate for the browser to check against its list of trusted CAs .
If the signer is on the list , or accessible through a chain of trust consisting of other trusted signers , the browser negotiates a fast encrypted data channel with the server and loads the page .
Certiﬁcates generally cost money because of the labor involved in validating the requests , so it pays to shop around .
The most notable of these CAs is the Let 's Encrypt project , which also supports the automation of the certiﬁcate creation and renewal process .
Underlying the host certiﬁcate is the key .
In the following procedure , an optional step provided for those who want a customized key , for example , one with a larger modulus or using a diﬀerent encryption algorithm .
These instructions for acquiring a CA-signed host certiﬁcate do not work unless you own a registered and hosted DNS domain .
This is the directory where you store the server 's private key for TLS .
If you prefer to use an existing host key to generate the CSR , skip to Step 3 .
Here are some examples of key conﬁgurations .
Any of the resulting keys works with your web server , but they vary in the degree and type of security that they implement .
66 Amazon Elastic Compute Cloud User Guide for Linux Instances Step 2 : Obtain a CA-signed Certiﬁcate Important Encrypting the key provides greater security , but because an encrypted key requires a password , services depending on it can not be auto-started .
RSA cryptography can be relatively slow because of the size of its public keys , which are based on the product of two large prime numbers .
However , it is possible to create keys for TLS that use non-RSA ciphers .
Keys based on the mathematics of elliptic curves are smaller and computationally faster when delivering an equivalent level of security .
Note Not all CAs provide the same level of support for elliptic-curve-based keys as for RSA keys .
The commands would be as shown in the following example .
Name Description Example Country Name The two-letter ISO abbreviation for your country .
US ( =United States ) State or Province Name The name of the state or province where your organization is located .
This name can not be abbreviated .
Seattle Organization Name The full legal name of your organization .
Do not abbreviate your organization name .
Unit Name Example Dept Common Name This value must exactly match the web address that you expect users to enter into a browser .
In testing with a self-signed certiﬁcate and no DNS resolution , the common name may consist of the hostname alone .
This password applies only to the CSR and to transactions between you and your CA , so follow the CA 's recommendations about this and the other optional ﬁeld , optional company name .
The CSR challenge password has no eﬀect on server operation .
The resulting ﬁle csr.pem contains your public key , your digital signature of your public key , and the metadata that you entered .
This usually consists of opening your CSR ﬁle in a text editor and copying the contents into a web form .
At this time , you may be asked to supply one or more subject alternate names ( SANs ) to be placed on the certiﬁcate .
A visitor to your site entering either of these names would see an error-free connection .
If your CA web form allows it , include the common name in the list of SANs .
After your request has been approved , you receive a new host certiﬁcate signed by the CA .
You might also be instructed to download an intermediate certiﬁcate ﬁle that contains additional certiﬁcates needed to complete the CA 's chain of trust .
Note Your CA might send you ﬁles in multiple formats intended for various purposes .
If you are uncertain which ﬁle to use , open the ﬁles with a text editor and ﬁnd the one containing one or more blocks beginning with the following line .
Note There are several ways to upload your new certiﬁcate to your EC2 instance , but the most straightforward and informative way is to open a text editor ( for example , vi , nano , or notepad ) on both your local computer and your instance , and then copy and paste the ﬁle contents between them .
This way , you can see immediately if there are any permission or path problems .
Be careful , however , not to add any additional lines while copying the contents , or to change them in any way .
The following example shows the commands to use .
The following example shows the commands to use .
Place the private key that you used to create the CSR in the /etc/pki/tls/private/ directory .
Note There are several ways to upload your custom key to your EC2 instance , but the most straightforward and informative way is to open a text editor ( for example , vi , nano , or notepad ) on both your local computer and your instance , and then copy and paste the ﬁle contents between them .
This way , you can see immediately if there are any permission or path problems .
Be careful , however , not to add any additional lines while copying the contents , or to change them in any way .
Edit /etc/httpd/conf.d/ssl.conf to reﬂect your new certiﬁcate and key ﬁles .
If you received an intermediate certiﬁcate ﬁle ( intermediate.crt in this example ) , provide its path and ﬁle name using Apache 's SSLCACertificateFile directive : SSLCACertificateFile /etc/pki/tls/certs/intermediate.crt Note c. Some CAs combine the host certiﬁcate and the intermediate certiﬁcates in a single ﬁle , making the SSLCACertificateFile directive unnecessary .
Consult the instructions provided by your CA .
Test your server by entering your domain name into a browser URL bar with the preﬁx https : // .
Your browser should load the test page over HTTPS without generating errors .
Step 3 : Test and Harden the Security Conﬁguration After your TLS is operational and exposed to the public , you should test how secure it really is .
This is easy to do using online services such as Qualys SSL Labs , which performs a free and thorough analysis of your security setup .
Based on the results , you may decide to harden the default security conﬁguration by controlling which protocols you accept , which ciphers you prefer , and which you exclude .
For more information , see how Qualys formulates its scores .
Important Real-world testing is crucial to the security of your server .
Small conﬁguration errors may lead to serious security breaches and loss of data .
Because recommended security practices change constantly in response to research and emerging threats , periodic security audits are essential to good server administration .
On the Qualys SSL Labs site , enter the fully qualiﬁed domain name of your server , in the form www.example.com .
The following table summarizes the report for a domain with settings identical to the default Apache conﬁguration on Amazon Linux 2 , and with a default Certbot certiﬁcate .
70 Amazon Elastic Compute Cloud User Guide for Linux Instances Step 3 : Test and Harden the Security Conﬁguration Overall rating B Certiﬁcate 100 % Protocol support 95 % Key exchange 70 % Cipher strength 90 % Though the overview shows that the conﬁguration is mostly sound , the detailed report ﬂags several potential problems , listed here in order of severity : ✗ The RC4 cipher is supported for use by certain older browsers .
A cipher is the mathematical core of an encryption algorithm .
Unless you have very good reasons to support legacy browsers , you should disable this .
Forward secrecy is a feature of algorithms that encrypt using temporary ( ephemeral ) session keys derived from the private key .
This means in practice that attackers can not decrypt HTTPS data even if they possess a web server 's long-term private key .
Open the conﬁguration ﬁle /etc/httpd/conf.d/ssl.conf in a text editor and comment out the following line by entering `` # '' at the beginning of the line .
The server now refuses to accept encrypted connections with clients using anything except TLS 1.2 .
The verbose wording in the directive conveys more clearly , to a human reader , what the server is conﬁgured to do .
Note Disabling TLS versions 1.0 and 1.1 in this manner blocks a small percentage of outdated web browsers from accessing your site .
In the conﬁguration ﬁle /etc/httpd/conf.d/ssl.conf , ﬁnd the section with the SSLCipherSuite directive and comment out the existing line by entering `` # '' at the beginning of the line .
Specify explicit cipher suites and a cipher order that prioritizes forward secrecy and avoids insecure ciphers .
The SSLCipherSuite directive used here is based on output from the Mozilla SSL 71 Amazon Elastic Compute Cloud User Guide for Linux Instances Step 3 : Test and Harden the Security Conﬁguration Conﬁguration Generator , which tailors a TLS conﬁguration to the speciﬁc software running on your server .
First determine your Apache and OpenSSL versions by using the output from the following commands .
If you choose the `` modern '' compatibility model , this creates an SSLCipherSuite directive that aggressively enforces security but still works for most browsers .
If your software does n't support the modern conﬁguration , you can update your software or choose the '' intermediate '' conﬁguration instead .
The term ephemeral indicates forward secrecy .
We recommend that you use an explicit list of ciphers instead of relying on defaults or terse directives whose content is n't visible .
Note Though shown here on several lines for readability , the directive must be on a single line when copied to /etc/httpd/conf.d/ssl.conf , with only a colon ( no spaces ) between cipher names .
With this directive turned on , the server tries to establish a strong secure connection before falling back to allowed ciphers with lesser security .
After completing both of these procedures , save the changes to /etc/httpd/conf.d/ssl.conf and restart Apache .
If you test the domain again on Qualys SSL Labs , you should see that the RC4 vulnerability and other warnings are gone and the summary looks something like the following .
Keep your EC2 Amazon Linux 2 instance up-to-date , watch for security announcements from OpenSSL , and be alert to reports of new security exploits in the technical press .
For more information , see Predeﬁned SSL Security Policies for Elastic Load Balancing in the User Guide for Classic Load Balancers .
You can remove the encryption and password requirement from the key .
Assuming that you have a private encrypted RSA key called custom.key in the default directory , and that the password on it is abcde12345 , run the following commands on your EC2 instance to generate an unencrypted version of the key .
When you are installing the required packages for SSL , you may see errors similar to the following .
This tutorial only supports instances freshly created from an oﬃcial Amazon Linux 2 AMI .
Certiﬁcate Automation : Let 's Encrypt with Certbot on Amazon Linux 2 The Let 's Encrypt certiﬁcate authority is the centerpiece of an eﬀort by the Electronic Frontier Foundation ( EFF ) to encrypt the entire internet .
In line with that goal , Let 's Encrypt host certiﬁcates are designed to be created , validated , installed , and maintained with minimal human intervention .
The automated aspects of certiﬁcate management are carried out by a software agent running on your web server .
After you install and conﬁgure the agent , it communicates securely with Let 's Encrypt and performs administrative tasks on Apache and the key management system .
This tutorial uses the free Certbot agent because it allows you either to supply a customized encryption key as the basis for your certiﬁcates , or to allow the agent itself to create a key based on its defaults .
For more information , consult the Certbot User Guide and man page .
Certbot is not oﬃcially supported on Amazon Linux 2 , but is available for download and functions correctly when installed .
We recommend that you make the following backups to protect your data and avoid inconvenience : 73 Amazon Elastic Compute Cloud User Guide for Linux Instances Certiﬁcate Automation : Let 's Encrypt with Certbot on Amazon Linux 2 • Before you begin , take a snapshot of your Amazon EBS root volume .
This allows you to restore the original state of your EC2 instance .
Certbot makes its own automated changes to this and other conﬁguration ﬁles .
Make a backup copy of your entire /etc/httpd directory in case you need to restore it .
Prepare to Install Complete the following procedures before you install Certbot .
These are required to supply dependencies needed by Certbot .
Download EPEL with the following command .
Install the repository packages as shown in the following command .
It should return information similar to the following .
Locate the `` Listen 80 '' directive and add the following lines after it , replacing the example domain names with the actual Common Name and Subject Alternative Name ( SAN ) .
[ ec2-user ~ ] $ sudo systemctl restart httpd Install and Run Certbot This procedure is based on the EFF documentation for installing Certbot on Fedora and on RHEL 7 .
Install Certbot packages and dependencies using the following command .
Agree to the Let 's Encrypt Terms of Service at the prompt .
Certbot displays the Common Name and Subject Alternative Name ( SAN ) that you provided in the VirtualHost block .
Which names would you like to activate HTTPS for ?
Certbot displays the following output as it creates certiﬁcates and conﬁgures Apache .
It then prompts you about redirecting HTTP queries to HTTPS .
Cleaning up challenges Created an SSL vhost at /etc/httpd/conf/httpd-le-ssl.conf Deploying Certificate for example.com to VirtualHost /etc/httpd/conf/httpd-le-ssl.conf Enabling site /etc/httpd/conf/httpd-le-ssl.conf by adding Include to root configuration 75 Amazon Elastic Compute Cloud User Guide for Linux Instances Certiﬁcate Automation : Let 's Encrypt with Certbot on Amazon Linux 2 Deploying Certificate for www.example.com to VirtualHost /etc/httpd/conf/httpd-lessl.conf Please choose whether or not to redirect HTTP traffic to HTTPS , removing HTTP access .
Choose this for new sites , or if you 're confident your site works on HTTPS .
You can undo this change by editing your web server 's configuration .
Press Enter to submit your choice .
Certbot completes the conﬁguration of Apache and reports success and other information .
To obtain a new or tweaked version of this certificate in the future , simply run certbot again with the `` certonly '' option .
You should make a secure backup of this folder now .
This configuration directory will also contain certificates and private keys obtained by Certbot so making regular backups of this folder is ideal .
Conﬁgure Automated Certiﬁcate Renewal Certbot is designed to become an invisible , error-resistant part of your server system .
If you have not conﬁgured your system to call the command automatically , you must re-run the certbot command manually before expiration .
This procedure shows how to automate Certbot by setting up a cron job .
Here is an explanation of each component of the command .
The selected values are arbitrary , but the Certbot developers suggest running the command at least twice daily .
This guarantees that any certiﬁcate found to be compromised is promptly revoked and replaced .
root The command runs with root permissions .
The renew subcommand causes Certbot to check any previously obtained certiﬁcates and to renew those that are approaching expiration .
This tutorial explains how to add support manually for SSL/TLS on an EC2 instance with the Amazon Linux AMI and Apache web server .
For historical reasons , web encryption is often referred to simply as SSL .
While web browsers still support SSL , its successor protocol TLS is less vulnerable to attack .
The Amazon Linux AMI disables server-side support all versions of SSL by default .
Security standards bodies consider TLS 1.0 to be unsafe , and both TLS 1.0 and TLS 1.1 are on track to be formally deprecated by the IETF .
This tutorial contains guidance based exclusively on enabling TLS 1.2 .
This tutorial refers to modern web encryption simply as TLS .
Important These procedures are intended for use with the Amazon Linux AMI .
If you are trying to set up a LAMP web server on an instance with a diﬀerent distribution , some procedures in this tutorial might not work for you .
For information about LAMP web servers on Ubuntu , see the Ubuntu community documentation ApacheMySQLPHP .
For information about Red Hat Enterprise Linux , see the Customer Portal documentation Web Servers .
Only the http24 package and its dependencies are needed ; you can ignore the instructions involving PHP and MySQL .
To use your EC2 instance to host a public web site , you need to register a domain name for your web server or transfer an existing domain name to your Amazon EC2 host .
Numerous third-party domain registration and DNS hosting services are available for this , or you can use Amazon Route 53 .
Step 1 : Enable TLS on the Server This procedure takes you through the process of setting up TLS on Amazon Linux with a self-signed digital certiﬁcate .
If you expose your selfsigned certiﬁcate to the internet , visitors to your site receive security warnings .
To ensure that all of your software packages are up to date , perform a quick software update on your instance .
This process may take a few minutes , but it is important to make sure you have the latest security updates and bug ﬁxes .
Note The -y option installs the updates without asking for conﬁrmation .
If you would like to examine the updates before installing , you can omit this option .
It contains `` directives '' telling Apache where to ﬁnd encryption keys and certiﬁcates , the TLS protocol versions to allow , and the encryption ciphers to accept .
This certiﬁcate is useful for testing that Apache is properly set up to use TLS .
Note When you replace the default TLS ﬁles with your own customized ﬁles , be sure that they are in PEM format .
Test it by typing the IP address or fully qualiﬁed domain name of your EC2 instance into a browser URL bar with the preﬁx https : // .
Override the warnings and proceed to the site .
If the default Apache test page opens , it means that you have successfully conﬁgured TLS on your server .
All data passing between the browser and server is now safely encrypted .
To prevent site visitors from encountering warning screens , you need to obtain a certiﬁcate that not only encrypts , but also publicly authenticates you as the owner of the site .
Each web browser contains a list of CAs trusted by the browser vendor to do this .
An X.509 certiﬁcate consists primarily of a public key that corresponds to your private server key , and a signature by the CA that is cryptographically tied to the public key .
When a browser connects to a web server over HTTPS , the server presents a certiﬁcate for the browser to check against its list of trusted CAs .
If the signer is on the list , or accessible through a chain of trust consisting of other trusted signers , the browser negotiates a fast encrypted data channel with the server and loads the page .
Certiﬁcates generally cost money because of the labor involved in validating the requests , so it pays to shop around .
The most notable of these is the Let 's Encrypt project , which also supports automation of the certiﬁcate creation and renewal process .
Underlying the host certiﬁcate is the key .
The default modulus size generated by OpenSSL in Amazon Linux is 2048 bits , which means that the existing auto-generated key is suitable for use in a CA-signed certiﬁcate .
An alternative procedure is described below for those who desire a customized key , for instance , one with a larger modulus or using a diﬀerent encryption algorithm .
These instructions for acquiring a CA-signed host certiﬁcate do not work unless you own a registered and hosted DNS domain .
This is the directory where the server 's private key for TLS is stored .
If you prefer to use your existing host key to generate the CSR , skip to Step 3 .
Here are some examples of key conﬁgurations .
Any of the resulting keys work with your web server , but they vary in how ( and how much ) security they implement .
80 Amazon Elastic Compute Cloud User Guide for Linux Instances Step 2 : Obtain a CA-signed Certiﬁcate Important Encrypting the key provides greater security , but because an encrypted key requires a password , services depending on it can not be auto-started .
RSA cryptography can be relatively slow because of the size of its public keys , which are based on the product of two large prime numbers .
However , it is possible to create keys for TLS that use non-RSA ciphers .
Keys based on the mathematics of elliptic curves are smaller and computationally faster when delivering an equivalent level of security .
Note Not all CAs provide the same level of support for elliptic-curve-based keys as for RSA keys .
Name Description Example Country Name The two-letter ISO abbreviation for your country .
US ( =United States ) State or Province Name The name of the state or province where your organization is located .
This name can not be abbreviated .
Seattle 81 Amazon Elastic Compute Cloud User Guide for Linux Instances Step 2 : Obtain a CA-signed Certiﬁcate Name Description Example Organization Name The full legal name of your organization .
Do not abbreviate your organization name .
Unit Name Example Dept Common Name This value must exactly match the web address that you expect users to type into a browser .
In testing with a selfsigned certiﬁcate and no DNS resolution , the common name may consist of the host name alone .
This password applies only to the CSR and to transactions between you and your CA , so follow the CA 's recommendations about this and the other optional ﬁeld , optional company name .
The CSR challenge password has no eﬀect on server operation .
The resulting ﬁle csr.pem contains your public key , your digital signature of your public key , and the metadata that you entered .
This usually consists of opening your CSR ﬁle in a text editor and copying the contents into a web form .
At this time , you may be asked to supply one or more subject alternate names ( SANs ) to be placed on the certiﬁcate .
A visitor to your site typing in either of these names would see an error-free connection .
If your CA web form allows it , include the common name in the list of SANs .
After your request has been approved , you receive a new host certiﬁcate signed by the CA .
You might also be instructed to download an intermediate certiﬁcate ﬁle that contains additional certiﬁcates needed to complete the CA 's chain of trust .
Note Your CA may send you ﬁles in multiple formats intended for various purposes .
Note There are several ways to upload your custom key to your EC2 instance , but the most straightforward and informative way is to open a text editor ( for example , vi , nano , or notepad ) on both your local computer and your instance , and then copy and paste the ﬁle contents between them .
This way , you can see immediately if there are any permission or path problems .
Be careful , however , not to add any additional lines while copying the contents , or to change them in any way .
If you used a custom key to create your CSR and the resulting host certiﬁcate , remove or rename the old key from the /etc/pki/tls/private/ directory , and then install the new key there .
on both your local computer and your instance , and then copy and paste the ﬁle contents between them .
This way , you can see immediately if there are any permission or path problems .
Be careful , however , not to add any additional lines while copying the contents , or to change them in any way .
Edit /etc/httpd/conf.d/ssl.conf to reﬂect your new certiﬁcate and key ﬁles .
If you received an intermediate certiﬁcate ﬁle ( intermediate.crt in this example ) , provide its path and ﬁle name using Apache 's SSLCACertificateFile directive : SSLCACertificateFile /etc/pki/tls/certs/intermediate.crt Note Some CAs combine the host certiﬁcate and the intermediate certiﬁcates in a single ﬁle , making this directive unnecessary .
Consult the instructions provided by your CA .
Test your server by entering your domain name into a browser URL bar with the preﬁx https : // .
Your browser should load the test page over HTTPS without generating errors .
Step 3 : Test and Harden the Security Conﬁguration After your TLS is operational and exposed to the public , you should test how secure it really is .
This is easy to do using online services such as Qualys SSL Labs , which performs a free and thorough analysis of your security setup .
Based on the results , you may decide to harden the default security conﬁguration by controlling which protocols you accept , which ciphers you prefer , and which you exclude .
For more information , see how Qualys formulates its scores .
Important Real-world testing is crucial to the security of your server .
Small conﬁguration errors may lead to serious security breaches and loss of data .
Because recommended security practices change constantly in response to research and emerging threats , periodic security audits are essential to good server administration .
On the Qualys SSL Labs site , type the fully qualiﬁed domain name of your server , in the form www.example.com .
Though the overview shows that the conﬁguration is mostly sound , the detailed report ﬂags several potential problems .
A cipher is the mathematical core of an encryption algorithm .
Unless you have very good reasons to support legacy browsers , you should disable this .
84 Amazon Elastic Compute Cloud User Guide for Linux Instances Step 3 : Test and Harden the Security Conﬁguration ✗ Old TLS versions are supported .
The server now refuses to accept encrypted connections with clients using anything except TLS 1.2 .
The verbose wording in the directive communicates more clearly , to a human reader , what the server is conﬁgured to do .
Note Disabling TLS versions 1.0 and 1.1 in this manner blocks a small percentage of outdated web browsers from accessing your site .
Open the conﬁguration ﬁle /etc/httpd/conf.d/ssl.conf and ﬁnd the section with commented-out examples for conﬁguring SSLCipherSuite and SSLProxyCipherSuite .
They were selected and ordered according to the following criteria : 85 Amazon Elastic Compute Cloud User Guide for Linux Instances Troubleshooting • Support for forward secrecy • Strength • Speed • Speciﬁc ciphers before cipher families • Allowed ciphers before denied ciphers Note that the high-ranking ciphers have ECDHE in their names , for Elliptic Curve Diﬃe-Hellman Ephemeral ; the ephemeral indicates forward secrecy .
We recommend that you use an explicit list of ciphers instead relying on defaults or terse directives whose content is n't visible .
Important The cipher list shown here is just one of many possible lists ; for instance , you might want to optimize a list for speed rather than forward secrecy .
Finally , each update to OpenSSL introduces new ciphers and deprecates old ones .
Keep your EC2 Amazon Linux instance up to date , watch for security announcements from OpenSSL , and be alert to reports of new security exploits in the technical press .
For more information , see Predeﬁned SSL Security Policies for Elastic Load Balancing in the User Guide for Classic Load Balancers .
With this directive turned on , the server tries to establish a strongly secure connection before falling back to allowed ciphers with lesser security .
If you test the domain again on Qualys SSL Labs , you should see that the RC4 vulnerability is gone .
You can remove the encryption and password requirement from the key .
Assuming that you have a private encrypted RSA key called custom.key in the default directory , and that the password on it is abcde12345 , run the following commands on your EC2 instance to generate an unencrypted version of the key .
Certiﬁcate Automation : Let 's Encrypt with Certbot on Amazon Linux The Let 's Encrypt certiﬁcate authority is the centerpiece of the Electronic Frontier Foundation ( EFF ) eﬀort to encrypt the entire internet .
In line with that goal , Let 's Encrypt host certiﬁcates are designed to be created , validated , installed , and maintained with minimal human intervention .
The automated aspects of certiﬁcate management are carried out by an agent running on the web server .
After you install and conﬁgure the agent , it communicates securely with Let 's Encrypt and performs administrative tasks on Apache and the key management system .
This tutorial uses the free Certbot agent because it allows you either to supply a customized encryption key as the basis for your certiﬁcates , or to allow the agent itself to create a key based on its defaults .
For more information , consult the Certbot User Guide or man page .
Certbot is not oﬃcially supported on Amazon Linux AMI , but is available for download and functions correctly when installed .
We recommend that you make the following backups to protect your data and avoid inconvenience : • Before you begin , take a snapshot of your Amazon EBS root volume .
This allows you to restore the original state of your EC2 instance .
Certbot makes its own automated changes to this and other conﬁguration ﬁles .
Make a backup copy of your entire /etc/httpd directory in case you need to restore it .
Enable the Extra Packages for Enterprise Linux ( EPEL ) repository from the Fedora project on your instance .
Packages from EPEL are required as dependencies when you run the Certbot installation script .
Download the latest release of Certbot from EFF onto your EC2 instance using the following command .
Run the ﬁle with root permissions and the -- debug ﬂag .
Agree to the Let 's Encrypt Terms of Service at the prompt .
At the prompt shown below , type your Common Name ( the name of your domain as described above ) and your Subject Alternative Name ( SAN ) , separating the two names with a space or a comma .
In this example , the names have been provided : No names were found in your configuration files .
On an Amazon Linux system with a default Apache conﬁguration , you see output similar to the example below , asking about the ﬁrst name you provided .
Which virtual host would you like to choose ?
Which virtual host would you like to choose ?
Authorize Certbot to create and all needed host certiﬁcates .
Which virtual host would you like to choose ?
Which virtual host would you like to choose ?
Choose whether to allow insecure connections to your web server .
If you choose option 2 ( as shown in the example ) , all connections to your server will either be encrypted or rejected .
Please choose whether HTTPS access is required or optional .
Certbot is designed to become an invisible , error-resistant part of your server system .
If you have not previously conﬁgured your system to call the command automatically , you must re-run the certbot command manually .
This procedure shows how to automate Certbot by setting up a cron job .
The selected values are arbitrary , but the Certbot developers suggest running the command at least twice daily .
This guarantees that any certiﬁcate found to be compromised is promptly revoked and replaced .
root The command runs with root privileges .
The renew subcommand causes Certbot to check any previously obtained certiﬁcates and to renew those that are approaching expiration .
Restart the cron daemon : [ ec2-user ~ ] $ sudo service crond restart Tutorial : Increase the Availability of Your Application on Amazon EC2 Suppose that you start out running your app or website on a single EC2 instance , and over time , traﬃc increases to the point that you require more than one instance to meet the demand .
You can launch multiple EC2 instances from your AMI and then use Elastic Load Balancing to distribute incoming traﬃc for your application across these EC2 instances .
This increases the availability of your application .
Placing your instances in multiple Availability Zones also improves the fault tolerance in your application .
If one Availability Zone experiences an outage , traﬃc is routed to the other Availability Zone .
You can use Amazon EC2 Auto Scaling to maintain a minimum number of running instances for your application at all times .
Amazon EC2 Auto Scaling can detect when your instance or application is unhealthy and replace it automatically to maintain the availability of your application .
You can also use Amazon EC2 Auto Scaling to scale your Amazon EC2 capacity up or down automatically based on demand , using criteria that you specify .
In this tutorial , we use Amazon EC2 Auto Scaling with Elastic Load Balancing to ensure that you maintain a speciﬁed number of healthy EC2 instances behind your load balancer .
Note that these instances do not need public IP addresses , because traﬃc goes to the load balancer and is then routed to the instances .
Created a virtual private cloud ( VPC ) with one public subnet in two or more Availability Zones .
Launched an instance in the VPC .
Connected to the instance and customized it .
Tested your application on your instance to ensure that your instance is conﬁgured correctly .
Created an IAM role that grants your application the access to AWS it needs .
Scale and Load Balance Your Application Use the following procedure to create a load balancer , create a launch conﬁguration for your instances , create an Auto Scaling group with two or more instances , and associate the load balancer with the Auto Scaling group .
91 Amazon Elastic Compute Cloud User Guide for Linux Instances Scale and Load Balance Your Application To scale and load-balance your application 1 .
Select an Availability Zone and then select the public subnet for that Availability Zone .
Type a name and description for the security group , or keep the default name and description .
This new security group contains a rule that allows traﬃc to the port conﬁgured for the listener .
On the Register Targets page , choose Next : Review to continue to the next page , as we 'll use Amazon EC2 Auto Scaling to add EC2 instances to the target group .
Choose Create Auto Scaling group to start the Create Auto Scaling Group wizard , and then choose Create launch conﬁguration .
On the Choose Instance Type page , select an instance type , and then choose Next : Conﬁgure details .
You can select an existing security group or create a new one .
This security group must allow HTTP traﬃc and health checks from the load 92 Amazon Elastic Compute Cloud User Guide for Linux Instances Test Your Load Balancer balancer .
If your instances will have public IP addresses , you can optionally allow SSH traﬃc if you need to connect to the instances .
Select the acknowledgment check box , and then choose Create launch conﬁguration .
After the launch conﬁguration is created , you must create an Auto Scaling group .
• If you are new to Amazon EC2 Auto Scaling and you are using the Create Auto Scaling group wizard , you are taken to the next step automatically .
Note that we recommend that you maintain approximately the same number of instances in each Availability Zone .
c. Select your VPC from Network and your two public subnets from Subnet .
d. Under Advanced Details , select Receive traﬃc from one or more load balancers .
Select your target group from Target Groups .
On the Conﬁgure scaling policies page , choose Review , as we will let Amazon EC2 Auto Scaling maintain the group at the speciﬁed size .
Note that later on , you can manually scale this Auto Scaling group , conﬁgure the group to scale on a schedule , or conﬁgure the group to scale based on demand .
On the Review page , choose Create Auto Scaling group .
Test Your Load Balancer When a client sends a request to your load balancer , the load balancer routes the request to one of its registered instances .
Verify that your instances are ready .
From the Auto Scaling Groups page , select your Auto Scaling group , and then choose the Instances tab .
When their states are InService , they are ready for use .
Verify that your instances are registered with the load balancer .
From the Target Groups page , select your target group , and then choose the Targets tab .
If the state of your instances is initial , it's possible that they are still registering .
When the state of your instances is healthy , they are ready for use .
After your instances are ready , you can test your load balancer as follows .
From the Load Balancers page , select your load balancer .
In a web browser , paste the DNS name for the load balancer into the address bar and press Enter .
93 Amazon Elastic Compute Cloud User Guide for Linux Instances Using an AMI Amazon Machine Images ( AMI ) An Amazon Machine Image ( AMI ) provides the information required to launch an instance .
You must specify an AMI when you launch an instance .
You can launch multiple instances from a single AMI when you need multiple instances with the same conﬁguration .
You can use diﬀerent AMIs to launch instances when you need instances with diﬀerent conﬁgurations .
• Launch permissions that control which AWS accounts can use the AMI to launch instances .
• A block device mapping that speciﬁes the volumes to attach to the instance when it 's launched .
Using an AMI The following diagram summarizes the AMI lifecycle .
After you create and register an AMI , you can use it to launch new instances .
( You can also launch instances from an AMI if the AMI owner grants you launch permissions . ) .
You can copy an AMI within the same Region or to diﬀerent Regions .
When you no longer require an AMI , you can deregister it .
You can search for an AMI that meets the criteria for your instance .
You can search for AMIs provided by AWS or AMIs provided by the community .
After you launch an instance from an AMI , you can connect to it .
When you are connected to an instance , you can use it just like you use any other server .
Creating your own AMI You can launch an instance from an existing AMI , customize the instance , and then save this updated conﬁguration as a custom AMI .
Instances launched from this new custom AMI include the customizations that you made when you created the AMI .
94 Amazon Elastic Compute Cloud User Guide for Linux Instances Buying , sharing , and selling AMIs The root storage device of the instance determines the process you follow to create an AMI .
The root volume of an instance is either an Amazon EBS volume or an instance store volume .
To help categorize and manage your AMIs , you can assign custom tags to them .
Buying , sharing , and selling AMIs After you create an AMI , you can keep it private so that only you can use it , or you can share it with a speciﬁed list of AWS accounts .
You can also make your custom AMI public so that the community can use it .
You can purchase AMIs from a third party , including AMIs that come with service contracts from organizations such as Red Hat .
You can also create an AMI and sell it to other Amazon EC2 users .
Deregistering your AMI You can deregister an AMI when you have ﬁnished with it .
After you deregister an AMI , it ca n't be used to launch new instances .
Existing instances launched from the AMI are not aﬀected .
Amazon Linux 2 and Amazon Linux AMI Amazon Linux 2 and the Amazon Linux AMI are supported and maintained Linux images provided by AWS .
• Updated on a regular basis to include the latest components , and these updates are also made available in the yum repositories for installation on running instances .
• Includes packages that enable easy integration with AWS services , such as the AWS CLI , Amazon EC2 API and AMI tools , the Boto library for Python , and the Elastic Load Balancing tools .
Launch permissions fall into the following categories .
Launch Permission Description public The owner grants launch permissions to all AWS accounts .
explicit The owner grants launch permissions to speciﬁc AWS accounts .
implicit The owner has implicit launch permissions for an AMI .
Developers can charge for their AMIs .
Storage for the root device All AMIs are categorized as either backed by Amazon EBS or backed by instance store .
The former means that the root device for an instance launched from the AMI is an Amazon EBS volume created from an Amazon EBS snapshot .
The latter means that the root device for an instance launched from the AMI is an instance store volume created from a template stored in Amazon S3 .
The following table summarizes the important diﬀerences when using the two types of AMIs .
Characteristic Amazon EBS-backed AMI Amazon instance store-backed AMI Boot time for an instance Usually less than 1 minute Usually less than 5 minutes Size limit for a root device 16 TiB 10 GiB Root device volume Amazon EBS volume Instance store volume Data persistence By default , the root volume is deleted when the instance terminates .
* Data on any other Amazon EBS volumes persists after instance termination by default .
Data on any instance store volumes persists only during the life of the instance .
Modiﬁcations The instance type , kernel , RAM disk , and user data can be changed while the instance is stopped .
Instance attributes are ﬁxed for the life of an instance .
96 Amazon Elastic Compute Cloud User Guide for Linux Instances Storage for the root device Characteristic Amazon EBS-backed AMI Amazon instance store-backed AMI Charges You 're charged for instance usage , Amazon EBS volume usage , and storing your AMI as an Amazon EBS snapshot .
AMI creation/bundling Uses a single command/call Requires installation and use of AMI tools Stopped state Can be placed in stopped state where instance is not running , but the root volume is persisted in Amazon EBS Can not be in stopped state ; instances are running or terminated * By default , Amazon EBS-backed instance root volumes have the DeleteOnTermination ﬂag set to true .
For information about how to change this ﬂag so that the volume persists after termination , see Changing the root volume to persist ( p. 20 ) .
Determining the root device type of your AMI To determine the root device type of an AMI using the console 1 .
Check the value of Root Device Type in the Details tab as follows : • If the value is ebs , this is an Amazon EBS-backed AMI .
To determine the root device type of an AMI using the command line You can use one of the following commands .
Stopping causes the instance to stop running ( its status goes from running to stopping to stopped ) .
A stopped instance persists in Amazon EBS , which allows it to be restarted .
For more information about what happens and what you can do while an instance is stopped , see Stop and start your instance ( p. 531 ) .
Default data storage and persistence Instances that use an instance store volume for the root device automatically have instance store available ( the root volume contains the root partition and you can store additional data ) .
You can add persistent storage to your instance by attaching one or more Amazon EBS volumes .
Any data on an instance store volume is deleted when the instance fails or terminates .
97 Amazon Elastic Compute Cloud User Guide for Linux Instances Virtualization types Instances that use Amazon EBS for the root device automatically have an Amazon EBS volume attached .
The volume appears in your list of volumes like any other .
With most instance types , Amazon EBSbacked instances do n't have instance store volumes by default .
You can add instance store volumes or additional Amazon EBS volumes using a block device mapping .
Boot times Instances launched from an Amazon EBS-backed AMI launch faster than instances launched from an instance store-backed AMI .
When you launch an instance from an instance store-backed AMI , all the parts have to be retrieved from Amazon S3 before the instance is available .
With an Amazon EBS-backed AMI , only the parts required to boot the instance need to be retrieved from the snapshot before the instance is available .
However , the performance of an instance that uses an Amazon EBS volume for its root device is slower for a short time while the remaining parts are retrieved from the snapshot and loaded into the volume .
When you stop and restart the instance , it launches quickly , because the state is stored in an Amazon EBS volume .
AMI creation To create Linux AMIs backed by instance store , you must create an AMI from your instance on the instance itself using the Amazon EC2 AMI tools .
AMI creation is much easier for AMIs backed by Amazon EBS .
The CreateImage API action creates your Amazon EBS-backed AMI and registers it .
There 's also a button in the AWS Management Console that lets you create an AMI from a running instance .
How you 're charged With AMIs backed by instance store , you 're charged for instance usage and storing your AMI in Amazon S3 .
With AMIs backed by Amazon EBS , you 're charged for instance usage , Amazon EBS volume storage and usage , and storing your AMI as an Amazon EBS snapshot .
With Amazon EC2 instance store-backed AMIs , each time you customize an AMI and create a new one , all of the parts are stored in Amazon S3 for each AMI .
So , the storage footprint for each customized AMI is the full size of the AMI .
For Amazon EBS-backed AMIs , each time you customize an AMI and create a new one , only the changes are stored .
So the storage footprint for subsequent AMIs you customize after the ﬁrst is much smaller , resulting in lower AMI storage charges .
As soon as you start your instance , we charge a minimum of one minute for usage .
After one minute , we charge only for the seconds used .
For example , if you run an instance for 20 seconds and then stop it , we charge for a full one minute .
We charge you for each second , with a one-minute minimum , that you keep the instance running , even if the instance remains idle and you do n't connect to it .
Linux AMI virtualization types Linux Amazon Machine Images use one of two types of virtualization : paravirtual ( PV ) or hardware virtual machine ( HVM ) .
The main diﬀerences between PV and HVM AMIs are the way in which they boot and whether they can take advantage of special hardware extensions ( CPU , network , and storage ) for better performance .
For the best performance , we recommend that you use current generation instance types and HVM AMIs when you launch your instances .
For more information about current generation instance types , 98 Amazon Elastic Compute Cloud User Guide for Linux Instances Finding a Linux AMI see Amazon EC2 Instance Types .
If you are using previous generation instance types and would like to upgrade , see Upgrade Paths .
HVM AMIs HVM AMIs are presented with a fully virtualized set of hardware and boot by executing the master boot record of the root block device of your image .
This virtualization type provides the ability to run an operating system directly on top of a virtual machine without any modiﬁcation , as if it were run on the bare-metal hardware .
The Amazon EC2 host system emulates some or all of the underlying hardware that is presented to the guest .
Unlike PV guests , HVM guests can take advantage of hardware extensions that provide fast access to the underlying hardware on the host system .
For more information on CPU virtualization extensions available in Amazon EC2 , see Intel Virtualization Technology on the Intel website .
HVM AMIs are required to take advantage of enhanced networking and GPU processing .
In order to pass through instructions to specialized network and GPU devices , the OS needs to be able to have access to the native hardware platform ; HVM virtualization provides this access .
All instance types support HVM AMIs .
To ﬁnd an HVM AMI , verify that the virtualization type of the AMI is set to hvm , using the console or the describe-images command .
PV AMIs PV AMIs boot with a special boot loader called PV-GRUB , which starts the boot cycle and then chain loads the kernel speciﬁed in the menu.lst ﬁle on your image .
Paravirtual guests can run on host hardware that does not have explicit support for virtualization , but they can not take advantage of special hardware extensions such as enhanced networking or GPU processing .
Historically , PV guests had better performance than HVM guests in many cases , but because of enhancements in HVM virtualization and the availability of PV drivers for HVM AMIs , this is no longer true .
Current generation instance types do not support PV AMIs .
To ﬁnd a PV AMI , verify that the virtualization type of the AMI is set to paravirtual , using the console or the describe-images command .
PV on HVM Paravirtual guests traditionally performed better with storage and network operations than HVM guests because they could leverage special drivers for I/O that avoided the overhead of emulating network and disk hardware , whereas HVM guests had to translate these instructions to emulated hardware .
Now PV drivers are available for HVM guests , so operating systems that can not be ported to run in a paravirtualized environment can still see performance advantages in storage and network I/O by using them .
With these PV on HVM drivers , HVM guests can get the same , or better , performance than paravirtual guests .
Finding a Linux AMI Before you can launch an instance , you must select an AMI to use .
You can select from the list of AMIs when you use the launch wizard to launch an instance , or you can search through all available AMIs using the Images page .
AMI IDs are unique to each AWS Region .
From the navigation bar , select the Region in which to launch your instances .
You can select any Region that 's available to you , regardless of your location .
On the Quick Start tab , select from one of the commonly used AMIs in the list .
If you do n't see the AMI that you need , select the AWS Marketplace or Community AMIs tab to ﬁnd additional AMIs .
From the navigation bar , select the Region in which to launch your instances .
You can select any Region that 's available to you , regardless of your location .
( Optional ) Use the Filter options to scope the list of displayed AMIs to see only the AMIs that interest you .
For example , to list all Linux AMIs provided by AWS , select Public images .
Choose the Search bar and select Owner from the menu , then select Amazon images .
Choose the Search bar again to select Platform and then the operating system from the list provided .
( Optional ) Choose the Show/Hide Columns icon to select which image attributes to display , such as the root device type .
Alternatively , you can select an AMI from the list and view its properties in the Details tab .
Before you select an AMI , it 's important that you check whether it 's backed by instance store or by Amazon EBS and that you are aware of the eﬀects of this diﬀerence .
To launch an instance from this AMI , select it and then choose Launch .
If you 're not ready to launch the instance now , make note of the AMI ID for later .
100 Amazon Elastic Compute Cloud User Guide for Linux Instances Finding an AMI using the AWS CLI Finding an AMI using the AWS CLI You can use AWS CLI commands for Amazon EC2 to list only the Linux AMIs that meet your needs .
After locating an AMI that meets your needs , make note of its ID so that you can use it to launch instances .
For more information , see Launching an Instance Using the AWS CLI in the AWS Command Line Interface User Guide .
For example , use the -- owners parameter to display public AMIs owned by Amazon .
Finding the latest Amazon Linux AMI using Systems Manager You can query the AWS Systems Manager Parameter Store for ID of the latest Amazon Linux AMI .
For more information , see Query for the latest Amazon Linux AMI IDs Using AWS Systems Manager Parameter Store .
Finding a Quick Start AMI When you launch an instance using the Amazon EC2 console , the Choose an Amazon Machine Image ( AMI ) page includes a list of popular AMIs on the Quick Start tab .
If you want to automate launching an instance using one of these quick start AMIs , you 'll need to programatically locate the ID of the current version of the AMI .
To locate the current version of a quick start AMI , you can enumerate all AMIs with its AMI name , and then ﬁnd the one with the most recent creation date .
One of the easiest ways to get started with Amazon EC2 is to use a shared AMI that has the components you need and then add custom content .
You can also create your own AMIs and share them with others .
Amazon ca n't vouch for the integrity or security of AMIs shared by other Amazon EC2 users .
Therefore , you should treat shared AMIs as you would any foreign code that you might consider deploying in your own data center and perform the appropriate due diligence .
We recommend that you get an AMI from a trusted source .
Amazon 's public images have an aliased owner , which appears as amazon in the account ﬁeld .
This enables you to ﬁnd AMIs from Amazon easily .
For information about creating an AMI , see Creating an Instance Store-Backed Linux AMI or Creating an Amazon EBS-Backed Linux AMI .
For more information about building , delivering , and maintaining your applications on the AWS Marketplace , see the AWS Marketplace Documentation .
102 Amazon Elastic Compute Cloud User Guide for Linux Instances Finding shared AMIs AMIs are a regional resource .
Therefore , when searching for a shared AMI ( public or private ) , you must search for it from within the Region from which it is being shared .
To make an AMI available in a diﬀerent Region , copy the AMI to the Region and then share it .
All AMIs that have been shared with you are listed .
To granulate your search , choose the Search bar and use the ﬁlter options provided in the menu .
To granulate your search , choose the Search bar and use the ﬁlter options provided in the menu .
Use ﬁlters to list only the types of AMIs that interest you .
For example , choose Owner : and then choose Amazon images to display only Amazon 's public images .
You can scope the list to the types of AMIs that interest you , as shown in the following examples .
Example : List all public AMIs The following command lists all public AMIs , including any public AMIs that you own .
aws ec2 describe-images -- executable-users all Example : List AMIs with explicit launch permissions The following command lists the AMIs for which you have explicit launch permissions .
This list does not include any AMIs that you own .
Amazon 's public AMIs have an aliased owner , which appears as amazon in the account ﬁeld .
This enables you to ﬁnd AMIs from Amazon easily .
aws ec2 describe-images -- owners amazon Example : List AMIs owned by an account The following command lists the AMIs owned by the speciﬁed AWS account .
aws ec2 describe-images -- owners 123456789012 103 Amazon Elastic Compute Cloud User Guide for Linux Instances Making an AMI public Example : Scope AMIs using a ﬁlter To reduce the number of displayed AMIs , use a ﬁlter to list only the types of AMIs that interest you .
-- filters `` Name=root-device-type , Values=ebs '' Using shared AMIs Before you use a shared AMI , take the following steps to conﬁrm that there are no pre-installed credentials that would allow unwanted access to your instance by a third party and no pre-conﬁgured remote logging that could transmit sensitive data to a third party .
Check the documentation for the Linux distribution used by the AMI for information about improving the security of the system .
To ensure that you do n't accidentally lose access to your instance , we recommend that you initiate two SSH sessions and keep the second session open until you 've removed credentials that you don't recognize and conﬁrmed that you can still log into your instance using SSH .
Identify and disable any unauthorized public SSH keys .
The only key in the ﬁle should be the key you used to launch the AMI .
Open the sshd_config ﬁle and edit the PermitRootLogin line as follows : PermitRootLogin without-password Alternatively , you can disable the ability to log into the instance as the root user : PermitRootLogin No Restart the sshd service .
Check whether there are any other user accounts that are able to log in to your instance .
Accounts with superuser privileges are particularly dangerous .
Remove or lock the password of any unknown accounts .
Check for open ports that you are n't using and running network services listening for incoming connections .
To prevent preconﬁgured remote logging , you should delete the existing conﬁguration ﬁle and restart the rsyslog service .
Verify that all cron jobs are legitimate .
If you discover a public AMI that you feel presents a security risk , contact the AWS security team .
Making an AMI public Amazon EC2 enables you to share your AMIs with other AWS accounts .
You can allow all AWS accounts to launch the AMI ( make the AMI public ) , or only allow a few speciﬁc accounts to launch the AMI ( see 104 Amazon Elastic Compute Cloud User Guide for Linux Instances Making an AMI public Sharing an AMI with speciﬁc AWS accounts ( p. 106 ) ) .
You are not billed when your AMI is launched by other AWS accounts ; only the accounts launching the AMI are billed .
AMIs with encrypted volumes can not be made public .
Therefore , sharing an AMI makes it available in that region .
To make an AMI available in a diﬀerent Region , copy the AMI to the Region and then share it .
To avoid exposing sensitive data when you share an AMI , read the security considerations in Guidelines for shared Linux AMIs ( p. 108 ) and follow the recommended actions .
You can share the AMI only with speciﬁc AWS accounts .
Sharing an AMI with all AWS accounts ( console ) After you make an AMI public , it is available in Community AMIs when you launch an instance in the same Region using the console .
Note that it can take a short while for an AMI to appear in Community AMIs after you make it public .
It can also take a short while for an AMI to be removed from Community AMIs after you make it private again .
Select your AMI from the list , and then choose Actions , Modify Image Permissions .
Sharing an AMI with all AWS accounts ( AWS CLI ) Each AMI has a launchPermission property that controls which AWS accounts , besides the owner 's , are allowed to use that AMI to launch instances .
By modifying the launchPermission property of an AMI , you can make the AMI public ( which grants launch permissions to all AWS accounts ) or share it with only the AWS accounts that you specify .
You can add or remove account IDs from the list of accounts that have launch permissions for an AMI .
To make the AMI public , specify the all group .
You can specify both public and explicit launch permissions .
Use the modify-image-attribute command as follows to add the all group to the launchPermission list for the speciﬁed AMI .
( Optional ) To make the AMI private again , remove the all group from its launch permissions .
Note that the owner of the AMI always has launch permissions and is therefore unaﬀected by this command .
All you need is the AWS account IDs .
If you share an AMI with encrypted volumes , you must also share any CMKs used to encrypt them .
Therefore , sharing an AMI makes it available in that region .
To make an AMI available in a diﬀerent Region , copy the AMI to the Region and then share it .
There is no limit to the number of AWS accounts with which an AMI can be shared .
Select your AMI in the list , and then choose Actions , Modify Image Permissions .
Specify the AWS account number of the user with whom you want to share the AMI in the AWS Account Number ﬁeld , then choose Add Permission .
To share this AMI with multiple users , repeat this step until you have added all the required users .
To allow create volume permissions for snapshots , select Add `` create volume '' permissions to the following associated snapshots when creating permissions .
You do not need to share the Amazon EBS snapshots that an AMI references in order to share the AMI .
Only the AMI itself needs to be shared ; the system automatically provides the instance access to the referenced Amazon EBS snapshots for the launch .
However , you do need to share any CMKs used to encrypt snapshots that the AMI references .
Choose Save when you are done .
( Optional ) To view the AWS account IDs with which you have shared the AMI , select the AMI in the list , and choose the Permissions tab .
To grant explicit launch permissions The following command grants launch permissions for the speciﬁed AMI to the speciﬁed AWS account .
Only the AMI itself needs to be shared ; the system automatically provides the instance access to the referenced Amazon EBS snapshots for the launch .
However , you do need to share any CMKs used to encrypt snapshots that the AMI references .
Note that the owner of the AMI always has launch permissions and is therefore unaﬀected by this command .
This is an easy way to share AMI references , so users do n't have to spend time ﬁnding your AMI in order to use it .
Note that your AMI must be public , or you must have shared it with the user to whom you want to send the bookmark .
Distribute the link to users who want to use your AMI .
To use a bookmark , choose the link or copy and paste it into your browser .
The launch wizard opens , with the AMI already selected .
Guidelines for shared Linux AMIs Use the following guidelines to reduce the attack surface and improve the reliability of the AMIs you create .
Important No list of security guidelines can be exhaustive .
Build your shared AMIs carefully and take time to consider where you might expose sensitive data .
For additional information about sharing AMIs safely , see the following articles : • How To Share and Use Public AMIs in A Secure Manner • Public AMI Publishing : Hardening and Clean-up Requirements Update the AMI tools before using them For AMIs backed by instance store , we recommend that your AMIs download and upgrade the Amazon EC2 AMI creation tools before you use them .
This ensures that new AMIs based on your shared AMIs have the latest AMI tools .
For Amazon Linux 2 , install the aws-amitools-ec2 package and add the AMI tools to your PATH with the following command .
Disable password-based remote logins for root Using a ﬁxed root password for a public AMI is a security risk that can quickly become known .
Even relying on users to change the password after the ﬁrst login opens a small window of opportunity for potential abuse .
Change the line to : PermitRootLogin without-password The location of this conﬁguration ﬁle might diﬀer for your distribution , or if you are not running OpenSSH .
If this is the case , consult the relevant documentation .
Disable local root access When you work with shared AMIs , a best practice is to disable direct root logins .
Remove SSH host key pairs If you plan to share an AMI derived from a public AMI , remove the existing SSH host key pairs located in /etc/ssh .
This forces SSH to generate new unique SSH key pairs when someone launches an instance using your AMI , improving security and reducing the likelihood of `` man-in-the-middle '' attacks .
Remove all of the following key ﬁles that are present on your system .
For more information see the shred documentation .
Important If you forget to remove the existing SSH host key pairs from your public AMI , our routine auditing process notiﬁes you and all customers running instances of your AMI of the potential security risk .
Install public key credentials After conﬁguring the AMI to prevent logging in using a password , you must make sure users can log in using another mechanism .
When a valid key pair name is provided to the RunInstances API call ( or through the command line API tools ) , the public key ( the portion of the key pair that Amazon EC2 retains on the server after a call to CreateKeyPair or ImportKeyPair ) is made available to the instance through an HTTP query against the instance metadata .
To log in through SSH , your AMI must retrieve the key value at boot and append it to /root/.ssh/ authorized_keys ( or the equivalent for any other user account on the AMI ) .
Users can launch instances of your AMI with a key pair and log in without requiring a root password .
Many distributions , including Amazon Linux and Ubuntu , use the cloud-init package to inject public key credentials for a conﬁgured user .
If your distribution does not support cloud-init , you can add the following code to a system start-up script ( such as /etc/rc.local ) to pull in the public key you speciﬁed at launch for the root user .
Note Rebundling an instance based on this AMI includes the key with which it was launched .
Disabling sshd DNS checks ( optional ) Disabling sshd DNS checks slightly weakens your sshd security .
If you do not disable sshd checks , DNS resolution failures prevent all logins .
Change the line to : UseDNS no Note The location of this conﬁguration ﬁle can diﬀer for your distribution or if you are not running OpenSSH .
If this is the case , consult the relevant documentation .
Identify yourself Currently , there is no easy way to know who provided a shared AMI , because each AMI is represented by an account ID .
This provides a convenient central location for users who are interested in trying new shared AMIs .
Protect yourself We recommend against storing sensitive data or software on any AMI that you share .
Users who launch a shared AMI might be able to rebundle it and register it as their own .
Follow these guidelines to help you to avoid some easily overlooked security risks : • We recommend using the -- exclude directory option on ec2-bundle-vol to skip any directories and subdirectories that contain secret information that you would not like to include in your bundle .
If you attempt more than one bundle upload in the same AMI , the shell history contains your secret access key .
The following example should be the last command executed before bundling from within the instance .
*history Warning The limitations of shred described in the warning above apply here as well .
Be aware that bash writes the history of the current session to the disk on exit .
If you log out of your instance after deleting ~/.bash_history , and then log back in , you will ﬁnd that ~/.bash_history has been re-created and contains all of the commands executed during your previous session .
Other programs besides bash also write histories to disk , Use caution and remove or exclude unnecessary dot-ﬁles and dot-directories .
Put these and other credentials in a location that is not bundled ( such as the instance store ) .
Paid AMIs A paid AMI is an AMI that you can purchase from a developer .
Amazon EC2 integrates with AWS Marketplace , enabling developers to charge other Amazon EC2 users for the use of their AMIs or to provide support for instances .
The AWS Marketplace is an online store where you can buy software that runs on AWS , including AMIs that you can use to launch your EC2 instance .
The AWS Marketplace AMIs are organized into categories , such as Developer Tools , to enable you to ﬁnd products to suit your requirements .
For more information about AWS Marketplace , see the AWS Marketplace site .
Launching an instance from a paid AMI is the same as launching an instance from any other AMI .
The instance is charged according to the rates set by the owner of the AMI , as well as the standard usage fees for the related web services , for example , the hourly rate for running an m1.small instance type in Amazon EC2 .
The owner of the paid AMI can conﬁrm whether a speciﬁc instance was launched using that paid AMI .
Important Amazon DevPay is no longer accepting new sellers or products .
AWS Marketplace is now the single , uniﬁed e-commerce platform for selling software and services through AWS .
For information about how to deploy and sell software from AWS Marketplace , see Selling on AWS Marketplace .
AWS Marketplace supports AMIs backed by Amazon EBS .
AWS Marketplace oﬀers an organized shopping experience .
112 Amazon Elastic Compute Cloud User Guide for Linux Instances Finding a paid AMI For information about how to sell your AMI on AWS Marketplace , see Selling on AWS Marketplace .
Finding a paid AMI There are several ways that you can ﬁnd AMIs that are available for you to purchase .
Choose Public images for the ﬁrst ﬁlter .
If you know the product code , choose Product Code , then type the product code .
Enter the name of the operating system in the search box , and click Go .
To scope the results further , use one of the categories or ﬁlters .
Each product is labeled with its product type : either AMI or Software as a Service .
This example returns the most recent AMI with the speciﬁed product code .
[ ImageId ] '' 113 Amazon Elastic Compute Cloud User Guide for Linux Instances Purchasing a paid AMI Purchasing a paid AMI You must sign up for ( purchase ) a paid AMI before you can launch an instance using the AMI .
Typically a seller of a paid AMI presents you with information about the AMI , including its price and a link where you can buy it .
When you click the link , you 're ﬁrst asked to log into AWS , and then you can purchase the AMI .
Purchasing a paid AMI using the console You can purchase a paid AMI by using the Amazon EC2 launch wizard .
Subscribing to a product using AWS Marketplace To use the AWS Marketplace , you must have an AWS account .
To launch instances from AWS Marketplace products , you must be signed up to use the Amazon EC2 service , and you must be subscribed to the product from which to launch the instance .
There are two ways to subscribe to products in the AWS Marketplace : • AWS Marketplace website : You can launch preconﬁgured software quickly with the 1-Click deployment feature .
• Amazon EC2 launch wizard : You can search for an AMI and launch an instance directly from the wizard .
Getting the product code for your instance You can retrieve the AWS Marketplace product code for your instance using its instance metadata .
Using paid support Amazon EC2 also enables developers to oﬀer support for software ( or derived AMIs ) .
Developers can create support products that you can sign up to use .
During sign-up for the support product , the developer gives you a product code , which you must then associate with your own AMI .
This enables the developer to conﬁrm that your instance is eligible for support .
It also ensures that when you run instances of the product , you are charged according to the terms for the product speciﬁed by the developer .
114 Amazon Elastic Compute Cloud User Guide for Linux Instances Bills for paid and supported AMIs Important You ca n't use a support product with Reserved Instances .
You always pay the price that's speciﬁed by the seller of the support product .
Bills for paid and supported AMIs At the end of each month , you receive an email with the amount your credit card has been charged for using any paid or supported AMIs during the month .
This bill is separate from your regular Amazon EC2 bill .
For more information , see Paying For AWS Marketplace Products .
Managing your AWS Marketplace subscriptions On the AWS Marketplace website , you can check your subscription details , view the vendor 's usage instructions , manage your subscriptions , and more .
Log in to the AWS Marketplace .
All your current subscriptions are listed .
Choose Usage Instructions to view speciﬁc instructions for using the product , for example , a user name for connecting to your running instance .
Ensure that you have terminated any instances running from the subscription .
Log in to the AWS Marketplace , and choose Your Marketplace Account , then Manage your software subscriptions .
You are prompted to conﬁrm your cancellation .
Note After you 've canceled your subscription , you are no longer able to launch any instances from that AMI .
To use that AMI again , you need to resubscribe to it , either on the AWS Marketplace website , or through the launch wizard in the Amazon EC2 console .
115 Amazon Elastic Compute Cloud User Guide for Linux Instances Creating an Amazon EBS-backed Linux AMI Creating an Amazon EBS-backed Linux AMI To create an Amazon EBS-backed Linux AMI , start from an instance that you 've launched from an existing Amazon EBS-backed Linux AMI .
This can be an AMI you have obtained from the AWS Marketplace , an AMI you have created using the AWS Server Migration Service or VM Import/Export , or any other AMI you can access .
After you customize the instance to suit your needs , create and register a new AMI , which you can use to launch new instances with these customizations .
The procedures described below work for Amazon EC2 instances backed by encrypted Amazon EBS volumes ( including the root volume ) as well as for unencrypted volumes .
The AMI creation process is diﬀerent for instance store-backed AMIs .
For more information about creating an Amazon EBS-backed Windows AMI , see Creating an Amazon EBS-Backed Windows AMI in the Amazon EC2 User Guide for Windows Instances .
Overview of creating Amazon EBS-backed AMIs First , launch an instance from an AMI that 's similar to the AMI that you 'd like to create .
You can connect to your instance and customize it .
When the instance is conﬁgured correctly , ensure data integrity by stopping the instance before you create an AMI , then create the image .
When you create an Amazon EBS-backed AMI , we automatically register it for you .
Amazon EC2 powers down the instance before creating the AMI to ensure that everything on the instance is stopped and in a consistent state during the creation process .
If you 're conﬁdent that your instance is in a consistent state appropriate for AMI creation , you can tell Amazon EC2 not to power down and reboot the instance .
Some ﬁle systems , such as XFS , can freeze and unfreeze activity , making it safe to create the image without rebooting the instance .
During the AMI-creation process , Amazon EC2 creates snapshots of your instance 's root volume and any other EBS volumes attached to your instance .
You 're charged for the snapshots until you deregister the AMI and delete the snapshots .
If any volumes attached to the instance are encrypted , the new AMI only launches successfully on instances that support Amazon EBS encryption .
Depending on the size of the volumes , it can take several minutes for the AMI-creation process to complete ( sometimes up to 24 hours ) .
You may ﬁnd it more eﬃcient to create snapshots of your volumes before creating your AMI .
This way , only small , incremental snapshots need to be created when the AMI is created , and the process completes more quickly ( the total time for snapshot creation remains the same ) .
After the process completes , you have a new AMI and snapshot created from the root volume of the instance .
When you launch an instance using the new AMI , we create a new EBS volume for its root volume using the snapshot .
If you add instance-store volumes or EBS volumes to your instance in addition to the root device volume , the block device mapping for the new AMI contains information for these volumes , and the block device mappings for instances that you launch from the new AMI automatically contain information for these volumes .
The instance-store volumes speciﬁed in the block device mapping for the new instance are new and do n't contain any data from the instance store volumes of the instance you used to create the AMI .
The data on EBS volumes persists .
Note When you create a new instance from an EBS-backed AMI , you should initialize both its root volume and any additional EBS storage before putting it into production .
116 Amazon Elastic Compute Cloud User Guide for Linux Instances Creating a Linux AMI from an instance Creating a Linux AMI from an instance You can create an AMI using the AWS Management Console or the command line .
Start with an existing AMI , launch an instance , customize it , create a new AMI from it , and ﬁnally launch an instance of your new AMI .
The steps in the following diagram match the steps in the procedure below .
To create an AMI from an instance using the console 1 .
Select an appropriate EBS-backed AMI to serve as a starting point for your new AMI , and conﬁgure it as needed before launch .
Choose Launch to launch an instance of the EBS-backed AMI that you 've selected .
Accept the default values as you step through the wizard .
You can perform any of the following actions on your instance to customize it for your needs : • Install software and applications • Copy data • Reduce start time by deleting temporary ﬁles , defragmenting your hard drive , and zeroing out free space • Attach additional Amazon EBS volumes 4 .
In the Create Image dialog box , specify the following information , and then choose Create Image .
Amazon EC2 shuts down the instance , takes snapshots of any attached volumes , creates and registers the AMI , and then reboots the instance .
Select No reboot to avoid having your instance shut down .
Warning If you select No reboot , we ca n't guarantee the ﬁle system integrity of the created image .
• Instance Volumes – The ﬁelds in this section enable you to modify the root volume , and add additional Amazon EBS and instance store volumes .
For information about each ﬁeld , pause on the i icon next to each ﬁeld to display ﬁeld tooltips .
Some important points are listed below .
117 Amazon Elastic Compute Cloud User Guide for Linux Instances Creating a Linux AMI from a snapshot • To change the size of the root volume , locate Root in the Volume Type column , and for Size ( GiB ) , type the required value .
• If you select Delete on Termination , when you terminate the instance created from this AMI , the EBS volume is deleted .
If you clear Delete on Termination , when you terminate the instance , the EBS volume is not deleted .
For Volume Type , choose EBS , and ﬁll in the ﬁelds in the row .
When you launch an instance from your new AMI , additional volumes are automatically attached to the instance .
Empty volumes must be formatted and mounted .
When you launch an instance from your new AMI , additional volumes are automatically initialized and mounted .
These volumes do not contain data from the instance store volumes of the running instance on which you based your AMI .
To view the status of your AMI while it is being created , in the navigation pane , choose AMIs .
Initially , the status is pending but should change to available after a few minutes .
When you launch an instance from this AMI , we use this snapshot to create its root device volume .
Launch an instance from your new AMI .
The new running instance contains all of the customizations that you applied in previous steps .
To create an AMI from an instance using the command line You can use one of the following commands .
In the Create Image from EBS Snapshot dialog box , complete the ﬁelds to create your AMI , then choose Create .
118 Amazon Elastic Compute Cloud User Guide for Linux Instances Creating an instance store-backed Linux AMI • ( PV virtualization type only ) Kernel ID and RAM disk ID : Choose the AKI and ARI from the lists .
If you choose the default AKI or do n't choose an AKI , you must specify an AKI every time you launch an instance using this AMI .
In addition , your instance may fail the health checks if the default AKI is incompatible with the instance .
• ( Optional ) Block Device Mappings : Add volumes or expand the default size of the root volume for the AMI .
To create an AMI from a snapshot using the command line You can use one of the following commands .
After you 've customized the instance to suit your needs , bundle the volume and register a new AMI , which you can use to launch new instances with these customizations .
The AMI creation process is diﬀerent for Amazon EBS-backed AMIs .
Overview of the creation process for instance storebacked AMIs The following diagram summarizes the process of creating an AMI from an instance store-backed instance .
First , launch an instance from an AMI that 's similar to the AMI that you 'd like to create .
You can connect to your instance and customize it .
When the instance is set up the way you want it , you can bundle it .
It takes several minutes for the bundling process to complete .
Next you upload the bundle to your Amazon S3 bucket and then register your AMI .
When you launch an instance using the new AMI , we create the root volume for the instance using the bundle that you uploaded to Amazon S3 .
The storage space used by the bundle in Amazon S3 incurs charges to your account until you delete it .
If you add instance store volumes to your instance in addition to the root device volume , the block device mapping for the new AMI contains information for these volumes , and the block device mappings for instances that you launch from the new AMI automatically contain information for these volumes .
Prerequisites Before you can create an AMI , you must complete the following tasks : • Install the AMI tools .
For more information , see Getting Set Up with the AWS Command Line Interface .
Alternatively , you can use the AWS CLI mb command .
For more information , see AWS Account Identiﬁers in the AWS General Reference .
• Ensure that you have your access key ID and secret access key .
For more information , see Access Keys in the AWS General Reference .
The X.509 certiﬁcate and private key are used to encrypt and decrypt your AMI .
For example , you can install software and applications , copy data , delete temporary ﬁles , and modify the Linux conﬁguration .
To use the tools , you must install them on your Linux instance .
The AMI tools are available as both an RPM and as a .zip ﬁle for Linux distributions that do n't support RPM .
To set up the AMI tools using the RPM 1 .
Install Ruby using the package manager for your Linux distribution , such as yum .
Download the RPM ﬁle using a tool such as wget or curl .
( Optional ) If you received an error in the previous step , add the location of your AMI tools installation to your RUBYLIB path .
Run the following command to determine the paths to add .
Add the locations from the previous step to your RUBYLIB path .
Install Ruby and unzip using the package manager for your Linux distribution , such as apt-get .
Set the EC2_AMITOOL_HOME environment variable to the installation directory for the tools .
Add the tools to your PATH environment variable .
You must create the certiﬁcate and then upload it to AWS .
The following procedures may not work for instances running other Linux distributions .
The AMI tools require GRUB Legacy to boot properly .
Install the partition management packages with the following command : [ ec2-user ~ ] $ sudo yum install -y gdisk kpartx parted 123 Amazon Elastic Compute Cloud User Guide for Linux Instances Creating an AMI from an instance store-backed instance To create an AMI from an instance store-backed Amazon Linux instance This procedure assumes that you have satisﬁed the prerequisites in Prerequisites ( p. 120 ) .
Upload your credentials to your instance .
We use these credentials to ensure that only you and Amazon EC2 can access your AMI .
The -i myprivate-key.pem option in the following scp command is the private key you use to connect to your instance with SSH , not the X.509 private key .
Be sure to specify the -e option to exclude the directory where your credentials are stored .
By default , the bundle process excludes ﬁles that might contain sensitive information .
Important By default , the AMI bundling process creates a compressed , encrypted collection of ﬁles in the /tmp directory that represents your root volume .
If you do not have enough free disk space in /tmp to store the bundle , you need to specify a diﬀerent location for the bundle to be stored with the -d /path/to/bundle/storage option .
For most commands , you can use sudo to gain elevated permissions , but in this case , you should run sudo -E su to keep your environment variables .
It can take a few minutes to create the image .
( Optional ) To add more instance store volumes , edit the block device mappings in the image.manifest.xml ﬁle for your AMI .
Creating an AMI from an instance store-backed Ubuntu instance This section describes the creation of an AMI from an Ubuntu Linux instance with an instance store volume as the root volume .
The following procedures may not work for instances running other Linux distributions .
To prepare to use the AMI tools ( HVM instances only ) The AMI tools require GRUB Legacy to boot properly .
You must check to see that your instance uses GRUB Legacy , and if not , you need to install and conﬁgure it .
HVM instances also require partitioning tools to be installed for the AMI tools to work properly .
Check to see if GRUB Legacy is present and install it if necessary .
Check the version of your GRUB installation .
Install the grub package using the following command .
Install the following partition management packages using the package manager for your distribution .
126 Amazon Elastic Compute Cloud User Guide for Linux Instances Creating an AMI from an instance store-backed instance • gdisk ( some distributions may call this package gptfdisk instead ) • kpartx • parted Use the following command .
Check the kernel parameters for your instance .
Edit the /boot/grub/menu.lst ﬁle with your favorite text editor ( such as vim or nano ) to change the console and add the parameters you identiﬁed earlier to the boot entries .
The ec2-bundle-vol 127 Amazon Elastic Compute Cloud User Guide for Linux Instances Creating an AMI from an instance store-backed instance command will not bundle this boot partition , so you need to comment out the /etc/fstab entry for the EFI partition as shown in the following example .
Upload your credentials to your instance .
We use these credentials to ensure that only you and Amazon EC2 can access your AMI .
Create a temporary directory on your instance for your credentials as follows : ubuntu : ~ $ mkdir /tmp/cert This enables you to exclude your credentials from the created image .
The -i my-private-key.pem option in the following scp command is the private key you use to connect to your instance with SSH , not the X.509 private key .
Be sure to specify the -e option to exclude the directory where your credentials are stored .
By default , the bundle process excludes ﬁles that might contain sensitive information .
Important By default , the AMI bundling process creates a compressed , encrypted collection of ﬁles in the /tmp directory that represents your root volume .
If you do not have enough free disk space in /tmp to store the bundle , you need to specify a diﬀerent location for the bundle to be stored with the -d /path/to/bundle/storage option .
For most commands , you can use sudo to gain elevated permissions , but in this case , you should run sudo -E su to keep your environment variables .
It can take a few minutes to create the image .
( Optional ) To add more instance store volumes , edit the block device mappings in the image.manifest.xml ﬁle for your AMI .
Converting your instance store-backed AMI to an Amazon EBS-backed AMI You can convert an instance store-backed Linux AMI that you own to an Amazon EBS-backed Linux AMI .
Important You ca n't convert an instance store-backed Windows AMI to an Amazon EBS-backed Windows AMI and you can not convert an AMI that you do not own .
Launch an Amazon Linux instance from an Amazon EBS-backed AMI .
Amazon Linux instances have the AWS CLI and AMI tools pre-installed .
Upload the X.509 private key that you used to bundle your instance store-backed AMI to your instance .
We use this key to ensure that only you and Amazon EC2 can access your AMI .
The my-private-key parameter in the following command is the private key you use to connect to your instance with SSH .
00:00 Set environment variables for your AWS access key and secret key .
Prepare an Amazon EBS volume for your new AMI .
Create an empty Amazon EBS volume in the same Availability Zone as your instance using the create-volume command .
Note the volume ID in the command output .
Important This Amazon EBS volume must be the same size or larger than the original instance store root volume .
Change directories to the bundle folder .
Copy the ﬁles from the unbundled image to the new Amazon EBS volume .
Probe the volume for any new partitions that were unbundled .
List the block devices to ﬁnd the device name to mount .
Create a mount point for the new Amazon EBS volume and mount the volume .
Open the /etc/fstab ﬁle on the EBS volume with your favorite text editor ( such as vim or nano ) and remove any entries for instance store ( ephemeral ) volumes .
Unmount the volume and detach it from the instance .
Create an AMI from the new Amazon EBS volume as follows .
Check to see that your snapshot is complete .
You need the AMI ID of the original instance store-backed AMI for this step .
Use these values in the following step .
If the output of the above command also lists an ari ID , take note of that as well .
d. Register your new AMI with the snapshot ID of your new Amazon EBS volume and the values from the previous step .
( Optional ) After you have tested that you can launch an instance from your new AMI , you can delete the Amazon EBS volume that you created for this procedure .
For information about your access keys , see Best Practices for Managing AWS Access Keys .
Example This example command displays the version information for the AMI tools that you 're using .
You 'll need to specify this key to unbundle this bundle , so keep it in a safe place .
Note that the key does n't have to be registered to your AWS account .
The us-gov-west-1 and cn-north-1 Regions use a non-default public key certiﬁcate and the path to that certiﬁcate must be speciﬁed with this option .
The path to the certiﬁcate varies based on the installation method of the AMI tools .
If you do n't provide the architecture on the command line , you 'll be prompted for it when bundling starts .
Product codes to attach to the image at registration time , separated by commas .
Required : No -B , -- block-device-mapping mapping Deﬁnes how block devices are exposed to an instance of this AMI if its instance type supports the speciﬁed device .
Required : No Output Status messages describing the stages and status of the bundling process .
Example This example creates a bundled AMI from an operating system image that was created in a loopback ﬁle .
Amazon EC2 attempts to inherit product codes , kernel settings , RAM disk settings , and block device mappings from the instance .
By default , the bundle process excludes ﬁles that might contain sensitive information .
136 Amazon Elastic Compute Cloud User Guide for Linux Instances AMI tools reference Required : Yes -d , -- destination destination The directory in which to create the bundle .
The us-gov-west-1 and cn-north-1 Regions use a non-default public key certiﬁcate and the path to that certiﬁcate must be speciﬁed with this option .
The path to the certiﬁcate varies based on the installation method of the AMI tools .
If you do n't provide this on the command line , you 'll be prompted to provide it when the bundling starts .
Product codes to attach to the image at registration time , separated by commas .
Required : No -B , -- block-device-mapping mapping Deﬁnes how block devices are exposed to an instance of this AMI if its instance type supports the speciﬁed device .
A list of absolute directory paths and ﬁles to exclude from the bundle operation .
When exclude is speciﬁed , the directories and subdirectories listed with the parameter will not be bundled with the volume .
A list of ﬁles to include in the bundle operation .
The speciﬁed ﬁles would otherwise be excluded from the AMI because they might contain sensitive information .
Bundling fails if you enable -- inherit but the instance metadata is not accessible .
If you do n't specify a partition table type , the default is the type used on the parent block device of the volume , if applicable , otherwise the default is gpt .
The script must expect a single argument , the mount point of the volume .
Required : No -- fstab path The path to the fstab to bundle into the image .
Required : No 138 Amazon Elastic Compute Cloud User Guide for Linux Instances AMI tools reference -- generate-fstab Bundles the volume using an Amazon EC2-provided fstab .
Required : No -- grub-config The path to an alternate grub conﬁguration ﬁle to bundle into the image .
This option allows you to specify a path to an alternative grub conﬁguration ﬁle , which will then be copied over the defaults ( if present ) .
Required : No Output Status messages describing the stages and status of the bundling .
Example This example creates a bundled AMI by compressing , encrypting and signing a snapshot of the local machine 's root ﬁle system .
Created image.part.22 139 Amazon Elastic Compute Cloud User Guide for Linux Instances AMI tools reference Created image.part.23 Generating digests for each part .
For more information , see the Using Temporary Security Credentials .
Required : Only when you are using temporary security credentials .
-- regionregion The Region to use in the request signature .
Required : No Output Amazon EC2 displays status messages indicating the stages and status of the delete process .
Required : No Output Status messages indicating the various stages of the download process are displayed .
Example This example creates the bundled directory ( using the Linux mkdir command ) and downloads the bundle from the aws-s3-bucket1 Amazon S3 bucket .
-- region region The Region to look up in the mapping ﬁle .
During migration , Amazon EC2 replaces the kernel and RAM disk in the manifest ﬁle with a kernel and RAM disk designed for the destination region .
The us-gov-west-1 and cn-north-1 Regions use a non-default public key certiﬁcate and the path to that certiﬁcate must be speciﬁed with this option .
The path to the certiﬁcate varies based on the installation method of the AMI tools .
Important We recommend that you use PV-GRUB instead of kernels and RAM disks .
Important We recommend that you use PV-GRUB instead of kernels and RAM disks .
Required : No Output Status messages describing the stages and status of the bundling process .
Example This example copies the AMI speciﬁed in the my-ami.manifest.xml manifest from the US to the EU .
Required : No Example This Linux and UNIX example unbundles the AMI speciﬁed in the image.manifest.xml ﬁle .
ec2-upload-bundle Description Uploads the bundle for an instance store-backed Linux AMI to Amazon S3 and sets the appropriate ACLs on the uploaded objects .
For more information , see the Using Temporary Security Credentials .
Required : Only when you are using temporary security credentials .
The manifest ﬁle is created during the bundling process and can be found in the directory containing the bundle .
The -- location ﬂag is the only way to target that speciﬁc location restraint .
• If the bucket does n't exist and you specify a Region , the tool creates the bucket in the speciﬁed Region .
• If the bucket exists and you specify us-east-1 as the Region , the tool uses the bucket 's actual location without any error message , any existing matching ﬁles are over-written .
The -- location ﬂag is the only way to target that speciﬁc location restraint .
147 Amazon Elastic Compute Cloud User Guide for Linux Instances AMI tools reference Default : us-east-1 Required : Required if using signature version 4 -- sigv version The signature version to use when signing the request .
Required : No -- part part Starts uploading the speciﬁed part and all subsequent parts .
The -- location ﬂag is the only way to target that speciﬁc location restraint .
If the bucket exists and you specify a location that does n't match the bucket 's actual location , the tool exits with an error .
If the bucket does n't exist and you specify a location , the tool creates the bucket in the speciﬁed location .
148 Amazon Elastic Compute Cloud User Guide for Linux Instances Using encryption with EBS-backed AMIs Required : No Output Amazon EC2 displays status messages that indicate the stages and status of the upload process .
Example This example uploads the bundle speciﬁed by the image.manifest.xml manifest .
Common options for AMI tools Most of the AMI tools accept the following optional parameters .
-- debug Displays information that can be useful when troubleshooting problems .
Using encryption with EBS-backed AMIs AMIs that are backed by Amazon EBS snapshots can take advantage of Amazon EBS encryption .
Snapshots of both data and root volumes can be encrypted and attached to an AMI .
You can launch 149 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance-launching scenarios instances and copy images with full EBS encryption support included .
Encryption parameters for these operations are supported in all Regions where AWS KMS is available .
EC2 instances with encrypted EBS volumes are launched from AMIs in the same way as other instances .
In addition , when you launch an instance from an AMI backed by unencrypted EBS snapshots , you can encrypt some or all of the volumes during launch .
Like EBS volumes , snapshots in AMIs can be encrypted by either your default AWS Key Management Service customer master key ( CMK ) , or to a customer managed key that you specify .
You must in all cases have permission to use the selected key .
AMIs with encrypted snapshots can be shared across AWS accounts .
Instance-launching scenarios Amazon EC2 instances are launched from AMIs using the RunInstances action with parameters supplied through block device mapping , either by means of the AWS Management Console or directly using the Amazon EC2 API or CLI .
For more information about block device mapping , see Block device mapping .
By default , without explicit encryption parameters , a RunInstances action maintains the existing encryption state of an AMI 's source snapshots while restoring EBS volumes from them .
If encryption by default is enabled , all volumes created from the AMI ( whether from encrypted or unencrypted snapshots ) will be encrypted .
If encryption by default is not enabled , then the instance maintains the encryption state of the AMI .
You can also launch an instance and simultaneously apply a new encryption state to the resulting volumes by supplying encryption parameters .
Consequently , the following behaviors are observed : Launch with no encryption parameters • An unencrypted snapshot is restored to an unencrypted volume , unless encryption by default is enabled , in which case all the newly created volumes will be encrypted .
• An encrypted snapshot that you own is restored to a volume that is encrypted to the same CMK .
• An encrypted snapshot that you do not own ( for example , the AMI is shared with you ) is restored to a volume that is encrypted by your AWS account 's default CMK .
The default behaviors can be overridden by supplying encryption parameters .
The available parameters are Encrypted and KmsKeyId .
Setting only the Encrypted parameter results in the following : Instance launch behaviors with Encrypted set , but no KmsKeyId speciﬁed • An unencrypted snapshot is restored to an EBS volume that is encrypted by your AWS account's default CMK .
• An encrypted snapshot that you own is restored to an EBS volume encrypted by the same CMK .
• An encrypted snapshot that you do not own ( i.e. , the AMI is shared with you ) is restored to a volume that is encrypted by your AWS account 's default CMK .
Setting both the Encrypted and KmsKeyId parameters allows you to specify a non-default CMK for an encryption operation .
The following behaviors result : 150 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance-launching scenarios Instance with both Encrypted and KmsKeyId set • An unencrypted snapshot is restored to an EBS volume encrypted by the speciﬁed CMK .
• An encrypted snapshot is restored to an EBS volume encrypted not to the original CMK , but instead to the speciﬁed CMK .
Submitting a KmsKeyId without also setting the Encrypted parameter results in an error .
The following sections provide examples of launching instances from AMIs using non-default encryption parameters .
In each of these scenarios , parameters supplied to the RunInstances action result in a change of encryption state during restoration of a volume from a snapshot .
Note For detailed console procedures to launch an instance from an AMI , see Launch Your Instance .
Encrypt a volume during launch In this example , an AMI backed by an unencrypted snapshot is used to launch an EC2 instance with an encrypted EBS volume .
The Encrypted parameter alone results in the volume for this instance being encrypted .
If no key ID is speciﬁed , the AWS account 's default CMK is used to encrypt the volume .
To encrypt the volume to a diﬀerent CMK that you own , supply the KmsKeyId parameter .
Re-encrypt a volume during launch In this example , an AMI backed by an encrypted snapshot is used to launch an EC2 instance with an EBS volume encrypted by a new CMK .
151 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance-launching scenarios If you own the AMI and supply no encryption parameters , the resulting instance has a volume encrypted by the same key as the snapshot .
If the AMI is shared rather than owned by you , and you supply no encryption parameters , the volume is encrypted by your default CMK .
With encryption parameters supplied as shown , the volume is encrypted by the speciﬁed CMK .
Change encryption state of multiple volumes during launch In this more complex example , an AMI backed by multiple snapshots ( each with its own encryption state ) is used to launch an EC2 instance with a newly encrypted volume and a re-encrypted volume .
152 Amazon Elastic Compute Cloud User Guide for Linux Instances Image-copying scenarios In this scenario , the RunInstances action is supplied with encryption parameters for each of the source snapshots .
When all possible encryption parameters are speciﬁed , the resulting instance is the same regardless of whether you own the AMI .
Image-copying scenarios Amazon EC2 AMIs are copied using the CopyImage action , either through the AWS Management Console or directly using the Amazon EC2 API or CLI .
By default , without explicit encryption parameters , a CopyImage action maintains the existing encryption state of an AMI 's source snapshots during copy .
You can also copy an AMI and simultaneously apply a new encryption state to its associated EBS snapshots by supplying encryption parameters .
Consequently , the following behaviors are observed : Copy with no encryption parameters • An unencrypted snapshot is copied to another unencrypted snapshot , unless encryption by default is enabled , in which case all the newly created snapshots will be encrypted .
• An encrypted snapshot that you own is copied to a snapshot encrypted with the same key .
• An encrypted snapshot that you do not own ( that is , the AMI is shared with you ) is copied to a snapshot that is encrypted by your AWS account 's default CMK .
153 Amazon Elastic Compute Cloud User Guide for Linux Instances Image-copying scenarios All of these default behaviors can be overridden by supplying encryption parameters .
The available parameters are Encrypted and KmsKeyId .
Setting only the Encrypted parameter results in the following : Copy-image behaviors with Encrypted set , but no KmsKeyId speciﬁed • An unencrypted snapshot is copied to a snapshot encrypted by the AWS account 's default CMK .
• An encrypted snapshot is copied to a snapshot encrypted by the same CMK .
• An encrypted snapshot that you do not own ( i.e. , the AMI is shared with you ) is copied to a volume that is encrypted by your AWS account 's default CMK .
Setting both the Encrypted and KmsKeyId parameters allows you to specify a customer managed CMK for an encryption operation .
The following behaviors result : Copy-image behaviors with both Encrypted and KmsKeyId set • An unencrypted snapshot is copied to a snapshot encrypted by the speciﬁed CMK .
• An encrypted snapshot is copied to a snapshot encrypted not to the original CMK , but instead to the speciﬁed CMK .
Submitting a KmsKeyId without also setting the Encrypted parameter results in an error .
The following section provides an example of copying an AMI using non-default encryption parameters , resulting in a change of encryption state .
Note For detailed console procedures to copy an AMI , see Copying an AMI .
Encrypt an unencrypted image during copy In this scenario , an AMI backed by an unencrypted root snapshot is copied to an AMI with an encrypted root snapshot .
As a result , the encryption status of the root snapshot changes , so that the target AMI is backed by a root snapshot containing the same data as the source snapshot , but encrypted using the speciﬁed key .
You incur storage costs for the snapshots in both AMIs , as well as charges for any instances you launch from either AMI .
Note Enabling encryption by default ( p. 1012 ) has the same eﬀect as setting the Encrypted parameter to true for all snapshots in the AMI .
154 Amazon Elastic Compute Cloud User Guide for Linux Instances Copying an AMI Setting the Encrypted parameter encrypts the single snapshot for this instance .
If you do not specify the KmsKeyId parameter , the default CMK is used to encrypt the snapshot copy .
Note You can also copy an image with multiple snapshots and conﬁgure the encryption state of each individually .
Copying an AMI You can copy an Amazon Machine Image ( AMI ) within or across AWS Regions using the AWS Management Console , the AWS Command Line Interface or SDKs , or the Amazon EC2 API , all of which support the CopyImage action .
You can copy AMIs with encrypted snapshots and also change encryption status during the copy process .
Copying a source AMI results in an identical but distinct target AMI with its own unique identiﬁer .
In the case of an Amazon EBS-backed AMI , each of its backing snapshots is , by default , copied to an identical but distinct target snapshot .
You can change or deregister the source AMI with no eﬀect on the target AMI .
There are no charges for copying an AMI .
If you copy an EBS-backed AMI , you will incur charges for the storage of any additional EBS snapshots .
AWS does not copy launch permissions , user-deﬁned tags , or Amazon S3 bucket permissions from the source AMI to the new AMI .
You ca n't copy an AMI that was obtained from the AWS Marketplace , regardless of whether you obtained it directly or it was shared with you .
Instead , launch an EC2 instance using the AWS Marketplace AMI and then create an AMI from the instance .
The following example policy allows the user to copy the AMI source in the speciﬁed bucket to the speciﬁed Region .
Cross-Region copying Copying an AMI across geographically diverse Regions provides the following beneﬁts : • Consistent global deployment : Copying an AMI from one Region to another enables you to launch consistent instances in diﬀerent Regions based on the same AMI .
• Scalability : You can more easily design and build global applications that meet the needs of your users , regardless of their location .
• Performance : You can increase performance by distributing your application , as well as locating critical components of your application in closer proximity to your users .
You can also take advantage of Region-speciﬁc features , such as instance types or other AWS services .
156 Amazon Elastic Compute Cloud User Guide for Linux Instances Cross-account copying The following diagram shows the relations among a source AMI and two copied AMIs in diﬀerent Regions , as well as the EC2 instances launched from each .
When you launch an instance from an AMI , it resides in the same Region where the AMI resides .
If you make changes to the source AMI and want those changes to be reﬂected in the AMIs in the target Regions , you must recopy the source AMI to the target Regions .
When you ﬁrst copy an instance store-backed AMI to a Region , we create an Amazon S3 bucket for the AMIs copied to that Region .
All instance store-backed AMIs that you copy to that Region are stored in this bucket .
Prerequisite Prior to copying an AMI , you must ensure that the contents of the source AMI are updated to support running in a diﬀerent Region .
For example , you should update any database connection strings or similar application conﬁguration data to point to the appropriate resources .
Otherwise , instances launched from the new AMI in the destination Region may still use the resources from the source Region , which can impact performance and cost .
Cross-account copying You can share an AMI with another AWS account .
Sharing an AMI does not aﬀect the ownership of the AMI .
The owning account is charged for the storage in the Region .
If you copy an AMI that has been shared with your account , you are the owner of the target AMI in your account .
The owner of the source AMI is charged standard Amazon EBS or Amazon S3 transfer fees , and you are charged for the storage of the target AMI in the destination Region .
Resource Permissions To copy an AMI that was shared with you from another account , the owner of the source AMI must grant you read permissions for the storage that backs the AMI , either the associated EBS snapshot ( for an 157 Amazon Elastic Compute Cloud User Guide for Linux Instances Encryption and copying Amazon EBS-backed AMI ) or an associated S3 bucket ( for an instance store-backed AMI ) .
If the shared AMI has encrypted snapshots , the owner must share the key or keys with you as well .
Encryption and copying The following table shows encryption support for various AMI-copying scenarios .
While it is possible to copy an unencrypted snapshot to yield an encrypted snapshot , you can not copy an encrypted snapshot to yield an unencrypted one .
Because an instance store-backed AMI does not rely on snapshots , you can not use copying to change its encryption status .
Copying an AMI backed by an unencrypted snapshot results in an identical target snapshot that is also unencrypted .
If the source AMI is backed by an encrypted snapshot , copying it results in an identical target snapshot that is encrypted by the same customer master key ( CMK ) .
Copying an AMI backed by multiple snapshots preserves , by default , the source encryption status in each target snapshot .
If you specify encryption parameters while copying an AMI , you can encrypt or re-encrypt its backing snapshots .
The following example shows a non-default case that supplies encryption parameters to the CopyImage action in order to change the target AMI 's encryption state .
Copy an unencrypted source AMI to an encrypted target AMI In this scenario , an AMI backed by an unencrypted root snapshot is copied to an AMI with an encrypted root snapshot .
As a result , the encryption status of the root snapshot changes , so that the target AMI is backed by a root snapshot containing the same data as the source snapshot , but encrypted using the speciﬁed key .
You incur storage costs for the snapshots in both AMIs , as well as charges for any instances you launch from either AMI .
Note Enabling encryption by default ( p. 1012 ) has the same eﬀect as setting the Encrypted parameter to true for all snapshots in the AMI .
158 Amazon Elastic Compute Cloud User Guide for Linux Instances Copying an AMI Setting the Encrypted parameter encrypts the single snapshot for this instance .
If you do not specify the KmsKeyId parameter , the default CMK is used to encrypt the snapshot copy .
Copying an AMI You can copy an AMI as follows .
Prerequisite Create or obtain an AMI backed by an Amazon EBS snapshot .
Note that you can use the Amazon EC2 console to search a wide variety of AMIs provided by AWS .
From the console navigation bar , select the Region that contains the AMI .
In the navigation pane , choose Images , AMIs to display the list of AMIs available to you in the Region .
Select the AMI to copy and choose Actions , Copy AMI .
In the Copy AMI dialog box , specify the following information and then choose Copy AMI : • Destination region : The Region in which to copy the AMI .
You can include operating system information in the name , as we do not provide this information when displaying details about the AMI .
• Description : By default , the description includes information about the source AMI so that you can distinguish a copy from its original .
You can change this description as needed .
If you have enabled encryption by default , the Encryption option is set and can not be unset from the AMI console .
• Master Key : The KMS key to used to encrypt the target snapshots .
We display a conﬁrmation page to let you know that the copy operation has been initiated and to provide you with the ID of the new AMI .
To check on the progress of the copy operation immediately , follow the provided link .
To check on the progress later , choose Done , and then when you are ready , use the navigation bar to switch to the target region ( if applicable ) and locate your AMI in the list of AMIs .
The initial status of the target AMI is pending and the operation is complete when the status is available .
To copy an AMI using the AWS CLI You can copy an AMI using the copy-image command .
You must specify both the source and destination Regions .
You can specify the destination Region using either the -- region parameter or an environment variable .
For more information , see Conﬁguring the AWS Command Line Interface .
To copy an AMI using the Tools for Windows PowerShell You can copy an AMI using the Copy-EC2Image command .
You must specify both the source and destination Regions .
You can specify the destination Region using either the -Region parameter or the Set-AWSDefaultRegion command .
Stopping a pending AMI copy operation You can stop a pending AMI copy as follows .
To stop an AMI copy operation using the console 1 .
From the navigation bar , select the destination Region from the Region selector .
Select the AMI to stop copying and choose Actions , Deregister .
To stop an AMI copy operation using the command line You can use one of the following commands .
• deregister-image ( AWS CLI ) • Unregister-EC2Image ( AWS Tools for Windows PowerShell ) Obtaining billing information You can determine the platform details and billing information associated with an Amazon Machine Image ( AMI ) before you launch an On-Demand Instance or Spot Instance , or purchase a Reserved 160 Amazon Elastic Compute Cloud User Guide for Linux Instances AMI billing information ﬁelds Instance .
For Spot Instances , you can use the platform details to conﬁrm that the AMI is supported for Spot Instances .
When purchasing a Reserved Instance , you can make sure that , for Platform , you select the correct value that maps to Platform details on the AMI .
By knowing the billing information before launching an instance or purchasing a Reserved Instance , you reduce the chance of erroneously launching instances from incorrect AMIs and incurring unplanned costs .
Usage operation The operation of the Amazon EC2 instance and the billing code that is associated with the AMI .
Usage operation corresponds to the lineitem/Operation column on your AWS Cost and Usage Report ( CUR ) and in the AWS Price List API .
You can view these ﬁelds on the Instances or AMIs page in the Amazon EC2 console , or in the response that is returned by the describe-images command .
Platform details and usage operation values The following table lists the platform details and usage operation values that can be displayed on the Instances or AMIs page in the Amazon EC2 console , or in the response that is returned by the describeimages command .
Platform details Usage operation ** Linux/UNIX RunInstances Red Hat BYOL Linux RunInstances:00g0 Red Hat Enterprise Linux RunInstances:0010 SQL Server Enterprise RunInstances:0100 SQL Server Standard RunInstances:0004 SQL Server Web RunInstances:0200 SUSE Linux RunInstances:000g Windows RunInstances:0002 161 Amazon Elastic Compute Cloud User Guide for Linux Instances Viewing platform details and usage operation values Platform details Usage operation ** Windows BYOL RunInstances:0800 Windows with SQL Server Enterprise * RunInstances:0102 Windows with SQL Server Standard * RunInstances:0006 Windows with SQL Server Web * RunInstances:0202 * If two software licenses are associated with an AMI , the Platform details ﬁeld shows both .
** If you are running Spot Instances , the lineitem/Operation on your AWS Cost and Usage Report might be diﬀerent from the Usage operation value that is listed here .
Viewing platform details and usage operation values You can view the platform details and usage operation values associated with an AMI from the AMI or from the instance .
You can view these values in the Amazon EC2 console or by using the AWS CLI .
From the AMI To view the platform details and usage operation associated with an AMI ( console ) 1 .
On the Details tab , check the values for Platform details and Usage operation .
To view the platform details and usage operation associated with an AMI ( AWS CLI ) Use the describe-images command .
In this example , the ami-0123456789EXAMPLE platform is Red Hat Enterprise Linux and the usage operation and billing code is RunInstances:0010 .
On the Details tab , check the values for Platform details and Usage operation .
To view the platform details and usage operation associated with an AMI ( console ) After you have launched an instance , you can ﬁnd the billing information by inspecting the billingProducts ﬁeld in the instance metadata .
Alternatively , you can use the describe-instances command to obtain the AMI ID for the instance , and then use the describe-images command , as described in the preceding procedure , to obtain the billing information from the PlatformDetails and UsageOperation ﬁelds in the response .
Conﬁrm billing information on your bill To ensure that you 're not incurring unplanned costs , you can conﬁrm that the billing information for an instance in your AWS Cost and Usage Report ( CUR ) matches the billing information associated with the AMI that you used to launch the instance .
To conﬁrm the billing information , ﬁnd the instance ID in your CUR and check the corresponding value in the lineitem/Operation column .
The value should match the value for Usage operation associated with the AMI .
If you launched an instance using this AMI , you can ﬁnd the instance ID in your CUR and check the corresponding value in the lineitem/Operation column .
Deregistering your Linux AMI You can deregister an AMI when you have ﬁnished using it .
After you deregister an AMI , you ca n't use it to launch new instances .
163 Amazon Elastic Compute Cloud User Guide for Linux Instances Cleaning up your Amazon EBS-backed AMI When you deregister an AMI , it does n't aﬀect any instances that you 've already launched from the AMI .
You 'll continue to incur usage costs for these instances .
Therefore , if you are ﬁnished with these instances , you should terminate them .
The procedure that you 'll use to clean up your AMI depends on whether it is backed by Amazon EBS or instance store .
You 'll continue to incur storage costs for the snapshots .
Therefore , if you are ﬁnished with the snapshots , you should delete them .
The following diagram illustrates the process for cleaning up your Amazon EBS-backed AMI .
164 Amazon Elastic Compute Cloud User Guide for Linux Instances Cleaning up your Amazon EBS-backed AMI To clean up your Amazon EBS-backed AMI 1 .
Select the AMI , and take note of its ID — this can help you ﬁnd the correct snapshot in the next step .
Note It may take a few minutes before the console removes the AMI from the list .
Choose Refresh to refresh the status .
In the navigation pane , choose Snapshots , and select the snapshot ( look for the AMI ID in the Description column ) .
( Optional ) If you are ﬁnished with an instance that you launched from the AMI , terminate it .
Cleaning up your instance store-backed AMI When you deregister an instance store-backed AMI , it does n't aﬀect the ﬁles that you uploaded to Amazon S3 when you created the AMI .
Therefore , if you are ﬁnished with these ﬁles , you should delete them .
The following diagram illustrates the process for cleaning up your instance store-backed AMI .
( Optional ) If you are ﬁnished with an instance that you launched from the AMI , you can terminate it using the terminate-instances command as follows .
( Optional ) If you are ﬁnished with the Amazon S3 bucket that you uploaded the bundle to , you can delete the bucket .
It also includes packages that enable easy integration with AWS , including launch conﬁguration tools and many popular AWS libraries and tools .
AWS provides ongoing security and maintenance updates for all instances running Amazon Linux .
Many applications developed on CentOS ( and similar distributions ) run on Amazon Linux .
If you are migrating from another Linux distribution to Amazon Linux , we recommend that you migrate to Amazon Linux 2 .
For more information , see the following blog post : Amazon Linux AMI end of life .
If you are currently using the Amazon Linux AMI , we recommend that you migrate to Amazon Linux 2 .
To migrate to Amazon Linux 2 , launch an instance or create a virtual machine using the current Amazon Linux 2 image .
Test your application , and make any changes required for it to run on Amazon Linux 2 .
167 Amazon Elastic Compute Cloud User Guide for Linux Instances Connecting to an Amazon Linux instance For more information , see Amazon Linux 2 and Amazon Linux AMI .
For Amazon Linux Docker container images , see amazonlinux on Docker Hub .
Connecting to an Amazon Linux instance Amazon Linux does not allow remote root SSH by default .
To enable SSH logins to an Amazon Linux instance , you must provide your key pair to the instance at launch .
You must also set the security group used to launch your instance to allow SSH access .
By default , the only account that can log in remotely using SSH is ec2-user ; this account also has sudo privileges .
If you enable remote root log in , be aware that it is less secure than relying on key pairs and a secondary user .
Identifying Amazon Linux images Each image contains a unique /etc/image-id ﬁle that identiﬁes it .
Amazon Linux contains an /etc/system-release ﬁle that speciﬁes the current release that is installed .
This ﬁle is updated using yum and is part of the system-release RPM .
For the complete list of packages in the Amazon Linux AMI , see Amazon Linux AMI 2017.09 Packages .
169 Amazon Elastic Compute Cloud User Guide for Linux Instances Package repository Also , to allow the installation of multiple versions of the API and AMI tools , we have placed symbolic links to the desired versions of these tools in /opt/aws , as described here : /opt/aws/bin Symbolic links to /bin directories in each of the installed tools directories .
Package repository Amazon Linux 2 and the Amazon Linux AMI are designed to be used with online package repositories hosted in each Amazon EC2 AWS Region .
These repositories provide ongoing updates to packages in Amazon Linux 2 and the Amazon Linux AMI , as well as access to hundreds of additional common opensource server applications .
The repositories are available in all Regions and are accessed using yum update tools .
Hosting repositories in each Region enables us to deploy updates quickly and without any data transfer charges .
Amazon Linux 2 and the Amazon Linux AMI are updated regularly with security and feature enhancements .
If you do not need to preserve data or customizations for your instances , you can simply launch new instances using the current AMI .
If you need to preserve data or customizations for your instances , you can maintain those instances through the Amazon Linux package repositories .
These repositories contain all the updated packages .
You can choose to apply these updates to your running instances .
Older versions of the AMI and update packages continue to be available for use , even as new versions are released .
Important Your instance must have access to the internet in order to access the repository .
Amazon Linux 2 is not conﬁgured to use the EPEL repository .
EPEL provides third-party packages in addition to those that are in the repositories .
Amazon Linux uses RPMs and yum for package 170 Amazon Elastic Compute Cloud User Guide for Linux Instances Package repository management , and that is likely the simplest way to install new applications .
You should always check to see if an application is available in our central Amazon Linux repository ﬁrst , because many applications are available there .
These applications can easily be added to your Amazon Linux instance .
To upload your applications onto a running Amazon Linux instance , use scp or sftp and then conﬁgure the application by logging on to your instance .
Your applications can also be uploaded during the instance launch by using the PACKAGE_SETUP action from the built-in cloud-init package .
Security updates Security updates are provided using the package repositories as well as updated AMI security alerts are published in the Amazon Linux Security Center .
For more information about AWS security policies or to report a security problem , go to the AWS Security Center .
Amazon Linux is conﬁgured to download and install critical or important security updates at launch time .
We recommend that you make the necessary updates for your use case after launch .
For example , you may want to apply all updates ( not just security updates ) at launch , or evaluate each update and apply only the ones applicable to your system .
The following snippet of cloud-init conﬁguration shows how you can change the settings in the user data text you pass to your instance initialization : ✔cloud-config repo_upgrade : security The possible values for repo_upgrade are as follows : security Apply outstanding critical or important updates that Amazon marks as security updates .
bugfix Apply updates that Amazon marks as bug ﬁxes .
Bug ﬁxes are a larger set of updates , which include security updates and ﬁxes for various other minor bugs .
all Apply all applicable available updates , regardless of their classiﬁcation .
none Do not apply any updates to the instance on startup .
That is , if you do n't specify a diﬀerent value in your user data , by default , Amazon Linux performs the security upgrades at launch for any packages installed at that time .
Amazon Linux also notiﬁes you of any updates to the installed packages by listing the number of available updates upon login using the /etc/motd ﬁle .
To install these updates , you need to run sudo yum upgrade on the instance .
Repository conﬁguration With Amazon Linux , AMIs are treated as snapshots in time , with a repository and update structure that always gives you the latest packages when you run yum update -y .
The repository structure is conﬁgured to deliver a continuous ﬂow of updates that enable you to roll from one version of Amazon Linux to the next .
For example , if you launch an instance from an older 171 Amazon Elastic Compute Cloud User Guide for Linux Instances Extras library ( Amazon Linux 2 ) version of the Amazon Linux AMI ( such as 2017.09 or earlier ) and run yum update -y , you end up with the latest packages .
You can disable rolling updates by enabling the lock-on-launch feature .
The lock-on-launch feature locks your instance to receive updates only from the speciﬁed release of the AMI .
For example , you can launch a 2017.09 AMI and have it receive only the updates that were released prior to the 2018.03 AMI , until you are ready to migrate to the 2018.03 AMI .
Important If you lock to a version of the repositories that is not the latest , you do not receive further updates .
To receive a continuous ﬂow of updates , you must use the latest AMI , or consistently update your AMI with the repositories pointed to latest .
Extras library ( Amazon Linux 2 ) With Amazon Linux 2 , you can use the Extras Library to install application and software updates on your instances .
These software updates are known as topics .
You can install a speciﬁc version of a topic or omit the version information to use the most recent version .
Source packages are available for all of the packages included in Amazon Linux and the online package repository .
Simply determine the package name for the source package you want to install and use the yumdownloader -- source command to view source within your running instance .
After you ﬁnish debugging , the package is available for use .
It enables you to specify actions that should happen to your instance at boot time .
You can pass desired actions to cloud-init through the user data ﬁelds when launching an instance .
This means you can use common AMIs for many use cases and conﬁgure them dynamically at startup .
They are read in lexical order , and later ﬁles overwrite values in earlier ﬁles .
• Instance store volumes that support TRIM are not formatted when an instance launches , so you must partition and format them before you can mount them .
You can use the disk_setup module to partition and format your instance store volumes at boot .
Each part of the multipart ﬁle can be handled by cloud-init if it is one of the supported formats .
If it understands the decoded data , it decodes the data and handles it appropriately .
This occurs late in the boot process ( after the initial conﬁguration actions are performed ) .
Each of the URLs is read , and their content passed through this same set of rules .
There is no mechanism provided for running it only one time .
The boothook must take care of this itself .
It is provided with the instance ID in the environment variable INSTANCE_ID .
Subscribing to Amazon Linux notiﬁcations To be notiﬁed when new AMIs are released , you can subscribe using Amazon SNS .
You must select the Region in which the SNS notiﬁcation that you are subscribing to was created .
d. For Endpoint , enter an email address that you can use to receive the notiﬁcations .
Open the email and choose Conﬁrm subscription to complete your subscription .
Whenever AMIs are released , we send notiﬁcations to the subscribers of the corresponding topic .
To stop receiving these notiﬁcations , use the following procedure to unsubscribe .
You must use the Region in which the SNS notiﬁcation was created .
Note The seed.iso boot image includes only the conﬁguration information required to boot the VM .
It does not include the Amazon Linux 2 operating system ﬁles .
To generate the seed.iso boot image , you need two conﬁguration ﬁles : • meta-data—This ﬁle includes the hostname and static network settings for the VM .
You use the user-data conﬁguration ﬁle to set the password for the default user account .
Create a new folder named seedconfig and navigate into it .
Open the meta-data ﬁle using your preferred editor and add the following .
You can configure static network settings with an entry like the following .
Open the user-data ﬁle using your preferred editor and add the following .
Add the following to prevent cloud-init from applying network settings at each boot , and to retain the network settings applied during the ﬁrst boot .
You can also create additional user accounts and specify their access mechanisms , passwords , and key pairs .
For more information about the supported directives , see Modules .
For an example userdata ﬁle that creates three additional users and speciﬁes a custom password for the default ec2user user account , see the sample Seed.iso ﬁle .
Navigate into the seedconfig folder , and execute the following command .
Navigate one level up from the seedconfig folder , and execute the following command .
The steps vary depending on your chosen VM platform .
You must connect the seed.iso boot image to the VM on ﬁrst boot .
After the VM has booted , log in using one of the user accounts that is deﬁned in the user-data conﬁguration ﬁle .
For virtualization platforms other than VMWare , you can disconnect the seed.iso boot image from the VM after you have logged in for the ﬁrst time .
User provided kernels If you have a need for a custom kernel on your Amazon EC2 instances , you can start with an AMI that is close to what you want , compile the custom kernel on your instance , and modify the menu.lst ﬁle to 177 Amazon Elastic Compute Cloud User Guide for Linux Instances HVM AMIs ( GRUB ) point to the new kernel .
This process varies depending on the virtualization type that your AMI uses .
The boot process is similar to that of a bare metal operating system with a partitioned disk and bootloader , which allows it to work with all currently supported Linux distributions .
The most common bootloader is GRUB , and the following section describes conﬁguring GRUB to use a custom kernel .
Conﬁguring GRUB for HVM AMIs The following is an example of a menu.lst conﬁguration ﬁle for an HVM AMI .
The Vanilla entry was copied from the original entry for this AMI , and the kernel and initrd paths were updated to the new locations .
The default 0 parameter points the bootloader to the ﬁrst entry that it sees ( in this case , the Vanilla entry ) , and the fallback 1 parameter points the bootloader to the next entry if there is a problem booting the ﬁrst .
By default , GRUB does not send its output to the instance console because it creates an extra boot delay .
If you are installing a custom kernel , you should consider enabling GRUB output by deleting the hiddenmenu line and adding serial and terminal lines to /boot/grub/menu.lst as shown in the example below .
Important Avoid printing large amounts of debug information during the boot process ; the serial console does not support high rate data transfer .
GRUB can fall back to another kernel in the event that the new kernel fails .
Having a fallback kernel allows the instance to boot even if the new kernel is n't found .
If your new Vanilla Linux kernel fails , the output will be similar to the example below .
When you start an instance , PV-GRUB starts the boot process and then chain loads the kernel speciﬁed by your image 's menu.lst ﬁle .
Most modern paravirtual AMIs use a PV-GRUB AKI by default ( including all of the paravirtual Linux AMIs available in the Amazon EC2 Launch Wizard Quick Start menu ) , so there are no additional steps that you need to take to use a diﬀerent kernel on your instance , provided that the kernel you want to use is compatible with your distribution .
The best way to run a custom kernel on your instance is to start with an AMI that is close to what you want and then to compile the custom kernel on your instance and modify the menu.lst ﬁle as shown in Conﬁguring GRUB ( p. 180 ) to boot with that kernel .
You can verify that the kernel image for an AMI is a PV-GRUB AKI by executing the following describeimages command with the Amazon EC2 command line tools ( substituting the kernel image ID you want to check : aws ec2 describe-images -- filters Name=image-id , Values=aki-880531cd Check whether the Name ﬁeld starts with pv-grub .
Other ﬁle system formats might not work .
While paravirtual instances use PV-GRUB to boot , HVM instance volumes are treated like actual disks , and the boot process is similar to the boot process of a bare metal operating system with a partitioned disk and bootloader .
Then you can create logical volumes with the LVM .
The Vanilla entry was copied from the original entry for this AMI , and the kernel and initrd paths were updated to the new locations .
The default 0 parameter points the bootloader to the ﬁrst entry it sees ( in this case , the Vanilla entry ) , and the fallback 1 parameter points the bootloader to the next entry if there is a problem booting the ﬁrst .
PV-GRUB can fall back to another kernel in the event that the new kernel fails .
Having a fallback kernel allows the instance to boot even if the new kernel is n't found .
We recommend that you always use the latest version of the PV-GRUB AKI , as not all versions of the PVGRUB AKI are compatible with all instance types .
You should verify that any AMI you want to copy to this Region is using a version of PV-GRUB that is available in this Region .
The following are the current AKI IDs for each Region .
Note We continue to provide hd00 AKIs for backward compatibility in regions where they were previously available .
Also , older versions of PV-GRUB are not available in all regions , so if you copy an AMI that uses an older version to a Region that does not support that version , you will be unable to boot instances launched from that AMI until you update the kernel image .
Use the following procedures to check your instance 's version of PV-GRUB and update it if necessary .
Find the kernel ID for your instance .
View the version information of that kernel ID .
To update your PV-GRUB version If your instance is using an older version of PV-GRUB , you should update it to the latest version .
Your instance must be stopped to modify the kernel image used .
Modify the kernel image used for your instance .
What instance type best meets my needs ?
Amazon EC2 provides diﬀerent instance types to enable you to choose the CPU , memory , storage , and networking capacity that you need to run your applications .
What purchasing option best meets my needs ?
Which type of root volume meets my needs ?
Each instance is backed by Amazon EBS or backed by instance store .
Select an AMI based on which type of root volume you need .
AWS Systems Manager enables you to remotely and securely manage the conﬁguration of your Amazon EC2 instances , and your on-premises instances and virtual machines ( VMs ) in hybrid environments , including VMs from other cloud providers .
For more information , see the AWS Systems Manager User Guide .
Instance types When you launch an instance , the instance type that you specify determines the hardware of the host computer used for your instance .
Each instance type oﬀers diﬀerent compute , memory , and storage capabilities and are grouped in instance families based on these capabilities .
Select an instance type based on the requirements of the application or software that you plan to run on your instance .
Amazon EC2 provides each instance with a consistent and predictable amount of CPU capacity , regardless of its underlying hardware .
Amazon EC2 shares other resources of the host computer , such as the network and the disk subsystem , among instances .
If each instance on a host computer tries to use as much of one of these shared resources as possible , each receives an equal share of that resource .
184 Amazon Elastic Compute Cloud User Guide for Linux Instances Available instance types Each instance type provides higher or lower minimum performance from a shared resource .
Allocating a larger share of shared resources also reduces the variance of I/O performance .
Current generation instances For the best performance , we recommend that you use the current generation instance types when you launch new instances .
To determine which instance types are available in which Regions or Availability Zones , use the describe-instance-type-oﬀerings command .
For more information about the current generation instance types , see Amazon EC2 Instance Types .
We encourage you to use the latest 186 Amazon Elastic Compute Cloud User Guide for Linux Instances Hardware speciﬁcations generation of instances to get the best performance , but we continue to support these previous generation instances .
If you are currently using a previous generation instance , you can see which current generation instance would be a suitable upgrade .
To determine which instance type best meets your needs , we recommend that you launch an instance and use your own benchmark application .
Because you pay by the instance second , it 's convenient and inexpensive to test multiple instance types before making a decision .
If your needs change , even after you make a decision , you can resize your instance later .
Note Amazon EC2 instances typically run on 64-bit virtual Intel processors as speciﬁed in the instance type product pages .
For more information about the hardware speciﬁcations for each Amazon EC2 instance type , see Amazon EC2 Instance Types .
Chip manufacturer Advanced Micro Devices ( AMD ) introduced the ﬁrst commercially successful 64-bit architecture based on the Intel x86 instruction set .
Consequently , the architecture is widely referred to as AMD64 regardless of the chip manufacturer .
Windows and several Linux distributions follow this practice .
This explains why the internal system information on an Ubuntu or Windows EC2 instance displays the CPU architecture as AMD64 even though the instances are running on Intel hardware .
AMI virtualization types The virtualization type of your instance is determined by the AMI that you use to launch it .
Some previous generation instance types support paravirtual ( PV ) and some AWS regions support PV instances .
For best performance , we recommend that you use an HVM AMI .
In addition , HVM AMIs are required to take advantage of enhanced networking .
HVM virtualization uses hardware-assist technology provided by the AWS platform .
With HVM virtualization , the guest VM runs as if it were on a native hardware platform , except that it still uses PV network and storage drivers for improved performance .
187 Amazon Elastic Compute Cloud User Guide for Linux Instances Instances built on the Nitro System Instances built on the Nitro System The Nitro System is a collection of AWS-built hardware and software components that enable high performance , high availability , and high security .
In addition , the Nitro System provides bare metal capabilities that eliminate virtualization overhead and support workloads that require full access to host hardware .
Nitro components The following components are part of the Nitro System : • Nitro card • Local NVMe storage volumes • Networking hardware support • Management • Monitoring • Security • Nitro security chip , integrated into the motherboard • Nitro hypervisor - A lightweight hypervisor that manages memory and CPU allocation and delivers performance that is indistinguishable from bare metal for most workloads .
• To maximize the networking and bandwidth performance of your instance type , you can do the following : • Launch supported instance types into a cluster placement group to optimize your instances for high performance computing ( HPC ) applications .
Instances in a common cluster placement group 188 Amazon Elastic Compute Cloud User Guide for Linux Instances Networking and storage features can beneﬁt from high-bandwidth , low-latency networking .
• Enable enhanced networking for supported current generation instance types to get signiﬁcantly higher packet per second ( PPS ) performance , lower network jitter , and lower latencies .
• Current generation instance types that are enabled for enhanced networking have the following networking performance attributes : • Traﬃc within the same Region over private IPv4 or IPv6 can support 5 Gbps for single-ﬂow traﬃc and up to 25 Gbps for multi-ﬂow traﬃc ( depending on the instance type ) .
• Traﬃc to and from Amazon S3 buckets within the same Region over the public IP address space or through a VPC endpoint can use all available instance aggregate bandwidth .
All current generation instances support 9001 MTU , or jumbo frames , and some previous generation instances support them as well .
Storage features • Some instance types support EBS volumes and instance store volumes , while other instance types support only EBS volumes .
Some instance types that support instance store volumes use solid state drives ( SSD ) to deliver very high random I/O performance .
Some instance types support NVMe instance store volumes .
Some instance types support NVMe EBS volumes .
Summary of networking and storage features The following table summarizes the networking and storage features supported by current generation instance types .
190 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance limits The following table summarizes the networking and storage features supported by previous generation instance types .
Instance store Placement group Enhanced networking C3 SSD Yes Intel 82599 VF G2 SSD Yes No I2 SSD Yes Intel 82599 VF M3 SSD No No R3 SSD Yes Intel 82599 VF Instance limits There is a limit on the total number of instances that you can launch in a region , and there are additional limits on some instance types .
For more information about the default limits , see How many instances can I run in Amazon EC2 ?
General purpose instances General purpose instances provide a balance of compute , memory , and networking resources , and can be used for a variety of workloads .
These instances provide an ideal cloud infrastructure , oﬀering a balance of compute , memory , and networking resources for a broad range of applications that are deployed in the cloud .
Bare metal instances , such as m5.metal , provide your applications with direct access to physical resources of the host server , such as processors and memory .
These instances are well suited for the following : • Workloads that require access to low-level hardware features ( for example , Intel VT ) that are not available or fully supported in virtualized environments • Applications that require a non-virtualized environment for licensing or support A1 instances These instances are ideally suited for scale-out workloads that are supported by the Arm ecosystem .
These instances are well-suited for the following applications : 191 Amazon Elastic Compute Cloud User Guide for Linux Instances General purpose instances • Web servers • Containerized microservices • Caching ﬂeets • Distributed data stores Bare metal instances , such as a1.metal , provide your applications with direct access to physical resources of the host server , such as processors and memory .
An Unlimited instance can sustain high CPU performance for any period of time whenever required .
Instance performance EBS-optimized instances enable you to get consistently high performance for your EBS volumes by eliminating contention between Amazon EBS I/O and other network traﬃc from your instance .
Some general purpose instances are EBS-optimized by default at no additional cost .
Some general purpose instance types provide the ability to control processor C-states and P-states on Linux .
Network performance You can enable enhanced networking on supported instance types to provide lower latencies , lower network jitter , and higher packet-per-second ( PPS ) performance .
Most applications do not consistently need a high level of network performance , but can beneﬁt from access to increased bandwidth when they send or receive data .
The following is a summary of network performance for general purpose instances that support enhanced networking .
They accrue credits when their bandwidth is below their baseline bandwidth , and can use these credits when they perform network data transfers .
For more information , 196 Amazon Elastic Compute Cloud User Guide for Linux Instances General purpose instances open a support case and ask about baseline bandwidth for the speciﬁc instance types that you are interested in .
SSD I/O performance If you use a Linux AMI with kernel version 4.4 or later and use all the SSD-based instance store volumes available to your instance , you get the IOPS ( 4,096 byte block size ) performance listed in the following table ( at queue depth saturation ) .
As you ﬁll the SSD-based instance store volumes for your instance , the number of write IOPS that you can achieve decreases .
This is due to the extra work the SSD controller must do to ﬁnd available space , rewrite existing data , and erase unused space so that it can be rewritten .
This process of garbage collection results in internal write ampliﬁcation to the SSD , expressed as the ratio of SSD write operations to user write operations .
This decrease in performance is even larger if the write operations are not in multiples of 4,096 bytes or not aligned to a 4,096-byte boundary .
If you write a smaller amount of bytes or bytes that are not aligned , the SSD controller must read the surrounding data and store the result in a new location .
SSD controllers can use several strategies to reduce the impact of write ampliﬁcation .
One such strategy is to reserve space in the SSD instance storage so that the controller can more eﬃciently manage the space available for write operations .
To reduce write ampliﬁcation , we recommend that you leave 10 % of the volume unpartitioned so that the SSD controller can use it for over-provisioning .
This decreases the storage that you can use , but increases performance even if the disk is close to full capacity .
For instance store volumes that support TRIM , you can use the TRIM command to notify the SSD controller whenever you no longer need data that you 've written .
This provides the controller with more free space , which can reduce write ampliﬁcation and increase performance .
Instance features The following is a summary of features for general purpose instances : EBS only NVMe EBS Instance store Placement group A1 Yes Yes No Yes M4 Yes No No Yes M5 Yes Yes No Yes M5a Yes Yes No Yes M5ad No Yes NVMe * Yes M5d No Yes NVMe * Yes M5dn No Yes NVMe * Yes M5n Yes Yes No Yes T2 Yes No No No T3 Yes Yes No No T3a Yes Yes No No * The root device volume must be an Amazon EBS volume .
In addition , you must use an HVM AMI to take advantage of enhanced networking .
• Support booting through UEFI with ACPI tables and support ACPI hot-plug of PCI devices .
• Launching a bare metal instance boots the underlying server , which includes verifying all hardware and ﬁrmware components .
This means that it can take 20 minutes from the time the instance enters the running state until it becomes available over the network .
• To attach or detach EBS volumes or secondary network interfaces from a bare metal instance requires PCIe native hotplug support .
Amazon Linux 2 and the latest versions of the Amazon Linux AMI support PCIe native hotplug , but earlier versions do not .
The upstream Linux kernel and the latest Amazon Linux AMIs support this device .
Bare metal instances also provide an ACPI SPCR table to enable the system to automatically use the PCI-based serial device .
The latest Windows AMIs automatically use the PCI-based serial device .
• Instances built on the Nitro System should have system-logind or acpid installed to support clean shutdown through API requests .
• There is a limit on the total number of instances that you can launch in a Region , and there are additional limits on some instance types .
Burstable performance instances are the only instance types that use credits for CPU usage .
For more information about instance pricing and additional hardware details , see Amazon EC2 Pricing and Amazon EC2 Instance Types .
If your account is less than 12 months old , you can use a t2.micro instance for free within certain usage limits .
• Ensure that the instance size you choose passes the minimum memory requirements of your operating system and applications .
Operating systems with graphical user interfaces that consume signiﬁcant memory and CPU resources ( for example , Windows ) might require a t2.micro or larger instance size for many use cases .
As the memory and CPU requirements of your workload grow over time , you can scale to larger instance sizes of the same instance type , or another instance type .
Best practices Follow these best practices to get the maximum beneﬁt from burstable performance instances .
200 Amazon Elastic Compute Cloud User Guide for Linux Instances General purpose instances • Use a recommended AMI – Use an AMI that provides the required drivers .
• Turn on instance recovery – Create a CloudWatch alarm that monitors an EC2 instance and automatically recovers it if it becomes impaired for any reason .
CPU credits and baseline performance for burstable performance instances Traditional Amazon EC2 instance types provide ﬁxed performance , while burstable performance instances provide a baseline level of CPU performance with the ability to burst above that baseline level .
The baseline performance and ability to burst are governed by CPU credits .
Other combinations of number of vCPUs , utilization , and time can also equate to one CPU credit .
For example , one CPU credit is equal to one vCPU running at 50 % utilization for two minutes , or two vCPUs running at 25 % utilization for two minutes .
The accounting process for whether credits are accrued or spent also happens at a millisecond-level resolution , so you do n't have to worry about overspending CPU credits ; a short burst of CPU uses a small fraction of a CPU credit .
If a burstable performance instance uses fewer CPU resources than is required for baseline performance ( such as when it is idle ) , the unspent CPU credits are accrued in the CPU credit balance .
If a burstable performance instance needs to burst above the baseline performance level , it spends the accrued credits .
The more credits that a burstable performance instance has accrued , the more time it can burst beyond its baseline when more performance is needed .
The following table lists the burstable performance instance types , the rate at which CPU credits are earned per hour , the maximum number of earned CPU credits that an instance can accrue , the number of vCPUs per instance , and the baseline performance level as a percentage of a full core performance ( using a single vCPU ) .
** The baseline performance in the table is per vCPU .
For instance sizes that have more than one vCPU , to calculate the baseline CPU utilization for the instance , multiply the vCPU percentage by the number of vCPUs .
CPU credit earn rate The number of CPU credits earned per hour is determined by the instance size .
The preceding table lists the credit earn rate for all instances .
202 Amazon Elastic Compute Cloud User Guide for Linux Instances General purpose instances CPU credit accrual limit While earned credits never expire on a running instance , there is a limit to the number of earned credits that an instance can accrue .
The limit is determined by the CPU credit balance limit .
After the limit is reached , any new credits that are earned are discarded , as indicated by the following image .
The full bucket indicates the CPU credit balance limit , and the spillover indicates the newly earned credits that exceed the limit .
The CPU credit balance limit diﬀers for each instance size .
The preceding table lists the maximum number of earned credits that each instance can accrue .
Launch credits do not count towards the CPU credit balance limit .
If a T2 instance has not spent its launch credits , and remains idle over a 24hour period while accruing earned credits , its CPU credit balance appears as over the limit .
These instances launch as unlimited by default , and therefore can burst immediately upon start without any launch credits .
Accrued CPU credits life span CPU credits on a running instance do not expire .
For T3 and T3a , the CPU credit balance persists for seven days after an instance stops and the credits are lost thereafter .
If you start the instance within seven days , no credits are lost .
For T2 , the CPU credit balance does not persist between instance stops and starts .
Baseline performance The number of credits that an instance earns per hour can be expressed as a percentage of CPU utilization .
It is known as the baseline performance , and sometimes just as the baseline .
203 Amazon Elastic Compute Cloud User Guide for Linux Instances General purpose instances Unlimited mode for burstable performance instances A burstable performance instance conﬁgured as unlimited can sustain high CPU performance for any period of time whenever required .
The hourly instance price automatically covers all CPU usage spikes if the average CPU utilization of the instance is at or below the baseline over a rolling 24-hour period or the instance lifetime , whichever is shorter .
For the vast majority of general-purpose workloads , instances conﬁgured as unlimited provide ample performance without any additional charges .
If the instance runs at higher CPU utilization for a prolonged period , it can do so for a ﬂat additional rate per vCPU-hour .
If you launch T3 Spot Instances as unlimited and plan to use them immediately and for a short duration , with no idle time for accruing CPU credits , you will incur charges for surplus credits .
If the average CPU usage over a 24-hour period exceeds the baseline , you will also incur charges for surplus credits .
It can be enabled or disabled at any time for a running or stopped instance .
You can set unlimited as the default credit option at the account level per AWS Region , per burstable performance instance family , so that all new burstable performance instances in the account launch using the default credit option .
You can change the default at the account level per AWS Region .
How Unlimited burstable performance instances work If a burstable performance instance conﬁgured as unlimited depletes its CPU credit balance , it can spend surplus credits to burst beyond the baseline .
When its CPU utilization falls below the baseline , 204 Amazon Elastic Compute Cloud User Guide for Linux Instances General purpose instances it uses the CPU credits that it earns to pay down the surplus credits that it spent earlier .
The ability to earn CPU credits to pay down surplus credits enables Amazon EC2 to average the CPU utilization of an instance over a 24-hour period .
If the average CPU usage over a 24-hour period exceeds the baseline , the instance is billed for the additional usage at a ﬂat additional rate per vCPU-hour .
If the instance runs at 30 % CPU utilization or less on average over a 24-hour period , there is no additional charge because the cost is already covered by the instance hourly price .
For more information about the baseline performance per vCPU for each instance type and how many credits each instance type earns , see the credit table ( p. 201 ) .
When to use unlimited mode versus ﬁxed CPU When determining whether you should use a burstable performance instance in unlimited mode , such as a T3 , or a ﬁxed performance instance , such as an M5 , you need to determine the breakeven CPU usage .
The breakeven CPU usage for a burstable performance instance is the point at which a burstable performance instance costs the same as a ﬁxed performance instance .
The breakeven CPU usage helps you determine the following : • If the average CPU usage over a 24-hour period is at or below the breakeven CPU usage , use a burstable performance instance in unlimited mode so that you can beneﬁt from the lower price of a burstable performance instance while getting the same performance as a ﬁxed performance instance .
• If the average CPU usage over a 24-hour period is above the breakeven CPU usage , the burstable performance instance will cost more than the equivalently-sized ﬁxed performance instance .
The following graph shows the breakeven CPU usage point where a t3.large costs the same as an m5.large .
If the workload needs less than 42.5 % average CPU usage , you can beneﬁt from the lower price of the t3.large while getting the same performance as an m5.large .
205 Amazon Elastic Compute Cloud User Guide for Linux Instances General purpose instances The following table shows how to calculate the breakeven CPU usage threshold so that you can determine when it 's less expensive to use a burstable performance instance in unlimited mode or a ﬁxed performance instance .
At the baseline , the hourly cost of the instance covers the cost of the CPU usage .
• Column G shows the ﬂat additional rate per vCPU-hour that an instance is charged if it bursts at 100 % CPU after it has depleted its earned credits .
• Column H shows the ﬂat additional rate per vCPU-minute that an instance is charged if it bursts at 100 % CPU after it has depleted its earned credits .
• Column I shows the number of additional minutes that the t3.large can burst per hour at 100 % CPU while paying the same price per hour as an m5.large .
However , if CPU utilization stays above the baseline , the instance can not earn enough credits to pay down the surplus credits that it has spent .
The surplus credits that are not paid down are charged at a ﬂat additional rate per vCPU-hour .
Surplus credits that were spent earlier are charged when any of the following occurs : • The spent surplus credits exceed the maximum number of credits ( p. 201 ) the instance can earn in a 24-hour period .
Spent surplus credits above the maximum are charged at the end of the hour .
207 Amazon Elastic Compute Cloud User Guide for Linux Instances General purpose instances Spent surplus credits are tracked by the CloudWatch metric CPUSurplusCreditBalance .
Surplus credits that are charged are tracked by the CloudWatch metric CPUSurplusCreditsCharged .
A T2 Unlimited instance can burst beyond the baseline at any time with no additional charge , as long as its average CPU utilization is at or below the baseline over a rolling 24-hour window or its lifetime , whichever is shorter .
As such , T2 Unlimited instances do not require launch credits to achieve high performance immediately after launch .
If a T2 instance is switched from standard to unlimited , any accrued launch credits are removed from the CPUCreditBalance before the remaining CPUCreditBalance is carried over .
T2 instances launch as standard by default , but you can enable unlimited at launch .
You can switch from unlimited to standard , and from standard to unlimited , at any time on a running or stopped instance .
You can set unlimited as the default credit option at the account level per AWS Region , per burstable performance instance family , so that all new burstable performance instances in the account launch using the default credit option .
You can check whether your burstable performance instance is conﬁgured as unlimited or standard using the Amazon EC2 console or the AWS CLI .
What happens to credits when switching between Unlimited and Standard CPUCreditBalance is a CloudWatch metric that tracks the number of credits accrued by an instance .
CPUSurplusCreditBalance is a CloudWatch metric that tracks the number of surplus credits spent by an instance .
When you change an instance conﬁgured as unlimited to standard , the following occurs : • The CPUCreditBalance value remains unchanged and is carried over .
When a standard instance is switched to unlimited , the following occurs : • The CPUCreditBalance value containing accrued earned credits is carried over .
• For T2 Standard instances , any launch credits are removed from the CPUCreditBalance value , and the remaining CPUCreditBalance value containing accrued earned credits is carried over .
Monitoring credit usage To see if your instance is spending more credits than the baseline provides , you can use CloudWatch metrics to track usage , and you can set up hourly alarms to be notiﬁed of credit usage .
208 Amazon Elastic Compute Cloud User Guide for Linux Instances General purpose instances Unlimited mode examples The following examples explain credit use for instances that are conﬁgured as unlimited .
When it depletes its CPU credit balance ( represented by the CloudWatch metric CPUCreditBalance ) , it can spend surplus CPU credits—that it has not yet earned—to burst for as long as it needs .
If it spends more than 144 CPU credits , it is charged for the diﬀerence at the end of the hour .
The intent of the example , illustrated by the following graph , is to show how an instance can burst using surplus credits even after it depletes its CPUCreditBalance .
The following workﬂow references the numbered points on the graph : P1 – At 0 hours on the graph , the instance is launched as unlimited and immediately begins to earn credits .
All unspent credits are accrued in the credit balance .
The instance earns more credits than it spends , but the CPUCreditBalance value can not exceed its maximum of 144 credits .
The instance spends more credits than it earns , and the CPUCreditBalance value reduces to 86.4 credits .
The instance earns more credits than it spends , and the CPUCreditBalance value increases to 122 credits .
About an hour into this period , the instance depletes its entire CPUCreditBalance of 122 credits , and starts to spend surplus credits to sustain the high CPU performance , totaling 448 surplus credits in this period ( 570-122=448 ) .
The instance earns as many credits as it spends , with no excess to pay down the CPUSurplusCreditBalance .
During this time , the instance earns 144 credits , which it uses to pay down the CPUSurplusCreditBalance .
209 Amazon Elastic Compute Cloud User Guide for Linux Instances General purpose instances Example 2 : Explaining credit use with T2 Unlimited In this example , you see the CPU utilization of a t2.nano instance launched as unlimited , and how it spends earned and surplus credits to sustain CPU performance .
When it depletes its CPU credit balance ( represented by the CloudWatch metric CPUCreditBalance ) , it can spend surplus CPU credits—that it has not yet earned—to burst for as long as it needs .
If it spends more than 72 CPU credits , it is charged for the diﬀerence at the end of the hour .
The intent of the example , illustrated by the following graph , is to show how an instance can burst using surplus credits even after it depletes its CPUCreditBalance .
You can assume that , at the start of the time line in the graph , the instance has an accrued credit balance equal to the maximum number of credits it can earn in 24 hours .
Any surplus 210 Amazon Elastic Compute Cloud User Guide for Linux Instances General purpose instances credits spent thereafter can not be oﬀset by earned credits within the 24-hour period , which results in a small additional charge at the end of the hour .
At this time , CPU utilization falls below the baseline , and the instance starts to earn credits at 3 credits per hour ( or 0.25 credits every 5 minutes ) , which it uses to pay down the CPUSurplusCreditBalance .
After the CPUSurplusCreditBalance value reduces to 0 , the instance starts to accrue earned credits in its CPUCreditBalance at 0.25 credits every 5 minutes .
Here is the month-end bill for this T2 Unlimited instance : 211 Amazon Elastic Compute Cloud User Guide for Linux Instances General purpose instances You can set billing alerts to be notiﬁed every hour of any accruing charges , and take action if required .
Standard mode for burstable performance instances A burstable performance instance conﬁgured as standard is suited to workloads with an average CPU utilization that is consistently below the baseline performance of the instance .
To burst above the baseline , the instance spends credits that it has accrued in its CPU credit balance .
If the instance is running low on accrued credits , performance is gradually lowered to the baseline performance level , so that the instance does not experience a sharp performance drop-oﬀ when its accrued CPU credit balance is depleted .
It can be enabled or disabled at any time for a running or stopped instance .
You can set standard as the default credit option at the account level per AWS Region , per burstable performance instance family , so that all new burstable performance instances in the account launch using the default credit option .
You can change the default at the account level per AWS Region .
For T2 Standard , when the instance is stopped , it loses all its accrued credits , and its credit balance is reset to zero .
When it is 212 Amazon Elastic Compute Cloud User Guide for Linux Instances General purpose instances restarted , it receives a new set of launch credits , and begins to accrue earned credits .
For T3 and T3a Standard , the CPU credit balance persists for seven days after the instance stops and the credits are lost thereafter .
If you start the instance within seven days , no credits are lost .
At start , it has not yet earned credits for a good startup experience ; therefore , to provide a good startup experience , it receives launch credits at start , which it spends ﬁrst while it accrues earned credits .
Launch credits T2 Standard instances get 30 launch credits per vCPU at launch or start .
Launch credits are designed to provide a good startup experience to allow instances to burst immediately after launch before they have accrued earned credits .
Unspent launch credits are accrued in the CPU credit balance , but do not count towards the CPU credit balance limit .
The following table lists the initial CPU credit allocation received at launch or start , and the number of vCPUs .
New accounts may have a lower limit , which increases over time based on your usage .
Tip To ensure that your workloads always get the performance they need , switch to Unlimited mode for burstable performance instances ( p. 204 ) or consider using a larger instance size .
213 Amazon Elastic Compute Cloud User Guide for Linux Instances General purpose instances Diﬀerences between launch credits and earned credits The following table lists the diﬀerences between launch credits and earned credits .
Credit earn rate Launch credits Earned credits T2 Standard instances get 30 launch credits per vCPU at launch or start .
If a T2 instance is switched from unlimited to standard , it does not get launch credits at the time of switching .
Credit earn limit The limit for receiving launch credits is 100 launches or starts of all T2 Standard instances combined per account , per Region , per rolling 24-hour period .
New accounts may have a lower limit , which increases over time based on your usage .
A T2 instance can not accrue more credits than the CPU credit balance limit .
If the CPU credit balance has reached its limit , any credits that are earned after the limit is reached are discarded .
Launch credits do not count towards the limit .
Credit use Launch credits are spent ﬁrst , before earned credits .
Earned credits are spent only after all launch credits are spent .
The number of accrued launch credits and accrued earned credits is tracked by the CloudWatch metric CPUCreditBalance .
Standard mode examples The following examples explain credit use when instances are conﬁgured as standard .
You see how the credit balance reﬂects the accrued earned credits .
After the limit is reached , new credits that are earned are discarded .
214 Amazon Elastic Compute Cloud User Guide for Linux Instances General purpose instances You might launch a T3 Standard instance and use it immediately .
Or , you might launch a T3 Standard instance and leave it idle for a few days before running applications on it .
Whether an instance is used or remains idle determines if credits are spent or accrued .
If an instance remains idle for 24 hours from the time it is launched , the credit balance reaches it limit , which is the maximum number of earned credits that can be accrued .
This example describes an instance that remains idle for 24 hours from the time it is launched , and walks you through seven periods of time over a 96-hour period , showing the rate at which credits are earned , accrued , spent , and discarded , and the value of the credit balance at the end of each period .
The following workﬂow references the numbered points on the graph : P1 – At 0 hours on the graph , the instance is launched as standard and immediately begins to earn credits .
All unspent credits are accrued in the credit balance .
The instance earns more credits than it spends , but the CPUCreditBalance value can not exceed its maximum of 144 credits .
Any credits that are earned in excess of the limit are discarded .
The instance spends more credits than it earns , and the CPUCreditBalance value reduces to 86.4 credits .
The instance earns more credits than it spends , and the CPUCreditBalance value increases to 122 credits .
At the end of this period , with the CPUCreditBalance at zero , CPU utilization is forced to drop to the baseline performance level of 5 % .
At the baseline , the instance earns as many credits as it spends .
The instance earns as many credits as it spends .
215 Amazon Elastic Compute Cloud User Guide for Linux Instances General purpose instances Example 2 : Explaining credit use with T2 Standard In this example , you see how a t2.nano instance launched as standard earns , accrues , and spends launch and earned credits .
You see how the credit balance reﬂects not only accrued earned credits , but also accrued launch credits .
Its credit balance limit is 72 earned credits ; launch credits do not count towards the limit .
After the limit is reached , new credits that are earned are discarded .
Or , you might launch a T2 Standard instance and leave it idle for a few days before running applications on it .
Whether an instance is used or remains idle determines if credits are spent or accrued .
If an instance remains idle for 24 hours from the time it is launched , the credit balance appears to exceed its limit because the balance reﬂects both accrued earned credits and accrued launch credits .
Thereafter , the limit always reﬂects the maximum number of earned credits that can be accrued .
This example describes an instance that remains idle for 24 hours from the time it is launched , and walks you through seven periods of time over a 96-hour period , showing the rate at which credits are earned , accrued , spent , and discarded , and the value of the credit balance at the end of each period .
It earns credits while in the running state .
All unspent credits are accrued in the credit balance .
In a real-world scenario , an EC2 instance consumes a small number of credits while launching and running , which prevents the balance from reaching the maximum theoretical value in this example .
The credit balance has reached its limit of 72 accrued earned credits , so newly earned credits are discarded .
After the limit is reached , newly earned credits are discarded .
Launch credits do not count towards the credit balance limit .
If the balance includes accrued launch credits , the balance appears to be over the limit .
The balance decreases because the accrued launch credits are spent ﬁrst , while newly earned credits are discarded because the credit balance is already at its limit of 72 earned credits .
Launch credits do not count towards the credit limit .
After the launch credits are spent , the balance can never go higher than what can be earned in 24 hours .
Furthermore , while an instance is running , it can not get more launch credits .
This is the same CPU utilization as in the previous period , but the balance does not decrease .
The balance does not decrease because the credit earn rate is higher than the credit spend rate .
However , the balance limit is 72 credits , so any earned credits that exceed the limit are discarded .
The balance plateaus at 72 credits , which is diﬀerent from the plateau of 102 credits during Period 2 , because there are no accrued launch credits .
If the instance earns more credits than it spends , newly earned credits over the limit are discarded .
The instance earns nine credits in the same three hours , which results in a net balance decrease of 27 credits .
At the end of three hours , the credit balance is 45 accrued earned credits .
In Period 3 , the accrued launch credits were spent , and any earned credits that exceeded the credit limit were discarded , resulting in a decrease in the credit balance .
Any earned credits that exceeded the limit were discarded , so the balance plateaued at its maximum of 72 credits .
In this period , there are no accrued launch credits , and the number of accrued earned credits in the balance is below the limit .
Furthermore , the instance earns more credits than it spends , resulting in an increase in the credit balance .
This is the same CPU utilization as in Period 2 , but the balance does not plateau at 102 credits—it plateaus at 72 credits , which is the credit balance limit for the instance .
After its credit balance limit is reached , any earned credits that exceed the limit are discarded .
After the limit is reached , newly earned credits are discarded .
The credit balance limit is determined by the number of credits that an instance can earn in 24 hours .
Working with burstable performance instances The steps for launching , monitoring , and modifying these instances are similar .
The key diﬀerence is the default credit speciﬁcation when they launch .
You must launch your instances using an Amazon EBS volume as the root device .
You can launch your instances as unlimited or standard using the Amazon EC2 console , an AWS SDK , a command line tool , or with an Auto Scaling group .
On the Choose an Instance Type page , select an instance type , and choose Next : Conﬁgure Instance Details .
Continue as prompted by the wizard .
When you 've ﬁnished reviewing your options on the Review Instance Launch page , choose Launch .
To launch a burstable performance instance as Unlimited or Standard ( AWS CLI ) 226 Amazon Elastic Compute Cloud User Guide for Linux Instances General purpose instances Use the run-instances command to launch your instances .
Valid credit speciﬁcations are unlimited and standard .
If you use an Auto Scaling group to launch your instances , we recommend that you conﬁgure your instances as unlimited .
If you do , the instances use surplus credits when they are automatically launched or restarted by the Auto Scaling group .
Using surplus credits prevents performance restrictions .
Creating a launch template You must use a launch template for launching instances as unlimited in an Auto Scaling group .
A launch conﬁguration does not support launching instances as unlimited .
Follow the Creating a Launch Template for an Auto Scaling Group procedure .
When you 've ﬁnished deﬁning the launch template parameters , choose Create launch template .
For more information , see Creating a Launch Template for an Auto Scaling Group in the Amazon EC2 Auto Scaling User Guide .
To create a launch template that launches instances as Unlimited ( AWS CLI ) Use the create-launch-template command and specify unlimited as the credit speciﬁcation .
227 Amazon Elastic Compute Cloud User Guide for Linux Instances General purpose instances To create an Auto Scaling group using a launch template ( console ) 1 .
On the navigation bar at the top of the screen , select the same Region that you used when you created the launch template .
In the navigation pane , choose Auto Scaling Groups , Create Auto Scaling group .
Choose Launch Template , select your launch template , and then choose Next Step .
Complete the ﬁelds for the Auto Scaling group .
When you 've ﬁnished reviewing your conﬁguration settings on the Review page , choose Create Auto Scaling group .
For more information , see Creating an Auto Scaling Group Using a Launch Template in the Amazon EC2 Auto Scaling User Guide .
On the navigation bar at the top of the screen , select the same Region that you used when you created the launch template .
From the Auto Scaling group list , select an Auto Scaling group , and choose Actions , Edit .
Viewing the credit speciﬁcation of a burstable performance instance You can view the credit speciﬁcation ( unlimited or standard ) of a running or stopped instance .
In the left navigation pane , choose Instances and select the instance .
• If the value is Enabled , then your instance is conﬁgured as unlimited .
• If the value is Disabled , then your instance is conﬁgured as standard .
If you do not specify one or more instance IDs , all instances with the credit speciﬁcation of unlimited are returned , as well as instances that were previously conﬁgured with the unlimited credit speciﬁcation .
In the left navigation pane , choose Instances and select the instance .
To modify the credit speciﬁcation for several instances at one time , select all applicable instances .
To change the credit speciﬁcation to unlimited , choose Enable .
To change the credit speciﬁcation to standard , choose Disable .
The current credit speciﬁcation for the instance appears in parentheses after the instance ID .
Valid credit speciﬁcations are unlimited and standard .
If you use the Launch Instance Wizard in the AWS Management Console to launch instances , the value for T2/T3 Unlimited overrides the account-level default credit speciﬁcation .
If you use the AWS CLI to 229 Amazon Elastic Compute Cloud User Guide for Linux Instances General purpose instances launch instances , all new burstable performance instances in the account launch using the default credit option .
The credit speciﬁcation for existing running or stopped instances is not aﬀected .
The modify-default-credit-specification API is an asynchronous operation , which works at an AWS Region level and modiﬁes the credit option for each Availability Zone .
All zones in a Region are updated within ﬁve minutes .
But if instances are launched during this operation , they might not get the new credit option until the zone is updated .
To verify whether the update has occurred , you can call get-default-credit-specification and check the default credit speciﬁcation for updates .
Note The default credit speciﬁcation for an instance family can be modiﬁed only once in a rolling 5minute period , and up to four times in a rolling 24-hour period .
To set the default credit speciﬁcation at the account level ( AWS CLI ) Use the modify-default-credit-speciﬁcation command .
Valid default credit speciﬁcations are unlimited and standard .
To view the default credit speciﬁcation at the account level ( AWS CLI ) Use the get-default-credit-speciﬁcation command .
Specify the AWS Region and instance family .
This balance is depleted when the CPU bursts and CPU credits are spent more quickly than they are earned .
• CPUSurplusCreditBalance – The number of surplus CPU credits spent to sustain CPU performance when the CPUCreditBalance value is zero .
230 Amazon Elastic Compute Cloud User Guide for Linux Instances General purpose instances The last two metrics apply only to instances conﬁgured as unlimited .
The following table describes the CloudWatch metrics for burstable performance instances .
Metric Description CPUCreditUsage The number of CPU credits spent by the instance for CPU utilization .
One CPU credit equals one vCPU running at 100 % utilization for one minute or an equivalent combination of vCPUs , utilization , and time ( for example , one vCPU running at 50 % utilization for two minutes or two vCPUs running at 25 % utilization for two minutes ) .
If you specify a period greater than ﬁve minutes , use the Sum statistic instead of the Average statistic .
Units : Credits ( vCPU-minutes ) CPUCreditBalance The number of earned CPU credits that an instance has accrued since it was launched or started .
For T2 Standard , the CPUCreditBalance also includes the number of launch credits that have been accrued .
Credits are accrued in the credit balance after they are earned , and removed from the credit balance when they are spent .
After the limit is reached , any new credits that are earned are discarded .
The credits in the CPUCreditBalance are available for the instance to spend to burst beyond its baseline CPU utilization .
When an instance is running , credits in the CPUCreditBalance do not expire .
Units : Credits ( vCPU-minutes ) CPUSurplusCreditBalance The number of surplus credits that have been spent by an unlimited instance when its CPUCreditBalance value is zero .
The CPUSurplusCreditBalance value is paid down by earned CPU credits .
If the number of surplus credits exceeds the maximum number of credits that the instance can earn in a 24-hour period , the spent surplus credits above the maximum incur an additional charge .
Units : Credits ( vCPU-minutes ) CPUSurplusCreditsCharged The number of spent surplus credits that are not paid down by earned CPU credits , and which thus incur an additional charge .
231 Amazon Elastic Compute Cloud User Guide for Linux Instances General purpose instances Metric Description Spent surplus credits are charged when any of the following occurs : • The spent surplus credits exceed the maximum number of credits that the instance can earn in a 24-hour period .
Spent surplus credits above the maximum are charged at the end of the hour .
Units : Credits ( vCPU-minutes ) Calculating CPU credit usage The CPU credit usage of instances is calculated using the instance CloudWatch metrics described in the preceding table .
Amazon EC2 sends the metrics to CloudWatch every ﬁve minutes .
A reference to the prior value of a metric at any point in time implies the previous value of the metric , sent ﬁve minutes ago .
Calculating CPU credit usage for Standard instances • The CPU credit balance increases if CPU utilization is below the baseline , when the credits spent are less than the credits earned in the prior ﬁve-minute interval .
• The CPU credit balance decreases if CPU utilization is above the baseline , when the credits spent are more than the credits earned in the prior ﬁve-minute interval .
Mathematically , this is captured by the following equation : Example CPUCreditBalance = prior CPUCreditBalance + [ Credits earned per hour * ( 5/60 ) CPUCreditUsage ] The size of the instance determines the number of credits that the instance can earn per hour and the number of earned credits that it can accrue in the credit balance .
To calculate the CPUCreditBalance value of the instance , use the preceding equation as follows : • CPUCreditBalance – The current credit balance to calculate .
In this example , the instance had accrued two credits .
Multiply the credits earned per hour by 5/60 ( ﬁve minutes ) to get the number of credits that the instance earned in the past ﬁve minutes .
• CPUCreditUsage – How many credits the instance spent in the past ﬁve minutes .
In this example , the instance spent one credit in the past ﬁve minutes .
When it depletes its accrued CPU credit balance , it can spend surplus credits to burst for as long as it needs .
When CPU utilization falls below the baseline , surplus credits are always paid down before the instance accrues earned credits .
We use the term Adjusted balance in the following equations to reﬂect the activity that occurs in this ﬁve-minute interval .
We use this value to arrive at the values for the CPUCreditBalance and CPUSurplusCreditBalance CloudWatch metrics .
A positive Adjusted balance value indicates that the instance accrued earned credits , and previous surplus credits , if any , were paid down .
Example CPUCreditBalance = min [ max earned credit balance , Adjusted balance ] CPUSurplusCreditBalance = 0 A negative Adjusted balance value indicates that the instance spent all its earned credits that it accrued and , in addition , also spent surplus credits for bursting .
As a result , the Adjusted balance value is assigned to CPUSurplusCreditBalance and CPUCreditBalance is set to 0 .
Example CPUSurplusCreditBalance = min [ max earned credit balance , -Adjusted balance ] CPUCreditBalance = 0 If the surplus credits spent exceed the maximum credits that the instance can accrue , the surplus credit balance is set to the maximum , as shown in the preceding equation .
The remaining surplus credits are charged as represented by the CPUSurplusCreditsCharged metric .
If the instance is switched from unlimited to standard , any remaining CPUSurplusCreditBalance is also charged .
233 Amazon Elastic Compute Cloud User Guide for Linux Instances Compute optimized instances Compute optimized instances Compute optimized instances are ideal for compute-bound applications that beneﬁt from highperformance processors .
Instance performance EBS-optimized instances enable you to get consistently high performance for your EBS volumes by eliminating contention between Amazon EBS I/O and other network traﬃc from your instance .
Some compute optimized instances are EBS-optimized by default at no additional cost .
Some compute optimized instance types provide the ability to control processor C-states and P-states on Linux .
Network performance You can enable enhanced networking on supported instance types to provide lower latencies , lower network jitter , and higher packet-per-second ( PPS ) performance .
Most applications do not consistently need a high level of network performance , but can beneﬁt from access to increased bandwidth when they send or receive data .
235 Amazon Elastic Compute Cloud User Guide for Linux Instances Compute optimized instances The following is a summary of network performance for compute optimized instances that support enhanced networking .
They accrue credits when their bandwidth is below their baseline bandwidth , and can use these credits when they perform network data transfers .
For more information , open a support case and ask about baseline bandwidth for the speciﬁc instance types that you are interested in .
SSD I/O performance If you use a Linux AMI with kernel version 4.4 or later and use all the SSD-based instance store volumes available to your instance , you get the IOPS ( 4,096 byte block size ) performance listed in the following table ( at queue depth saturation ) .
As you ﬁll the SSD-based instance store volumes for your instance , the number of write IOPS that you can achieve decreases .
This is due to the extra work the SSD controller must do to ﬁnd available space , rewrite existing data , and erase unused space so that it can be rewritten .
This process of garbage collection results in internal write ampliﬁcation to the SSD , expressed as the ratio of SSD write operations to user write operations .
This decrease in performance is even larger if the write operations are not in multiples of 4,096 bytes or not aligned to a 4,096-byte boundary .
If you write a smaller amount of bytes or bytes that are not aligned , the SSD controller must read the surrounding data and store the result in a new location .
SSD controllers can use several strategies to reduce the impact of write ampliﬁcation .
One such strategy is to reserve space in the SSD instance storage so that the controller can more eﬃciently manage the space available for write operations .
To reduce write ampliﬁcation , we recommend that you leave 10 % of the volume unpartitioned so that the SSD controller can use it for over-provisioning .
This decreases the storage that you can use , but increases performance even if the disk is close to full capacity .
For instance store volumes that support TRIM , you can use the TRIM command to notify the SSD controller whenever you no longer need data that you 've written .
This provides the controller with more free space , which can reduce write ampliﬁcation and increase performance .
Instance features The following is a summary of features for compute optimized instances : EBS only NVMe EBS Instance store Placement group C4 Yes No No Yes C5 Yes Yes No Yes C5d No Yes NVMe * Yes C5n Yes Yes No Yes * The root device volume must be an Amazon EBS volume .
In addition , you must use an HVM AMI to take advantage of enhanced networking .
• Launching a bare metal instance boots the underlying server , which includes verifying all hardware and ﬁrmware components .
This means that it can take 20 minutes from the time the instance enters the running state until it becomes available over the network .
• To attach or detach EBS volumes or secondary network interfaces from a bare metal instance requires PCIe native hotplug support .
Amazon Linux 2 and the latest versions of the Amazon Linux AMI support PCIe native hotplug , but earlier versions do not .
The upstream Linux kernel and the latest Amazon Linux AMIs support this device .
Bare metal instances also provide an ACPI SPCR table to enable the system to automatically use the PCI-based serial device .
The latest Windows AMIs automatically use the PCI-based serial device .
• Instances built on the Nitro System should have acpid installed to support clean shutdown through API requests .
• There is a limit on the total number of instances that you can launch in a Region , and there are additional limits on some instance types .
Memory optimized instances Memory optimized instances are designed to deliver fast performance for workloads that process large data sets in memory .
238 Amazon Elastic Compute Cloud User Guide for Linux Instances Memory optimized instances • In-memory databases using optimized data storage formats and analytics for business intelligence ( for example , SAP HANA ) .
Bare metal instances , such as r5.metal , provide your applications with direct access to physical resources of the host server , such as processors and memory .
These instances are well suited for the following : • Workloads that require access to low-level hardware features ( for example , Intel VT ) that are not available or fully supported in virtualized environments • Applications that require a non-virtualized environment for licensing or support For more information , see Amazon EC2 R5 Instances .
These instances are designed to run large in-memory databases , including production installations of SAP HANA .
They oﬀer bare metal performance with direct access to host hardware .
For more information , see SAP HANA on the AWS Cloud .
For more information , see SAP HANA on the AWS Cloud .
z1d instances These instances deliver both high compute and high memory and are well-suited for the following applications : • Electronic Design Automation ( EDA ) • Relational database workloads 239 Amazon Elastic Compute Cloud User Guide for Linux Instances Memory optimized instances z1d.metal instances provide your applications with direct access to physical resources of the host server , such as processors and memory .
These instances are well suited for the following : • Workloads that require access to low-level hardware features ( for example , Intel VT ) that are not available or fully supported in virtualized environments • Applications that require a non-virtualized environment for licensing or support For more information , see Amazon EC2 z1d Instances .
For more information about the hardware speciﬁcations for each Amazon EC2 instance type , see Amazon EC2 Instance Types .
Memory optimized instances have high memory and require 64-bit HVM AMIs to take advantage of that capacity .
HVM AMIs provide superior performance in comparison to paravirtual ( PV ) AMIs on memory optimized instances .
Instance performance R4 instances feature up to 64 vCPUs and are powered by two AWS-customized Intel XEON processors based on E5-2686v4 that feature high-memory bandwidth and larger L3 caches to boost the performance of in-memory applications .
X1e and X1 instances feature up to 128 vCPUs and are powered by four Intel Xeon E7-8880 v3 processors that feature high-memory bandwidth and larger L3 caches to boost the performance of inmemory applications .
Memory optimized instances enable increased cryptographic performance through the latest Intel AESNI feature , support Intel Transactional Synchronization Extensions ( TSX ) to boost the performance of inmemory transactional data processing , and support Advanced Vector Extensions 2 ( Intel AVX2 ) processor instructions to expand most integer commands to 256 bits .
Some memory optimized instances provide the ability to control processor C-states and P-states on Linux .
Network performance You can enable enhanced networking on supported instance types to provide lower latencies , lower network jitter , and higher packet-per-second ( PPS ) performance .
Most applications do not consistently need a high level of network performance , but can beneﬁt from access to increased bandwidth when they send or receive data .
The following is a summary of network performance for memory optimized instances that support enhanced networking .
They accrue credits when their bandwidth is below their baseline bandwidth , and can use these credits when they perform network data transfers .
For more information , open a support case and ask about baseline bandwidth for the speciﬁc instance types that you are interested in .
SSD I/O performance If you use a Linux AMI with kernel version 4.4 or later and use all the SSD-based instance store volumes available to your instance , you get the IOPS ( 4,096 byte block size ) performance listed in the following table ( at queue depth saturation ) .
As you ﬁll the SSD-based instance store volumes for your instance , the number of write IOPS that you can achieve decreases .
This is due to the extra work the SSD controller must do to ﬁnd available space , rewrite existing data , and erase unused space so that it can be rewritten .
This process of garbage collection results in internal write ampliﬁcation to the SSD , expressed as the ratio of SSD write operations to user write operations .
This decrease in performance is even larger if the write operations are not in multiples of 4,096 bytes or not aligned to a 4,096-byte boundary .
If you write a smaller amount of bytes or bytes that are not aligned , the SSD controller must read the surrounding data and store the result in a new location .
SSD controllers can use several strategies to reduce the impact of write ampliﬁcation .
One such strategy is to reserve space in the SSD instance storage so that the controller can more eﬃciently manage the space available for write operations .
To reduce write ampliﬁcation , we recommend that you leave 10 % of the volume unpartitioned so that the SSD controller 245 Amazon Elastic Compute Cloud User Guide for Linux Instances Memory optimized instances can use it for over-provisioning .
This decreases the storage that you can use , but increases performance even if the disk is close to full capacity .
For instance store volumes that support TRIM , you can use the TRIM command to notify the SSD controller whenever you no longer need data that you 've written .
This provides the controller with more free space , which can reduce write ampliﬁcation and increase performance .
Instance features The following is a summary of features for memory optimized instances .
EBS only NVMe EBS Instance store Placement group R4 Yes No No Yes R5 Yes Yes No Yes R5a Yes Yes No Yes R5ad No Yes NVME * Yes R5d No Yes NVME * Yes R5dn No Yes NVME * Yes R5n Yes Yes No Yes u-6tb1.metal Yes Yes No No u-9tb1.metal Yes Yes No No u-12tb1.metal Yes Yes No No u-18tb1.metal Yes Yes No No u-24tb1.metal Yes Yes No No X1 No No SSD Yes X1e No No SSD * Yes z1d No Yes NVME * Yes * The root device volume must be an Amazon EBS volume .
We strongly recommend that you use the latest AMIs when you launch memory optimized instances .
• Launching a bare metal instance boots the underlying server , which includes verifying all hardware and ﬁrmware components .
This means that it can take 20 minutes from the time the instance enters the running state until it becomes available over the network .
• To attach or detach EBS volumes or secondary network interfaces from a bare metal instance requires PCIe native hotplug support .
Amazon Linux 2 and the latest versions of the Amazon Linux AMI support PCIe native hotplug , but earlier versions do not .
The upstream Linux kernel and the latest Amazon Linux AMIs support this device .
Bare metal instances also provide an ACPI SPCR table to enable the system to automatically use the PCI-based serial device .
The latest Windows AMIs automatically use the PCI-based serial device .
If you experience this issue , update to the latest version of this AMI .
• There is a limit on the total number of instances that you can launch in a Region , and there are additional limits on some instance types .
Storage optimized instances Storage optimized instances are designed for workloads that require high , sequential read and write access to very large data sets on local storage .
D2 instances D2 instances are well suited for the following applications : • Massive parallel processing ( MPP ) data warehouse • MapReduce and Hadoop distributed computing • Log or data processing applications H1 instances H1 instances are well suited for the following applications : • Data-intensive workloads such as MapReduce and distributed ﬁle systems • Applications requiring sequential access to large amounts of data on direct-attached instance storage • Applications that require high-throughput access to large quantities of data I3 and I3en instances These instances are well suited for the following applications : • High frequency online transaction processing ( OLTP ) systems • Relational databases • NoSQL databases • Cache for in-memory databases ( for example , Redis ) • Data warehousing applications • Distributed ﬁle systems Bare metal instances provide your applications with direct access to physical resources of the host server , such as processors and memory .
These instances are well suited for the following : • Workloads that require access to low-level hardware features ( for example , Intel VT ) that are not available or fully supported in virtualized environments • Applications that require a non-virtualized environment for licensing or support For more information , see Amazon EC2 I3 Instances .
Instance store volumes persist only for the life of the instance .
When you stop or terminate an instance , the applications and data in its instance store volumes are erased .
We recommend that you regularly back up or replicate important data in your instance store volumes .
The following is a summary of the hardware speciﬁcations for storage optimized instances .
Instance performance To ensure the best disk throughput performance from your instance on Linux , we recommend that you use the most recent version of Amazon Linux 2 or the Amazon Linux AMI .
For instances with NVMe instance store volumes , you must use a Linux AMI with kernel version 4.4 or later .
Otherwise , your instance will not achieve the maximum IOPS performance available .
D2 instances provide the best disk performance when you use a Linux kernel that supports persistent grants , an extension to the Xen block ring protocol that signiﬁcantly improves disk throughput and scalability .
For more information about persistent grants , see this article in the Xen Project Blog .
EBS-optimized instances enable you to get consistently high performance for your EBS volumes by eliminating contention between Amazon EBS I/O and other network traﬃc from your instance .
Some storage optimized instances are EBS-optimized by default at no additional cost .
Some storage optimized instance types provide the ability to control processor C-states and P-states on Linux .
Network performance You can enable enhanced networking on supported instance types to provide lower latencies , lower network jitter , and higher packet-per-second ( PPS ) performance .
Most applications do not consistently need a high level of network performance , but can beneﬁt from access to increased bandwidth when they send or receive data .
The following is a summary of network performance for storage optimized instances that support enhanced networking .
They accrue credits when their bandwidth is below their baseline bandwidth , and can use these credits when they perform network data transfers .
For more information , open a support case and ask about baseline bandwidth for the speciﬁc instance types that you are interested in .
SSD I/O performance If you use a Linux AMI with kernel version 4.4 or later and use all the SSD-based instance store volumes available to your instance , you get the IOPS ( 4,096 byte block size ) performance listed in the following table ( at queue depth saturation ) .
This is due to the extra work that the SSD controller must do to ﬁnd available space , rewrite existing data , and erase unused space so that it can be rewritten .
This process of garbage collection results in internal write ampliﬁcation to the SSD , expressed as the ratio of SSD write operations to user write operations .
This decrease in performance is even larger if the write operations are not in multiples of 4,096 bytes or not aligned to a 4,096-byte boundary .
If you write a smaller amount of bytes or bytes that are not aligned , the SSD controller must read the surrounding data and store the result in a new location .
SSD controllers can use several strategies to reduce the impact of write ampliﬁcation .
One such strategy is to reserve space in the SSD instance storage so that the controller can more eﬃciently manage the space available for write operations .
To reduce write ampliﬁcation , we recommend that you leave 10 % of the volume unpartitioned so that the SSD controller can use it for over-provisioning .
This decreases the storage that you can use , but increases performance even if the disk is close to full capacity .
For instance store volumes that support TRIM , you can use the TRIM command to notify the SSD controller whenever you no longer need data that you 've written .
This provides the controller with more free space , which can reduce write ampliﬁcation and increase performance .
Instance features The following is a summary of features for storage optimized instances : EBS only Instance store Placement group D2 No HDD Yes H1 No HDD * Yes I3 No NVMe * Yes I3en No NVMe * Yes * The root device volume must be an Amazon EBS volume .
We strongly recommend that you use the latest AMIs when you launch d2.8xlarge instances .
Update the kernel to the latest version by following your operating system-speciﬁc instructions .
( Optional ) Create an AMI from the instance that you can use to launch any additional d2.8xlarge instances that you need in the future .
If the instance still does not boot properly , proceed to the next step .
( Optional ) If the instance still does not boot properly , the kernel on your instance may not support more than 32 vCPUs .
However , you may be able to boot the instance if you limit the vCPUs .
Add the maxcpus=32 option to your boot kernel parameters by following your operating system-speciﬁc instructions .
d. ( Optional ) Create an AMI from the instance that you can use to launch any additional d2.8xlarge instances that you need in the future .
253 Amazon Elastic Compute Cloud User Guide for Linux Instances Accelerated computing instances Release notes • You must launch storage optimized instances using an HVM AMI .
This means that it can take 20 minutes from the time the instance enters the running state until it becomes available over the network .
• To attach or detach EBS volumes or secondary network interfaces from a bare metal instance requires PCIe native hotplug support .
Amazon Linux 2 and the latest versions of the Amazon Linux AMI support PCIe native hotplug , but earlier versions do not .
The upstream Linux kernel and the latest Amazon Linux AMIs support this device .
Bare metal instances also provide an ACPI SPCR table to enable the system to automatically use the PCI-based serial device .
The latest Windows AMIs automatically use the PCI-based serial device .
• With FreeBSD AMIs , bare metal instances take nearly an hour to boot and I/O to the local NVMe storage does not complete .
• There is a limit on the total number of instances that you can launch in a Region , and there are additional limits on some instance types .
Linux accelerated computing instances If you require high processing capability , you 'll beneﬁt from using accelerated computing instances , which provide access to hardware-based compute accelerators such as Graphics Processing Units ( GPUs ) or Field Programmable Gate Arrays ( FPGAs ) .
Accelerated computing instances enable more parallelism for higher throughput on compute-intensive workloads .
254 Amazon Elastic Compute Cloud User Guide for Linux Instances Accelerated computing instances GPU-based instances provide access to NVIDIA GPUs with thousands of compute cores .
You can use GPUbased accelerated computing instances to accelerate scientiﬁc , engineering , and rendering applications by leveraging the CUDA or Open Computing Language ( OpenCL ) parallel computing frameworks .
FPGA-based instances provide access to large FPGAs with millions of parallel system logic cells .
You can use FPGA-based accelerated computing instances to accelerate workloads such as genomics , ﬁnancial analysis , real-time video processing , big data analysis , and security workloads by leveraging custom hardware accelerations .
You can develop these accelerations using hardware description languages such as Verilog or VHDL , or by using higher-level languages such as OpenCL parallel computing frameworks .
You can either develop your own hardware acceleration code or purchase hardware accelerations through the AWS Marketplace .
You can cluster accelerated computing instances into a cluster placement group .
Cluster placement groups provide low latency and high-bandwidth connectivity between the instances within a single Availability Zone .
Accelerated computing instance families Accelerated computing instance families use hardware accelerators , or co-processors , to perform some functions , such as ﬂoating point number calculations , graphics processing , or data pattern matching , more eﬃciently than is possible in software running on CPUs .
The following accelerated computing instance families are available for you to launch in Amazon EC2 .
F1 instances F1 instances use Xilinx UltraScale+ VU9P FPGAs and are designed to accelerate computationally intensive algorithms , such as data-ﬂow or highly parallel operations not suited to general purpose CPUs .
Developers can use the FPGA Developer AMI and AWS Hardware Developer Kit to create custom hardware accelerations for use on F1 instances .
The FPGA Developer AMI includes development tools for 255 Amazon Elastic Compute Cloud User Guide for Linux Instances Accelerated computing instances full-cycle FPGA development in the cloud .
Using these tools , developers can create and share Amazon FPGA Images ( AFIs ) that can be loaded onto the FPGA of an F1 instance .
Inferentia was developed to enable highly cost-eﬀective low latency inference performance at any scale .
Developers can use the AWS Deep Learning AMI which comes with prepackaged and optimized software for AWS Inferentia .
P3 instances P3 instances use NVIDIA Tesla V100 GPUs and are designed for general purpose GPU computing using the CUDA or OpenCL programming models or through a machine learning framework .
P2 instances P2 instances use NVIDIA Tesla K80 GPUs and are designed for general purpose GPU computing using the CUDA or OpenCL programming models .
G4 instances G4 instances use NVIDIA Tesla GPUs and provide a cost-eﬀective , high-performance platform for general purpose GPU computing using the CUDA or machine learning frameworks along with graphics applications using DirectX or OpenGL .
Each GPU has 16 GiB of GDDR6 memory , making G4 instances well-suited for machine learning inference , video transcoding , and graphics applications like remote graphics workstations and game streaming in the cloud .
G3 instances also provide NVIDIA GRID Virtual Workstation features , such as support for four monitors with resolutions up to 4096x2160 , and NVIDIA GRID Virtual Applications .
G3 instances support NVIDIA GRID Virtual Workstation and NVIDIA GRID Virtual Applications .
NVIDIA GRID GPUs also support NVIDIA ’ s fast capture and encode API operations .
Hardware speciﬁcations The following is a summary of the hardware speciﬁcations for accelerated computing instances .
Instance performance There are several GPU setting optimizations that you can perform to achieve the best performance on your instances .
EBS-optimized instances enable you to get consistently high performance for your EBS volumes by eliminating contention between Amazon EBS I/O and other network traﬃc from your instance .
Some accelerated computing instances are EBS-optimized by default at no additional cost .
Some accelerated computing instance types provide the ability to control processor C-states and P-states on Linux .
Network performance You can enable enhanced networking on supported instance types to provide lower latencies , lower network jitter , and higher packet-per-second ( PPS ) performance .
Most applications do not consistently need a high level of network performance , but can beneﬁt from access to increased bandwidth when they send or receive data .
The following is a summary of network performance for accelerated computing instances that support enhanced networking .
They accrue credits when their bandwidth is below their baseline bandwidth , and can use these credits when they perform network data transfers .
For more information , open a support case and ask about baseline bandwidth for the speciﬁc instance types that you are interested in .
Instance features The following is a summary of features for accelerated computing instances .
• There is a limit on the total number of instances that you can launch in a Region , and there are additional limits on some instance types .
Installing NVIDIA drivers on Linux instances An instance with an attached GPU , such as a P3 or G4 instance , must have the appropriate NVIDIA driver installed .
Depending on the instance type , you can either download a public NVIDIA driver , download a driver from Amazon S3 that is available only to AWS customers , or use an AMI with the driver preinstalled .
Tesla drivers These drivers are intended primarily for compute workloads , which use GPUs for computational tasks such as parallelized ﬂoating-point calculations for machine learning and fast Fourier transforms for high performance computing applications .
GRID drivers These drivers are certiﬁed to provide optimal performance for professional visualization applications that render content such as 3D models or high-resolution videos .
You can conﬁgure GRID drivers to support two modes .
Quadro Virtual Workstations provide access to four 4K displays per GPU .
GRID vApps provide RDSH App hosting capabilities .
260 Amazon Elastic Compute Cloud User Guide for Linux Instances Accelerated computing instances Gaming drivers These drivers contain optimizations for gaming and are updated frequently to provide performance enhancements .
NVIDIA control panel The NVIDIA control panel is supported with GRID and Gaming drivers .
It is not supported with Tesla drivers .
Supported APIs • OpenCL , OpenGL , and Vulkan • NVIDIA CUDA and related libraries ( for example , cuDNN , TensorRT , nvJPEG , and cuBLAS ) • NVENC for video encoding and NVDEC for video decoding Available drivers by instance type The following table summarizes the supported NVIDIA drivers for each GPU instance type .
Instance type Tesla driver GRID driver Gaming driver G2 Yes No No G3 Yes Yes No G4 Yes Yes Yes P2 Yes No No P3 Yes Yes † No † Using Marketplace AMIs only Installation options Use one of the following options to get the NVIDIA drivers required for your GPU instance .
• Marketplace oﬀerings with the Tesla driver • Marketplace oﬀerings with the GRID driver • Marketplace oﬀerings with the Gaming driver 261 Amazon Elastic Compute Cloud User Guide for Linux Instances Accelerated computing instances To update the driver version installed using one of these AMIs , you must uninstall the NVIDIA packages from your instance to avoid version conﬂicts .
Uninstalling the NVIDIA packages erases the CUDA toolkit .
You must reinstall the CUDA toolkit after installing the NVIDIA driver .
Option 2 : Public NVIDIA Tesla drivers To download the NVIDIA driver Log on to your Linux instance and download the 64-bit NVIDIA driver appropriate for the instance type from http : //www.nvidia.com/Download/Find.aspx .
To install the NVIDIA driver on Linux For more information about installing and conﬁguring the driver , see the NVIDIA Driver Installation Quickstart Guide .
By downloading , you agree to use the downloaded software only to develop AMIs for use with the NVIDIA Tesla T4 or NVIDIA Tesla M60 hardware .
Upon installation of the software , you are bound by the terms of the NVIDIA GRID Cloud End User License Agreement .
To install the NVIDIA GRID driver on your Linux instance 1 .
Install gcc and make , if they are not already installed .
Update your package cache and get necessary package updates for your instance .
Reboot your instance to load the latest kernel version .
Reconnect to your instance after it has rebooted .
Install the gcc compiler and the kernel headers package for the version of the kernel you are currently running .
Copy the following code block and paste it into a terminal .
Multiple versions of the GRID driver are stored in this bucket .
You can see all of the available versions using the following command .
Add permissions to run the driver installation utility using the following command .
Run the self-install script as follows to install the GRID driver that you downloaded .
Conﬁrm that the driver is functional .
The response for the following command lists the installed version of the NVIDIA driver and details about the GPUs .
( Optional ) To help take advantage of the four displays of up to 4K resolution , set up the highperformance display protocol NICE DCV .
To activate GRID Virtual Applications for RDSH Application hosting capabilities , complete the GRID Virtual Application activation steps in Activate NVIDIA GRID Virtual Applications ( p. 266 ) .
By downloading them , you agree to use the downloaded software only to develop AMIs for use with the NVIDIA Tesla T4 hardware .
Upon installation of the software , you are bound by the terms of the NVIDIA GRID Cloud End User License Agreement .
To install the NVIDIA gaming driver on your Linux instance 1 .
Install gcc and make , if they are not already installed .
Update your package cache and get necessary package updates for your instance .
Reboot your instance to load the latest kernel version .
Reconnect to your instance after it has rebooted .
Install the gcc compiler and the kernel headers package for the version of the kernel you are currently running .
Copy the following code block and paste it into a terminal .
Multiple versions of the gaming driver are stored in this bucket .
Add permissions to run the driver installation utility using the following command .
Run the installer using the following command : [ ec2-user ~ ] $ sudo ./NVIDIA-Linux-x86_64*.run 265 Amazon Elastic Compute Cloud User Guide for Linux Instances Accelerated computing instances When prompted , accept the license agreement and specify the installation options as required ( you can accept the default options ) .
Use the following command to create the required conﬁguration ﬁle .
Use the following command to download and rename the certiﬁcation ﬁle .
( Optional ) To help take advantage of the four displays of up to 4K resolution , set up the highperformance display protocol NICE DCV .
Activate NVIDIA GRID Virtual Applications To activate the GRID Virtual Applications on G3 and G4 instances ( NVIDIA GRID Virtual Workstation is enabled by default ) , you must deﬁne the product type for the driver in the /etc/nvidia/gridd.conf ﬁle .
Reboot the instance to pick up the new conﬁguration .
By default , the NVIDIA driver uses an autoboost feature , which varies the GPU clock speeds .
By disabling the autoboost feature and setting the GPU clock speeds to their maximum frequency , you can consistently achieve the maximum performance with your GPU instances .
The following procedure helps you to conﬁgure the GPU settings to be persistent , disable the autoboost feature , and set the GPU clock speeds to their maximum frequency .
266 Amazon Elastic Compute Cloud User Guide for Linux Instances Accelerated computing instances To optimize GPU settings 1 .
Conﬁgure the GPU settings to be persistent .
This command can take several minutes to run .
Disable the autoboost feature for all GPUs on the instance .
Set all GPU clock speeds to their maximum frequency .
Use the memory and graphics clock speeds speciﬁed in the following commands .
Note Some versions of the NVIDIA driver do not allow setting application clock speed and throw a `` Setting applications clocks is not supported for GPU … '' error , which you can ignore .
For more information , see the documentation for the AWS FPGA Hardware Development Kit .
Getting started with AWS Inferentia development The AWS Deep Learning AMIs provide the tools for developing , testing , and building machine learning applications using AWS Inferentia .
You can use the Deep Learning AMIs for AWS Inferentia development on any Amazon EC2 Inf1 instance .
For more information , see the documentation for AWS Neuron .
267 Amazon Elastic Compute Cloud User Guide for Linux Instances Finding an instance type Finding an instance type Before you can launch an instance , you must select an instance type to use .
The instance type that you choose can diﬀer depending on your requirements for the instances that you 'll launch .
You can search through all available instance types using the Instance Types page .
From the navigation bar , select the Region in which to launch your instances .
You can select any Region that 's available to you , regardless of your location .
( Optional ) Choose the preferences icon to select which instance type attributes to display , such as the On-Demand Linux pricing .
Alternatively , you can select an instance type from the list and view all attributes in the Details pane .
( Optional ) Use the Filter options to scope the list of displayed instance types to see only the instance types that interest you .
For example , you can list all of the instance types that have more than eight vCPUs and that support hibernation .
The ﬁle includes all instance types that match the ﬁlters you set , if any , and that match all attributes displayed in the table .
Finding an instance type using the AWS CLI You can use AWS CLI commands for Amazon EC2 to list only the instance types that meet your needs .
After locating an instance type that meets your needs , make note of it so that you can use it to launch instances .
For more information , see Launching an Instance Using the AWS CLI in the AWS Command Line Interface User Guide .
For example , you can use the following ﬁlter to display only instance types with 48 vCPUs .
aws ec2 describe-instance-type-offerings -- location-type `` availability-zone '' 268 Amazon Elastic Compute Cloud User Guide for Linux Instances Changing the instance type You can add the following ﬁlter to the previous command to display only instance types that are oﬀered in the us-east-1a Availability Zone .
If this is the case , you can change the size of your instance .
For example , if your t2.micro instance is too small for its workload , you can change it to another instance type that is appropriate for the workload .
You might also want to migrate from a previous generation instance type to a current generation instance type to take advantage of some features ; for example , support for IPv6 .
If the root device for your instance is an EBS volume , you can change the size of the instance simply by changing its instance type , which is known as resizing it .
If the root device for your instance is an instance store volume , you must migrate your application to a new instance with the instance type that you need .
When you resize an instance , you must select an instance type that is compatible with the conﬁguration of the instance .
If the instance type that you want is not compatible with the instance conﬁguration you have , then you must migrate your application to a new instance with the instance type that you need .
Important When you resize an instance , the resized instance usually has the same number of instance store volumes that you speciﬁed when you launched the original instance .
With instance types that support NVMe instance store volumes ( which are available by default ) , the resized instance might have additional instance store volumes , depending on the AMI .
Otherwise , you can migrate your application to an instance with a new instance type manually , specifying the number of instance store volumes that you need when you launch the new instance .
You ca n't resize an instance that was launched from a PV AMI to an instance type that is HVM only .
To check the virtualization type of your instance , see the Virtualization ﬁeld on the details pane of the Instances screen in the Amazon EC2 console .
• Architecture : AMIs are speciﬁc to the architecture of the processor , so you must select an instance type with the same processor architecture as the current instance type .
For example : • A1 instances are the only instances that support processors based on the Arm architecture .
If you are resizing an instance type with a processor based on the Arm architecture , you are limited to the instance types that support a processor based on the Arm architecture .
To check whether your instance is in a VPC , check the VPC ID value on the details pane of the Instances screen in the Amazon EC2 console .
If you resize an instance from an instance type that does not support NVMe to an instance type that supports NVMe , you must ﬁrst install the NVMe drivers ( p. 1023 ) on your instance .
When you stop and start an instance , be aware of the following : • We move the instance to new hardware ; however , the instance ID does not change .
• If your instance is in an Auto Scaling group , the Amazon EC2 Auto Scaling service marks the stopped instance as unhealthy , and may terminate it and launch a replacement instance .
To prevent this , you can suspend the scaling processes for the group while you 're resizing your instance .
For more information , see Suspending and Resuming Scaling Processes in the Amazon EC2 Auto Scaling User Guide .
• If your instance is in a cluster placement group ( p. 789 ) and , after changing the instance type , the instance start fails , try the following : stop all the instances in the cluster placement group , change the instance type for the aﬀected instance , and then restart all the instances in the cluster placement group .
• Ensure that you plan for downtime while your instance is stopped .
Stopping and resizing an instance may take a few minutes , and restarting your instance may take a variable amount of time depending on your application 's startup scripts .
Use the following procedure to resize an Amazon EBS–backed instance using the AWS Management Console .
270 Amazon Elastic Compute Cloud User Guide for Linux Instances Changing the instance type To resize an Amazon EBS–backed instance 1 .
( Optional ) If the new instance type requires drivers that are not installed on the existing instance , you must connect to your instance and install the drivers ﬁrst .
It can take a few minutes for the instance to stop .
This action is disabled if the instance state is not stopped .
From Instance Type , select the instance type that you want .
If the instance type that you want does not appear in the list , then it is not compatible with the conﬁguration of your instance ( for example , because of virtualization type ) .
It can take a few minutes for the instance to enter the running state .
( Troubleshooting ) If your instance wo n't boot , it is possible that one of the requirements for the new instance type was not met .
For more information , see Why is my Linux instance not booting after I changed its type ?
Migrating an instance store-backed instance When you want to move your application from one instance store-backed instance to an instance storebacked instance with a diﬀerent instance type , you must migrate it by creating an image from your instance , and then launching a new instance from this image with the instance type that you need .
To ensure that your users can continue to use the applications that you 're hosting on your instance uninterrupted , you must take any Elastic IP address that you 've associated with your original instance and associate it with the new instance .
Then you can terminate the original instance .
Back up any data on your instance store volumes that you need to keep to persistent storage .
When you are ﬁnished creating an AMI from your instance , return to this procedure .
From the ﬁlter lists , choose Owned by me , and choose the image that you created in the previous step .
Notice that AMI Name is the name that you speciﬁed when you registered the image and Source is your Amazon S3 bucket .
271 Amazon Elastic Compute Cloud User Guide for Linux Instances Changing the instance type Note If you do not see the AMI that you created in the previous step , make sure that you have selected the Region in which you created your AMI .
When you specify options for the instance , be sure to select the new instance type that you want .
If the instance type that you want ca n't be selected , then it is not compatible with conﬁguration of the AMI that you created ( for example , because of virtualization type ) .
You can also specify any EBS volumes that you detached from the original instance .
It can take a few minutes for the instance to enter the running state .
Select the instance and verify that you are about to terminate the original instance , not the new instance ( for example , check the name or launch time ) .
Migrating to a new instance conﬁguration If the current conﬁguration of your instance is incompatible with the new instance type that you want , then you ca n't resize the instance to that instance type .
Instead , you can migrate your application to a new instance with a conﬁguration that is compatible with the new instance type that you want .
If you want to move from an instance launched from a PV AMI to an instance type that is HVM only , the general process is as follows : To migrate your application to a compatible instance 1 .
Back up any data on your instance store volumes that you need to keep to persistent storage .
• If you are using an Elastic IP address , select the VPC that the original instance is currently running in .
• Any EBS volumes that you detached from the original instance and want to attach to the new instance , or new EBS volumes based on the snapshots that you created .
• If you want to allow the same traﬃc to reach the new instance , select the security group that is associated with the original instance .
Install your application and any required software on the instance .
Restore any data that you backed up from the instance store volumes of the original instance .
Select the Elastic IP address that is associated with the original instance and choose Actions , Disassociate address .
Select the instance and verify that you are about to terminate the original instance , not the new instance ( for example , check the name or launch time ) .
272 Amazon Elastic Compute Cloud User Guide for Linux Instances Getting recommendations Getting recommendations for an instance type AWS Compute Optimizer provides Amazon EC2 instance recommendations to help you improve performance , save money , or both .
You can use these recommendations to decide whether to move to a new instance type .
To make recommendations , Compute Optimizer analyzes your existing instance speciﬁcations and utilization metrics .
The compiled data is then used to recommend which Amazon EC2 instance types are best able to handle the existing workload .
This topic outlines how to view recommendations through the Amazon EC2 console .
For more information , see the AWS Compute Optimizer User Guide .
Note To get recommendations from Compute Optimizer , you must ﬁrst opt in to Compute Optimizer .
For more information , see Getting Started with AWS Compute Optimizer in the AWS Compute Optimizer User Guide .
Other instance types are not considered by Compute Optimizer .
If you 're using other instance types , they will not be listed in the Compute Optimizer recommendations view .
An optimized EC2 instance runs your workloads with optimal performance and infrastructure cost .
For optimized instances , Compute Optimizer might sometimes recommend a new generation instance type .
This might occur if you 've been opted in to Compute Optimizer for less than 12 hours , or when the instance has been running for less than 30 hours , or when the instance type is not supported by Compute Optimizer .
273 Amazon Elastic Compute Cloud User Guide for Linux Instances Getting recommendations Viewing recommendations After you opt in to Compute Optimizer , you can view the ﬁndings that Compute Optimizer generates for your EC2 instances in the EC2 console .
You can then access the Compute Optimizer console to view the recommendations .
If you recently opted in , ﬁndings might not be reﬂected in the EC2 console for up to 12 hours .
Select an instance , and on the Description tab , inspect the Finding ﬁeld .
The instance opens in Compute Optimizer , where it is labeled as the Current instance .
The bottom half of the window shows recent CloudWatch metric data for the current instance : CPU utilization , Memory utilization , Network in , and Network out .
( Optional ) In the Compute Optimizer console , choose the settings ( ) icon to change the visible columns in the table , or to view the public pricing information for a diﬀerent purchasing option for the current and recommended instance types .
Before you change your current instance type , ﬁrst evaluate the impact on Reserved Instance utilization and coverage .
Determine whether you want to use one of the recommendations .
Decide whether to optimize for performance improvement , for cost reduction , or for a combination of the two .
For more information , see Viewing Resource Recommendations in the AWS Compute Optimizer User Guide .
To view recommendations for all EC2 instances across all Regions through the Compute Optimizer console 1 .
To ﬁlter recommendations to one or more AWS Regions , enter the name of the Region in the Filter by one or more Regions text box , or choose one or more Regions in the drop-down list that appears .
To view recommendations for resources in another account , choose Account , and then select a diﬀerent account ID .
This option is available only if you are signed in to a master account of an organization , and you opted in all member accounts within the organization .
For more information , see Viewing Resource Details in the AWS Compute Optimizer User Guide .
274 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance Purchasing Options Considerations for evaluating recommendations Before changing an instance type , consider the following : • The recommendations don ’ t forecast your usage .
Recommendations are based on your historical usage over the most recent 14-day time period .
Be sure to choose an instance type that is expected to meet your future resource needs .
• Focus on the graphed metrics to determine whether actual usage is lower than instance capacity .
For example , notice how CPU percentage metrics change during the day and whether there are peaks that need to be accommodated .
For more information , see Viewing Available Metrics in the Amazon CloudWatch User Guide .
If you periodically burst above the baseline , make sure that you can continue to do so based on the vCPUs of the new instance type .
Before you change your current instance type , ﬁrst evaluate the impact on Reserved Instance utilization and coverage .
• When migrating to a diﬀerent instance family , make sure the current instance type and the new instance type are compatible , for example , in terms of virtualization , architecture , or network type .
Performance risk indicates the amount of eﬀort you might need to spend in order to validate whether the recommended instance type meets the performance requirements of your workload .
We also recommend rigorous load and performance testing before and after making any changes .
275 Amazon Elastic Compute Cloud User Guide for Linux Instances Determining the Instance Lifecycle • Dedicated Instances – Pay , by the hour , for instances that run on single-tenant hardware .
If you require a capacity reservation , purchase Reserved Instances or Capacity Reservations for a speciﬁc Availability Zone , or purchase Scheduled Instances .
Spot Instances are a cost-eﬀective choice if you can be ﬂexible about when your applications run and if they can be interrupted .
Dedicated Hosts or Dedicated Instances can help you address compliance requirements and reduce costs by using your existing server-bound software licenses .
For more information about Savings Plans , see the AWS Savings Plans User Guide .
The purchasing option that you choose aﬀects the lifecycle of the instance .
For example , an On-Demand Instance runs when you launch it and ends when you terminate it .
A Spot Instance runs as long as capacity is available and your maximum price is higher than the Spot price .
You can launch a Scheduled Instance during its scheduled time period ; Amazon EC2 launches the instances and then terminates them three minutes before the time period ends .
Use the following procedure to determine the lifecycle of an instance .
If the value is host , the instance is running on a Dedicated Host .
( Optional ) If you have purchased a Reserved Instance and want to verify that it is being applied , you can check the usage reports for Amazon EC2 .
You pay only for the seconds that your On-Demand Instances are in the running state .
We recommend that you use On-Demand Instances for applications with short-term , irregular workloads that can not be interrupted .
On-Demand Instance Limits There is a limit on the number of running On-Demand Instances per AWS account per Region .
OnDemand Instance limits are managed in terms of the number of virtual central processing units ( vCPUs ) that your running On-Demand Instances are using , regardless of the instance type .
Each limit speciﬁes the vCPU limit for one or more instance families .
With vCPU limits , you can use your limit in terms of the number of vCPUs required to launch any combination of instance types that meet your changing application needs .
Calculating How Many vCPUs You Need You can use the vCPU limits calculator to determine the number of vCPUs that you require for your application needs .
When using the calculator , keep the following in mind : The calculator assumes that you have reached your current limit .
The value that you enter for Instance Count is the number of instances that you need to launch in addition to what is permitted by your current limit .
The calculator adds your current limit to the Instance Count to arrive at a new limit .
The following screenshot shows the vCPU limits calculator .
278 Amazon Elastic Compute Cloud User Guide for Linux Instances On-Demand Instances You can view and use the following controls and information : • Instance type – The instance types that you add to the vCPU limits calculator .
• Instance count – The number of instances that you require for the selected instance type .
• vCPU count – The number of vCPUs that corresponds to the Instance count .
• Current limit – Your current limit for the limit type to which the instance type belongs .
The limit applies to all instance types of the same limit type .
For example , in the preceding screenshot , the current limit for m5.2xlarge and c5.4xlarge is 1,920 vCPUs , which is the limit for all the instance types that belong to the All Standard instances limit .
• New limit – The new limit , in number of vCPUs , which is calculated by adding vCPU count and Current limit .
• Add instance type – Choose Add instance type to add another instance type to the calculator .
• Instance limit name – The limit type for the instance types that you selected .
• vCPUs needed – The number of vCPUs that corresponds to the number of instances that you speciﬁed in Instance count .
For the All Standard instances limit type , the vCPUs needed is calculated by adding the values for vCPU count for all the instance types of this limit type .
• New limit – The new limit is calculated by adding Current limit and vCPUs needed .
Choose Add instance type , choose the required instance type , and specify the required number of instances .
To add more instance types , choose Add instance type again .
View Limits calculation for the required new limit .
Requesting a Limit Increase You can request a limit increase for each On-Demand Instance limit type from the Limits page or the vCPU limits calculator in the Amazon EC2 console .
Complete the required ﬁelds on the AWS Support Center limit increase form with your use case .
For Primary Instance Type , select the limit type that corresponds to the Instance limit name in the vCPU limits calculator .
For the new limit value , use the value that appears in the New limit column in the vCPU limits calculator .
Monitoring On-Demand Instance Limits and Usage You can view and manage your On-Demand Instance limits from the Limits page in the Amazon EC2 console , from the Amazon EC2 Services quotas page in the Service Quotas console , and from the Service Limits page in the AWS Trusted Advisor console .
You can also conﬁgure alarms to warn about approaching limits .
For more information , see Using Amazon CloudWatch Alarms in the Service Quotas User Guide .
Querying the Prices of AWS Services You can use the Price List Service API or the AWS Price List API to query the prices of On-Demand Instances .
For more information , see Using the AWS Price List API in the AWS Billing and Cost Management User Guide .
Reserved Instances Reserved Instances provide you with signiﬁcant savings on your Amazon EC2 costs compared to OnDemand Instance pricing .
Reserved Instances are not physical instances , but rather a billing discount applied to the use of On-Demand Instances in your account .
These On-Demand Instances must match certain attributes , such as instance type and Region , in order to beneﬁt from the billing discount .
Savings Plans also oﬀer signiﬁcant savings on your Amazon EC2 costs compared to On-Demand Instance pricing .
This provides you with the ﬂexibility to use the instance conﬁgurations that best meet your needs and continue to save money , instead of making a commitment to a speciﬁc instance conﬁguration .
For more information , see the AWS Savings Plans User Guide .
Reserved Instance Overview The following diagram shows a basic overview of purchasing and using Reserved Instances .
You purchase a Reserved Instance that matches the attributes of your running instance , and the billing beneﬁt is immediately applied .
You do not have any running instances in your account that match the attributes of this Reserved Instance .
In the ﬁnal step , you launch an instance that matches the attributes of the C4 Reserved Instance , and the billing beneﬁt is immediately applied .
Key variables that determine Reserved Instance pricing The Reserved Instance pricing is determined by the following key variables .
Instance attributes A Reserved Instance has four instance attributes that determine its price .
The attributes also determine how the Reserved Instance is applied to a running instance in your account .
281 Amazon Elastic Compute Cloud User Guide for Linux Instances Reserved Instances Reserved Instances do not renew automatically ; when they expire , you can continue using the EC2 instance without interruption , but you are charged On-Demand rates .
In the above example , when the Reserved Instances that cover the T2 and C4 instances expire , you go back to paying the On-Demand rates until you terminate the instances or purchase new Reserved Instances that match the instance attributes .
Payment options The following payment options are available for Reserved Instances : • All Upfront : Full payment is made at the start of the term , with no other costs or additional hourly charges incurred for the remainder of the term , regardless of hours used .
• Partial Upfront : A portion of the cost must be paid upfront and the remaining hours in the term are billed at a discounted hourly rate , regardless of whether the Reserved Instance is being used .
• No Upfront : You are billed a discounted hourly rate for every hour within the term , regardless of whether the Reserved Instance is being used .
Note No Upfront Reserved Instances are based on a contractual obligation to pay monthly for the entire term of the reservation .
For this reason , a successful billing history is required before you can purchase No Upfront Reserved Instances .
Generally speaking , you can save more money making a higher upfront payment for Reserved Instances .
You can also ﬁnd Reserved Instances oﬀered by third-party sellers at lower prices and shorter term lengths on the Reserved Instance Marketplace .
Oﬀering class If your computing needs change , you may be able to modify or exchange your Reserved Instance , depending on the oﬀering class .
• Convertible : These provide a lower discount than Standard Reserved Instances , but can be exchanged for another Convertible Reserved Instance with diﬀerent instance attributes .
Convertible Reserved Instances can also be modiﬁed .
Reserved Instance limits There is a limit to the number of Reserved Instances that you can purchase per month .
You can not exceed your running On-Demand Instance limit by purchasing regional Reserved Instances .
If you purchase more regional Reserved Instances , you will not be able to launch more instances because you have reached your On-Demand Instance limit .
Before purchasing regional Reserved Instances , make sure your On-Demand Instance limit matches or exceeds the number of regional Reserved Instances you intend to own .
If required , make sure you request an increase to your On-Demand Instance limit before purchasing more regional Reserved Instances .
You can exceed your running On-Demand Instance limit by purchasing zonal Reserved Instances .
Regional and zonal Reserved Instances ( scope ) When you purchase a Reserved Instance , you determine the scope of the Reserved Instance .
The scope is either regional or zonal .
Diﬀerences between regional and zonal Reserved Instances The following table highlights some key diﬀerences between regional Reserved Instances and zonal Reserved Instances : Regional Reserved Instances Zonal Reserved Instances Availability Zone ﬂexibility The Reserved Instance discount applies to instance usage in any Availability Zone in the speciﬁed Region .
No Availability Zone ﬂexibility— the Reserved Instance discount applies to instance usage in the speciﬁed Availability Zone only .
Capacity reservation No capacity reservation—a regional Reserved Instance does not provide a capacity reservation .
Instance size ﬂexibility The Reserved Instance discount applies to instance usage within the instance family , regardless of size .
Only supported on Amazon Linux/Unix Reserved Instances with default tenancy .
No instance size ﬂexibility— the Reserved Instance discount applies to instance usage for the speciﬁed instance type and size only .
283 Amazon Elastic Compute Cloud User Guide for Linux Instances Reserved Instances Types of Reserved Instances ( oﬀering classes ) When you purchase a Reserved Instance , you can choose between a Standard or Convertible oﬀering class .
If your computing needs change , you may be able to modify or exchange your Reserved Instance , depending on the oﬀering class .
Oﬀering classes may also have additional restrictions or limitations .
The following are the diﬀerences between Standard and Convertible oﬀering classes .
Standard Reserved Instance Convertible Reserved Instance Some attributes , such as instance size , can be modiﬁed during the term ; however , the instance family can not be modiﬁed .
Can be exchanged during the term for another Convertible Reserved Instance with new attributes including instance family , instance type , platform , scope , or tenancy .
You can also modify some attributes of a Convertible Reserved Instance .
Can be sold in the Reserved Instance Marketplace .
Can not be sold in the Reserved Instance Marketplace .
Standard and Convertible Reserved Instances can be purchased to apply to instances in a speciﬁc Availability Zone ( zonal Reserved Instances ) , or to instances in a Region ( regional Reserved Instances ) .
If you want to purchase capacity reservations that recur on a daily , weekly , or monthly basis , a Scheduled Reserved Instance may meet your needs .
How Reserved Instances are applied If you purchase a Reserved Instance and you already have a running instance that matches the speciﬁcations of the Reserved Instance , the billing beneﬁt is immediately applied .
You do not have to restart your instances .
If you do not have an eligible running instance , launch an instance and ensure that you match the same criteria that you speciﬁed for your Reserved Instance .
Reserved Instances apply to usage in the same manner , irrespective of the oﬀering type ( Standard or Convertible ) , and are automatically applied to running On-Demand Instances with matching attributes .
How zonal Reserved Instances are applied Reserved Instances assigned to a speciﬁc Availability Zone provide the Reserved Instance discount to matching instance usage in that Availability Zone .
For example , if you purchase two c4.xlarge default tenancy Linux/Unix Standard Reserved Instances in Availability Zone us-east-1a , then up to two c4.xlarge default tenancy Linux/Unix instances running in the Availability Zone us-east-1a can beneﬁt from the Reserved Instance discount .
How regional Reserved Instances are applied Regional Reserved Instances are purchased for a Region and provide Availability Zone ﬂexibility .
The Reserved Instance discount applies to instance usage in any Availability Zone in that Region .
284 Amazon Elastic Compute Cloud User Guide for Linux Instances Reserved Instances Regional Reserved Instances also provide instance size ﬂexibility where the Reserved Instance discount applies to instance usage within the instance family , regardless of size .
Limitations for instance size ﬂexibility Instance size ﬂexibility does not apply to the following Reserved Instances : • Reserved Instances that are purchased for a speciﬁc Availability Zone ( zonal Reserved Instances ) • Reserved Instances with dedicated tenancy • Reserved Instances for Windows Server , Windows Server with SQL Standard , Windows Server with SQL Server Enterprise , Windows Server with SQL Server Web , RHEL , and SLES • Reserved Instances for G4 instances Instance size ﬂexibility determined by normalization factor Instance size ﬂexibility is determined by the normalization factor of the instance size .
The discount applies either fully or partially to running instances of the same instance family , depending on the instance size of the reservation , in any Availability Zone in the Region .
The only attributes that must be matched are the instance family , tenancy , and platform .
Instance size ﬂexibility is applied from the smallest to the largest instance size within the instance family based on the normalization factor .
The following table lists the diﬀerent sizes within an instance family , and the corresponding normalization factor per hour .
This scale is used to apply the discounted rate of Reserved Instances to the normalized usage of the instance family .
If you purchase a t2.medium default tenancy Amazon Linux/Unix Reserved Instance in the US East ( N. Virginia ) and you have two running t2.small instances in your account in that Region , the billing beneﬁt is applied in full to both instances .
The normalization factor is also applied when modifying Reserved Instances .
Normalization factor for bare metal instances Instance size ﬂexibility also applies to bare metal instances within the instance family .
If you have regional Amazon Linux/Unix Reserved Instances with shared tenancy on bare metal instances , you can beneﬁt from the Reserved Instance savings within the same instance family .
The opposite is also true : if you have regional Amazon Linux/Unix Reserved Instances with shared tenancy on instances in the same 286 Amazon Elastic Compute Cloud User Guide for Linux Instances Reserved Instances family as a bare metal instance , you can beneﬁt from the Reserved Instance savings on the bare metal instance .
A bare metal instance is the same size as the largest instance within the same instance family .
They vary based on the speciﬁc instance family .
For example , if you purchase two i3.8xlarge default tenancy Amazon Linux/ Unix Reserved Instances in the US East ( N. Virginia ) , and you have one running i3.metal instance in that Region , the billing beneﬁt is applied in full to the i3.metal instance .
Examples of applying Reserved Instances The following scenarios cover the ways in which Reserved Instances are applied .
• The m4.large regional Reserved Instances provide Availability Zone and instance size ﬂexibility , because they are regional Amazon Linux Reserved Instances with default tenancy .
In this case , the four m4.large regional Reserved Instances provide the billing beneﬁt to an entire hour of usage of the two m4.xlarge instances .
• The c4.large regional Reserved Instance in us-east-1 provides Availability Zone and instance size ﬂexibility , because it is a regional Amazon Linux Reserved Instance with default tenancy , and applies to the c4.xlarge instance .
Example Scenario 2 : Regional Reserved Instances in linked accounts Reserved Instances are ﬁrst applied to usage within the purchasing account , followed by qualifying usage in any other account in the organization .
For regional Reserved Instances that oﬀer instance size ﬂexibility , the beneﬁt is applied from the smallest to the largest instance size within the instance family .
There is no capacity reservation because the Reserved Instances are regional Reserved Instances .
There is no capacity reservation because the Reserved Instances are regional Reserved Instances .
Example Scenario 3 : Zonal Reserved Instances in a linked account In general , Reserved Instances that are owned by an account are applied ﬁrst to usage in that account .
However , if there are qualifying , unused Reserved Instances for a speciﬁc Availability Zone ( zonal Reserved Instances ) in other accounts in the organization , they are applied to the account before regional Reserved Instances owned by the account .
This is done to ensure maximum Reserved Instance utilization and a lower bill .
For billing purposes , all the accounts in the organization are treated as one account .
The following example may help explain this .
• If the regional Reserved Instance owned by account A was ﬁrst applied to the usage in account A , the zonal Reserved Instance owned by account C remains unused and usage in account B is charged at OnDemand rates .
For more information , see Reserved Instances in the Billing and Cost Management Report .
How you are billed All Reserved Instances provide you with a discount compared to On-Demand pricing .
With Reserved Instances , you pay for the entire term regardless of actual use .
289 Amazon Elastic Compute Cloud User Guide for Linux Instances Reserved Instances When Reserved Instances expire , you are charged On-Demand rates for EC2 instance usage .
You can queue a Reserved Instance for purchase up to three years in advance .
This can help you ensure that you have uninterrupted coverage .
The AWS Free Tier is available for new AWS accounts .
If you are using the AWS Free Tier to run Amazon EC2 instances , and you purchase a Reserved Instance , you are charged under standard pricing guidelines .
Persecond billing is available for instances using an open-source Linux distribution , such as Amazon Linux and Ubuntu .
Per-hour billing is used for commercial Linux distributions , such as Red Hat Enterprise Linux and SUSE Linux Enterprise Server .
You can run multiple instances concurrently , but can only receive the beneﬁt of the Reserved Instance discount for a total of 3600 seconds per clock-hour ; instance usage that exceeds 3600 seconds in a clock-hour is billed at the On-Demand rate .
For example , if you purchase one m4.xlarge Reserved Instance and run four m4.xlarge instances concurrently for one hour , one instance is charged at one hour of Reserved Instance usage and the other three instances are charged at three hours of On-Demand usage .
However , if you purchase one m4.xlarge Reserved Instance and run four m4.xlarge instances for 15 minutes ( 900 seconds ) each within the same hour , the total running time for the instances is one hour , which results in one hour of Reserved Instance usage and 0 hours of On-Demand usage .
If multiple eligible instances are running concurrently , the Reserved Instance billing beneﬁt is applied to all the instances at the same time up to a maximum of 3600 seconds in a clock-hour ; thereafter , OnDemand rates apply .
290 Amazon Elastic Compute Cloud User Guide for Linux Instances Reserved Instances Cost Explorer on the Billing and Cost Management console enables you to analyze the savings against running On-Demand Instances .
The Reserved Instances FAQ includes an example of a list value calculation .
However , if you have any Reserved Instances in your account , you continue to receive a bill for these until they expire .
Viewing your bill You can ﬁnd out about the charges and fees to your account by viewing the AWS Billing and Cost Management console .
• On the Bills page , under Details expand the Elastic Compute Cloud section and the Region to get billing information about your Reserved Instances .
You can view the charges online , or you can download a CSV ﬁle .
You can also track your Reserved Instance utilization using the AWS Cost and Usage Report .
For more information , see Reserved Instances under Cost and Usage Report in the AWS Billing and Cost Management User Guide .
Reserved Instances and consolidated billing The pricing beneﬁts of Reserved Instances are shared when the purchasing account is part of a set of accounts billed under one consolidated billing payer account .
The instance usage across all member accounts is aggregated in the payer account every month .
This is typically useful for companies in which there are diﬀerent functional teams or groups ; then , the normal Reserved Instance logic is applied to calculate the bill .
For more information , see Consolidated Billing and AWS Organizations in the AWS Organizations User Guide .
If you close the account that purchased the Reserved Instance , the payer account will continue being charged for the Reserved Instance until either the Reserved Instance expires or the closed account is permanently deleted .
After it is deleted , the member accounts will stop beneﬁtting from the Reserved Instance billing discount .
For more information about closing an account , see Closing an AWS Account in the AWS Organizations User Guide .
291 Amazon Elastic Compute Cloud User Guide for Linux Instances Reserved Instances Reserved Instance discount pricing tiers If your account qualiﬁes for a discount pricing tier , it automatically receives discounts on upfront and instance usage fees for Reserved Instance purchases that you make within that tier level from that point on .
To qualify for a discount , the list value of your Reserved Instances in the Region must be $ 500,000 USD or more .
The following rules apply : • Pricing tiers and related discounts apply only to purchases of Amazon EC2 Standard Reserved Instances .
• Pricing tiers do not apply to Reserved Instances for Windows with SQL Server Standard , SQL Server Web , and SQL Server Enterprise .
• Pricing tiers do not apply to Reserved Instances for Linux with SQL Server Standard , SQL Server Web , and SQL Server Enterprise .
• Pricing tier discounts only apply to purchases made from AWS .
They do not apply to purchases of third-party Reserved Instances .
• Discount pricing tiers are currently not applicable to Convertible Reserved Instance purchases .
Multiply the hourly recurring price for each reservation by the total number of hours for the term and add the undiscounted upfront price ( also known as the ﬁxed price ) listed on the Reserved Instances pricing page at the time of purchase .
Because the list value is based on undiscounted ( public ) pricing , it is not aﬀected if you qualify for a volume discount or if the price drops after you buy your Reserved Instances .
To view the ﬁxed price values for Reserved Instances using the command line • describe-reserved-instances ( AWS CLI ) • Get-EC2ReservedInstance ( AWS Tools for Windows PowerShell ) 292 Amazon Elastic Compute Cloud User Guide for Linux Instances Reserved Instances • DescribeReservedInstances ( Amazon EC2 API ) Buying with a discount tier When you buy Reserved Instances , Amazon EC2 automatically applies any discounts to the part of your purchase that falls within a discount pricing tier .
You do n't need to do anything diﬀerently , and you can buy Reserved Instances using any of the Amazon EC2 tools .
After the list value of your active Reserved Instances in a Region crosses into a discount pricing tier , any future purchase of Reserved Instances in that Region are charged at a discounted rate .
If a single purchase of Reserved Instances in a Region takes you over the threshold of a discount tier , then the portion of the purchase that is above the price threshold is charged at the discounted rate .
If your list value falls below the price point for that discount pricing tier—for example , if some of your Reserved Instances expire—future purchases of Reserved Instances in the Region are not discounted .
However , you continue to get the discount applied against any Reserved Instances that were originally purchased within the discount pricing tier .
When you buy Reserved Instances , one of four possible scenarios occurs : • No discount—Your purchase within a Region is still below the discount threshold .
No discount is applied to one or more reservations and the discounted rate is applied to the remaining reservations .
You are charged two diﬀerent rates : one or more reservations at the lower discounted rate , and the remaining reservations at the higher discounted rate .
Crossing pricing tiers If your purchase crosses into a discounted pricing tier , you see multiple entries for that purchase : one for that part of the purchase charged at the regular price , and another for that part of the purchase charged at the applicable discounted rate .
The Reserved Instance service generates several Reserved Instance IDs because your purchase crossed from an undiscounted tier , or from one discounted tier to another .
There is an ID for each set of reservations in a tier .
Consequently , the ID returned by your purchase CLI command or API action is diﬀerent from the actual ID of the new Reserved Instances .
Consolidated billing for pricing tiers A consolidated billing account aggregates the list value of member accounts within a Region .
When the list value of all active Reserved Instances for the consolidated billing account reaches a discount pricing tier , any Reserved Instances purchased after this point by any member of the consolidated billing account are charged at the discounted rate ( as long as the list value for that consolidated account stays above the discount pricing tier threshold ) .
Buying Reserved Instances To purchase a Reserved Instance , search for Reserved Instance oﬀerings from AWS and third-party sellers , adjusting your search parameters until you ﬁnd the exact match that you 're looking for .
293 Amazon Elastic Compute Cloud User Guide for Linux Instances Reserved Instances When you search for Reserved Instances to buy , you receive a quote on the cost of the returned oﬀerings .
When you proceed with the purchase , AWS automatically places a limit price on the purchase price .
The total cost of your Reserved Instances wo n't exceed the amount that you were quoted .
If the price rises or changes for any reason , the purchase is not completed .
If , at the time of purchase , there are oﬀerings similar to your choice but at a lower price , AWS sells you the oﬀerings at the lower price .
Before you conﬁrm your purchase , review the details of the Reserved Instance that you plan to buy , and make sure that all the parameters are accurate .
Note To purchase and modify Reserved Instances , ensure that your IAM user account has the appropriate permissions , such as the ability to describe Availability Zones .
For information , see Example Policies for Working With the AWS CLI or an AWS SDK and Example Policies for Working in the Amazon EC2 Console .
• For SUSE Linux and RHEL distributions , you must choose oﬀerings for those speciﬁc platforms , i.e. , for the SUSE Linux or Red Hat Enterprise Linux platforms .
• If you bring your existing RHEL subscription , you must choose an oﬀering for the Linux/UNIX platform , not an oﬀering for the Red Hat Enterprise Linux platform .
Important • If you purchase a Reserved Instance to apply to an On-Demand Instance that was launched from an AMI with a billing product code , make sure that the Reserved Instance has the matching billing product code .
If you purchase a Reserved Instance without the matching 294 Amazon Elastic Compute Cloud User Guide for Linux Instances Reserved Instances billing product code , the Reserved Instance will not be applied to the On-Demand Instance .
• Reserved Instances do not apply to On-Demand Instances that were launched from AWS Marketplace AMIs .
For information about the supported platforms for Windows , see Choosing a platform in the Amazon EC2 User Guide for Windows Instances .
For example , you can queue a purchase for around the time that an existing Reserved Instance expires .
This can help you ensure that you have uninterrupted coverage .
You can queue purchases for regional Reserved Instances , but not zonal Reserved Instances or Reserved Instances from other sellers .
You can queue a purchase up to three years in advance .
On the scheduled date and time , the purchase is executed using the default payment method .
After the payment is successful , the billing beneﬁt is applied .
You can view your queued purchases in the Amazon EC2 console .
You can cancel a queued purchase any time before its scheduled time .
Buying Standard Reserved Instances You can buy Standard Reserved Instances in a speciﬁc Availability Zone and get a capacity reservation .
Alternatively , you can forego the capacity reservation and purchase a regional Standard Reserved Instance .
In the navigation pane , choose Reserved Instances , and then choose Purchase Reserved Instances .
For Oﬀering Class , choose Standard to display Standard Reserved Instances .
To purchase a capacity reservation , choose Only show oﬀerings that reserve capacity in the topright corner of the purchase screen .
Select other conﬁgurations as needed and choose Search .
To purchase a Standard Reserved Instance from the Reserved Instance Marketplace , look for 3rd Party in the Seller column in the search results .
Select the Reserved Instances to purchase , enter the quantity , and choose Add to Cart .
To see a summary of the Reserved Instances that you selected , choose View Cart .
If Order On is Now , the purchase is completed immediately .
You can select a diﬀerent date for each eligible oﬀering in the cart .
The purchase is queued until 00:00 , in the time zone of your browser , on the selected date .
If , at the time of placing the order , there are oﬀerings similar to your choice but with a lower price , AWS sells you the oﬀerings at the lower price .
The status of your order is listed in the State column .
When your order is complete , the State value changes from payment-pending to active .
When the Reserved Instance is active , it is ready to use .
295 Amazon Elastic Compute Cloud User Guide for Linux Instances Reserved Instances Note If the status goes to retired , AWS may not have received your payment .
You can apply additional parameters to narrow your results .
You must specify the Reserved Instance oﬀering ID you obtained the previous step and you must specify the number of instances for the reservation .
Alternatively , to queue the purchase , add the following parameter to the previous call .
Use the describe-reserved-instances command to get the status of your Reserved Instance .
You do not have to restart your instances .
If you do not have a suitable running instance , launch an instance and ensure that you match the same criteria that you speciﬁed for your Reserved Instance .
Buying Convertible Reserved Instances You can buy Convertible Reserved Instances in a speciﬁc Availability Zone and get a capacity reservation .
Alternatively , you can forego the capacity reservation and purchase a regional Convertible Reserved Instance .
In the navigation pane , choose Reserved Instances , and then choose Purchase Reserved Instances .
For Oﬀering Class , choose Convertible to display Convertible Reserved Instances .
To purchase a capacity reservation , choose Only show oﬀerings that reserve capacity in the topright corner of the purchase screen .
Select other conﬁgurations as needed and choose Search .
Select the Convertible Reserved Instances to purchase , enter the quantity , and choose Add to Cart .
If Order On is Now , the purchase is completed immediately .
You can select a diﬀerent date for each eligible oﬀering in the cart .
The purchase is queued until 00:00 , in the time zone of your browser , on the selected date .
If , at the time of placing the order , there are oﬀerings similar to your choice but with a lower price , AWS sells you the oﬀerings at the lower price .
The status of your order is listed in the State column .
When your order is complete , the State value changes from payment-pending to active .
When the Reserved Instance is active , it is ready to use .
Note If the status goes to retired , AWS may not have received your payment .
You must specify the Reserved Instance oﬀering ID you obtained the previous step and you must specify the number of instances for the reservation .
Alternatively , to queue the purchase , add the following parameter to the previous call .
Use the describe-reserved-instances command to get the status of your Reserved Instance .
You do not have to restart your instances .
If you do not have a suitable running instance , launch an instance and ensure that you match the same criteria that you speciﬁed for your Reserved Instance .
Viewing your Reserved Instances You can view the Reserved Instances you 've purchased using the Amazon EC2 console , or a command line tool .
Your active and retired Reserved Instances are listed .
The State column displays the state .
To view your Reserved Instances using the command line • describe-reserved-instances ( AWS CLI ) • Get-EC2ReservedInstance ( Tools for Windows PowerShell ) 298 Amazon Elastic Compute Cloud User Guide for Linux Instances Reserved Instances Canceling a queued purchase You can queue a purchase up to three years in advance .
You can cancel a queued purchase any time before its scheduled time .
Select one or more Reserved Instances .
Renewing a Reserved Instance queues the purchase of a Reserved Instance with the same conﬁguration until the current Reserved Instance expires .
Select one or more Reserved Instances .
Using your Reserved Instances Reserved Instances are automatically applied to running On-Demand Instances provided that the speciﬁcations match .
If you have no running On-Demand Instances that match the speciﬁcations of your Reserved Instance , the Reserved Instance is unused until you launch an instance with the required speciﬁcations .
If you 're launching an instance to take advantage of the billing beneﬁt of a Reserved Instance , ensure that you specify the following information during launch : • Platform : You must choose an Amazon Machine Image ( AMI ) that matches the platform ( product description ) of your Reserved Instance .
For example , if you speciﬁed Linux/UNIX , you can launch an instance from an Amazon Linux AMI or an Ubuntu AMI .
• Availability Zone : If you purchased a Reserved Instance for a speciﬁc Availability Zone , you must launch the instance into the same Availability Zone .
If you purchased a regional Reserved Instance , you can launch your instance into any Availability Zone .
• Tenancy : The tenancy of your instance must match the tenancy of the Reserved Instance ; for example , dedicated or shared .
You can use Amazon EC2 Auto Scaling or other AWS services to launch the On-Demand Instances that use your Reserved Instance beneﬁts .
Reserved Instance Marketplace The Reserved Instance Marketplace is a platform that supports the sale of third-party and AWS customers ' unused Standard Reserved Instances , which vary in term lengths and pricing options .
For example , you may want to sell Reserved Instances after moving instances to a new AWS Region , changing to a new instance type , ending projects before the term expiration , when your business needs change , or if you have unneeded capacity .
If you want to sell your unused Reserved Instances on the Reserved Instance Marketplace , you must meet certain eligibility criteria .
Contents • Selling on the Reserved Instance Marketplace ( p. 300 ) • Buying from the Reserved Instance Marketplace ( p. 305 ) Selling on the Reserved Instance Marketplace As soon as you list your Reserved Instances in the Reserved Instance Marketplace , they are available for potential buyers to ﬁnd .
All Reserved Instances are grouped according to the duration of the term remaining and the hourly price .
To fulﬁll a buyer 's request , AWS ﬁrst sells the Reserved Instance with the lowest upfront price in the speciﬁed grouping .
Then , we sell the Reserved Instance with the next lowest price , until the buyer's entire order is fulﬁlled .
AWS then processes the transactions and transfers ownership of the Reserved Instances to the buyer .
After the sale , you 've given up the capacity reservation and the discounted recurring fees .
If you continue to use your instance , AWS charges you the OnDemand price starting from the time that your Reserved Instance was sold .
300 Amazon Elastic Compute Cloud User Guide for Linux Instances Reserved Instances The following limitations and restrictions apply when selling Reserved Instances : • Only Amazon EC2 Standard Reserved Instances can be sold in the Reserved Instance Marketplace .
Reserved Instances for other AWS , such as Amazon RDS and Amazon ElastiCache , can not be sold .
• There must be at least one month remaining in the term of the Standard Reserved Instance .
• You can sell No Upfront , Partial Upfront , or All Upfront Reserved Instances in the Reserved Instance Marketplace .
If there is an upfront payment on a Reserved Instance , it can be sold only after AWS has received the upfront payment and the reservation has been active ( you 've owned it ) for at least 30 days .
• You can not modify your listing in the Reserved Instance Marketplace directly .
However , you can change your listing by ﬁrst canceling it and then creating another listing with new parameters .
You can also modify your Reserved Instances before listing them .
• AWS charges a service fee of 12 percent of the total upfront price of each Standard Reserved Instance you sell in the Reserved Instance Marketplace .
The upfront price is the price the seller is charging for the Standard Reserved Instance .
Registering as a seller Note Only the AWS account root user can register an account as a seller .
To sell in the Reserved Instance Marketplace , you must ﬁrst register as a seller .
During registration , you provide the following information : • Bank information—AWS must have your bank information in order to disburse funds collected when you sell your reservations .
• Tax information—All sellers are required to complete a tax information interview to determine any necessary tax reporting obligations .
After AWS receives your completed seller registration , you receive an email conﬁrming your registration and informing you that you can get started selling in the Reserved Instance Marketplace .
Bank account for disbursement AWS must have your bank information in order to disburse funds collected when you sell your Reserved Instance .
Open the Reserved Instance Marketplace Seller Registration page and sign in using your AWS credentials .
On the Manage Bank Account page , provide the following information about the bank through to receive payment : • Bank account holder name • Routing number • Account number • Bank account type 301 Amazon Elastic Compute Cloud User Guide for Linux Instances Reserved Instances Note If you are using a corporate bank account , you are prompted to send the information about the bank account via fax ( 1-206-765-3424 ) .
After registration , the bank account provided is set as the default , pending veriﬁcation with the bank .
It can take up to two weeks to verify a new bank account , during which time you ca n't receive disbursements .
For an established account , it usually takes about two days for disbursements to complete .
On the Reserved Instance Marketplace Seller Registration page , sign in with the account that you used when you registered .
On the Manage Bank Account page , add a new bank account or modify the default bank account as needed .
Tax information Your sale of Reserved Instances might be subject to a transaction-based tax , such as sales tax or valueadded tax .
You are responsible for collecting and sending the transaction-based taxes to the appropriate tax authority .
As part of the seller registration process , you must complete a tax interview in the Seller Registration Portal .
The tax information you enter as part of the tax interview might diﬀer depending on whether you operate as an individual or business , and whether you or your business are a US or non-US person or entity .
As you ﬁll out the tax interview , keep in mind the following : • Information provided by AWS , including the information in this topic , does not constitute tax , legal , or other professional advice .
To ﬁnd out how the IRS reporting requirements might aﬀect your business , or if you have other questions , contact your tax , legal , or other professional advisor .
• To fulﬁll the IRS reporting requirements as eﬃciently as possible , answer all questions and enter all information requested during the interview .
Avoid misspellings or entering incorrect tax identiﬁcation numbers .
They can result in an invalidated tax form .
Based on your tax interview responses and IRS reporting thresholds , Amazon may ﬁle Form 1099-K. Amazon mails a copy of your Form 1099-K on or before January 31 in the year following the year that your tax account reaches the threshold levels .
For more information about IRS requirements and Form 1099-K , see the IRS website .
Pricing your Reserved Instances The upfront fee is the only fee that you can specify for the Reserved Instance that you 're selling .
The upfront fee is the one-time fee that the buyer pays when they purchase a Reserved Instance .
To sell more , complete the Request to Raise Sales Limit on Amazon EC2 Reserved Instances form .
You can not modify your listing directly .
However , you can change your listing by ﬁrst canceling it and then creating another listing with new parameters .
You can cancel your listing at any time , as long as it 's in the activestate .
You can not cancel the listing if it 's already matched or being processed for a sale .
If some of the instances in your listing are matched and you cancel the listing , only the remaining unmatched instances are removed from the listing .
Because the value of Reserved Instances decreases over time , by default , AWS can set prices to decrease in equal increments month over month .
However , you can set diﬀerent upfront prices based on when your reservation sells .
For example , if your Reserved Instance has nine months of its term remaining , you can specify the amount that you would accept if a customer were to purchase that Reserved Instance with nine months remaining .
You could set another price with ﬁve months remaining , and yet another price with one month remaining .
Listing your Reserved Instances As a registered seller , you can choose to sell one or more of your Reserved Instances .
You can choose to sell all of them in one listing or in portions .
In addition , you can list Reserved Instances with any conﬁguration of instance type , platform , and scope .
It checks for oﬀerings that match your Reserved Instance and matches the one with the lowest price .
Otherwise , it calculates a suggested price based on the cost of the Reserved Instance for its remaining time .
If you cancel your listing and a portion of that listing has already been sold , the cancellation is not eﬀective on the portion that has been sold .
Only the unsold portion of the listing is no longer available in the Reserved Instance Marketplace .
To list a Reserved Instance in the Reserved Instance Marketplace using the AWS Management Console 1 .
Select the Reserved Instances to list , and choose Sell Reserved Instances .
On the Conﬁgure Your Reserved Instance Listing page , set the number of instances to sell and the upfront price for the remaining term in the relevant columns .
See how the value of your reservation changes over the remainder of the term by selecting the arrow next to the Months Remaining column .
If you are an advanced user and you want to customize the pricing , you can enter diﬀerent values for the subsequent months .
To return to the default linear price drop , choose Reset .
Choose Continue when you are ﬁnished conﬁguring your listing .
Conﬁrm the details of your listing , on the Conﬁrm Your Reserved Instance Listing page and if you 're satisﬁed , choose List Reserved Instance .
Select the Reserved Instance that you 've listed and choose My Listings .
303 Amazon Elastic Compute Cloud User Guide for Linux Instances Reserved Instances To manage Reserved Instances in the Reserved Instance Marketplace using the AWS CLI 1 .
Note the ID of the Reserved Instance you want to list and call create-reserved-instances-listing .
You must specify the ID of the Reserved Instance , the number of instances , and the pricing schedule .
Reserved Instance listing states Listing State on the My Listings tab of the Reserved Instances page displays the current status of your listings : The information displayed by Listing State is about the status of your listing in the Reserved Instance Marketplace .
It is diﬀerent from the status information that is displayed by the State column in the Reserved Instances page .
This State information is about your reservation .
A Reserved Instance might be closed because the sale of the listing was completed .
Lifecycle of a listing When all the instances in your listing are matched and sold , the My Listings tab shows that the Total instance count matches the count listed under Sold .
Also , there are no Available instances left for your listing , and its Status is closed .
When only a portion of your listing is sold , AWS retires the Reserved Instances in the listing and creates the number of Reserved Instances equal to the Reserved Instances remaining in the count .
So , the listing ID and the listing that it represents , which now has fewer reservations for sale , is still active .
Any future sales of Reserved Instances in this listing are processed this way .
When all the Reserved Instances in the listing are sold , AWS marks the listing as closed .
Because of this partial sale , AWS creates a new reservation with a count of three to represent the remaining reservations that are still for sale .
This is how your listing looks in the My Listings tab : Reserved Instance listing ID 5ec28771-05ﬀ-4b9b-aa31-9e57dexample 304 Amazon Elastic Compute Cloud User Guide for Linux Instances Reserved Instances • Total reservation count = 5 • Sold = 2 • Available = 3 • Status = active If you cancel your listing and a portion of that listing has already sold , the cancelation is not eﬀective on the portion that has been sold .
Only the unsold portion of the listing is no longer available in the Reserved Instance Marketplace .
After your Reserved Instance is sold When your Reserved Instance is sold , AWS sends you an email notiﬁcation .
Each day that there is any kind of activity , you receive one email notiﬁcation capturing all the activities of the day .
To track the status of a Reserved Instance listing in the console , choose Reserved Instance , My Listings .
The My Listings tab contains the Listing State value .
It also contains information about the term , listing price , and a breakdown of how many instances in the listing are available , pending , sold , and canceled .
You can also use the describe-reserved-instances-listings command with the appropriate ﬁlter to obtain information about your listings .
Getting paid As soon as AWS receives funds from the buyer , a message is sent to the registered owner account email for the sold Reserved Instance .
AWS sends an Automated Clearing House ( ACH ) wire transfer to your speciﬁed bank account .
Typically , this transfer occurs between one to three days after your Reserved Instance has been sold .
You will receive an email with a disbursement report after the funds are released .
Keep in mind that you ca n't receive disbursements until AWS receives veriﬁcation from your bank .
This can take up to two weeks .
The Reserved Instance that you sold continues to appear when you describe your Reserved Instances .
You receive a cash disbursement for your Reserved Instances through a wire transfer directly into your bank account .
AWS charges a service fee of 12 percent of the total upfront price of each Reserved Instance you sell in the Reserved Instance Marketplace .
Information shared with the buyer When you sell in the Reserved Instance Marketplace , AWS shares your company ’ s legal name on the buyer ’ s statement in accordance with US regulations .
In addition , if the buyer calls AWS Support because the buyer needs to contact you for an invoice or for some other tax-related reason , AWS may need to provide the buyer with your email address so that the buyer can contact you directly .
For similar reasons , the buyer 's ZIP code and country information are provided to the seller in the disbursement report .
As a seller , you might need this information to accompany any necessary transaction taxes that you remit to the government ( such as sales tax and value-added tax ) .
AWS can not oﬀer tax advice , but if your tax specialist determines that you need speciﬁc additional information , contact AWS Support .
Buying from the Reserved Instance Marketplace You can purchase Reserved Instances from third-party sellers who own Reserved Instances that they no longer need from the Reserved Instance Marketplace .
You can do this using the Amazon EC2 console 305 Amazon Elastic Compute Cloud User Guide for Linux Instances Reserved Instances or a command line tool .
The process is similar to purchasing Reserved Instances from AWS .
There are a few diﬀerences between Reserved Instances purchased in the Reserved Instance Marketplace and Reserved Instances purchased directly from AWS : • Term—Reserved Instances that you purchase from third-party sellers have less than a full standard term remaining .
Full standard terms from AWS run for one year or three years .
The usage or recurring fees remain the same as the fees set when the Reserved Instances were originally purchased from AWS .
• Types of Reserved Instances—Only Amazon EC2 Standard Reserved Instances can be purchased from the Reserved Instance Marketplace .
Convertible Reserved Instances , Amazon RDS and Amazon ElastiCache Reserved Instances are not available for purchase on the Reserved Instance Marketplace .
Basic information about you is shared with the seller , for example , your ZIP code and country information .
This information enables sellers to calculate any necessary transaction taxes that they have to remit to the government ( such as sales tax or value-added tax ) and is provided as a disbursement report .
In rare circumstances , AWS might have to provide the seller with your email address , so that they can contact you regarding questions related to the sale ( for example , tax questions ) .
For similar reasons , AWS shares the legal entity name of the seller on the buyer 's purchase invoice .
If you need additional information about the seller for tax or related reasons , contact AWS Support .
Modifying Reserved Instances When your needs change , you can modify your Standard or Convertible Reserved Instances and continue to beneﬁt from the billing beneﬁt .
You can modify attributes such as the Availability Zone , instance size ( within the same instance family ) , and scope of your Reserved Instance .
Note You can also exchange a Convertible Reserved Instance for another Convertible Reserved Instance with a diﬀerent conﬁguration .
You can modify all or a subset of your Reserved Instances .
You can separate your original Reserved Instances into two or more new Reserved Instances .
You can also merge two or more Reserved Instances into a single Reserved Instance .
For example , if you have four t2.small Reserved Instances of one instance each , you can merge them to create one t2.large Reserved Instance .
After modiﬁcation , the beneﬁt of the Reserved Instances is applied only to instances that match the new parameters .
For example , if you change the Availability Zone of a reservation , the capacity reservation and pricing beneﬁts are automatically applied to instance usage in the new Availability Zone .
Instances that no longer match the new parameters are charged at the On-Demand rate , unless your account has other applicable reservations .
If your modiﬁcation request succeeds : • The modiﬁed reservation becomes eﬀective immediately and the pricing beneﬁt is applied to the new instances beginning at the hour of the modiﬁcation request .
For example , if you successfully modify your reservations at 9:15PM , the pricing beneﬁt transfers to your new instance at 9:00PM .
You can 306 Amazon Elastic Compute Cloud User Guide for Linux Instances Reserved Instances get the eﬀective date of the modiﬁed Reserved Instances by using the describe-reserved-instances command .
Its end date is the start date of the new reservation , and the end date of the new reservation is the same as the end date of the original Reserved Instance .
If you modify a three-year reservation that had 16 months left in its term , the resulting modiﬁed reservation is a 16-month reservation with the same end date as the original one .
• The ﬁxed price of the modiﬁed reservation does not aﬀect the discount pricing tier calculations applied to your account , which are based on the ﬁxed price of the original reservation .
If your modiﬁcation request fails , your Reserved Instances maintain their original conﬁguration , and are immediately available for another modiﬁcation request .
There is no fee for modiﬁcation , and you do not receive any new bills or invoices .
You can modify your reservations as frequently as you like , but you can not change or cancel a pending modiﬁcation request after you submit it .
After the modiﬁcation has completed successfully , you can submit another modiﬁcation request to roll back any changes you made , if needed .
Modiﬁable attribute Supported platforms Limitations Change Availability Zones within the same Region Linux and Windows - Change the scope from Availability Zone to Region and vice versa Linux and Windows If you change the scope from Availability Zone to Region , you lose the capacity reservation beneﬁt .
If you change the scope from Region to Availability Zone , you lose Availability Zone ﬂexibility and instance size ﬂexibility ( if applicable ) .
Change the instance size within the same instance family Linux/UNIX only Instance size ﬂexibility is not available for Reserved Instances on the other platforms , which include Linux with SQL Server Standard , Linux with SQL Server Web , Linux with SQL Server 307 The reservation must use default tenancy .
Some instance families are not supported , because there are no other sizes available .
Amazon Elastic Compute Cloud User Guide for Linux Instances Reserved Instances Modiﬁable attribute Supported platforms Limitations Enterprise , Red Hat Enterprise Linux , SUSE Linux , Windows , Windows with SQL Standard , Windows with SQL Server Enterprise , and Windows with SQL Server Web .
Change the network from EC2Classic to Amazon VPC and vice versa Linux and Windows The network platform must be available in your AWS account .
Requirements Amazon EC2 processes your modiﬁcation request if there is suﬃcient capacity for your target conﬁguration ( if applicable ) , and if the following conditions are met : • The Reserved Instance can not be modiﬁed before or at the same time that you purchase it • The Reserved Instance must be active • There can not be a pending modiﬁcation request • The Reserved Instance is not listed in the Reserved Instance Marketplace • There must be a match between the instance size footprint of the active reservation and the target conﬁguration .
• The input Reserved Instances are all Standard Reserved Instances or all Convertible Reserved Instances , not some of each type • The input Reserved Instances must expire within the same hour , if they are Standard Reserved Instances • The Reserved Instance is not a G4 instance .
Support for modifying instance sizes You can modify the instance size of a Reserved Instance if the platform is Linux/UNIX and the instance family has multiple sizes .
For example , the c4 instance family is in the Compute optimized family and is available in multiple sizes .
You can not modify the instance size of the Reserved Instances for the following instance types , because only one size is available for each of the instance families .
When you modify a Reserved Instance , 308 Amazon Elastic Compute Cloud User Guide for Linux Instances Reserved Instances the footprint of the target conﬁguration must match that of the original conﬁguration , otherwise the modiﬁcation request is not processed .
This is only meaningful within the same instance family .
Instance types can not be modiﬁed from one family to another .
The following table illustrates the normalization factor that applies within an instance family .
You can allocate your reservations into diﬀerent instance sizes across the same instance family , for example , across the T2 instance family , as long as the instance size footprint of your reservation remains the same .
This is because the existing instance size footprint of your current reservation is smaller than the proposed reservation .
You merge both reservations to a single reservation with one t2.medium instance—the combined instance size footprint of the two original reservations equals the footprint of the modiﬁed reservation .
309 Amazon Elastic Compute Cloud User Guide for Linux Instances Reserved Instances You can also modify a reservation to divide it into two or more reservations .
Normalization factor for bare metal instances You can modify .metal Reserved Instances into other sizes within the same family , and , similarly , you can modify other sized Reserved Instances in the same family into .metal Reserved Instances .
A bare metal instance is the same size as the largest instance within the same instance family .
They vary based on the speciﬁc instance family .
Before you modify the instance size , calculate the total instance size footprint ( p. 308 ) of the reservations that you want to modify and ensure that it matches the total instance size footprint of your target conﬁgurations .
To modify your Reserved Instances using the AWS Management Console 1 .
On the Reserved Instances page , select one or more Reserved Instances to modify , and choose Actions , Modify Reserved Instances .
Note If your Reserved Instances are not in the active state or can not be modiﬁed , Modify Reserved Instances is disabled .
The ﬁrst entry in the modiﬁcation table displays attributes of selected Reserved Instances , and at least one target conﬁguration beneath it .
The Units column displays the total instance size footprint .
Choose Add for each new conﬁguration to add .
Modify the attributes as needed for each conﬁguration , and then choose Continue : • Scope : Choose whether the conﬁguration applies to an Availability Zone or to the whole Region .
Not applicable for regional Reserved Instances .
The combined conﬁgurations must equal the instance size footprint of your original conﬁgurations .
To split the Reserved Instances into multiple conﬁgurations , reduce the count , choose Add , and specify a count for the additional conﬁguration .
This process retires the original Reserved Instance after the new Reserved Instances are activated .
To conﬁrm your modiﬁcation choices when you ﬁnish specifying your target conﬁgurations , choose Submit Modiﬁcations .
You can determine the status of your modiﬁcation request by looking at the State column in the Reserved Instances screen .
The following are the possible states .
• active ( pending modiﬁcation ) — Transition state for original Reserved Instances • retired ( pending modiﬁcation ) — Transition state for original Reserved Instances while new Reserved Instances are being created • retired — Reserved Instances successfully modiﬁed and replaced • active — One of the following : • New Reserved Instances created from a successful modiﬁcation request • Original Reserved Instances after a failed modiﬁcation request To modify your Reserved Instances using the command line 1 .
At this point , Amazon EC2 has only determined that the parameters of your modiﬁcation request are valid .
Your modiﬁcation request can still fail during processing due to unavailable capacity .
In some situations , you might get a message indicating incomplete or failed modiﬁcation requests instead of a conﬁrmation .
Use the information in such messages as a starting point for resubmitting another modiﬁcation request .
Not all selected Reserved Instances can be processed for modiﬁcation Amazon EC2 identiﬁes and lists the Reserved Instances that can not be modiﬁed .
If you receive a message like this , go to the Reserved Instances page in the Amazon EC2 console and check the information for the Reserved Instances .
Error in processing your modiﬁcation request You submitted one or more Reserved Instances for modiﬁcation and none of your requests can be processed .
Depending on the number of reservations you are modifying , you can get diﬀerent versions of the message .
Amazon EC2 displays the reasons why your request can not be processed .
For example , you might have speciﬁed the same target conﬁguration—a combination of Availability Zone and platform—for one or more subsets of the Reserved Instances you are modifying .
Try submitting the modiﬁcation requests again , but ensure that the instance details of the reservations match , and that the target conﬁgurations for all subsets being modiﬁed are unique .
312 Amazon Elastic Compute Cloud User Guide for Linux Instances Reserved Instances Exchanging Convertible Reserved Instances You can exchange one or more Convertible Reserved Instances for another Convertible Reserved Instance with a diﬀerent conﬁguration , including instance family , operating system , and tenancy .
There are no limits to how many times you perform an exchange , as long as the target Convertible Reserved Instance is of an equal or higher value than the Convertible Reserved Instances that you are exchanging .
When you exchange your Convertible Reserved Instance , the number of instances for your current reservation is exchanged for a number of instances that cover the equal or higher value of the conﬁguration of the target Convertible Reserved Instance .
Amazon EC2 calculates the number of Reserved Instances that you can receive as a result of the exchange .
Your Convertible Reserved Instance must be : • Active • Not pending a previous exchange request The following rules apply : • Convertible Reserved Instances can only be exchanged for other Convertible Reserved Instances currently oﬀered by AWS .
• Convertible Reserved Instances are associated with a speciﬁc Region , which is ﬁxed for the duration of the reservation 's term .
• You can exchange one or more Convertible Reserved Instances at a time for one Convertible Reserved Instance only .
• To exchange a portion of a Convertible Reserved Instance , you can modify it into two or more reservations , and then exchange one or more of the reservations for a new Convertible Reserved Instance .
• All Upfront Convertible Reserved Instances can be exchanged for Partial Upfront Convertible Reserved Instances , and vice versa .
Note If the total value ( upfront price + hourly price * number of remaining hours ) of the new Convertible Reserved Instance is less than the total value of the exchanged Convertible Reserved Instance , AWS automatically gives you a quantity of instances in the Convertible Reserved Instance that ensures that the total value is the same or higher than that of the exchanged Convertible Reserved Instance .
313 Amazon Elastic Compute Cloud User Guide for Linux Instances Reserved Instances • To beneﬁt from better pricing , you can exchange a No Upfront Convertible Reserved Instance for an All Upfront or Partial Upfront Convertible Reserved Instance .
• You can not exchange All Upfront and Partial Upfront Convertible Reserved Instances for No Upfront Convertible Reserved Instances .
• You can exchange a No Upfront Convertible Reserved Instance for another No Upfront Convertible Reserved Instance only if the new Convertible Reserved Instance 's hourly price is the same or higher than the exchanged Convertible Reserved Instance 's hourly price .
Note If the total value ( hourly price * number of remaining hours ) of the new Convertible Reserved Instance is less than the total value of the exchanged Convertible Reserved Instance , AWS automatically gives you a quantity of instances in the Convertible Reserved Instance that ensures that the total value is the same or higher than that of the exchanged Convertible Reserved Instance .
• If you exchange multiple Convertible Reserved Instances that have diﬀerent expiration dates , the expiration date for the new Convertible Reserved Instance is the date that 's furthest in the future .
If you merge multiple Convertible Reserved Instances with diﬀerent term lengths , the new Convertible Reserved Instance has a 3-year term .
Its end date is the start date of the new reservation , and the end date of the new reservation is the same as the end date of the original Convertible Reserved Instance .
For example , if you modify a three-year reservation that had 16 months left in its term , the resulting modiﬁed reservation is a 16-month reservation with the same end date as the original one .
Calculating Convertible Reserved Instances exchanges Exchanging Convertible Reserved Instances is free .
However , you may be required to pay a true-up cost , which is a prorated upfront cost of the diﬀerence between the Convertible Reserved Instances that you had and the Convertible Reserved Instances that you receive from the exchange .
This list value is compared to the list value of the Convertible Reserved Instances that you want in order to determine how many instance reservations you can receive from the exchange .
The fourth Convertible Reserved Instance has the same end date as the other three .
If you are exchanging Partial or All Upfront Convertible Reserved Instances , you pay the true-up cost for the fourth reservation .
314 Amazon Elastic Compute Cloud User Guide for Linux Instances Reserved Instances Merging Convertible Reserved Instances If you merge two or more Convertible Reserved Instances , the term of the new Convertible Reserved Instance must be the same as the original Convertible Reserved Instances , or the highest of the original Convertible Reserved Instances .
The expiration date for the new Convertible Reserved Instance is the expiration date that 's furthest in the future .
The expiration date of the new Convertible Reserved Instance is 2018-12-31 .
The expiration date of the new Convertible Reserved Instance is 2018-07-31 .
The expiration date of the new Convertible Reserved Instance is 2019-12-31 .
Exchanging a portion of a Convertible Reserved Instance You can use the modiﬁcation process to split your Convertible Reserved Instance into smaller reservations , and then exchange one or more of the new reservations for a new Convertible Reserved Instance .
The following examples demonstrate how you can do this .
Example Example : Convertible Reserved Instance with multiple instances In this example , you have a t2.micro Convertible Reserved Instance with four instances in the reservation .
Modify the t2.micro Convertible Reserved Instance by splitting it into two t2.micro Convertible Reserved Instances with two instances each .
Exchange one of the new t2.micro Convertible Reserved Instances for an m4.xlarge Convertible Reserved Instance .
315 Amazon Elastic Compute Cloud User Guide for Linux Instances Reserved Instances Example Example : Convertible Reserved Instance with a single instance In this example , you have a t2.large Convertible Reserved Instance .
Modify the t2.large Convertible Reserved Instance by splitting it into two t2.medium Convertible Reserved Instances .
Exchange one of the new t2.medium Convertible Reserved Instances for an m3.medium Convertible Reserved Instance .
Submitting exchange requests You can exchange your Convertible Reserved Instances using the Amazon EC2 console or a command line tool .
Exchanging a Convertible Reserved Instance using the console You can search for Convertible Reserved Instances oﬀerings and select your new conﬁguration from the choices provided .
Choose Reserved Instances , select the Convertible Reserved Instances to exchange , and choose Actions , Exchange Reserved Instance .
Select the attributes of the desired conﬁguration using the drop-down menus , and choose Find Oﬀering .
Select a new Convertible Reserved Instance The Instance Count column displays the number of Reserved Instances that you receive for the exchange .
When you have selected a Convertible Reserved Instance that meets your needs , choose Exchange .
The Reserved Instances that were exchanged are retired , and the new Reserved Instances are displayed in the Amazon EC2 console .
You reserve the capacity in advance , so that you know it is available when you need it .
You pay for the time that the instances are scheduled , even if you do not use them .
Scheduled Instances are a good choice for workloads that do not run continuously , but do run on a regular schedule .
For example , you can use Scheduled Instances for an application that runs during business hours or for batch processing that runs at the end of the week .
If you require a capacity reservation on a continuous basis , Reserved Instances might meet your needs and decrease costs .
If you are ﬂexible about when your instances run , Spot Instances might meet your needs and decrease costs .
317 Amazon Elastic Compute Cloud User Guide for Linux Instances Scheduled Instances To get started , you must search for an available schedule .
You can search across multiple pools or a single pool .
You must launch your Scheduled Instances during their scheduled time periods , using a launch conﬁguration that matches the following attributes of the schedule that you purchased : instance type , Availability Zone , network , and platform .
Amazon EC2 must ensure that the EC2 instances have terminated by the end of the current scheduled time period so that the capacity is available for any other Scheduled Instances it is reserved for .
Therefore , Amazon EC2 terminates the EC2 instances three minutes before the end of the current scheduled time period .
You ca n't stop or reboot Scheduled Instances , but you can terminate them manually as needed .
If you terminate a Scheduled Instance before its current scheduled time period ends , you can launch it again after a few minutes .
Otherwise , you must wait until the next scheduled time period .
The following diagram illustrates the lifecycle of a Scheduled Instance .
A service-linked role includes all the permissions that Amazon EC2 requires to call other AWS services on your behalf .
For more information , see A New Role Appeared in My Account in the IAM User Guide .
If you no longer need to use Scheduled Instances , we recommend that you delete the AWSServiceRoleForEC2ScheduledInstances role .
After this role is deleted from your account , Amazon EC2 will create the role again if you purchase Scheduled Instances .
318 Amazon Elastic Compute Cloud User Guide for Linux Instances Scheduled Instances Purchasing a Scheduled Instance To purchase a Scheduled Instance , you can use the Scheduled Reserved Instances Reservation Wizard .
If the currently selected Region does not support Scheduled Instances , the page is unavailable .
Note that the console ensures that you specify a value for the minimum duration that meets the minimum required utilization for your Scheduled Instance ( 1,200 hours per year ) .
Under Instance details , select the operating system and network from Platform .
To narrow the results , select one or more instance types from Instance type or one or more Availability Zones from Availability Zone .
For each schedule that you select , set the quantity of instances and choose Add to Cart .
e. Your cart is displayed at the bottom of the page .
When you are ﬁnished adding and removing schedules from your cart , choose Review and purchase .
On the Review and purchase page , verify your selections and edit them as needed .
To purchase a Scheduled Instance ( AWS CLI ) Use the describe-scheduled-instance-availability command to list the available schedules that meet your needs , and then use the purchase-scheduled-instances command to complete the purchase .
319 Amazon Elastic Compute Cloud User Guide for Linux Instances Scheduled Instances Launching a Scheduled Instance After you purchase a Scheduled Instance , it is available for you to launch during its scheduled time periods .
If the currently selected Region does not support Scheduled Instances , the page is unavailable .
Select the Scheduled Instance and choose Launch Scheduled Instances .
On the Conﬁgure page , complete the launch speciﬁcation for your Scheduled Instances and choose Review .
Important The launch speciﬁcation must match the instance type , Availability Zone , network , and platform of the schedule that you purchased .
On the Review page , verify the launch conﬁguration and modify it as needed .
To launch a Scheduled Instance ( AWS CLI ) Use the describe-scheduled-instances command to list your Scheduled Instances , and then use the runscheduled-instances command to launch each Scheduled Instance during its scheduled time periods .
320 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances Spot Instances A Spot Instance is an unused EC2 instance that is available for less than the On-Demand price .
Because Spot Instances enable you to request unused EC2 instances at steep discounts , you can lower your Amazon EC2 costs signiﬁcantly .
The Spot price of each instance type in each Availability Zone is set by Amazon EC2 , and adjusted gradually based on the long-term supply of and demand for Spot Instances .
Your Spot Instance runs whenever capacity is available and the maximum price per hour for your request exceeds the Spot price .
Spot Instances are a cost-eﬀective choice if you can be ﬂexible about when your applications run and if your applications can be interrupted .
• Spot Instance request – Provides the maximum price per hour that you are willing to pay for a Spot Instance .
When the maximum price per hour for your request exceeds the Spot price , Amazon EC2 fulﬁlls your request if capacity is available .
Amazon EC2 automatically resubmits a persistent Spot request after the Spot Instance associated with the request is terminated .
Your Spot Instance request can optionally specify a duration for the Spot Instances .
• Spot Fleet – A set of Spot Instances that is launched based on criteria that you specify .
The Spot Fleet selects the Spot Instance pools that meet your needs and launches Spot Instances to meet the target capacity for the ﬂeet .
By default , Spot Fleets are set to maintain target capacity by launching replacement instances after Spot Instances in the ﬂeet are terminated .
• Spot Instance interruption – Amazon EC2 terminates , stops , or hibernates your Spot Instance when the Spot price exceeds the maximum price for your request or capacity is no longer available .
Key diﬀerences between Spot Instances and On-Demand Instances The following table lists the key diﬀerences between Spot Instances and On-Demand Instances .
Launch time Spot Instances On-Demand Instances Can only be launched immediately if the Spot Request is active and capacity is available .
Can only be launched immediately if you make a manual launch request and capacity is available .
321 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances Spot Instances On-Demand Instances Available capacity If capacity is not available , the Spot Request continues to automatically make the launch request until capacity becomes available .
Hourly price The hourly price for Spot Instances varies based on demand .
Instance interruption You can stop and start an Amazon EBS-backed Spot Instance .
In addition , the Amazon EC2 Spot service can interrupt ( p. 384 ) an individual Spot Instance if capacity is no longer available , the Spot price exceeds your maximum price , or demand for Spot Instances increases .
Strategies for using Spot Instances One strategy to maintain a minimum level of guaranteed compute resources for your applications is to launch a core group of On-Demand Instances , and supplement them with Spot Instances when the opportunity arises .
Another strategy is to launch Spot Instances with a speciﬁed duration ( also known as Spot blocks ) , which are designed not to be interrupted and will run continuously for the duration you select .
In rare situations , Spot blocks may be interrupted due to Amazon EC2 capacity needs .
In these cases , we provide a two-minute warning before we terminate an instance , and you are not charged for the terminated instances even if you used them .
How to get started The ﬁrst thing you need to do is get set up to use Amazon EC2 .
It can also be helpful to have experience launching On-Demand Instances before launching Spot Instances .
You can also provision Spot Instances using other services in AWS .
Amazon EC2 Auto Scaling and Spot Instances You can create launch templates or conﬁgurations with the maximum price that you are willing to pay , so that Amazon EC2 Auto Scaling can launch Spot Instances .
For more information , see Launching Spot Instances in Your Auto Scaling Group and Using Multiple Instance Types and Purchase Options in the Amazon EC2 Auto Scaling User Guide .
Amazon EMR and Spot Instances There are scenarios where it can be useful to run Spot Instances in an Amazon EMR cluster .
For more information , see Spot Instances and When Should You Use Spot Instances in the Amazon EMR Management Guide .
AWS CloudFormation templates AWS CloudFormation enables you to create and manage a collection of AWS resources using a template in JSON format .
AWS CloudFormation templates can include the maximum price you are willing to pay .
AWS SDK for Java You can use the Java programming language to manage your Spot Instances .
AWS SDK for .NET You can use the .NET programming environment to manage your Spot Instances .
Pricing and savings You pay the Spot price for Spot Instances , which is set by Amazon EC2 and adjusted gradually based on the long-term supply of and demand for Spot Instances .
If the maximum price for your request exceeds 323 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances the current Spot price , Amazon EC2 fulﬁlls your request if capacity is available .
Your Spot Instances run until you terminate them , capacity is no longer available , the Spot price exceeds your maximum price , or your Amazon EC2 Auto Scaling group terminates them during scale in .
Spot Instances with a predeﬁned duration use a ﬁxed hourly price that remains in eﬀect for the Spot Instance while it runs .
If you or Amazon EC2 interrupts a running Spot Instance , you are charged for the seconds used or the full hour , or you receive no charge , depending on the operating system used and who interrupted the Spot Instance .
View prices To view the current ( updated every ﬁve minutes ) lowest Spot price per AWS Region and instance type , see the Spot Instances Pricing page .
We independently map Availability Zones to codes for each AWS account .
View savings You can view the savings made from using Spot Instances for a single Spot Fleet or for all Spot Instances .
You can view the savings made in the last hour or the last three days , and you can view the average cost per vCPU hour and per memory ( GiB ) hour .
Savings are estimated and may diﬀer from actual savings because they do not include the billing adjustments for your usage .
View billing To review your bill , go to your AWS Account Activity page .
Your bill contains links to usage reports that provide details about your bill .
How Spot Instances work To use Spot Instances , create a Spot Instance request or a Spot Fleet request .
The request can include the maximum price that you are willing to pay per hour per instance ( the default is the On-Demand price ) , and other constraints such as the instance type and Availability Zone .
If your maximum price exceeds the current Spot price for the speciﬁed instance , and capacity is available , your request is fulﬁlled immediately .
Otherwise , the request is fulﬁlled whenever the maximum price exceeds the Spot price and the capacity is available .
When you use Spot Instances , you must be prepared for interruptions .
Amazon EC2 can interrupt your Spot Instance when the Spot price exceeds your maximum price , when the demand for Spot Instances rises , or when the supply of Spot Instances decreases .
In addition , if the Spot service must terminate one of the instances in a launch group ( for example , if the Spot price exceeds your maximum price ) , it must terminate them all .
However , if you terminate one or more of the instances in a launch group , Amazon EC2 does not terminate the remaining instances in the launch group .
Although this option can be useful , adding this constraint can decrease the chances that your Spot Instance request is fulﬁlled and increase the chances that your Spot Instances are terminated .
For example , your launch group includes instances in multiple Availability Zones .
If capacity in one of these Availability Zones decreases and is no longer available , then Amazon EC2 terminates all instances for the launch group .
If you create another successful Spot Instance request that speciﬁes the same ( existing ) launch group as an earlier successful request , then the new instances are added to the launch group .
Subsequently , if an instance in this launch group is terminated , all instances in the launch group are terminated , which includes instances launched by the ﬁrst and second requests .
Launching Spot Instances in an Availability Zone group Specify an Availability Zone group in your Spot Instance request to tell the Spot service to launch a set of Spot Instances in the same Availability Zone .
Amazon EC2 need not interrupt all instances in an Availability Zone group at the same time .
If Amazon EC2 must interrupt one of the instances in an Availability Zone group , the others remain running .
Although this option can be useful , adding this constraint can lower the chances that your Spot Instance request is fulﬁlled .
If you specify an Availability Zone group but do n't specify an Availability Zone in the Spot Instance request , the result depends on the network you speciﬁed .
Default VPC Amazon EC2 uses the Availability Zone for the speciﬁed subnet .
If you deleted the default subnet for an Availability Zone , then you must specify a diﬀerent subnet .
Nondefault VPC Amazon EC2 uses the Availability Zone for the speciﬁed subnet .
Launching Spot Instances in a VPC You specify a subnet for your Spot Instances the same way that you specify a subnet for your OnDemand Instances .
• You should use the default maximum price ( the On-Demand price ) , or base your maximum price on the Spot price history of Spot Instances in a VPC .
• [ Default VPC ] If you want your Spot Instance launched in a speciﬁc low-priced Availability Zone , you must specify the corresponding subnet in your Spot Instance request .
If you do not specify a subnet , 325 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances Amazon EC2 selects one for you , and the Availability Zone for this subnet might not have the lowest Spot price .
The Spot Fleet attempts to launch the number of Spot Instances and On-Demand Instances to meet the target capacity that you speciﬁed in the Spot Fleet request .
The request for Spot Instances is fulﬁlled if there is available capacity and the maximum price you speciﬁed in the request exceeds the current Spot price .
The Spot Fleet also attempts to maintain its target capacity ﬂeet if your Spot Instances are interrupted .
You can also set a maximum amount per hour that you ’ re willing to pay for your ﬂeet , and Spot Fleet launches instances until it reaches the maximum amount .
When the maximum amount you 're willing to pay is reached , the ﬂeet stops launching instances even if it hasn ’ t met the target capacity .
The Spot Fleet selects the Spot Instance pools that are used to fulﬁll the request , based on the launch speciﬁcations included in your Spot Fleet request , and the conﬁguration of the Spot Fleet request .
The Spot Instances come from the selected pools .
In your Spot Fleet request , you specify your desired target capacity and how much of that capacity must be On-Demand .
The balance comprises Spot capacity , which is launched if there is available Amazon EC2 capacity and availability .
Prioritizing instance types for On-Demand capacity When Spot Fleet attempts to fulﬁll your On-Demand capacity , it defaults to launching the lowest-priced instance type ﬁrst .
If OnDemandAllocationStrategy is set to prioritized , Spot Fleet uses priority to determine which instance type to use ﬁrst in fulﬁlling On-Demand capacity .
The priority is assigned to the launch template override , and the highest priority is launched ﬁrst .
Because you often have unused Reserved 326 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances Instances for c4.large , you can set the launch template override priority so that the order is c4.large , c3.large , and then c5.large .
Allocation strategy for Spot Instances The allocation strategy for the Spot Instances in your Spot Fleet determines how it fulﬁlls your Spot Fleet request from the possible Spot Instance pools represented by its launch speciﬁcations .
The following are the allocation strategies that you can specify in your Spot Fleet request : lowestPrice The Spot Instances come from the pool with the lowest price .
diversified The Spot Instances are distributed across all pools .
capacityOptimized The Spot Instances come from the pool with optimal capacity for the number of instances that are launching .
InstancePoolsToUseCount The Spot Instances are distributed across the number of Spot pools that you specify .
This parameter is valid only when used in combination with lowestPrice .
Maintaining target capacity After Spot Instances are terminated due to a change in the Spot price or available capacity of a Spot Instance pool , a Spot Fleet of type maintain launches replacement Spot Instances .
If the allocation strategy is lowestPrice , the ﬂeet launches replacement instances in the pool where the Spot price is currently the lowest .
If the allocation strategy is diversified , the ﬂeet distributes the replacement Spot Instances across the remaining pools .
If the allocation strategy is lowestPrice in combination with InstancePoolsToUseCount , the ﬂeet selects the Spot pools with the lowest price and launches Spot Instances across the number of Spot pools that you specify .
Conﬁguring Spot Fleet for cost optimization To optimize the costs for your use of Spot Instances , specify the lowestPrice allocation strategy so that Spot Fleet automatically deploys the least expensive combination of instance types and Availability Zones based on the current Spot price .
For On-Demand Instance target capacity , Spot Fleet always selects the least expensive instance type based on the public On-Demand price , while continuing to follow the allocation strategy ( either lowestPrice , capacityOptimized , or diversified ) for Spot Instances .
Conﬁguring Spot Fleet for cost optimization and diversiﬁcation To create a ﬂeet of Spot Instances that is both cheap and diversiﬁed , use the lowestPrice allocation strategy in combination with InstancePoolsToUseCount .
Spot Fleet automatically deploys the cheapest combination of instance types and Availability Zones based on the current Spot price across the number of Spot pools that you specify .
This combination can be used to avoid the most expensive Spot Instances .
Conﬁguring Spot Fleet for capacity optimization With Spot Instances , pricing changes slowly over time based on long-term trends in supply and demand , but capacity ﬂuctuates in real time .
The capacityOptimized strategy automatically launches Spot Instances into the most available pools by looking at real-time capacity data and predicting which 327 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances are the most available .
This works well for workloads such as big data and analytics , image and media rendering , machine learning , and high performance computing that may have a higher cost of interruption associated with restarting work and checkpointing .
By oﬀering the possibility of fewer interruptions , the capacityOptimized strategy can lower the overall cost of your workload .
Choosing an appropriate allocation strategy You can optimize your Spot Fleets based on your use case .
If your ﬂeet is small or runs for a short time , the probability that your Spot Instances may be interrupted is low , even with all the instances in a single Spot Instance pool .
Therefore , the lowestPrice strategy is likely to meet your needs while providing the lowest cost .
If your ﬂeet is large or runs for a long time , you can improve the availability of your ﬂeet by distributing the Spot Instances across multiple pools .
If the Spot price for one pool exceeds your maximum price for this pool , only 10 % of your ﬂeet is aﬀected .
Using this strategy also makes your ﬂeet less sensitive to increases in the Spot price in any one pool over time .
With the diversified strategy , the Spot Fleet does not launch Spot Instances into any pools with a Spot price that is equal to or higher than the On-Demand price .
To create a cheap and diversiﬁed ﬂeet , use the lowestPrice strategy in combination with InstancePoolsToUseCount .
You can use a low or high number of Spot pools across which to allocate your Spot Instances .
For example , if you run batch processing , we recommend specifying a low number of Spot pools ( for example , InstancePoolsToUseCount=2 ) to ensure that your queue always has compute capacity while maximizing savings .
If your ﬂeet runs workloads that may have a higher cost of interruption associated with restarting work and checkpointing , then use the capacityOptimized strategy .
This strategy oﬀers the possibility of fewer interruptions , which can lower the overall cost of your workload .
Spot Fleet uses this as the default maximum price for each of its launch speciﬁcations .
You can optionally specify a maximum price in one or more launch speciﬁcations .
This price is speciﬁc to the launch speciﬁcation .
If a launch speciﬁcation includes a speciﬁc price , the Spot Fleet uses this maximum price , overriding the global maximum price .
Any other launch speciﬁcations that do not include a speciﬁc maximum price still use the global maximum price .
Control spending Spot Fleet stops launching instances when it has either reached the target capacity or the maximum amount you ’ re willing to pay .
To control the amount you pay per hour for your ﬂeet , you can specify the SpotMaxTotalPrice for Spot Instances and the OnDemandMaxTotalPrice for On-Demand Instances .
When the maximum total price is reached , Spot Fleet stops launching instances even if it hasn ’ t met the target capacity .
The following examples show two diﬀerent scenarios .
In the ﬁrst , Spot Fleet stops launching instances when it has met the target capacity .
In the second , Spot Fleet stops launching instances when it has reached the maximum amount you ’ re willing to pay .
Spot Fleet instance weighting When you request a ﬂeet of Spot Instances , you can deﬁne the capacity units that each instance type would contribute to your application 's performance , and adjust your maximum price for each Spot Instance pool accordingly using instance weighting .
By default , the price that you specify is per instance hour .
When you use the instance weighting feature , the price that you specify is per unit hour .
You can calculate your price per unit hour by dividing your price for an instance type by the number of units that it represents .
Spot Fleet calculates the number of Spot Instances to launch by dividing the target capacity by the instance weight .
If the result is n't an integer , the Spot Fleet rounds it up to the next integer , so that the size of your ﬂeet is not below its target capacity .
Spot Fleet can select any pool that you specify in your launch speciﬁcation , even if the capacity of the instances launched exceeds the requested target capacity .
The following tables provide examples of calculations to determine the price per unit for a Spot Fleet request with a target capacity of 10 .
Set the target capacity for your Spot Fleet either in instances ( the default ) or in the units of your choice , such as virtual CPUs , memory , storage , or throughput .
For each launch conﬁguration , specify the weight , which is the number of units that the instance type represents toward the target capacity .
With the lowestPrice strategy , all four instances come from the pool that provides the lowest price per unit .
With the diversified strategy , the Spot Fleet launches one instance in each of the three pools , and the fourth instance in whichever pool provides the lowest price per unit .
Walkthrough : Using Spot Fleet with instance weighting This walkthrough uses a ﬁctitious company called Example Corp to illustrate the process of requesting a Spot Fleet using instance weighting .
Objective Example Corp , a pharmaceutical company , wants to leverage the computational power of Amazon EC2 for screening chemical compounds that might be used to ﬁght cancer .
Planning Example Corp ﬁrst reviews Spot Best Practices .
Next , Example Corp determines the following requirements for their Spot Fleet .
Instance types 330 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances Example Corp has a compute- and memory-intensive application that performs best with at least 60 GB of memory and eight virtual CPUs ( vCPUs ) .
They want to maximize these resources for the application at the lowest possible price .
By considering the base for their application ( 60 GB of RAM and eight vCPUs ) as 1 unit , Example Corp decides that 20 times this amount would meet their needs .
So the company sets the target capacity of their Spot Fleet request to 20 .
Instance weights After determining the target capacity , Example Corp calculates instance weights .
Price per unit hour Example Corp uses the On-Demand price per instance hour as a starting point for their price .
They could also use recent Spot prices , or a combination of the two .
To calculate the price per unit hour , they divide their starting price per instance hour by the weight .
Verifying permissions Before creating a Spot Fleet request , Example Corp veriﬁes that it has an IAM role with the required permissions .
Fulﬁllment The allocation strategy determines which Spot Instance pools your Spot Instances come from .
With the lowestPrice strategy ( which is the default strategy ) , the Spot Instances come from the pool with the lowest price per unit at the time of fulﬁllment .
If Example Corp used the diversified strategy , the Spot Instances would come from all three pools .
Spot Instance pricing history When you request Spot Instances , we recommend that you use the default maximum price ( the OnDemand price ) .
If you want to specify a maximum price , we recommend that you review the Spot price history before you do so .
You can view the Spot price history for the last 90 days , ﬁltering by instance type , operating system , and Availability Zone .
Spot Instance prices are set by Amazon EC2 and adjust gradually based on long-term trends in supply and demand for Spot Instance capacity .
For the current Spot Instance prices see Amazon EC2 Spot Instances Pricing .
332 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances To view the Spot price history ( console ) 1 .
Choose Get started , scroll to the bottom of the screen , and then choose Cancel .
Move your pointer over the graph to display the prices at speciﬁc times in the selected date range .
To view the Spot price history using the command line You can use one of the following commands .
At the per-ﬂeet level , the usage and savings information includes all instances launched and terminated by the ﬂeet .
You can view this information from the last hour or the last three days .
333 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances The following screenshot from the Spot Requests page shows the Spot usage and savings information for a Spot Fleet .
You can view the following usage and savings information : • Spot Instances – The number of Spot Instances launched and terminated by the Spot Fleet .
When viewing the savings summary , the number represents all your running Spot Instances .
• vCPU-hours – The number of vCPU hours used across all the Spot Instances for the selected time frame .
• Spot total – The total amount to pay for the selected time frame .
• Details table – The diﬀerent instance types ( the number of instances per instance type is in parentheses ) that comprise the Spot Fleet .
When viewing the savings summary , these comprise all your running Spot Instances .
Savings information can only be viewed using the Amazon EC2 console .
By default , the page displays usage and savings information for the last three days .
You can choose last hour or the last three days .
For Spot Fleets that were launched less than an hour ago , the page shows the estimated savings for the hour .
Spot Instance requests To use Spot Instances , you create a Spot Instance request that includes the desired number of instances , the instance type , the Availability Zone , and the maximum price that you are willing to pay per instance hour .
If your maximum price exceeds the current Spot price , Amazon EC2 fulﬁlls your request immediately if capacity is available .
Otherwise , Amazon EC2 waits until your request can be fulﬁlled or until you cancel the request .
The following illustration shows how Spot requests work .
Notice that the request type ( one-time or persistent ) determines whether the request is opened again when Amazon EC2 interrupts a Spot Instance or if you stop a Spot Instance .
If the request is persistent , the request is opened again after your Spot Instance is interrupted .
If the request is persistent and you stop your Spot Instance , the request only opens after you start your Spot Instance .
The following illustration represents the transitions between the request states .
If the Spot price exceeds your maximum price or capacity is not available , your Spot Instance is terminated and the Spot Instance request is closed .
A persistent Spot Instance request remains active until it expires or you cancel it , even if the request is fulﬁlled .
If the Spot price exceeds your maximum price or capacity is not available , your Spot Instance is interrupted .
After your instance is interrupted , when your maximum price exceeds the Spot price 336 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances or capacity becomes available again , the Spot Instance is started if stopped or resumed if hibernated .
You can stop a Spot Instance and start it again if capacity is available and your maximum price exceeds the current Spot price .
If the Spot Instance is terminated ( irrespective of whether the Spot Instance is in a stopped or running state ) , the Spot Instance request is opened again and Amazon EC2 launches a new Spot Instance .
You can track the status of your Spot Instance requests , as well as the status of the Spot Instances launched , through the status .
Deﬁning a duration for your Spot Instances Spot Instances with a deﬁned duration ( also known as Spot blocks ) are designed not to be interrupted and will run continuously for the duration you select .
This makes them ideal for jobs that take a ﬁnite time to complete , such as batch processing , encoding and rendering , modeling and analysis , and continuous integration .
The price that you pay depends on the speciﬁed duration .
When a request with a duration is fulﬁlled , the price for your Spot Instance is ﬁxed , and this price remains in eﬀect until the instance terminates .
You are billed at this price for each hour or partial hour that the instance is running .
A partial instance hour is billed to the nearest second .
When you deﬁne a duration in your Spot request , the duration period for each Spot Instance starts as soon as the instance receives its instance ID .
The Spot Instance runs until you terminate it or the duration period ends .
At the end of the duration period , Amazon EC2 marks the Spot Instance for termination and provides a Spot Instance termination notice , which gives the instance a two-minute warning before it terminates .
In rare situations , Spot blocks may be interrupted due to Amazon EC2 capacity needs .
In these cases , we provide a two-minute warning before we terminate an instance , and you are not charged for the terminated instances even if you used them .
For example , the following command creates a Spot request that launches Spot Instances that run for two hours .
The information is in the actualBlockHourlyPrice ﬁeld .
Dedicated Spot Instances are physically isolated from instances that belong to other AWS accounts .
To run a Dedicated Spot Instance , do one of the following : 337 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances • Specify a tenancy of dedicated when you create the Spot Instance request .
You can not request a Spot Instance with a tenancy of default if you request it in a VPC with an instance tenancy of dedicated .
The following instance types support Dedicated Spot Instances .
A service-linked role is a unique type of IAM role that is linked directly to an AWS service .
Service-linked roles provide a secure way to delegate permissions to AWS services because only the linked service can assume a service-linked role .
338 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances If you had an active Spot Instance request before October 2017 , when Amazon EC2 began supporting this service-linked role , Amazon EC2 created the AWSServiceRoleForEC2Spot role in your AWS account .
For more information , see A New Role Appeared in My Account in the IAM User Guide .
Ensure that this role exists before you use the AWS CLI or an API to request a Spot Instance .
To create the role , use the IAM console as follows .
If you no longer need to use Spot Instances , we recommend that you delete the AWSServiceRoleForEC2Spot role .
After this role is deleted from your account , Amazon EC2 will create the role again if you request Spot Instances .
Granting access to CMKs for use with encrypted AMIs and EBS snapshots If you specify an encrypted AMI ( p. 149 ) or an encrypted Amazon EBS snapshot ( p. 1010 ) for your Spot Instances and you use a customer managed customer master key ( CMK ) for encryption , you must grant the AWSServiceRoleForEC2Spot role permission to use the CMK so that Amazon EC2 can launch Spot Instances on your behalf .
To do this , you must add a grant to the CMK , as shown in the following procedure .
When providing permissions , grants are an alternative to key policies .
For more information , see Using Grants and Using Key Policies in AWS KMS in the AWS Key Management Service Developer Guide .
To grant the AWSServiceRoleForEC2Spot role permissions to use the CMK • Use the create-grant command to add a grant to the CMK and to specify the principal ( the AWSServiceRoleForEC2Spot service-linked role ) that is given permission to perform the operations that the grant permits .
The CMK is speciﬁed by the key-id parameter and the ARN of the CMK .
You ca n't change the parameters of your Spot Instance request , including your maximum price , after you 've submitted the request .
If you request multiple Spot Instances at one time , Amazon EC2 creates separate Spot Instance requests so that you can track the status of each request separately .
339 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances Prerequisites Before you begin , decide on your maximum price , how many Spot Instances you 'd like , and what instance type to use .
Amazon EC2 launches your Spot Instance when the maximum price exceeds the Spot price and capacity is available .
The Spot Instance runs until it is interrupted or you terminate it yourself .
Use the describespot-instance-requests command to monitor your Spot Instance request .
A Spot Instance runs until it is interrupted or you terminate it yourself .
If your maximum price is exactly equal to the Spot price , there is a chance that your Spot Instance remains running , depending on demand .
You can see both Spot Instance requests and Spot Fleet requests .
If a Spot Instance request has been fulﬁlled , Capacity is the ID of the Spot Instance .
For a Spot Fleet , Capacity indicates how much of the requested capacity has been fulﬁlled .
To view the IDs of the instances in a Spot Fleet , choose the expand arrow , or select the ﬂeet and choose Instances .
Spot Instance requests are not tagged instantly and for a period of time may appear separate from Spot Fleet Requests ( SFR ) .
340 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances To ﬁnd running Spot Instances ( AWS CLI ) To enumerate your Spot Instances , use the describe-spot-instance-requests command with the -- query option .
You can assign a tag to a Spot Instance request after you create it .
The tags that you create for your Spot Instance requests only apply to the requests .
These tags are not added automatically to the Spot Instance that the Spot service launches to fulﬁll the request .
You must add tags to a Spot Instance yourself after the Spot Instance is launched .
To add a tag to your Spot Instance request or Spot Instance using the AWS CLI Use the create-tags command to tag your resources .
You can only cancel Spot Instance requests that are open , active , or disabled .
• Your Spot Instance request is open when your request has not yet been fulﬁlled and no instances have been launched .
• Your Spot Instance request is active when your request has been fulﬁlled and Spot Instances have launched as a result .
• Your Spot Instance request is disabled when you stop your Spot Instance .
If your Spot Instance request is active and has an associated running Spot Instance , or your Spot Instance request is disabled and has an associated stopped Spot Instance , canceling the request does not terminate the instance .
In the navigation pane , choose Spot Requests and select the Spot request .
The steps for stopping a Spot Instance are similar to the steps for stopping an On-Demand Instance .
You can only stop a Spot Instance if the Spot Instance was launched from a persistent Spot Instance request .
Note While a Spot Instance is stopped , you can modify some of its instance attributes , but not the instance type .
We do n't charge usage for a stopped Spot Instance , or data transfer fees , but we do charge for the storage for any Amazon EBS volumes .
In the navigation pane , choose Instances and select the Spot Instance .
The steps for starting a Spot Instance are similar to the steps for starting an On-Demand Instance .
Prerequisites You can only start a Spot Instance if : 342 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances • You manually stopped the Spot Instance .
• The Spot price is lower than your maximum price .
Limitations • You ca n't start a Spot Instance if it is part of ﬂeet or launch group , Availability Zone group , or Spot block .
In the navigation pane , choose Instances and select the Spot Instance .
aws ec2 start-instances -- instance-ids i-1234567890abcdef0 Terminating a Spot Instance If your Spot Instance request is active and has an associated running Spot Instance , or your Spot Instance request is disabled and has an associated stopped Spot Instance , canceling the request does not terminate the instance ; you must terminate the running Spot Instance manually .
If you terminate a running or stopped Spot Instance that was launched by a persistent Spot request , the Spot request returns to the open state so that a new Spot Instance can be launched .
To cancel a persistent Spot request and terminate its Spot Instances , you must cancel the Spot request ﬁrst and then terminate the Spot Instances .
Launch a Dedicated Spot Instance ( p. 345 ) 343 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances Example 1 : Launch Spot Instances The following example does not include an Availability Zone or subnet .
Amazon EC2 launches the instances in the default subnet of the selected Availability Zone .
Amazon EC2 launches the instances in the default subnet of the speciﬁed Availability Zone .
When you specify a network interface , you must include the subnet ID and security group ID using the network interface , rather than using the SubnetId and SecurityGroupIds ﬁelds shown in example 3 .
Amazon EC2 attempts to maintain your Spot Fleet 's target capacity as Spot prices change .
There are two types of Spot Fleet requests : request and maintain .
You can create a Spot Fleet to submit a one-time request for your desired capacity , or require it to maintain a target capacity over time .
Both types of requests beneﬁt from Spot Fleet 's allocation strategy .
When you make a one-time request , Spot Fleet places the required requests but does not attempt to replenish Spot Instances if capacity is diminished .
If capacity is not available , Spot Fleet does not submit requests in alternative Spot pools .
To maintain a target capacity , Spot Fleet places requests to meet the target capacity and automatically replenish any interrupted instances .
It is not possible to modify the target capacity of a one-time request after it 's been submitted .
To change the target capacity , cancel the request and submit a new one .
A Spot Fleet request remains active until it expires or you cancel it .
When you cancel a Spot Fleet request , you may specify whether canceling your Spot Fleet request terminates the Spot Instances in your Spot Fleet .
Each launch speciﬁcation includes the information that Amazon EC2 needs to launch an instance , such as an AMI , instance type , subnet or Availability Zone , and one or more security groups .
• active – The Spot Fleet has been validated and Amazon EC2 is attempting to maintain the target number of running Spot Instances .
The request remains in this state until it is modiﬁed or canceled .
The request remains in this state until the modiﬁcation is fully processed or the Spot Fleet is canceled .
A one-time request can not be modiﬁed , and this state does not apply to such Spot requests .
Its existing Spot Instances continue to run until they are interrupted or terminated .
The request remains in this state until all instances are interrupted or terminated .
The request remains in this state until all instances are terminated .
• cancelled – The Spot Fleet is canceled and has no running Spot Instances .
The Spot Fleet request is deleted two days after its instances were terminated .
The following illustration represents the transitions between the request states .
If you exceed your Spot Fleet limits , the request is canceled immediately .
346 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances Spot Fleet prerequisites If you use the Amazon EC2 console to create a Spot Fleet , it creates a role named aws-ec2-spotfleet-tagging-role that grants the Spot Fleet permission to request , launch , terminate , and tag instances on your behalf .
This role is selected when you create your Spot Fleet request .
If you use the AWS CLI or an API instead , you must ensure that this role exists .
You can either use the Request Spot Instances wizard ( the role is created when you advance to the second page of the wizard ) or use the IAM console as follows .
Important If you choose to tag instances in the ﬂeet and you choose to maintain target capacity ( the Spot Fleet request is of type maintain ) , the diﬀerences in permissions of the IAM user and the IamFleetRole might lead to inconsistent tagging behavior of instances in the ﬂeet .
If the IamFleetRole does not include the CreateTags permission , some of the instances launched by the ﬂeet might not be tagged .
While we are working to ﬁx this inconsistency , to ensure that all instances launched by the ﬂeet are tagged , we recommend that you use the aws-ec2-spotfleet-tagging-role role for the IamFleetRole .
Alternatively , to use an existing role , attach the AmazonEC2SpotFleetTaggingRole AWS Managed Policy to the existing role .
Otherwise , you need to manually add the CreateTags permission to your existing policy .
Spot Fleet and IAM users If your IAM users will create or manage a Spot Fleet , be sure to grant them the required permissions as follows .
To grant an IAM user permissions for Spot Fleet 1 .
On the Create policy page , choose JSON , replace the text with the following , and choose Review policy .
To limit the user to speciﬁc Amazon EC2 API actions , specify those actions instead .
An IAM user must have permission to call the iam : ListRoles action to enumerate existing IAM roles , the iam : PassRole action to specify the Spot Fleet role , and the iam : ListInstanceProfiles action to enumerate existing instance proﬁles .
On the Review policy page , type a policy name and description and choose Create policy .
In the navigation pane , choose Users and select the user .
Select the policy that you created earlier and choose Next : Review .
Spot Fleet health checks Spot Fleet checks the health status of the Spot Instances in the ﬂeet every two minutes .
The health status of an instance is either healthy or unhealthy .
Spot Fleet determines the health status of an instance using the status checks provided by Amazon EC2 .
If the status of either the instance status check or the system status check is impaired for three consecutive health checks , the health status of the instance is unhealthy .
You can conﬁgure your Spot Fleet to replace unhealthy instances .
After enabling health check replacement , an instance is replaced after its health status is reported as unhealthy .
The Spot Fleet could go below its target capacity for up to a few minutes while an unhealthy instance is being replaced .
Requirements • Health check replacement is supported only with Spot Fleets that maintain a target capacity , not with one-time Spot Fleets .
• You can conﬁgure your Spot Fleet to replace unhealthy instances only when you create it .
• IAM users can use health check replacement only if they have permission to call the ec2 : DescribeInstanceStatus action .
348 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances Planning a Spot Fleet request Before you create a Spot Fleet request , review Spot Best Practices .
Use these best practices when you plan your Spot Fleet request so that you can provision the type of instances you want at the lowest possible price .
We also recommend that you do the following : • Determine whether you want to create a Spot Fleet that submits a one-time request for the desired target capacity , or one that maintains a target capacity over time .
• Determine the instance types that meet your application requirements .
• Determine the target capacity for your Spot Fleet request .
You can set the target capacity in instances or in custom units .
• Determine what portion of the Spot Fleet target capacity must be On-Demand capacity .
To calculate the price per unit , divide the price per instance hour by the number of units ( or weight ) that this instance represents .
If you are not using instance weighting , the default price per unit is the price per instance hour .
• Review the possible options for your Spot Fleet request .
For more information , see the request-spotﬂeet command in the AWS CLI Command Reference .
Service-linked role for Spot Fleet requests Amazon EC2 uses service-linked roles for the permissions that it requires to call other AWS services on your behalf .
A service-linked role is a unique type of IAM role that is linked directly to an AWS service .
Service-linked roles provide a secure way to delegate permissions to AWS services because only the linked service can assume a service-linked role .
349 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances If you had an active Spot Fleet request before October 2017 , when Amazon EC2 began supporting this service-linked role , Amazon EC2 created the AWSServiceRoleForEC2SpotFleet role in your AWS account .
For more information , see A New Role Appeared in My Account in the IAM User Guide .
Ensure that this role exists before you use the AWS CLI or an API to create a Spot Fleet .
To create the role , use the IAM console as follows .
If you no longer need to use Spot Fleet , we recommend that you delete the AWSServiceRoleForEC2SpotFleet role .
After this role is deleted from your account , Amazon EC2 will create the role again if you request a Spot Fleet .
Granting access to CMKs for use with encrypted AMIs and EBS snapshots If you specify an encrypted AMI ( p. 149 ) or an encrypted Amazon EBS snapshot ( p. 1010 ) in your Spot Fleet request and you use a customer managed customer master key ( CMK ) for encryption , you must grant the AWSServiceRoleForEC2SpotFleet role permission to use the CMK so that Amazon EC2 can launch Spot Instances on your behalf .
To do this , you must add a grant to the CMK , as shown in the following procedure .
When providing permissions , grants are an alternative to key policies .
For more information , see Using Grants and Using Key Policies in AWS KMS in the AWS Key Management Service Developer Guide .
To grant the AWSServiceRoleForEC2SpotFleet role permissions to use the CMK • Use the create-grant command to add a grant to the CMK and to specify the principal ( the AWSServiceRoleForEC2SpotFleet service-linked role ) that is given permission to perform the operations that the grant permits .
The CMK is speciﬁed by the key-id parameter and the ARN of the CMK .
Amazon EC2 conﬁgures a ﬂeet that best meets your needs and follows Spot best practice .
Otherwise , you can modify any of the default settings .
350 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances Quickly create a Spot Fleet request ( console ) Follow these steps to quickly create a Spot Fleet request .
For Tell us your application or task need , choose Flexible workloads , Load balancing workloads , Big data workloads , or Deﬁned duration workloads .
Under Conﬁgure your instances , for Minimum compute unit , choose the minimum hardware speciﬁcations ( vCPUs , memory , and storage ) that you need for your application or task , either as specs or as an instance type .
• For as specs , specify the required number of vCPUs and amount of memory .
• For as an instance type , accept the default instance type , or choose Change instance type to choose a diﬀerent instance type .
Under Tell us how much capacity you need , for Total target capacity , specify the number of units to request for target capacity .
You can choose instances or vCPUs .
6. Review the recommended Fleet request settings based on your application or task selection , and choose Launch .
Create a Spot Fleet request using deﬁned parameters ( console ) You can create a Spot Fleet using the parameters that you deﬁne .
For Tell us your application or task need , choose Flexible workloads , Load balancing workloads , Big data workloads , or Deﬁned duration workloads .
The launch template must specify an Amazon Machine Image ( AMI ) , as you can not override the AMI using Spot Fleet if you specify a launch template .
For AMI , choose one of the basic AMIs provided by AWS , or choose Search for AMI to use an AMI from our user community , the AWS Marketplace , or one of your own .
c. For Minimum compute unit , choose the minimum hardware speciﬁcations ( vCPUs , memory , and storage ) that you need for your application or task , either as specs or as an instance type .
• For as specs , specify the required number of vCPUs and amount of memory .
• For as an instance type , accept the default instance type , or choose Change instance type to choose a diﬀerent instance type .
351 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances [ New VPC ] Choose Create new VPC to go the Amazon VPC console .
When you are done , return to the wizard and refresh the list .
e. ( Optional ) For Availability Zone , let AWS choose the Availability Zones for your Spot Instances , or specify one or more Availability Zones .
If you have more than one subnet in an Availability Zone , choose the appropriate subnet from Subnet .
To add subnets , choose Create new subnet to go to the Amazon VPC console .
When you are done , return to the wizard and refresh the list .
[ New key pair ] Choose Create new key pair to go the Amazon VPC console .
When you are done , return to the wizard and refresh the list .
( Optional ) To add storage , specify additional instance store volumes or Amazon EBS volumes , depending on the instance type .
To enable this option , you must ﬁrst choose Maintain target capacity .
[ New security group ] Choose Create new security group to go the Amazon VPC console .
When you are done , return to the wizard and refresh the list .
For each tag , to tag the instances and the Spot Fleet request with the same tag , ensure that both Instance tags and Fleet tags are selected .
To tag only the instances launched by the ﬂeet , clear Fleet tags .
To tag only the Spot Fleet request , clear Instance tags .
For Total target capacity , specify the number of units to request for target capacity .
You can choose instances or vCPUs .
To specify a target capacity of 0 so that you can add capacity later , choose Maintain target capacity .
The number must be less than the Total target capacity .
Amazon EC2 calculates the diﬀerence , and allocates the diﬀerence to Spot units to request .
352 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances Important To specify an optional On-Demand portion , you must ﬁrst choose a launch template .
To maintain the target capacity , choose Maintain target capacity .
You can then specify that the Spot service terminates , stops , or hibernates Spot Instances when they are interrupted .
To do so , choose the corresponding option from Interruption behavior .
Review the ﬂeet request and ﬂeet allocation strategy based on your application or task selection .
To change the instance types or allocation strategy , clear Apply recommendations .
To use the default role after changing the role , choose Use default role .
If your maximum price is lower than the Spot price for the instance types that you selected , your Spot Instances are not launched .
To keep them running after your request expires , clear Terminate the instances when the request expires .
f. ( Optional ) To register your Spot Instances with a load balancer , choose Receive traﬃc from one or more load balancers and choose one or more Classic Load Balancers or target groups .
The Spot Fleet request type is fleet .
When the request is fulﬁlled , requests of type instance are added , where the state is active and the status is fulfilled .
You can assign tags using the Amazon EC2 console or a command line tool .
When you tag a Spot Fleet request , the instances that are launched by the Spot Fleet are not automatically tagged .
You need to explicitly tag the instances launched by the Spot Fleet .
You can choose to assign tags to only the Spot Fleet request , or to only the instances launched by the ﬂeet , or to both .
Prerequisite Grant the IAM user the permission to tag resources .
This grants the IAM user permission to create tags .
This grants the IAM user permission to create a Spot Fleet request .
This allows users to tag all resource types .
If you specify spot-fleet-request as a resource , you will get an unauthorized exception when you try to tag the ﬂeet .
The following example illustrates how not to set the policy .
To add a tag , expand Additional conﬁgurations , choose Add new tag , and enter the key and value for the tag .
For each tag , you can tag the Spot Fleet request and the instances with the same tag .
To tag both , ensure that both Instance tags and Fleet tags are selected .
To tag only the Spot Fleet request , clear Instance tags .
To tag only the instances launched by the ﬂeet , clear Fleet tags .
Complete the required ﬁelds to create a Spot Fleet request , and then choose Launch .
To tag a new Spot Fleet request using the AWS CLI To tag a Spot Fleet request when you create it , conﬁgure the Spot Fleet request conﬁguration as follows : • Specify the tags for the Spot Fleet request in SpotFleetRequestConfig .
If you specify another value , the ﬂeet request will fail .
If you specify another value , the ﬂeet request will fail .
If you specify another value , the ﬂeet request will fail .
Alternatively , you can specify the tags for the instance in the launch template ( p. 453 ) that is referenced in the Spot Fleet request .
The instances that are launched by the ﬂeet are tagged with one tag ( which is the same as one of the tags for the Spot Fleet request ) : Key=Cost-Center and Value=123 .
If you specify another value , the ﬂeet request will fail .
In the following example , the instances that are launched by the ﬂeet are tagged with one tag : Key=Cost-Center and Value=123 .
Choose the Tags tab and choose Create Tag .
To view Spot Fleet request tags using the console 1 .
Select your Spot Fleet request and choose the Tags tab .
To describe Spot Fleet request tags Use the describe-tags command to view the tags for the speciﬁed resource .
In the following example , you describe the tags for the speciﬁed Spot Fleet request .
Use the describe-spot-ﬂeet-requests command to view the conﬁguration of the speciﬁed Spot Fleet request , which includes any tags that were speciﬁed for the ﬂeet request .
The Spot Instances run until they are interrupted or you terminate them .
To list the Spot Instances for the Spot Fleet , choose Instances .
To view the history for the Spot Fleet , choose History .
To monitor your Spot Fleet ( AWS CLI ) Use the describe-spot-ﬂeet-requests command to describe your Spot Fleet requests .
You can only modify a Spot Fleet request if you selected Maintain target capacity when you created the Spot Fleet request .
When you increase the target capacity , the Spot Fleet launches additional Spot Instances .
When you increase the target capacity , the Spot Fleet launches the additional Spot Instances according to the allocation strategy for its Spot Fleet request .
If the allocation strategy is lowestPrice , the Spot Fleet launches the instances from the lowest-priced Spot Instance pool in the Spot Fleet request .
If the allocation strategy is diversified , the Spot Fleet distributes the instances across the pools in the Spot Fleet request .
When you decrease the target capacity , the Spot Fleet cancels any open requests that exceed the new target capacity .
You can request that the Spot Fleet terminate Spot Instances until the size of the ﬂeet reaches the new target capacity .
If the allocation strategy is lowestPrice , the Spot Fleet terminates the instances with the highest price per unit .
If the allocation strategy is diversified , the Spot Fleet terminates instances across the pools .
Alternatively , you can request that the Spot Fleet keep the ﬂeet at its current size , but not replace any Spot Instances that are interrupted or that you terminate manually .
When a Spot Fleet terminates an instance because the target capacity was decreased , the instance receives a Spot Instance interruption notice .
( Optional ) If you are decreasing the target capacity but want to keep the ﬂeet at its current size , clear Terminate instances .
To modify a Spot Fleet request using the AWS CLI Use the modify-spot-ﬂeet-request command to update the target capacity of the speciﬁed Spot Fleet request .
This cancels all Spot requests associated with the Spot Fleet , so that no new Spot Instances are launched for your Spot Fleet .
You must specify whether the Spot Fleet should terminate its Spot Instances .
If you terminate the instances , the Spot Fleet request enters the cancelled_terminating state .
Otherwise , the Spot Fleet request enters the cancelled_running state and the instances continue to run until they are interrupted or you terminate them manually .
In Cancel spot request , verify that you want to cancel the Spot Fleet .
To keep the ﬂeet at its current size , clear Terminate instances .
To cancel a Spot Fleet request using the AWS CLI Use the cancel-spot-ﬂeet-requests command to cancel the speciﬁed Spot Fleet request and terminate the instances .
Make sure you omit the NetworkInterfaceID parameter in your launch speciﬁcation .
The Spot Fleet launches the instances in the lowest-priced Availability Zone that has a default subnet .
The price you pay does not exceed the On-Demand price .
Availability Zones The Spot Fleet launches the instances in the default subnet of the lowest-priced Availability Zone that you speciﬁed .
The Spot service launches the instances in whichever subnet is in the lowest-priced Availability Zone .
You ca n't specify diﬀerent subnets from the same Availability Zone in a Spot Fleet request .
When you specify a network interface , you must include the subnet ID and security group ID using the network interface .
The Spot Fleet launches the instances using the speciﬁed instance type with the lowest price .
Override the price for the request We recommended that you use the default maximum price , which is the On-Demand price .
If you prefer , you can specify a maximum price for the ﬂeet request and maximum prices for individual launch speciﬁcations .
The following examples specify a maximum price for the ﬂeet request and maximum prices for two of the three launch speciﬁcations .
The maximum price for the ﬂeet request is used for any launch speciﬁcation that does not specify a maximum price .
The Spot Fleet launches the instances using the instance type with the lowest price .
The launch speciﬁcations have diﬀerent instance types but the same AMI and Availability Zone or subnet .
The Spot Fleet distributes the 30 instances across the three launch speciﬁcations , such that there are 10 instances of each type .
For this scenario , include each Availability Zone available to you in the launch speciﬁcation .
The Spot Fleet selects the instance type with the lowest price per unit hour .
The Spot Fleet calculates the number of Spot Instances to launch by dividing the target capacity by the instance weight .
If the result is n't an integer , the Spot Fleet rounds it up to the next integer , so that the size of your ﬂeet is not below its target capacity .
368 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances If the c3.xlarge request is successful , Spot provisions 7 of these instances .
The balance of the target capacity is fulﬁlled as Spot if there is capacity and availability .
Spot capacity is not speciﬁed ; it is implied in the balance of the target capacity minus the OnDemand capacity .
Important To ensure accuracy , we recommend that you enable detailed monitoring when using these metrics .
Spot Fleet metrics The AWS/EC2Spot namespace includes the following metrics , plus the CloudWatch metrics for the Spot Instances in your ﬂeet .
Metric Description AvailableInstancePoolsCount The Spot Instance pools speciﬁed in the Spot Fleet request .
Units : Count BidsSubmittedForCapacity The capacity for which Amazon EC2 has submitted Spot Fleet requests .
Units : Count 370 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances Metric Description EligibleInstancePoolCount The Spot Instance pools speciﬁed in the Spot Fleet request where Amazon EC2 can fulﬁll requests .
Amazon EC2 does not fulﬁll requests in pools where the maximum price you 're willing to pay for Spot Instances is less than the Spot price or the Spot price is greater than the price for On-Demand Instances .
Units : Count MaxPercentCapacityAllocation The maximum value of PercentCapacityAllocation across all Spot Fleet pools speciﬁed in the Spot Fleet request .
Units : Percent PendingCapacity The diﬀerence between TargetCapacity and FulfilledCapacity .
Units : Count PercentCapacityAllocation The capacity allocated for the Spot Instance pool for the speciﬁed dimensions .
To get the maximum value recorded across all Spot Instance pools , use MaxPercentCapacityAllocation .
Units : Percent TargetCapacity The target capacity of the Spot Fleet request .
Units : Count TerminatingCapacity The capacity that is being terminated because the provisioned capacity is greater than the target capacity .
Units : Count If the unit of measure for a metric is Count , the most useful statistic is Average .
Spot Fleet dimensions To ﬁlter the data for your Spot Fleet , use the following dimensions .
Dimensions Description AvailabilityZone Filter the data by Availability Zone .
FleetRequestId Filter the data by Spot Fleet request .
InstanceType Filter the data by instance type .
View the CloudWatch metrics for your Spot Fleet You can view the CloudWatch metrics for your Spot Fleet using the Amazon CloudWatch console .
These metrics are displayed as monitoring graphs .
These graphs show data points if the Spot Fleet is active .
371 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances Metrics are grouped ﬁrst by namespace , and then by the various combinations of dimensions within each namespace .
For example , you can view all Spot Fleet metrics or Spot Fleet metrics groups by Spot Fleet request ID , instance type , or Availability Zone .
( Optional ) To ﬁlter the metrics by dimension , select one of the following : • Fleet Request Metrics — Group by Spot Fleet request • By Availability Zone — Group by Spot Fleet request and Availability Zone • By Instance Type — Group by Spot Fleet request and instance type • By Availability Zone/Instance Type — Group by Spot Fleet request , Availability Zone , and instance type 4 .
To view the data for a metric , select the check box next to the metric .
Automatic scaling for Spot Fleet Automatic scaling is the ability to increase or decrease the target capacity of your Spot Fleet automatically based on demand .
A Spot Fleet can either launch instances ( scale out ) or terminate instances ( scale in ) , within the range that you choose , in response to one or more scaling policies .
This is similar to the way that your thermostat maintains the temperature of your home—you select temperature and the thermostat does the rest .
Fulﬁlled capacity can be a ﬂoating-point number but target capacity must be an integer , so Spot Fleet rounds up to the next integer .
You must take these behaviors into account when you 372 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances look at the outcome of a scaling policy when an alarm is triggered .
When the alarm is triggered , the automatic scaling process subtracts 1 from 30.1 to get 29.1 and then rounds it up to 30 , so no scaling action is taken .
If the scaling policy decreases target capacity by 20 % and an alarm is triggered , the automatic scaling process subtracts 12*0.2 from 12 to get 9.6 and then rounds it up to 10 , so no scaling action is taken .
The scaling policies that you create for Spot Fleet support a cooldown period .
This is the number of seconds after a scaling activity completes where previous trigger-related scaling activities can inﬂuence future scaling events .
For scale-out policies , while the cooldown period is in eﬀect , the capacity that has been added by the previous scale-out event that initiated the cooldown is calculated as part of the desired capacity for the next scale out .
For scale in policies , the cooldown period is used to block subsequent scale in requests until it has expired .
The intention is to scale in conservatively to protect your application 's availability .
We recommend that you scale based on instance metrics with a 1-minute frequency because that ensures a faster response to utilization changes .
Scaling on metrics with a 5-minute frequency can result in slower response time and scaling on stale metric data .
To send metric data for your instances to CloudWatch in 1-minute periods , you must speciﬁcally enable detailed monitoring .
For more information about conﬁguring scaling for Spot Fleet , see the following resources : • application-autoscaling section of the AWS CLI Command Reference • Application Auto Scaling API Reference • Application Auto Scaling User Guide IAM permissions required for Spot Fleet automatic scaling Automatic scaling for Spot Fleet is made possible by a combination of the Amazon EC2 , Amazon CloudWatch , and Application Auto Scaling APIs .
Spot Fleet requests are created with Amazon EC2 , alarms are created with CloudWatch , and scaling policies are created with Application Auto Scaling .
In addition to the IAM permissions for Spot Fleet ( p. 347 ) and Amazon EC2 , the IAM user that accesses ﬂeet scaling settings must have the appropriate permissions for the services that support dynamic scaling .
IAM users must have permissions to use the actions shown in the following example policy .
For more information , see Authentication and Access Control in the Application Auto Scaling User Guide .
The Application Auto Scaling service also needs permission to describe your Spot Fleet and CloudWatch alarms , and permissions to modify your Spot Fleet target capacity on your behalf .
This service-linked role grants Application Auto Scaling permission to describe the alarms for your policies , to monitor the current capacity of the ﬂeet , and to modify the capacity of the ﬂeet .
The original managed Spot Fleet role for Application Auto Scaling was aws-ec2-spot-fleet-autoscale-role , but it is no longer required .
The service-linked role is the default role for Application Auto Scaling .
For more information , see Service-Linked Roles in the Application Auto Scaling User Guide .
Scale Spot Fleet using a target tracking policy With target tracking scaling policies , you select a metric and set a target value .
Spot Fleet creates and manages the CloudWatch alarms that trigger the scaling policy and calculates the scaling adjustment based on the metric and the target value .
The scaling policy adds or removes capacity as required to keep the metric at , or close to , the speciﬁed target value .
In addition to keeping the metric close to the target value , a target tracking scaling policy also adjusts to the ﬂuctuations in the metric due to a ﬂuctuating load pattern and minimizes rapid ﬂuctuations in the capacity of the ﬂeet .
You can create multiple target tracking scaling policies for a Spot Fleet , provided that each of them uses a diﬀerent metric .
The ﬂeet scales based on the policy that provides the largest ﬂeet capacity .
This enables you to cover multiple scenarios and ensure that there is always enough capacity to process your application workloads .
To ensure application availability , the ﬂeet scales out proportionally to the metric as fast as it can , but scales in more gradually .
When a Spot Fleet terminates an instance because the target capacity was decreased , the instance receives a Spot Instance interruption notice .
Do not edit or delete the CloudWatch alarms that Spot Fleet manages for a target tracking scaling policy .
Spot Fleet deletes the alarms automatically when you delete the target tracking scaling policy .
Automatic scaling is not supported for one-time requests or Spot blocks .
Select your Spot Fleet request and choose Auto Scaling .
Use Scale capacity between to set the minimum and maximum capacity for your ﬂeet .
Automatic scaling does not scale your ﬂeet below the minimum capacity or above the maximum capacity .
Scale Spot Fleet using step scaling policies With step scaling policies , you specify CloudWatch alarms to trigger the scaling process .
For example , if you want to scale out when CPU utilization reaches a certain level , create an alarm using the CPUUtilization metric provided by Amazon EC2 .
When you create a step scaling policy , you must specify one of the following scaling adjustment types : • Add – Increase the target capacity of the ﬂeet by a speciﬁed number of capacity units or a speciﬁed percentage of the current capacity .
• Remove – Decrease the target capacity of the ﬂeet by a speciﬁed number of capacity units or a speciﬁed percentage of the current capacity .
• Set to – Set the target capacity of the ﬂeet to the speciﬁed number of capacity units .
When an alarm is triggered , the automatic scaling process calculates the new target capacity using the fulﬁlled capacity and the scaling policy , and then updates the target capacity accordingly .
For example , suppose that the target capacity and fulﬁlled capacity are 10 and the scaling policy adds 1 .
When a Spot Fleet terminates an instance because the target capacity was decreased , the instance receives a Spot Instance interruption notice .
Automatic scaling is not supported for one-time requests or Spot blocks .
Prerequisites • Consider which CloudWatch metrics are important to your application .
You can create CloudWatch alarms based on metrics provided by AWS or your own custom metrics .
375 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances • For the AWS metrics that you will use in your scaling policies , enable CloudWatch metrics collection if the service that provides the metrics does not enable it by default .
On the Specify metric and conditions page , choose Select metric .
The Specify metric and conditions page appears , showing a graph and other information about the metric you selected .
When evaluating the alarm , each period is aggregated into one data point .
For Conditions , deﬁne the alarm by deﬁning the threshold condition .
For example , you can deﬁne a threshold to trigger the alarm whenever the value of the metric is greater than or equal to 80 percent .
This creates an alarm that goes to ALARM state if that many consecutive periods are breaching .
For more information , see Evaluating an Alarm in the Amazon CloudWatch User Guide .
For Missing data treatment , choose one of the options ( or leave the default of Treat missing data as missing ) .
For more information , see Conﬁguring How CloudWatch Alarms Treat Missing Data in the Amazon CloudWatch User Guide .
( Optional ) To receive notiﬁcation of a scaling event , for Notiﬁcation , you can choose or create the Amazon SNS topic you want to use to receive notiﬁcations .
Otherwise , you can delete the notiﬁcation now and add one later as needed .
Select your Spot Fleet request and choose Auto Scaling .
Use Scale capacity between to set the minimum and maximum capacity for your ﬂeet .
Automatic scaling does not scale your ﬂeet below the minimum capacity or above the maximum capacity .
Initially , Scaling policies contains policies named ScaleUp and ScaleDown .
You can complete these policies , or choose Remove policy to delete them .
You can also choose Add policy .
For Policy trigger , select an existing alarm or choose Create new alarm to open the Amazon CloudWatch console and create an alarm .
By default , an add policy has a lower bound of -inﬁnity and an upper bound of the alarm threshold .
To conﬁgure step scaling policies for your Spot Fleet using the AWS CLI 1 .
Create an alarm that triggers the scaling policy using the put-metric-alarm command .
Scale Spot Fleet using scheduled scaling Scaling based on a schedule enables you to scale your application in response to predictable changes in demand .
To use scheduled scaling , you create scheduled actions , which tell Spot Fleet to perform scaling activities at speciﬁc times .
When you create a scheduled action , you specify the Spot Fleet , when the scaling activity should occur , minimum capacity , and maximum capacity .
You can create scheduled actions that scale one time only or that scale on a recurring schedule .
Automatic scaling is not supported for one-time requests or Spot blocks .
Select your Spot Fleet request and choose Scheduled Scaling .
Select your Spot Fleet request and choose Scheduled Scaling .
For more information about the cron expressions supported by scheduled scaling , see Cron Expressions in the Amazon CloudWatch Events User Guide .
Select your Spot Fleet request and choose Scheduled Scaling .
Make the needed changes and choose Submit .
Select your Spot Fleet request and choose Scheduled Scaling .
To manage scheduled scaling using the AWS CLI Use the following commands : • put-scheduled-action • describe-scheduled-actions • delete-scheduled-action Spot request status To help you track your Spot Instance requests and plan your use of Spot Instances , use the request status provided by Amazon EC2 .
For example , the request status can provide the reason why your Spot request is n't fulﬁlled yet , or list the constraints that are preventing the fulﬁllment of your Spot request .
At each step of the process—also called the Spot request lifecycle—speciﬁc events determine successive request states .
Each step is depicted as a node , and the status code for each node describes the status of the Spot request and Spot Instance .
378 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances Pending evaluation As soon as you create a Spot Instance request , it goes into the pending-evaluation state unless one or more request parameters are not valid ( bad-parameters ) .
Status code Request state Instance state pending-evaluation open n/a bad-parameters closed n/a Holding If one or more request constraints are valid but ca n't be met yet , or if there is not enough capacity , the request goes into a holding state waiting for the constraints to be met .
The request options aﬀect the likelihood of the request being fulﬁlled .
For example , if you specify a maximum price below the current Spot price , your request stays in a holding state until the Spot price goes below your maximum price .
If you specify an Availability Zone group , the request stays in a holding state until the Availability Zone constraint is met .
In the event of an outage of one of the Availability Zones , there is a chance that the spare EC2 capacity available for Spot Instance requests in other Availability Zones can be aﬀected .
Status code Request state Instance state capacity-not-available open n/a 379 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances Status code Request state Instance state price-too-low open n/a not-scheduled-yet open n/a launch-group-constraint open n/a az-group-constraint open n/a placement-groupconstraint open n/a constraint-notfulfillable open n/a Pending evaluation/fulﬁllment-terminal Your Spot Instance request can go to a terminal state if you create a request that is valid only during a speciﬁc time period and this time period expires before your request reaches the pending fulﬁllment phase .
It might also happen if you cancel the request , or if a system error occurs .
Pending fulﬁllment When the constraints you speciﬁed ( if any ) are met and your maximum price is equal to or higher than the current Spot price , your Spot request goes into the pending-fulfillment state .
At this point , Amazon EC2 is getting ready to provision the instances that you requested .
If the process stops at this point , it is likely to be because it was canceled by the user before a Spot Instance was launched .
It may also be because an unexpected system error occurred .
Status code Request state Instance state pending-fulfillment open n/a Fulﬁlled When all the speciﬁcations for your Spot Instances are met , your Spot request is fulﬁlled .
If a Spot Instance is hibernated or stopped when interrupted , it remains in this state until the request can be fulﬁlled again or the request is canceled .
380 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances Status code Request state Instance state fulfilled active pending → running fulfilled active stopped → running If you stop a Spot Instance , your Spot request goes into the marked-for-stop or instancestopped-by-user state until the Spot Instance can be started again or the request is cancelled .
Status code Request state Instance state marked-for-stop active stopping instance-stopped-by-user* disabled or cancelled** stopped * A Spot Instance goes into the instance-stopped-by-user state if you stop the instance or run the shutdown command from the instance .
On restart , the Spot Instance request returns to the pending-evaluation state and then Amazon EC2 launches a new Spot Instance when the constraints are met .
** The Spot request state is disabled if you stop the Spot Instance but do not cancel the request .
The request state is cancelled if your spot instance is stopped and the request expires .
Fulﬁlled-terminal Your Spot Instances continue to run as long as your maximum price is at or above the Spot price , there is available capacity for your instance type , and you do n't terminate the instance .
If a change in the Spot price or available capacity requires Amazon EC2 to terminate your Spot Instances , the Spot request goes into a terminal state .
A request also goes into the terminal state if you cancel the Spot request or terminate the Spot Instances .
The request state is cancelled if you terminate the instance and cancel the request .
Even if you terminate a Spot Instance before you cancel its request , there might be a delay before Amazon EC2 detects that your Spot Instance was terminated .
In this case , the request state can either be closed or cancelled .
Persistent requests When your Spot Instances are terminated ( either by you or Amazon EC2 ) , if the Spot request is a persistent request , it returns to the pending-evaluation state and then Amazon EC2 can launch a new Spot Instance when the constraints are met .
Getting request status information You can get request status information using the AWS Management Console or a command line tool .
In the navigation pane , choose Spot Requests and select the Spot request .
To get request status information using the command line You can use one of the following commands .
Together , these help you determine the disposition of your Spot request .
The following are the Spot request status codes : az-group-constraint Amazon EC2 can not launch all the instances you requested in the same Availability Zone .
bad-parameters One or more parameters for your Spot request are not valid ( for example , the AMI you speciﬁed does not exist ) .
The status message indicates which parameter is not valid .
382 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances canceled-before-fulfillment The user canceled the Spot request before it was fulﬁlled .
capacity-not-available There is not enough capacity available for the instances that you requested .
constraint-not-fulfillable The Spot request ca n't be fulﬁlled because one or more constraints are not valid ( for example , the Availability Zone does not exist ) .
The status message indicates which constraint is not valid .
fulfilled The Spot request is active , and Amazon EC2 is launching your Spot Instances .
instance-stopped-by-price Your instance was stopped because the Spot price exceeded your maximum price .
instance-stopped-by-user Your instance was stopped because a user stopped the instance or ran the shutdown command from the instance .
instance-stopped-no-capacity Your instance was stopped because there was no longer enough Spot capacity available for the instance .
instance-terminated-by-price Your instance was terminated because the Spot price exceeded your maximum price .
If your request is persistent , the process restarts , so your request is pending evaluation .
instance-terminated-by-schedule Your Spot Instance was terminated at the end of its scheduled duration .
instance-terminated-launch-group-constraint One or more of the instances in your launch group was terminated , so the launch group constraint is no longer fulﬁlled .
instance-terminated-no-capacity Your instance was terminated because there is no longer enough Spot capacity available for the instance .
launch-group-constraint Amazon EC2 can not launch all the instances that you requested at the same time .
All instances in a launch group are started and terminated together .
limit-exceeded The limit on the number of EBS volumes or total volume storage was exceeded .
For more information about these limits and how to request an increase , see Amazon EBS Limits in the Amazon Web Services General Reference .
383 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances marked-for-termination The Spot Instance is marked for termination .
not-scheduled-yet The Spot request is not evaluated until the scheduled date .
pending-evaluation After you make a Spot Instance request , it goes into the pending-evaluation state while the system evaluates the parameters of your request .
placement-group-constraint The Spot request ca n't be fulﬁlled yet because a Spot Instance ca n't be added to the placement group at this time .
price-too-low The request ca n't be fulﬁlled yet because your maximum price is below the Spot price .
In this case , no instance is launched and your request remains open .
request-canceled-and-instance-running You canceled the Spot request while the Spot Instances are still running .
The request is cancelled , but the instances remain running .
schedule-expired The Spot request expired because it was not fulﬁlled before the speciﬁed date .
Spot Instance interruptions Demand for Spot Instances can vary signiﬁcantly from moment to moment , and the availability of Spot Instances can also vary signiﬁcantly depending on how many unused EC2 instances are available .
It is always possible that your Spot Instance might be interrupted .
Therefore , you must ensure that your application is prepared for a Spot Instance interruption .
An On-Demand Instance speciﬁed in an EC2 Fleet or Spot Fleet can not be interrupted .
384 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances • Capacity – If there are not enough unused EC2 instances to meet the demand for Spot Instances , Amazon EC2 interrupts Spot Instances .
The order in which the instances are interrupted is determined by Amazon EC2 .
• Constraints – If your request includes a constraint such as a launch group or an Availability Zone group , these Spot Instances are terminated as a group when the constraint can no longer be met .
Interruption behavior You can specify whether Amazon EC2 should hibernate , stop , or terminate Spot Instances when they are interrupted .
You can choose the interruption behavior that meets your needs .
The default is to terminate Spot Instances when they are interrupted .
To change the interruption behavior , choose an option from Interruption behavior in the console when you are creating a Spot request , or specify InstanceInterruptionBehavior in the launch conﬁguration or the launch template .
To change interruption behavior in the console when you are creating a Spot request , choose Maintain target capacity .
When you select this option , Interruption behavior will appear and you can then specify that the Spot service terminates , stops , or hibernates Spot Instances when they are interrupted .
Stopping interrupted Spot Instances You can change the behavior so that Amazon EC2 stops Spot Instances when they are interrupted if the following requirements are met .
You can not specify a launch group in the Spot Instance request .
• The root volume must be an EBS volume , not an instance store volume .
After a Spot Instance is stopped by the Spot service , only the Spot service can restart the Spot Instance , and the same launch speciﬁcation must be used .
For a Spot Instance launched by a persistent Spot Instance request , the Spot service restarts the stopped instance when capacity is available in the same Availability Zone and for the same instance type as the stopped instance .
If instances in an EC2 Fleet or Spot Fleet are stopped and the ﬂeet is of type maintain , the Spot service launches replacement instances to maintain the target capacity .
The Spot service ﬁnds the best pools based on the speciﬁed allocation strategy ( lowestPrice , diversified , or InstancePoolsToUseCount ) ; it does not prioritize the pool with the earlier stopped instances .
Later , if the allocation strategy leads to a pool containing the earlier stopped instances , the Spot service restarts the stopped instances to meet the target capacity .
Later , when the c3.large instances are interrupted , the Spot service stops the instances and replenishes capacity from another pool that ﬁts the lowestPrice strategy .
This time , the pool happens to be a c4.large pool and the Spot service launches c4.large instances to meet the target capacity .
In each of these transitions , the Spot service does not prioritize pools with earlier stopped instances , but rather prioritizes purely on the speciﬁed allocation strategy .
The lowestPrice strategy can lead back to pools with earlier stopped instances .
For example , if instances are interrupted in the c5.large pool and the lowestPrice strategy leads it back to the c3.large or c4.large pools , the earlier stopped instances are restarted to fulﬁll target capacity .
While a Spot Instance is stopped , you can modify some of its instance attributes , but not the instance type .
If you detach or delete an EBS volume , it is not attached when the Spot Instance is started .
If you 385 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances detach the root volume and the Spot service attempts to start the Spot Instance , instance start fails and the Spot service terminates the stopped instance .
You can terminate a Spot Instance while it is stopped .
While a Spot Instance is stopped , you are charged only for the EBS volumes , which are preserved .
With EC2 Fleet and Spot Fleet , if you have many stopped instances , you can exceed the limit on the number of EBS volumes for your account .
Hibernating interrupted Spot Instances You can change the behavior so that Amazon EC2 hibernates Spot Instances when they are interrupted if the following requirements are met .
You can not specify a launch group in the Spot Instance request .
• The root volume must be an EBS volume , not an instance store volume , and it must be large enough to store the instance memory ( RAM ) during hibernation .
We recommend that you use user data to start the agent on instance startup .
Recommendation • We strongly recommend that you use an encrypted Amazon EBS volume as the root volume , because instance memory is stored on the root volume during hibernation .
This ensures that the contents of memory ( RAM ) are encrypted when the data is at rest on the volume and when data is moving between the instance and volume .
• EBS encryption by default : You can enable EBS encryption by default to ensure all new EBS volumes created in your AWS account are encrypted .
• Encrypted AMI : You can enable EBS encryption by using an encrypted AMI to launch your instance .
If your AMI does not have an encrypted root snapshot , you can copy it to a new AMI and request 386 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances encryption .
When a Spot Instance is hibernated by the Spot service , the EBS volumes are preserved and instance memory ( RAM ) is preserved on the root volume .
The private IP addresses of the instance are also preserved .
Instance storage volumes and public IP addresses , other than Elastic IP addresses , are not preserved .
While the instance is hibernating , you are charged only for the EBS volumes .
With EC2 Fleet and Spot Fleet , if you have many hibernated instances , you can exceed the limit on the number of EBS volumes for your account .
The agent prompts the operating system to hibernate when the instance receives a signal from the Spot service .
If the agent is not installed , the underlying operating system does n't support hibernation , or there is n't enough volume space to save the instance memory , hibernation fails and the Spot service stops the instance instead .
When the Spot service hibernates a Spot Instance , you receive an interruption notice , but you do not have two minutes before the Spot Instance is interrupted .
While the instance is in the process of hibernating , instance health checks might fail .
When the hibernation process completes , the state of the instance is stopped .
After a Spot Instance is hibernated by the Spot service , it can only be resumed by the Spot service .
The Spot service resumes the instance when capacity becomes available with a Spot price that is less than your speciﬁed maximum price .
Preparing for interruptions Here are some best practices to follow when you use Spot Instances : • Use the default maximum price , which is the On-Demand price .
• Ensure that your instance is ready to go as soon as the request is fulﬁlled by using an Amazon Machine Image ( AMI ) that contains the required software conﬁguration .
You can also use user data to run commands at start-up .
• Use Spot Instance interruption notices to monitor the status of your Spot Instances .
• While we make every eﬀort to provide this warning as soon as possible , it is possible that your Spot Instance is terminated before the warning can be made available .
Test your application to ensure that it handles an unexpected instance termination gracefully , even if you are testing for interruption notices .
You can do so by running the application using an On-Demand Instance and then terminating the On-Demand Instance yourself .
Preparing for instance hibernation You must install a hibernation agent on your instance , unless you used an AMI that already includes the agent .
You must run the agent on instance startup , whether the agent was included in your AMI or you installed it yourself .
For directions to prepare a Windows instance , see Preparing for Instance Hibernation in the Amazon EC2 User Guide for Windows Instances .
387 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances To prepare an Amazon Linux instance 1 .
Verify that your kernel supports hibernation and update the kernel if necessary .
If your AMI does n't include the agent , install the agent using the following command .
If your AMI does n't include the agent , install the agent using the following command .
The hibernation agent is only available on Ubuntu 16.04 or later .
Add the following to the user data .
✔ ! /bin/bash /usr/bin/enable-ec2-spot-hibernation Spot Instance interruption notices The best way to protect against Spot Instance interruption is to architect your application to be faulttolerant .
In addition , you can take advantage of Spot Instance interruption notices , which provide a twominute warning before Amazon EC2 must stop or terminate your Spot Instance .
We recommend that you check for these warnings every 5 seconds .
If you specify hibernation as the interruption behavior , you receive an interruption notice , but you do not receive a two-minute warning because the hibernation process begins immediately .
EC2 Spot Instance interruption notice When Amazon EC2 is going to interrupt your Spot Instance , it emits an event two minutes prior to the actual interruption .
This event can be detected by Amazon CloudWatch Events .
For more information , see the Amazon CloudWatch Events User Guide .
The following is an example of the event for Spot Instance interruption .
The following example indicates the time at which this instance will be stopped .
If your Spot Instance is marked for termination by the Spot service , the termination-time item is present in your instance metadata .
*Z ; then echo terminated ; fi 389 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances The termination-time item speciﬁes the approximate time in UTC when the instance receives the shutdown signal .
For example : 2015-01-05T18:02:00Z If Amazon EC2 is not preparing to terminate the instance , or if you terminated the Spot Instance yourself , the termination-time item is either not present ( so you receive an HTTP 404 error ) or contains a value that is not a time value .
If Amazon EC2 fails to terminate the instance , the request status is set to fulfilled .
The termination-time value remains in the instance metadata with the original approximate time , which is now in the past .
Who interrupts the Spot Instance Operating system Interrupted in the ﬁrst hour If you stop or terminate the Spot Instance Linux ( excluding RHEL and SUSE ) Charged for the seconds Charged for the seconds used used Windows , RHEL , SUSE Charged for the full hour even if you used a partial hour Charged for the full hours used , and charged a full hour for the interrupted partial hour Linux ( excluding RHEL and SUSE ) No charge Charged for the seconds used Windows , RHEL , SUSE No charge Charged for the full hours used , but no charge for the interrupted partial hour If Amazon EC2 interrupts the Spot Instance Interrupted in any hour after the ﬁrst hour When a Spot Instance in a Spot block is interrupted , you ’ re charged as follows .
Who interrupts the Spot Instance Operating system Interrupted in the ﬁrst hour If you stop or terminate the Spot Instance Linux ( excluding RHEL and SUSE ) Charged for the seconds Charged for the seconds used used Windows , RHEL , SUSE Charged for the full hour even if you used a partial hour Charged for the full hours used , and charged a full hour for the interrupted partial hour Linux ( excluding RHEL and SUSE ) No charge No charge Windows , RHEL , SUSE No charge No charge If Amazon EC2 interrupts the Spot Instance 390 Interrupted in any hour after the ﬁrst hour Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances Spot Instance data feed To help you understand the charges for your Spot Instances , Amazon EC2 provides a data feed that describes your Spot Instance usage and pricing .
This data feed is sent to an Amazon S3 bucket that you specify when you subscribe to the data feed .
Data feed ﬁles arrive in your bucket typically once an hour , and each hour of usage is typically covered in a single data ﬁle .
These ﬁles are compressed ( gzip ) before they are delivered to your bucket .
Amazon EC2 can write multiple ﬁles for a given hour of usage where ﬁles are large ( for example , when ﬁle contents for the hour exceed 50 MB before compression ) .
Each line in the data ﬁle corresponds to one instance hour and contains the ﬁelds listed in the following table .
Field Description Timestamp The timestamp used to determine the price charged for this instance usage .
UsageType The type of usage and instance type being charged for .
Operation The product being charged for .
For Linux Spot Instances , this ﬁeld is set to RunInstances .
Spot usage is grouped according to Availability Zone .
InstanceID The ID of the Spot Instance that generated this instance usage .
MyBidID The ID for the Spot Instance request that generated this instance usage .
MyMaxPrice The maximum price speciﬁed for this Spot Instance request .
MarketPrice The Spot price at the time speciﬁed in the Timestamp ﬁeld .
Charge The price charged for this instance usage .
391 Amazon Elastic Compute Cloud User Guide for Linux Instances Spot Instances Field Description Version The version included in the data feed ﬁle name for this record .
Amazon S3 bucket requirements When you subscribe to the data feed , you must specify an Amazon S3 bucket to store the data feed ﬁles .
Otherwise , the bucket owner must grant your AWS account this permission .
• When you subscribe to a data feed , these permissions are used to update the bucket ACL to give the AWS data feed account FULL_CONTROL permission .
The AWS data feed account writes data feed ﬁles to the bucket .
If your account does n't have the required permissions , the data feed ﬁles can not be written to the bucket .
Note If you update the ACL and remove the permissions for the AWS data feed account , the data feed ﬁles can not be written to the bucket .
You must resubscribe to the data feed to receive the data feed ﬁles .
• Each data feed ﬁle has its own ACL ( separate from the ACL for the bucket ) .
The bucket owner has FULL_CONTROL permission to the data ﬁles .
The AWS data feed account has read and write permissions .
• If you delete your data feed subscription , Amazon EC2 does n't remove the read and write permissions for the AWS data feed account on either the bucket or the data ﬁles .
You must remove these permissions yourself .
Subscribing to your Spot Instance data feed To subscribe to your data feed , use the create-spot-datafeed-subscription command .
If you terminate your Spot Instance but do not cancel the request , the request counts against this limit until Amazon EC2 detects the termination and closes the request .
When your account is new , your limit might be lower than 20 to start , but can increase over time .
In addition , your account might have limits on speciﬁc Spot Instance types .
If you submit a Spot Instance request and you receive the error Max spot instance count exceeded , you can complete the AWS Support Center Create case form to request a Spot Instance limit increase .
Spot Fleet limits The usual Amazon EC2 limits apply to instances launched by a Spot Fleet or an EC2 Fleet , such as Spot request price limits , instance limits , and volume limits .
If you need more than the default limits for target capacity , complete the AWS Support Center Create case form to request a limit increase .
You can not request a limit increase for these limits .
T3 Spot Instances If you plan to use your T3 Spot Instances immediately and for a short duration , with no idle time for accruing CPU credits , we recommend that you launch your T3 Spot Instances in standard ( p. 212 ) mode to avoid paying higher costs .
If you use the instance for a short duration , your instance does n't have 393 Amazon Elastic Compute Cloud User Guide for Linux Instances Dedicated Hosts time to accrue CPU credits to pay down the surplus credits , and you are charged for the surplus credits when you terminate your instance .
Unlimited mode for T3 Spot Instances is suitable only if the instance runs for long enough to accrue CPU credits for bursting .
T2 Spot Instances Launch credits are meant to provide a productive initial launch experience for T2 instances by providing suﬃcient compute resources to conﬁgure the instance .
Repeated launches of T2 instances to access new launch credits is not permitted .
Dedicated Hosts An Amazon EC2 Dedicated Host is a physical server with EC2 instance capacity fully dedicated to your use .
There are no performance , security , or physical diﬀerences between Dedicated Instances and instances on Dedicated Hosts .
The following table highlights some of the key diﬀerences between Dedicated Hosts and Dedicated Instances : Dedicated Host Dedicated Instance Billing Per-host billing Per-instance billing Visibility of sockets , cores , and host ID Provides visibility of the number of sockets and physical cores No visibility Host and instance aﬃnity Allows you to consistently deploy your instances to the same physical server over time Not supported 394 Amazon Elastic Compute Cloud User Guide for Linux Instances Dedicated Hosts Dedicated Host Dedicated Instance Targeted instance placement Provides additional visibility and control over how instances are placed on a physical server Not supported Automatic instance recovery Supported .
When you bring your own license , you are responsible for managing your own licenses .
However , Amazon EC2 has features that help you maintain license compliance , such as instance aﬃnity and targeted placement .
These are the general steps to follow in order to bring your own volume licensed machine image into Amazon EC2 .
Verify that the license terms controlling the use of your machine images allow usage in a virtualized cloud environment .
After you have veriﬁed that your machine image can be used within Amazon EC2 , import it using VM Import/Export .
For information about how to import your machine image , see the VM Import/Export User Guide .
After you import your machine image , you can launch instances from it onto active Dedicated Hosts in your account .
When you run these instances , depending on the operating system , you might be required to activate these instances against your own KMS server .
Note To track how your images are used in AWS , enable host recording in AWS Conﬁg .
You can use AWS Conﬁg to record conﬁguration changes to a Dedicated Host and use the output as a data source for license reporting .
Dedicated Host Instance Capacity Dedicated Hosts powered by the AWS Nitro System can support multiple instance types within the same instance family .
You can run any number of instances up to the core capacity associated with the host .
For example , the table below shows the diﬀerent instance type combinations you can run on a Dedicated Host .
For a list of all instance families and instance type conﬁgurations supported on Dedicated Hosts see Amazon EC2 Dedicated Host Pricing .
Dedicated Hosts Restrictions Before you allocate Dedicated Hosts , take note of the following limitations and restrictions : • RHEL , SUSE Linux , and SQL Server AMIs ( whether oﬀered by AWS or on the AWS Marketplace ) ca n't be used with Dedicated Hosts .
It is possible to request a limit increase : Request to Raise Allocation Limit on Amazon EC2 Dedicated Hosts .
For more information , see Creating a Launch Template for an Auto Scaling Group in the Amazon EC2 Auto Scaling User Guide .
• The AWS Free Usage tier is not available for Dedicated Hosts .
• Instance placement control refers to managing instance launches onto Dedicated Hosts .
Placement groups are not supported for Dedicated Hosts .
Pricing and Billing The price for a Dedicated Host varies by payment option .
You pay per second ( with a minimum of 60 seconds ) for active Dedicated Host , regardless of the quantity or the size of instances that you choose to launch on it .
396 Amazon Elastic Compute Cloud User Guide for Linux Instances Dedicated Hosts You can release an On-Demand Dedicated Host at any time to stop accruing charges for it .
Dedicated Host Reservations Dedicated Host Reservations provide a billing discount compared to running On-Demand Dedicated Hosts .
Reservations are available in three payment options : • No Upfront—No Upfront Reservations provide you with a discount on your Dedicated Host usage over a term and do not require an upfront payment .
• Partial Upfront—A portion of the reservation must be paid upfront and the remaining hours in the term are billed at a discounted rate .
Available in one-year and three-year terms and covers the entire cost of the term upfront , with no additional future charges .
You must have active Dedicated Hosts in your account before you can purchase reservations .
Reservations are applied to the instance family on the host , not the instance size .
The instance family and Region of the reservation must match that of the Dedicated Hosts you want to associate it with .
Savings Plans Savings Plans are a ﬂexible pricing model that oﬀers signiﬁcant savings over On-Demand Instances .
This provides you with the ﬂexibility to use the Dedicated Hosts that best meet your needs and continue to save money , instead of making a commitment to a speciﬁc Dedicated Host .
For more information , see the AWS Savings Plans User Guide .
Pricing for Windows Server on Dedicated Hosts Subject to Microsoft licensing terms , you can bring your existing Windows Server and SQL Server licenses to Dedicated Hosts .
There is no additional charge for software usage if you choose to bring your own licenses .
In addition , you can also use Windows Server AMIs provided by Amazon to run the latest versions of Windows Server on Dedicated Hosts .
This is common for scenarios where you have existing SQL Server licenses eligible to run on Dedicated Hosts , but need Windows Server to run the SQL Server workload .
Windows Server AMIs provided by Amazon are supported on current generation instance types only .
Working with Dedicated Hosts To use a Dedicated Host , you ﬁrst allocate hosts for use in your account .
You then launch instances onto the hosts by specifying host tenancy for the instance .
You must select a speciﬁc host for the instance to launch on to , or you can allow it to launch on to any host that has auto-placement enabled and matches its instance type .
When an instance is stopped and restarted , the Host aﬃnity setting determines whether it 's restarted on the same , or a diﬀerent , host .
If you no longer need an On-Demand host , you can stop the instances running on the host , direct them to launch on a diﬀerent host , and then release the host .
397 Amazon Elastic Compute Cloud User Guide for Linux Instances Dedicated Hosts Dedicated Hosts are also integrated with AWS License Manager .
With License Manager , you can create a host resource group , which is a collection of Dedicated Hosts that are managed as a single entity .
This allows you to launch instances onto Dedicated Hosts without manually allocating and managing those hosts .
For more information , see Host Resource Groups in the AWS License Manager User Guide .
After you allocate the Dedicated Host , the Dedicated Host capacity is made available in your account immediately and you can start launching instances onto the Dedicated Host .
You can allocate a Dedicated Host using the following methods .
In the navigation pane , choose Dedicated Hosts and then choose Allocate Dedicated Host .
For Instance family , choose the instance family for the Dedicated Host .
Specify whether the Dedicated Host supports multiple instance types within the selected instance family , or a speciﬁc instance type only .
• To conﬁgure the Dedicated Host to support multiple instance types in the selected instance family , for Support multiple instance types , choose Enable .
Enabling this allows you to launch diﬀerent instance types from the same instance family onto the Dedicated Host .
For example , if you choose the m5 instance family and choose this option , you can launch m5.xlarge and m5.4xlarge instances onto the Dedicated Host .
398 Amazon Elastic Compute Cloud User Guide for Linux Instances Dedicated Hosts • To conﬁgure the Dedicated Host to support a speciﬁc instance type within the selected instance family , clear Support multiple instance types , and then for Instance type , choose the instance type to support .
This allows you to launch a single instance type on the Dedicated Host .
For example , if you choose this option and specify m5.4xlarge as the supported instance type , you can launch only m5.4xlarge instances onto the Dedicated Host .
For Availability Zone , choose the Availability Zone in which to allocate the Dedicated Host .
To allow the Dedicated Host to accept untargeted instance launches that match its instance type , for Instance auto-placement , choose Enable .
To enable host recovery for the Dedicated Host , for Host recovery , choose Enable .
For Quantity , enter the number of Dedicated Hosts to allocate .
For Instance family , choose the instance family for the Dedicated Host .
Specify whether the Dedicated Host supports multiple instance types within the selected instance family , or a speciﬁc instance type only .
• To conﬁgure the Dedicated Host to support multiple instance types in the selected instance family , select Support multiple instance types .
Enabling this allows you to launch diﬀerent instance types from the same instance family onto the Dedicated Host .
For example , if you choose the m5 instance family and choose this option , you can launch m5.xlarge and m5.4xlarge instances onto the Dedicated Host .
• To conﬁgure the Dedicated Host to support a speciﬁc instance type within the selected instance family , clear Support multiple instance types , and then for Instance type , choose the instance type to support .
Enabling this allows you to launch a single instance type on the Dedicated Host .
For example , if you choose this option and specify m5.4xlarge as the supported instance type , you can launch only m5.4xlarge instances onto the Dedicated Host .
For Availability Zone , choose the Availability Zone in which to allocate the Dedicated Host .
To allow the Dedicated Host to accept untargeted instance launches that match its instance type , for Instance auto-placement , choose Enable .
To enable host recovery for the Dedicated Host , for Host recovery choose Enable .
For Quantity , enter the number of Dedicated Hosts to allocate .
AWS CLI To allocate a Dedicated Host 399 Amazon Elastic Compute Cloud User Guide for Linux Instances Dedicated Hosts Use the allocate-hosts AWS CLI command .
The following command allocates a Dedicated Host that supports multiple instance types from the m5 instance family in us-east-1a Availability Zone .
The host also has host recovery enabled and it has auto-placement disabled .
The following command allocates a Dedicated Host that supports multiple instance types from the m5 instance family in us-east-1a Availability Zone .
The host also has host recovery enabled and it has auto-placement disabled .
The TagSpecification parameter used to tag a Dedicated Host on creation requires an object that speciﬁes the type of resource to be tagged , the tag key , and the tag value .
The following commands create the required object .
You ca n't launch instances with host tenancy if you do not have active Dedicated Hosts with enough available capacity for the instance type that you are launching .
Note The instances launched onto Dedicated Hosts can only be launched in a VPC .
400 Amazon Elastic Compute Cloud User Guide for Linux Instances Dedicated Hosts Before you launch your instances , take note of the limitations .
You can launch an instance onto a Dedicated Host using the following methods .
Console To launch an instance onto a speciﬁc Dedicated Host from the Dedicated Hosts page 1 .
Choose Dedicated Hosts in the navigation pane .
Select an AMI from the list .
On the Choose an Instance Type page , select the instance type to launch and then choose Next : Conﬁgure Instance Details .
If the Dedicated Host supports a single instance type only , the supported instance type is selected by default and ca n't be changed .
If the Dedicated Host supports multiple instance types , you must select an instance type within the supported instance family based on the available instance capacity of the Dedicated Host .
We recommend that you launch the larger instance sizes ﬁrst , and then ﬁll the remaining instance capacity with the smaller instance sizes as needed .
On the Conﬁgure Instance Details page , conﬁgure the instance settings to suit your needs , and then for Aﬃnity , choose one of the following options : • Oﬀ—The instance launches onto the speciﬁed host , but it is not guaranteed to restart on the same Dedicated Host if stopped .
The Tenancy and Host options are pre-conﬁgured based on the host that you selected .
When prompted , select an existing key pair or create a new one , and then choose Launch Instances .
To launch an instance onto a Dedicated Host using the Launch Instance wizard 1 .
Select an AMI from the list .
Select the type of instance to launch and choose Next : Conﬁgure Instance Details .
On the Conﬁgure Instance Details page , conﬁgure the instance settings to suit your needs , and then conﬁgure the following settings , which are speciﬁc to a Dedicated Host : • Tenancy—Choose Dedicated Host - Launch this instance on a Dedicated Host .
The list displays only Dedicated Hosts that support the selected instance type .
401 Amazon Elastic Compute Cloud User Guide for Linux Instances Dedicated Hosts • Aﬃnity—Choose one of the following options : • Oﬀ—The instance launches onto the speciﬁed host , but it is not guaranteed to restart on it if stopped .
If you are unable to see these settings , check that you have selected a VPC in the Network menu .
When prompted , select an existing key pair or create a new one , and then choose Launch Instances .
AWS CLI To launch an instance onto a Dedicated Host Use the run-instances AWS CLI command and specify the instance aﬃnity , tenancy , and host in the Placement request parameter .
PowerShell To launch an instance onto a Dedicated Host Use the New-EC2Instance AWS Tools for Windows PowerShell command and specify the instance aﬃnity , tenancy , and host in the Placement request parameter .
Launching Instances into a Host Resource Group When you launch an instance into a host resource group that has a Dedicated Host with available instance capacity , Amazon EC2 launches the instance onto that host .
If the host resource group does not have a host with available instance capacity , Amazon EC2 automatically allocates a new host in the host resource group , and then launches the instance onto that host .
For more information , see Host Resource Groups in the AWS License Manager User Guide .
You can launch an instance into a host resource group using the following methods .
Select an AMI from the list .
Select the type of instance to launch and choose Next : Conﬁgure Instance Details .
On the Conﬁgure Instance Details page , conﬁgure the instance settings to suit your needs , and then do the following : a .
c. For Host resource group name , choose the host resource group in which to launch the instance .
402 Amazon Elastic Compute Cloud User Guide for Linux Instances Dedicated Hosts You ca n't target a speciﬁc host by choosing a host ID , and you ca n't enable instance aﬃnity when launching an instance into a host resource group .
When prompted , select an existing key pair or create a new one , and then choose Launch Instances .
AWS CLI To launch an instance into a host resource group Use the run-instances AWS CLI command , and in the Placement request parameter , omit the Tenancy option and specify the host resource group ARN .
PowerShell To launch an instance into a host resource group Use the New-EC2Instance AWS Tools for Windows PowerShell command , and in the Placement request parameter , omit the Tenancy option and specify the host resource group ARN .
Understanding Auto-Placement and Aﬃnity Placement control for Dedicated Hosts happens on both the instance level and host level .
It allows you to manage whether instances that you launch are launched onto a speciﬁc host , or onto any available host that has matching conﬁgurations .
When the auto-placement of a Dedicated Host is disabled , it only accepts Host tenancy instance launches that specify its unique host ID .
This is the default setting for new Dedicated Hosts .
When the auto-placement of a Dedicated Host is enabled , it accepts any untargeted instance launches that match its instance type conﬁguration .
When launching an instance , you need to conﬁgure its tenancy .
Launching an instance onto a Dedicated Host without providing a speciﬁc HostId enables it to launch on any Dedicated Host that has autoplacement enabled and that matches its instance type .
Host Aﬃnity Host Aﬃnity is conﬁgured at the instance level .
When aﬃnity is set to Host , an instance launched onto a speciﬁc host always restarts on the same host if stopped .
This applies to both targeted and untargeted launches .
When aﬃnity is set to Off , and you stop and restart the instance , it can be restarted on any available host .
Modifying Dedicated Host Auto-Placement You can modify the auto-placement settings of a Dedicated Host after you have allocated it to your AWS account , using one of the following methods .
403 Amazon Elastic Compute Cloud User Guide for Linux Instances Dedicated Hosts New console To modify the auto-placement of a Dedicated Host 1 .
Choose Dedicated Hosts in the navigation pane .
The following example enables auto-placement for the speciﬁed Dedicated Host .
The following example enables auto-placement for the speciﬁed Dedicated Host .
If it currently supports a single instance type , you can modify it to support multiple instance types within that instance family .
Similarly , if it currently supports multiple instance types , you can modify it to support a speciﬁc instance type only .
To modify a Dedicated Host to support multiple instance types , you must ﬁrst stop all running instances on the host .
The Dedicated Host transitions to the pending state while the modiﬁcation is in progress .
You ca n't start stopped instances 404 Amazon Elastic Compute Cloud User Guide for Linux Instances Dedicated Hosts or launch new instances on the Dedicated Host while it is in the pending state .
To modify a Dedicated Host that supports multiple instance types to support only a speciﬁc instance type , the host must either have no running instances , or the running instances must be of the instance type that you want the host to support .
For example , to modify a host that supports multiple instance types in the m5 instance family to support only m5.large instances , the Dedicated Host must either have no running instances , or it must have only m5.large instances running on it .
You can modify the supported instance types using one of the following methods .
Select the Dedicated Host to modify and choose Actions , Modify host .
Do one of the following , depending on the current conﬁguration of the Dedicated Host : • If the Dedicated Host currently supports a speciﬁc instance type , Support multiple instance types is not enabled , and Instance type lists the supported instance type .
To modify the host to support multiple types in the current instance family , for Support multiple instance types , choose Enable .
You must ﬁrst stop all instances running on the host before modifying it to support multiple instance types .
• If the Dedicated Host currently supports multiple instance types in an instance family , Enabled is selected for Support multiple instance types .
To modify the host to support a speciﬁc instance type , for Support multiple instance types , clear Enable , and then for Instance type , select the speciﬁc instance type to support .
You ca n't change the instance family supported by the Dedicated Host .
Select the Dedicated Host to modify and choose Actions , Modify Supported Instance Types .
Do one of the following , depending on the current conﬁguration of the Dedicated Host : • If the Dedicated Host currently supports a speciﬁc instance type , No is selected for Support multiple instance types .
To modify the host to support multiple types in the current instance family , for Support multiple instance types , select Yes .
You must ﬁrst stop all instances running on the host before modifying it to support multiple instance types .
• If the Dedicated Host currently supports multiple instance types in an instance family , Yes is selected for Support multiple instance types , and Instance family displays the supported instance family .
To modify the host to support a speciﬁc instance type , for Support multiple instance types , select No , and then for Instance type , select the speciﬁc instance type to support .
405 Amazon Elastic Compute Cloud User Guide for Linux Instances Dedicated Hosts You ca n't change the instance family supported by the Dedicated Host .
AWS CLI To modify the supported instance types for a Dedicated Host Use the modify-hosts AWS CLI command .
The following command modiﬁes a Dedicated Host to support multiple instance types within the m5 instance family .
The following command modiﬁes a Dedicated Host to support multiple instance types within the m5 instance family .
You can also modify the aﬃnity between the instance and the host .
To modify either instance tenancy or aﬃnity , the instance must be in the stopped state .
You can modify an instance 's tenancy and aﬃnity using the following methods .
• Aﬃnity—Choose one of the following : • This instance can run on any one of my hosts—The instance launches onto any available Dedicated Host in your account that supports its instance type .
• This instance can only run on the selected host—The instance is only able to run on the Dedicated Host selected for Target Host .
If no target host is listed , you might not have available , compatible Dedicated Hosts in your account .
AWS CLI To modify instance tenancy or aﬃnity Use the modify-instance-placement AWS CLI command .
The following example changes the speciﬁed instance 's aﬃnity from default to host , and speciﬁes the Dedicated Host that the instance has aﬃnity with .
The following example changes the speciﬁed instance 's aﬃnity from default to host , and speciﬁes the Dedicated Host that the instance has aﬃnity with .
407 Amazon Elastic Compute Cloud User Guide for Linux Instances Dedicated Hosts For information about the host , choose Details .
Available vCPUs indicates the vCPUs that are available on the Dedicated Host for new instance launches .
For example , a Dedicated Host that supports multiple instance types within the c5 instance family , and that has no instances running on it , has 72 available vCPUs .
This means that you can launch diﬀerent combinations of instance types onto the Dedicated Host to consume the 72 available vCPUs .
For information about instances running on the host , choose Running instances .
Available vCPUs indicates the vCPUs that are available on the Dedicated Host for new instance launches .
For example , a Dedicated Host that supports multiple instance types within the c5 instance family , and that has no instances running on it , has 72 available vCPUs .
This means that you can launch diﬀerent combinations of instance types onto the Dedicated Host to consume the 72 available vCPUs .
For information about instances running on the host , choose Instances .
AWS CLI To view the capacity of a Dedicated Host Use the describe-hosts AWS CLI command .
The following example uses the describe-hosts ( AWS CLI ) command to view the available instance capacity for a Dedicated Host that supports multiple instance types within the c5 instance family .
The Dedicated Host already has two c5.4xlarge instances and four c5.2xlarge instances running on it .
This helps you to quickly ﬁnd a speciﬁc Dedicated Host based on the custom tags that you assigned .
Dedicated Host tags can also be used for cost allocation tracking .
You can also apply tags to Dedicated Hosts at the time of creation .
You can tag a Dedicated Host using the following methods .
Select the Dedicated Host to tag , and then choose Actions , Manage tags .
In the Manage tags screen , choose Add tag , and then specify the key and value for the tag .
( Optional ) Choose Add tag to add additional tags to the Dedicated Host .
Select the Dedicated Host to tag , and then choose Tags .
In the Add/Edit Tags dialog box , choose Create Tag , and then specify the key and value for the tag .
( Optional ) Choose Create Tag to add additional tags to the Dedicated Host .
The following command tags the speciﬁed Dedicated Host with Owner=TeamA .
The New-EC2Tag command needs a Tag object , which speciﬁes the key and value pair to be used for the Dedicated Host tag .
The following commands create a Tag object named $ tag , with a key and value pair of Owner and TeamA respectively .
You can view information about a Dedicated Host using the following methods .
Locate the Dedicated Host in the list and review the value in the State column .
AWS CLI To view the state of a Dedicated Host Use the describe-hosts AWS CLI command and then review the state property in the hostSet response element .
aws ec2 describe-hosts -- host-id h-012a3456b7890cdef PowerShell To view the state of a Dedicated Host Use the Get-EC2Host AWS Tools for Windows PowerShell command and then review the state property in the hostSet response element .
State Description available AWS has n't detected an issue with the Dedicated Host .
No maintenance or repairs are scheduled .
Instances can be launched onto this Dedicated Host .
released The Dedicated Host has been released .
The host ID is no longer in use .
If action must be taken , you are notiﬁed via the AWS Management Console or email .
410 Amazon Elastic Compute Cloud User Guide for Linux Instances Dedicated Hosts State Description pending The Dedicated Host can not be used for new instance launches .
You receive an eviction notice through your instances and by email .
Your instances might continue to run .
If you stop or terminate all instances on a Dedicated Host with this state , AWS retires the host .
AWS does not restart instances in this state .
Instances ca n't be launched onto Dedicated Hosts in this state .
releasedpermanent-failure AWS permanently releases Dedicated Hosts that have failed and no longer have running instances on them .
The Dedicated Host ID is no longer available for use .
Releasing Dedicated Hosts Any running instances on the Dedicated Host must be stopped before you can release the host .
These instances can be migrated to other Dedicated Hosts in your account so that you can continue to use them .
You can release a Dedicated Host using the following methods .
On the Dedicated Hosts page , select the Dedicated Host to release .
Choose Dedicated Hosts in the navigation pane .
On the Dedicated Hosts page , select the Dedicated Host to release .
The state of the Dedicated Host is changed to released , and you are not able to launch any instances onto that host .
Note If you have recently released Dedicated Hosts , it can take some time for them to stop counting towards your limit .
During this time , you might experience LimitExceeded errors when trying to allocate new Dedicated Hosts .
If this is the case , try allocating new hosts again after a few minutes .
The instances that were stopped are still available for use and are listed on the Instances page .
They retain their host tenancy setting .
Purchasing Dedicated Host Reservations You can purchase reservations using the following methods : Console To purchase reservations 1 .
On the Purchase Dedicated Host Reservation screen , you can search for available oﬀerings using the default settings , or you can specify custom values for the following : • Host instance family—The options listed correspond with the Dedicated Hosts in your account that are not already assigned to a reservation .
Choose Find oﬀering and select an oﬀering that matches your requirements .
Choose the Dedicated Hosts to associate with the reservation , and then choose Review .
Use the describe-host-reservation-oﬀerings AWS CLI command to list the available oﬀerings that match your needs .
The following example lists the oﬀerings that support instances in the m4 instance family and have a one-year term .
Note The term is speciﬁed in seconds .
The command returns a list of oﬀerings that match your criteria .
Note the offeringId of the oﬀering to purchase .
Use the purchase-host-reservation AWS CLI command to purchase the oﬀering and provide the offeringId noted in the previous step .
The following example purchases the speciﬁed reservation and associates it with a speciﬁc Dedicated Host that is already allocated in the AWS account .
Use the Get-EC2HostReservationOﬀering AWS Tools for Windows PowerShell command to list the available oﬀerings that match your needs .
The following examples list the oﬀerings that support instances in the m4 instance family and have a one-year term .
Note The term is speciﬁed in seconds .
The command returns a list of oﬀerings that match your criteria .
Note the offeringId of the oﬀering to purchase .
Use the New-EC2HostReservation AWS Tools for Windows PowerShell command to purchase the oﬀering and provide the offeringId noted in the previous step .
The following example purchases the speciﬁed reservation and associates it with a speciﬁc Dedicated Host that is already allocated in the AWS account .
PS C : \ > New-EC2HostReservation -OfferingId hro-03f707bf363b6b324 HostIdSet h-013abcd2a00cbd123 Viewing Dedicated Host Reservations You can view information about the Dedicated Hosts that are associated with your reservation , including : • The term of the reservation • The payment option • The start and end dates You can view details of your Dedicated Host reservations using the following methods .
Choose Dedicated Hosts in the navigation pane .
On the Dedicated Hosts page , choose Dedicated Host Reservations , and then select the reservation from the list provided .
Choose Details for information about the reservation .
Choose Hosts for information about the Dedicated Hosts with which the reservation is associated .
AWS CLI To view the details of a Dedicated Host reservation Use the describe-host-reservations AWS CLI command .
aws ec2 describe-host-reservations PowerShell To view the details of a Dedicated Host reservation Use the Get-EC2HostReservation AWS Tools for Windows PowerShell command .
This helps you to quickly ﬁnd a speciﬁc Dedicated Host Reservation based on the custom tags that you assigned .
You can tag a Dedicated Host Reservation using the command line tools only .
AWS CLI To tag a Dedicated Host Reservation Use the create-tags AWS CLI command .
The New-EC2Tag command needs a Tag parameter , which speciﬁes the key and value pair to be used for the Dedicated Host Reservation tag .
The following commands create the Tag parameter .
This enables you to create and manage Dedicated Hosts centrally , and share the Dedicated Host across multiple AWS accounts or within your AWS organization .
Consumers can launch instances onto Dedicated Hosts that are shared with them in the same way that they would launch instances onto Dedicated Hosts that they allocate in their own account .
The owner is responsible for managing the Dedicated Host and the instances that they launch onto it .
Owners ca n't modify instances that consumers launch onto shared Dedicated Hosts .
Consumers are responsible for managing the instances that they launch onto Dedicated Hosts shared with them .
Consumers ca n't view or modify instances owned by other consumers or by the Dedicated Host owner , and they ca n't modify Dedicated Hosts that are shared with them .
• To share a Dedicated Host with your AWS organization or an organizational unit in your AWS organization , you must enable sharing with AWS Organizations .
For more information , see Enable Sharing with AWS Organizations in the AWS RAM User Guide .
Related Services AWS Resource Access Manager Dedicated Host sharing integrates with AWS Resource Access Manager ( AWS RAM ) .
AWS RAM is a service that enables you to share your AWS resources with any AWS account or through AWS Organizations .
With AWS RAM , you share resources that you own by creating a resource share .
A resource share speciﬁes the resources to share , and the consumers with whom to share them .
Consumers can be individual AWS accounts , or organizational units or an entire organization from AWS Organizations .
415 Amazon Elastic Compute Cloud User Guide for Linux Instances Dedicated Hosts For more information about AWS RAM , see the AWS RAM User Guide .
Sharing Across Availability Zones To ensure that resources are distributed across the Availability Zones for a Region , we independently map Availability Zones to names for each account .
This could lead to Availability Zone naming diﬀerences across accounts .
For example , the Availability Zone us-east-1a for your AWS account might not have the same location as us-east-1a for another AWS account .
To identify the location of your Dedicated Hosts relative to your accounts , you must use the Availability Zone ID ( AZ ID ) .
The Availability Zone ID is a unique and consistent identiﬁer for an Availability Zone across all AWS accounts .
For example , use1-az1 is an Availability Zone ID for the us-east-1 Region and it is the same location in every AWS account .
To view the Availability Zone IDs for the Availability Zones in your account 1 .
The Availability Zone IDs for the current Region are displayed in the Your AZ ID panel on the righthand side of the screen .
Sharing a Dedicated Host When an owner shares a Dedicated Host , it enables consumers to launch instances on the host .
Consumers can launch as many instances onto the shared host as its available capacity allows .
If you share a Dedicated Host with auto-placement enabled , keep the following in mind as it could lead to unintended Dedicated Host usage : • If consumers launch instances with Dedicated Host tenancy and they do not have capacity on a Dedicated Host that they own in their account , the instance is automatically launched onto the shared Dedicated Host .
A resource share is an AWS RAM resource that lets you share your resources across AWS accounts .
A resource share speciﬁes the resources to share , and the consumers with whom they are shared .
You can add the Dedicated Host to an existing resource , or you can add it to a new resource share .
If you are part of an organization in AWS Organizations and sharing within your organization is enabled , consumers in your organization are automatically granted access to the shared Dedicated Host .
Otherwise , consumers receive an invitation to join the resource share and are granted access to the shared Dedicated Host after accepting the invitation .
Note After you share a Dedicated Host , it could take a few minutes for consumers to have access to it .
You can share a Dedicated Host that you own by using the AWS RAM console or the AWS CLI .
To share a Dedicated Host that you own using the AWS RAM console See Creating a Resource Share in the AWS RAM User Guide .
To share a Dedicated Host that you own using the AWS CLI Use the create-resource-share command .
Unsharing a Shared Dedicated Host The Dedicated Host owner can unshare a shared Dedicated Host at any time .
When you unshare a shared Dedicated Host , the following rules apply : 416 Amazon Elastic Compute Cloud User Guide for Linux Instances Dedicated Hosts • Consumers with whom the Dedicated Host was shared can no longer launch new instances onto it .
• Instances owned by consumers that were running on the Dedicated Host at the time of unsharing continue to run but are scheduled for retirement .
Consumers receive retirement notiﬁcations for the instances and they have two weeks to take action on the notiﬁcations .
However , if the Dedicated Host is reshared with the consumer within the retirement notice period , the instance retirements are cancelled .
To unshare a shared Dedicated Host that you own , you must remove it from the resource share .
You can do this by using the AWS RAM console or the AWS CLI .
To unshare a shared Dedicated Host that you own using the AWS RAM console See Updating a Resource Share in the AWS RAM User Guide .
To unshare a shared Dedicated Host that you own using the AWS CLI Use the disassociate-resource-share command .
Identifying a Shared Dedicated Host Owners and consumers can identify shared Dedicated Hosts using the Amazon EC2 console and AWS CLI .
The screen lists Dedicated Hosts that you own and Dedicated Hosts that are shared with you .
The Owner column shows the AWS account ID of the Dedicated Host owner .
To identify a shared Dedicated Host using the AWS CLI Use the describe-hosts command .
The command returns the Dedicated Hosts that you own and Dedicated Hosts that are shared with you .
Viewing Instances Running on a Shared Dedicated Host Owners and consumers can view the instances running on a shared Dedicated Host at any time using the Amazon EC2 console and the AWS CLI .
Select the Dedicated Host for which to view the instances and choose Instances .
The tab lists the instances that are running on the host .
Owners see all of the instances running on the host , including instances launched by consumers .
Consumers only see running instances that they launched onto the host .
The Owner column shows the AWS account ID of the account that launched the instance .
To view the instances running on a shared Dedicated Host using the AWS CLI Use the describe-hosts command .
The command returns the instances running on each Dedicated Host .
Owners see all of the instances running on the host .
Consumers only see running instances that they launched on the shared hosts .
InstanceOwnerId shows the AWS account ID of the instance owner .
417 Amazon Elastic Compute Cloud User Guide for Linux Instances Dedicated Hosts Shared Dedicated Host Permissions Permissions for Owners Owners are responsible for managing their shared Dedicated Hosts and the instances that they launch onto them .
Owners can view all instances running on the shared Dedicated Host , including those launched by consumers .
However , owners ca n't take any action on running instances that were launched by consumers .
Permissions for Consumers Consumers are responsible for managing the instances that they launch onto a shared Dedicated Host .
Consumers ca n't modify the shared Dedicated Host in any way , and they ca n't view or modify instances that were launched by other consumers or the Dedicated Host owner .
Billing and Metering There are no additional charges for sharing Dedicated Hosts .
Owners are billed for Dedicated Hosts that they share .
Consumers are not billed for instances that they launch onto shared Dedicated Hosts .
Dedicated Host Reservations continue to provide billing discounts for shared Dedicated Hosts .
Only Dedicated Host owners can purchase Dedicated Host Reservations for shared Dedicated Hosts that they own .
Dedicated Host Limits Shared Dedicated Hosts count towards the owner 's Dedicated Hosts limits only .
Consumer 's Dedicated Hosts limits are not aﬀected by Dedicated Hosts that have been shared with them .
Similarly , instances that consumers launch onto shared Dedicated Hosts do not count towards their instance limits .
Host Recovery and Dedicated Host Sharing Host recovery recovers instances launched by the Dedicated Host owner and the consumers with whom it has been shared .
The replacement Dedicated Host is allocated to the owner 's account .
It is added to the same resource shares as the original Dedicated Host , and it is shared with the same consumers .
Host Recovery Host recovery automatically restarts your instances on to a new replacement host if failures are detected on your Dedicated Host .
Host recovery reduces the need for manual intervention and lowers the operational burden if there is an unexpected Dedicated Host failure .
Additionally , built-in integration with AWS License Manager automates the tracking and management of your licenses if a host recovery occurs .
Note AWS License Manager integration is supported only in Regions in which AWS License Manager is available .
Examples of problems that can cause host-level health checks to fail include : • Loss of network connectivity • Loss of system power • Hardware or software issues on the physical host When a system failure is detected on your Dedicated Host , host recovery is initiated and Amazon EC2 automatically allocates a replacement Dedicated Host .
The replacement Dedicated Host receives a new host ID , but retains the same attributes as the original Dedicated Host , including : • Availability Zone • Instance type • Tags • Auto placement settings After the replacement Dedicated Host is allocated , the instances are recovered on to the replacement Dedicated Host .
The recovered instances retain the same attributes as the original instances , including : • Instance ID • Private IP addresses • Elastic IP addresses • EBS volume attachments • All instance metadata If instances have a host aﬃnity relationship with the impaired Dedicated Host , the recovered instances establish host aﬃnity with the replacement Dedicated Host .
When all of the instances have been recovered on to the replacement Dedicated Host , the impaired Dedicated Host is released , and the replacement Dedicated Host becomes available for use .
When host recovery is initiated , the AWS account owner is notiﬁed by email and by an AWS Personal Health Dashboard event .
A second notiﬁcation is sent after the host recovery has been successfully completed .
Stopped instances are not recovered on to the replacement Dedicated Host .
If you attempt to start a stopped instance that targets the impaired Dedicated Host , the instance start fails .
We recommend that you modify the stopped instance to either target a diﬀerent Dedicated Host , or to launch on any available Dedicated Host with matching conﬁgurations and auto-placement enabled .
Instances with instance storage are not recovered on to the replacement Dedicated Host .
As a remedial measure , the impaired Dedicated Host is marked for retirement and you receive a retirement notiﬁcation after the host recovery is complete .
Follow the remedial steps described in the retirement notiﬁcation 419 Amazon Elastic Compute Cloud User Guide for Linux Instances Dedicated Hosts within the speciﬁed time period to manually recover the remaining instances on the impaired Dedicated Host .
If you are using AWS License Manager to track your licenses , AWS License Manager allocates new licenses for the replacement Dedicated Host based on the license conﬁguration limits .
If the license conﬁguration has hard limits that will be breached as a result of the host recovery , the recovery process is not allowed and you are notiﬁed of the host recovery failure through an Amazon SNS notiﬁcation .
If the license conﬁguration has soft limits that will be breached as a result of the host recovery , the recovery is allowed to continue and you are notiﬁed of the limit breach through an Amazon SNS notiﬁcation .
For more information , see Using License Conﬁgurations in the AWS License Manager User Guide .
Conﬁguring Host Recovery You can conﬁgure host recovery at the time of Dedicated Host allocation , or after allocation using the Amazon EC2 console or AWS Command Line Interface ( CLI ) .
Select the Dedicated Host for which to enable host recovery , and then choose Actions , Modify Host Recovery .
Select the Dedicated Host for which to disable host recovery , and then choose Actions , Modify Host Recovery .
420 Amazon Elastic Compute Cloud User Guide for Linux Instances Dedicated Hosts To disable host recovery after allocation ( AWS CLI ) Use the modify-hosts command and specify the host-recovery parameter .
Select the Dedicated Host , and in the Description tab , review the Host Recovery ﬁeld .
Host Recovery States When a Dedicated Host failure is detected , the impaired Dedicated Host enters the under-assessment state , and all of the instances enter the impaired state .
You ca n't launch instances on to the impaired Dedicated Host while it is in the under-assessment state .
After the replacement Dedicated Host is allocated , it enters the pending state .
It remains in this state until the host recovery process is complete .
You ca n't launch instances on to the replacement Dedicated Host while it is in the pending state .
Recovered instances on the replacement Dedicated Host remain in the impaired state during the recovery process .
After the host recovery is complete , the replacement Dedicated Host enters the available state , and the recovered instances return to the running state .
You can launch instances on to the replacement Dedicated Host after it enters the available state .
The original impaired Dedicated Host is permanently released and it enters the released-permanent-failure state .
If the impaired Dedicated Host has instances that do not support host recovery , such as instances with instance store-backed volumes , the Dedicated Host is not released .
Manually Recovering Unsupported Instances Host recovery does not support recovering instances that use instance store volumes .
Follow the instructions below to manually recover any of your instances that could not be automatically recovered .
421 Amazon Elastic Compute Cloud User Guide for Linux Instances Dedicated Hosts Warning Data on instance store volumes is lost when an instance is stopped or terminated .
This includes instance store volumes that are attached to an instance that has an EBS volume as the root device .
To protect data from instance store volumes , back it up to persistent storage before the instance is stopped or terminated .
Manually Recovering EBS-Backed Instances For EBS-backed instances that could not be automatically recovered , we recommend that you manually stop and start the instances to recover them onto a new Dedicated Host .
Launch a replacement instance on a new Dedicated Host from your most recent AMI .
Migrate all of the necessary data to the replacement instance .
Terminate the original instance on the impaired Dedicated Host .
Related Services Dedicated Host integrates with the following AWS services : • AWS License Manager—Tracks licenses across your Amazon EC2 Dedicated Hosts ( supported only in Regions in which AWS License Manager is available ) .
For more information , see the AWS License Manager User Guide .
Pricing There are no additional charges for using host recovery , but the usual Dedicated Host charges apply .
As soon as host recovery is initiated , you are no longer billed for the impaired Dedicated Host .
Billing for the replacement Dedicated Host begins only after it enters the available state .
If the impaired Dedicated Host was billed using the On-Demand rate , the replacement Dedicated Host is also billed using the On-Demand rate .
If the impaired Dedicated Host had an active Dedicated Host Reservation , it is transferred to the replacement Dedicated Host .
Tracking Conﬁguration Changes You can use AWS Conﬁg to record conﬁguration changes for Dedicated Hosts , and for instances that are launched , stopped , or terminated on them .
You can then use the information captured by AWS Conﬁg as a data source for license reporting .
AWS Conﬁg records conﬁguration information for Dedicated Hosts and instances individually , and pairs this information through relationships .
There are three reporting conditions : • AWS Conﬁg recording status—When On , AWS Conﬁg is recording one or more AWS resource types , which can include Dedicated Hosts and Dedicated Instances .
To capture the information required for license reporting , verify that hosts and instances are being recorded with the following ﬁelds .
422 Amazon Elastic Compute Cloud User Guide for Linux Instances Dedicated Hosts • Instance recording status—When Enabled , the conﬁguration information for Dedicated Instances is recorded .
If any of these three conditions are disabled , the icon in the Edit Conﬁg Recording button is red .
To derive the full beneﬁt of this tool , ensure that all three recording methods are enabled .
When all three are enabled , the icon is green .
You are directed to the Set up AWS Conﬁg page in the AWS Conﬁg console , where you can set up AWS Conﬁg and start recording for your hosts , instances , and other supported resource types .
For more information , see Setting up AWS Conﬁg using the Console in the AWS Conﬁg Developer Guide .
Note AWS Conﬁg records your resources after it discovers them , which might take several minutes .
After AWS Conﬁg starts recording conﬁguration changes to your hosts and instances , you can get the conﬁguration history of any host that you have allocated or released and any instance that you have launched , stopped , or terminated .
For example , at any point in the conﬁguration history of a Dedicated Host , you can look up how many instances are launched on that host , along with the number of sockets and cores on the host .
For any of those instances , you can also look up the ID of its Amazon Machine Image ( AMI ) .
You can use this information to report on licensing for your own server-bound software that is licensed per-socket or per-core .
You can view conﬁguration histories in any of the following ways : • By using the AWS Conﬁg console .
To view this page , choose the gray icon in the Conﬁg Timeline column of the Dedicated Hosts page .
For more information , see Viewing Conﬁguration Details in the AWS Conﬁg Console in the AWS Conﬁg Developer Guide .
Then , you can use the get-resource-conﬁg-history command to get the conﬁguration details of a host or instance for a speciﬁc time interval .
For more information , see View Conﬁguration Details Using the CLI in the AWS Conﬁg Developer Guide .
• By using the AWS Conﬁg API in your applications .
First , you can use the ListDiscoveredResources action to get a list of all hosts and instances .
Then , you can use the GetResourceConﬁgHistory action to get the conﬁguration details of a host or instance for a speciﬁc time interval .
For example , to get a list of all of your Dedicated Hosts from AWS Conﬁg , run a CLI command such as the following .
On the Dedicated Hosts page , choose Edit Conﬁg Recording .
In the AWS Conﬁg console , follow the steps provided to turn on recording .
For more information , see Setting up AWS Conﬁg using the Console .
For more information , see Viewing Conﬁguration Details in the AWS Conﬁg Console .
423 Amazon Elastic Compute Cloud User Guide for Linux Instances Dedicated Instances To activate AWS Conﬁg using the command line or API • Using the AWS CLI , see Viewing Conﬁguration Details ( AWS CLI ) in the AWS Conﬁg Developer Guide .
Dedicated Instances that belong to diﬀerent AWS accounts are physically isolated at the hardware level .
In addition , Dedicated Instances that belong to AWS accounts that are linked to a single payer account are also physically isolated at the hardware level .
However , Dedicated Instances may share hardware with other instances from the same AWS account that are not Dedicated Instances .
With a Dedicated Host , you have visibility and control over how instances are placed on the server .
Dedicated Instance Basics Each instance that you launch into a VPC has a tenancy attribute .
This attribute has the following values .
Tenancy Value Description default Your instance runs on shared hardware .
host Your instance runs on a Dedicated Host , which is an isolated server with conﬁgurations that you can control .
After you launch an instance , there are some limitations to changing its tenancy .
• You can not change the tenancy of an instance from default to dedicated or host after you've launched it .
• You can not change the tenancy of an instance from dedicated or host to default after you've launched it .
You can change the tenancy of an instance from dedicated to host , or from host to dedicated after you 've launched it .
This attribute has the following values .
Tenancy Value Description default An instance launched into the VPC runs on shared hardware by default , unless you explicitly specify a diﬀerent tenancy during instance launch .
dedicated An instance launched into the VPC is a Dedicated Instance by default , unless you explicitly specify a tenancy of host during instance launch .
You can not specify a tenancy of default during instance launch .
424 Amazon Elastic Compute Cloud User Guide for Linux Instances Dedicated Instances You can change the instance tenancy of a VPC from dedicated to default after you create it .
You can not change the instance tenancy of a VPC to dedicated .
To create Dedicated Instances , you can do the following : • Create the VPC with the instance tenancy set to dedicated ( all instances launched into this VPC are Dedicated Instances ) .
• Create the VPC with the instance tenancy set to default , and specify a tenancy of dedicated for any instances when you launch them .
Dedicated Instances Limitations Some AWS services or their features wo n't work with a VPC with the instance tenancy set to dedicated .
Check the service 's documentation to conﬁrm if there are any limitations .
Some instance types can not be launched into a VPC with the instance tenancy set to dedicated .
Amazon EBS with Dedicated Instances When you launch an Amazon EBS-backed Dedicated Instance , the EBS volume does n't run on singletenant hardware .
Reserved Instances with Dedicated Tenancy To guarantee that suﬃcient capacity is available to launch Dedicated Instances , you can purchase Dedicated Reserved Instances .
When you purchase a Dedicated Reserved Instance , you are purchasing the capacity to launch a Dedicated Instance into a VPC at a much reduced usage fee ; the price break in the usage charge applies only if you launch an instance with dedicated tenancy .
When you purchase a Reserved Instance with default tenancy , it applies only to a running instance with default tenancy ; it would not apply to a running instance with dedicated tenancy .
You ca n't use the modiﬁcation process to change the tenancy of a Reserved Instance after you've purchased it .
Automatic Scaling of Dedicated Instances You can use Amazon EC2 Auto Scaling to launch Dedicated Instances .
For more information , see Launching Auto Scaling Instances in a VPC in the Amazon EC2 Auto Scaling User Guide .
Automatic Recovery of Dedicated Instances You can conﬁgure automatic recovery for a Dedicated Instances if it becomes impaired due to an underlying hardware failure or a problem that requires AWS involvement to repair .
Dedicated Spot Instances You can run a Dedicated Spot Instance by specifying a tenancy of dedicated when you create a Spot Instance request .
Pricing for Dedicated Instances Pricing for Dedicated Instances is diﬀerent to pricing for On-Demand Instances .
425 Amazon Elastic Compute Cloud User Guide for Linux Instances Dedicated Instances Burstable Performance Instances with Dedicated Instances You can leverage the beneﬁts of running on dedicated tenancy hardware with the section called “ Burstable performance instances ” ( p. 200 ) .
T3 Dedicated Instances launch in unlimited mode by default , and they provide a baseline level of CPU performance with the ability to burst to a higher CPU level when required by your workload .
The T3 baseline performance and ability to burst are governed by CPU credits .
Because of the burstable nature of the T3 instance types , we recommend that you monitor how your T3 instances use the CPU resources of the dedicated hardware for the best performance .
T3 Dedicated Instances are intended for customers with diverse workloads that display random CPU behavior , but that ideally have average CPU usage at or below the baseline usages .
Amazon EC2 has systems in place to identify and correct variability in performance .
However , it is still possible to experience short term variability if you launch multiple T3 Dedicated Instances that have correlated CPU usage patterns .
Working with Dedicated Instances You can create a VPC with an instance tenancy of dedicated to ensure that all instances launched into the VPC are Dedicated Instances .
Alternatively , you can specify the tenancy of the instance during launch .
If you 're using the Amazon VPC console , you can create a VPC using the VPC wizard or the Your VPCs page .
On the next page of the wizard , choose Dedicated from the Hardware tenancy list .
To set the tenancy option when you create a VPC using the command line • create-vpc ( AWS CLI ) • New-EC2Vpc ( AWS Tools for Windows PowerShell ) 426 Amazon Elastic Compute Cloud User Guide for Linux Instances Dedicated Instances If you launch an instance into a VPC that has an instance tenancy of dedicated , your instance is automatically a Dedicated Instance , regardless of the tenancy of the instance .
Launching Dedicated Instances into a VPC You can launch a Dedicated Instance using the Amazon EC2 launch instance wizard .
On the Choose an Amazon Machine Image ( AMI ) page , select an AMI and choose Select .
On the Choose an Instance Type page , select the instance type and choose Next : Conﬁgure Instance Details .
Note Ensure that you choose an instance type that 's supported as a Dedicated Instance .
Continue as prompted by the wizard .
When you 've ﬁnished reviewing your options on the Review Instance Launch page , choose Launch to choose a key pair and launch the Dedicated Instance .
To set the tenancy option for an instance during launch using the command line • run-instances ( AWS CLI ) • New-EC2Instance ( AWS Tools for Windows PowerShell ) Displaying Tenancy Information To display tenancy information for your VPC using the console 1 .
Check the instance tenancy of your VPC in the Tenancy column .
To display tenancy information for your instance using the console 1 .
Check the tenancy of your instance in the Tenancy column .
The Description tab in the details pane displays information about the instance , including its tenancy .
For more information about allocating and working with Dedicated Hosts , and the instance types that can be used with Dedicated Hosts , see Working with Dedicated Hosts ( p. 397 ) .
Similarly , you can change the tenancy of a stopped Dedicated Host instance to dedicated after launching it .
To change the tenancy of an instance using the console 1 .
In the navigation pane , choose Instances and select your instance .
In the Tenancy list , choose whether to run your instance on dedicated hardware or on a Dedicated Host .
To modify the tenancy value of an instance using the command line • modify-instance-placement ( AWS CLI ) • Edit-EC2InstancePlacement ( AWS Tools for Windows PowerShell ) Changing the Tenancy of a VPC You can change the instance tenancy attribute of a VPC from dedicated to default .
Modifying the instance tenancy of the VPC does not aﬀect the tenancy of any existing instances in the VPC .
The next time you launch an instance in the VPC , it has a tenancy of default , unless you specify otherwise during launch .
428 Amazon Elastic Compute Cloud User Guide for Linux Instances On-Demand Capacity Reservations You can not change the instance tenancy attribute of a VPC to dedicated .
You can modify the instance tenancy attribute of a VPC using the AWS CLI , an AWS SDK , or the Amazon EC2 API only .
To modify the instance tenancy attribute of a VPC using the AWS CLI • Use the modify-vpc-tenancy command to specify the ID of the VPC and instance tenancy value .
The only supported value is default .
This gives you the ability to create and manage capacity reservations independently from the billing discounts oﬀered by Savings Plans or regional Reserved Instances .
By creating Capacity Reservations , you ensure that you always have access to EC2 capacity when you need it , for as long as you need it .
When you no longer need the reservation , cancel the Capacity Reservation to stop incurring charges for it .
When you create a Capacity Reservation , you specify : • The Availability Zone in which to reserve the capacity • The number of instances for which to reserve capacity • The instance attributes , including the instance type , tenancy , and platform/OS Capacity Reservations can only be used by instances that match their attributes .
By default , they are automatically used by running instances that match the attributes .
If you do n't have any running instances that match the attributes of the Capacity Reservation , it remains unused until you launch an instance with matching attributes .
In addition , you can use Savings Plans and regional Reserved Instances with your Capacity Reservations to beneﬁt from billing discounts .
AWS automatically applies your discount when the attributes of a Capacity Reservation match the attributes of a Savings Plan or regional Reserved Instance .
Can be created and canceled as needed .
Instances launched into a Capacity Reservation are charged at their standard OnDemand rates .
However , you can use Savings Plans or regional Reserved Instances with Capacity Reservations to get a billing discount .
Zonal Reserved Instances do not apply to Capacity Reservations .
Provide billing discounts Instance Limits Limited to your OnDemand Instance limits per Region .
Do not reserve capacity in an Availability Zone .
For more information , see the following : • Reserved Instances ( p. 280 ) • AWS Savings Plans User Guide Capacity Reservation Limits The number of instances for which you are allowed to reserve capacity is based on your account 's OnDemand Instance limit .
You can reserve capacity for as many instances as that limit allows , minus the number of instances that are already running .
Capacity Reservation Limitations and Restrictions Before you create Capacity Reservations , take note of the following limitations and restrictions .
• Active and unused Capacity Reservations count toward your On-Demand Instance limits • Capacity Reservations are not transferable from one AWS account to another • Zonal Reserved Instance billing discounts do not apply to Capacity Reservations • Capacity Reservations ca n't be created in placement groups 430 Amazon Elastic Compute Cloud User Guide for Linux Instances On-Demand Capacity Reservations • Capacity Reservations ca n't be used with Dedicated Hosts • Capacity Reservations ca n't be used with Bring Your Own License ( BYOL ) Capacity Reservation Pricing and Billing The price for a Capacity Reservation varies by payment option .
Pricing When the Capacity Reservation is active , you are charged the equivalent On-Demand rate whether you run the instances or not .
If you do not use the reservation , this shows up as unused reservation on your EC2 bill .
When you run an instance that matches the attributes of a reservation , you just pay for the instance and nothing for the reservation .
There are no upfront or additional charges .
For example , if you create a Capacity Reservation for 20 m4.large Linux instances and run 15 m4.large Linux instances in the same Availability Zone , you will be charged for 15 active instances and for 5 unused instances in the reservation .
Billing discounts for Savings Plans and regional Reserved Instances apply to Capacity Reservations .
This means that you are charged for partial hours .
The following example shows how a Capacity Reservation is billed .
In this example , the Capacity Reservation is active in the account for ﬁve hours .
The Capacity Reservation is unused for the ﬁrst hour , so it is billed for one unused hour at the m4.large instance type 's standard On-Demand rate .
In hours two through ﬁve , the Capacity Reservation is occupied by an m4.large instance .
During this time , the Capacity Reservation accrues no charges , and the account is instead billed for the m4.large instance occupying it .
In the sixth hour , the Capacity Reservation is canceled and the m4.large instance runs normally outside of the reserved capacity .
For that hour , it is charged at the OnDemand rate of the m4.large instance type .
Billing Discounts Billing discounts for Savings Plans and regional Reserved Instances apply to Capacity Reservations .
AWS automatically applies these discounts to Capacity Reservations that have matching attributes .
When a Capacity Reservation is used by an instance , the discount is applied to the instance .
Discounts are preferentially applied to instance usage before covering unused Capacity Reservations .
431 Amazon Elastic Compute Cloud User Guide for Linux Instances On-Demand Capacity Reservations Billing discounts for zonal Reserved Instances do not apply to Capacity Reservations .
For more information , see the following : • Reserved Instances ( p. 280 ) • AWS Savings Plans User Guide Viewing Your Bill You can review the charges and fees to your account on the AWS Billing and Cost Management console .
• On the Bills page , under Details , expand the Elastic Compute Cloud section and the Region to get billing information about your Capacity Reservations .
You can view the charges online , or you can download a CSV ﬁle .
For more information , see Capacity Reservation Line Items in the AWS Billing and Cost Management User Guide .
Working with Capacity Reservations To start using Capacity Reservations , you create the capacity reservation in the required Availability Zone .
Then , you can launch instances into the reserved capacity , view its capacity utilization in real time , and increase or decrease its capacity as needed .
By default , Capacity Reservations automatically match new instances and running instances that have matching attributes ( instance type , platform , and Availability Zone ) .
This means that any instance with matching attributes automatically runs in the Capacity Reservation .
This enables you to explicitly control which instances are allowed to run in that reserved capacity .
You can specify how the reservation ends .
You can choose to manually cancel the Capacity Reservation or end it automatically at a speciﬁed time .
If you specify an end time , the Capacity Reservation is canceled within an hour of the speciﬁed time .
After a reservation ends , you can no longer target instances to the Capacity Reservation .
Instances running in the reserved capacity continue to run uninterrupted .
If instances targeting a Capacity Reservation are stopped , you can not restart them until you remove their Capacity Reservation targeting preference or conﬁgure them to target a diﬀerent Capacity Reservation .
The capacity remains reserved for your use as long as the Capacity Reservation is active , and you can launch instances into it at any time .
If the Capacity Reservation is open , new instances and existing instances that have matching attributes automatically run in the Capacity Reservation 's capacity .
If the Capacity Reservation is targeted , instances must speciﬁcally target it to run in the reserved capacity .
432 Amazon Elastic Compute Cloud User Guide for Linux Instances On-Demand Capacity Reservations Your request to create a Capacity Reservation could fail if one of the following is true : • Amazon EC2 does not have suﬃcient capacity to fulﬁll the request .
If your application is ﬂexible across instance types and sizes , try diﬀerent instance attributes .
• The requested quantity exceeds your On-Demand Instance limit for the selected instance family .
Increase your On-Demand Instance limit for the instance family and try again .
Choose Capacity Reservations , and then choose Create Capacity Reservation .
On the Create a Capacity Reservation page , conﬁgure the following settings in the Instance details section .
The instance type , platform , and Availability Zone of the instances that you launch must match the instance type , platform , and Availability Zone that you specify here or the Capacity Reservation is not applied .
For example , if an open Capacity Reservation does n't match , an instance launch that targets that Capacity Reservation explicitly will fail .
Instance Type—The type of instance to launch into the reserved capacity .
This option is selected by default for some instance types .
Attach instance store at launch—Specify whether instances launched into the Capacity Reservation use temporary block-level storage .
The data on an instance store volume persists only during the life of the associated instance .
If you specify a quantity that exceeds your remaining On-Demand Instance limit for the selected instance type , the request is denied .
If you launch an instance with matching attributes , it is placed into the reserved capacity automatically .
Launching an instance into a Capacity Reservation reduces its available capacity by the number of instances launched .
For example , if you launch three instances , the Capacity Reservation 's available capacity is reduced by three .
To launch instances into an existing Capacity Reservation using the console 1 .
Open the Launch Instance wizard by choosing Launch Instances from Dashboard or Instances .
Complete the Conﬁgure Instance Details page .
For Capacity Reservation , choose one of the following options : • Open — Launches the instances into any Capacity Reservation that has matching attributes and suﬃcient capacity for the number of instances you selected .
If there is no matching Capacity Reservation with suﬃcient capacity , the instance uses On-Demand capacity .
If this Capacity Reservation does not have suﬃcient capacity for the number of instances you selected , the instance launch fails .
Complete the remaining steps to launch the instances .
To launch an instance into an existing Capacity Reservation using the AWS CLI Use the run-instances command and specify the -- capacity-reservation-specification parameter .
You can not modify a Capacity Reservation after it has expired or after you have explicitly canceled it .
When modifying a Capacity Reservation , you can only increase or decrease the quantity and change the way in which it is released .
If you need to modify any of these attributes , we recommend that you cancel the reservation , and then create a new one with the required attributes .
If you specify a new quantity that exceeds your remaining On-Demand Instance limit for the selected instance type , the update fails .
434 Amazon Elastic Compute Cloud User Guide for Linux Instances On-Demand Capacity Reservations To modify a Capacity Reservation using the console 1 .
Choose Capacity Reservations , select the Capacity Reservation to modify , and then choose Edit .
Modify the Quantity or Reservation ends options as needed , and choose Save changes .
Choose Instances and select the instance to modify .
Stop the instance if it is not already stopped .
For Capacity Reservation , choose one of the following options : • Open — Starts the instance in any open Capacity Reservation that has matching attributes ( instance type , platform , and Availability Zone ) and available capacity .
If you do not have a matching Capacity Reservation with available capacity , the instance uses On-Demand capacity .
If the instance attributes ( instance type , platform , and Availability Zone ) do not match those of the Capacity Reservation , or if the selected Capacity Reservation does not have suﬃcient capacity , the instance launch fails .
• expired—The Capacity Reservation expired automatically at the date and time speciﬁed in your reservation request .
The reserved capacity is no longer available for your use .
The reserved capacity is no longer available for your use .
• pending—The Capacity Reservation request was successful but the capacity provisioning is still pending .
Choose Capacity Reservations and select a Capacity Reservation to view .
Choose View launched instances for this reservation .
To view your Capacity Reservations using the AWS CLI Use the describe-capacity-reservations command : aws ec2 describe-capacity-reservations Canceling a Capacity Reservation You can cancel a Capacity Reservation at any time if you no longer need the reserved capacity .
When you cancel a Capacity Reservation , the capacity is released immediately , and it is no longer reserved for your use .
You can cancel empty Capacity Reservations and Capacity Reservations that have running instances .
If you cancel a Capacity Reservation that has running instances , the instances continue to run normally outside of the capacity reservation at standard On-Demand Instance rates or at a discounted rate if you have a matching Savings Plan or regional Reserved Instance .
After you cancel a Capacity Reservation , instances that target it can no longer launch .
Modify these instances so that they either target a diﬀerent Capacity Reservation , launch into any open Capacity Reservation with matching attributes and suﬃcient capacity , or avoid launching into a Capacity Reservation .
Choose Capacity Reservations and select the Capacity Reservation to cancel .
To cancel a Capacity Reservation using the AWS CLI Use the cancel-capacity-reservation command : aws ec2 cancel-capacity-reservation -- capacity-reservation-id reservation_id Working with Shared Capacity Reservations Capacity Reservation sharing enables Capacity Reservation owners to share their reserved capacity with other AWS accounts or within an AWS organization .
This enables you to create and manage Capacity 436 Amazon Elastic Compute Cloud User Guide for Linux Instances On-Demand Capacity Reservations Reservations centrally , and share the reserved capacity across multiple AWS accounts or within your AWS organization .
Consumers can launch instances into Capacity Reservations that are shared with them in the same way that they launch instances into Capacity Reservations that they own in their own account .
The Capacity Reservation owner is responsible for managing the Capacity Reservation and the instances that they launch into it .
Owners can not modify instances that consumers launch into Capacity Reservations that they have shared .
Consumers are responsible for managing the instances that they launch into Capacity Reservations shared with them .
Consumers can not view or modify instances owned by other consumers or by the Capacity Reservation owner .
You can not share a Capacity Reservation that has been shared with you .
• You can only share Capacity Reservations for shared tenancy instances .
You can not share Capacity Reservations for dedicated tenancy instances .
• Capacity Reservation sharing is not available to new AWS accounts or AWS accounts that have a limited billing history .
New accounts that are linked to a qualiﬁed master ( payer ) account or are linked through an AWS organization are exempt from this restriction .
• To share a Capacity Reservation with your AWS organization or an organizational unit in your AWS organization , you must enable sharing with AWS Organizations .
For more information , see Enable Sharing with AWS Organizations in the AWS RAM User Guide .
Related Services Capacity Reservation sharing integrates with AWS Resource Access Manager ( AWS RAM ) .
AWS RAM is a service that enables you to share your AWS resources with any AWS account or through AWS Organizations .
With AWS RAM , you share resources that you own by creating a resource share .
A resource share speciﬁes the resources to share , and the consumers with whom to share them .
Consumers can be individual AWS accounts , or organizational units or an entire organization from AWS Organizations .
437 Amazon Elastic Compute Cloud User Guide for Linux Instances On-Demand Capacity Reservations For more information about AWS RAM , see the AWS RAM User Guide .
Sharing Across Availability Zones To ensure that resources are distributed across the Availability Zones for a Region , we independently map Availability Zones to names for each account .
This could lead to Availability Zone naming diﬀerences across accounts .
For example , the Availability Zone us-east-1a for your AWS account might not have the same location as us-east-1a for another AWS account .
To identify the location of your Capacity Reservations relative to your accounts , you must use the Availability Zone ID ( AZ ID ) .
The AZ ID is a unique and consistent identiﬁer for an Availability Zone across all AWS accounts .
For example , use1-az1 is an AZ ID for the us-east-1 Region and it is the same location in every AWS account .
To view the AZ IDs for the Availability Zones in your account 1 .
The AZ IDs for the current Region are displayed in the Your AZ ID panel on the right-hand side of the screen .
Sharing a Capacity Reservation When you share a Capacity Reservation that you own with other AWS accounts , you enable them to launch instances into your reserved capacity .
If you share an open Capacity Reservation , keep the following in mind as it could lead to unintended Capacity Reservation usage : • If consumers have running instances that match the Capacity Reservation 's attributes , have the CapacityReservationPreference parameter set to open , and are not yet running in reserved capacity , they automatically use the shared Capacity Reservation .
• If consumers launch instances that have matching attributes ( instance type , platform , and Availability Zone ) and have the CapacityReservationPreference parameter set to open , they automatically launch into the shared Capacity Reservation .
A resource share is an AWS RAM resource that lets you share your resources across AWS accounts .
A resource share speciﬁes the resources to share , and the consumers with whom they are shared .
When you share a Capacity Reservation using the Amazon EC2 console , you add it to an existing resource share .
To add the Capacity Reservation to a new resource share , you must create the resource share using the AWS RAM console .
If you are part of an organization in AWS Organizations and sharing within your organization is enabled , consumers in your organization are automatically granted access to the shared Capacity Reservation .
Otherwise , consumers receive an invitation to join the resource share and are granted access to the shared Capacity Reservation after accepting the invitation .
You can share a Capacity Reservation that you own using the Amazon EC2 console , AWS RAM console , or the AWS CLI .
Choose the Capacity Reservation to share and choose Actions , Share reservation .
Select the resource share to which to add the Capacity Reservation and choose Share Capacity Reservation .
438 Amazon Elastic Compute Cloud User Guide for Linux Instances On-Demand Capacity Reservations It could take a few minutes for consumers to get access to the shared Capacity Reservation .
To share a Capacity Reservation that you own using the AWS RAM console See Creating a Resource Share in the AWS RAM User Guide .
To share a Capacity Reservation that you own using the AWS CLI Use the create-resource-share command .
Unsharing a Shared Capacity Reservation The Capacity Reservation owner can unshare a shared Capacity Reservation at any time .
When you unshare a shared Capacity Reservation , the following rules apply : • Instances owned by consumers that were running in the shared capacity at the time of unsharing continue to run normally outside of the reserved capacity , and the capacity is restored to the Capacity Reservation subject to Amazon EC2 capacity availability .
• Consumers with whom the Capacity Reservation was shared can no longer launch new instances into the reserved capacity .
To unshare a shared Capacity Reservation that you own , you must remove it from the resource share .
You can do this using the Amazon EC2 console , AWS RAM console , or the AWS CLI .
Choose the Capacity Reservation to unshare and choose the Sharing tab .
The Sharing tab lists the resource shares to which the Capacity Reservation has been added .
Select the resource share from which to remove the Capacity Reservation and choose Remove from resource share .
To unshare a shared Capacity Reservation that you own using the AWS RAM console See Updating a Resource Share in the AWS RAM User Guide .
To unshare a shared Capacity Reservation that you own using the AWS CLI Use the disassociate-resource-share command .
Identifying a Shared Capacity Reservation Owners and consumers can identify shared Capacity Reservations using the Amazon EC2 console and AWS CLI To identify a shared Capacity Reservation using the Amazon EC2 console 1 .
The screen lists Capacity Reservations that you own and Capacity Reservations that are shared with you .
The Owner column shows the AWS account ID of the Capacity Reservation owner .
( me ) next to the AWS account ID indicates that you are the owner .
439 Amazon Elastic Compute Cloud User Guide for Linux Instances On-Demand Capacity Reservations To identify a shared Capacity Reservation using the AWS CLI Use the describe-capacity-reservations command .
The command returns the Capacity Reservations that you own and Capacity Reservations that are shared with you .
OwnerId shows the AWS account ID of the Capacity Reservation owner .
Viewing Shared Capacity Reservation Usage The owner of a shared Capacity Reservation can view its usage at any time using the Amazon EC2 console and the AWS CLI .
Select the Capacity Reservation for which to view the usage and choose the Usage tab .
The AWS account ID column shows the account IDs of the consumers currently using the Capacity Reservation .
The Launched instances column shows the number of instances each consumer currently has running in the reserved capacity .
To view Capacity Reservation usage using the AWS CLI Use the get-capacity-reservation-usage command .
AccountId shows the account ID of the account using the Capacity Reservation .
UsedInstanceCount shows the number of instances the consumer currently has running in the reserved capacity .
Shared Capacity Reservation Permissions Permissions for Owners Owners are responsible for managing and canceling their shared Capacity Reservations .
Owners can not modify instances running in the shared Capacity Reservation that are owned by other accounts .
Owners remain responsible for managing instances that they launch into the shared Capacity Reservation .
Permissions for Consumers Consumers are responsible for managing their instances that are running the shared Capacity Reservation .
Consumers can not modify the shared Capacity Reservation in any way , and they can not view or modify instances that are owned by other consumers or the Capacity Reservation owner .
Billing and Metering There are no additional charges for sharing Capacity Reservations .
The Capacity Reservation owner is billed for instances that they run inside the Capacity Reservation and for unused reserved capacity .
Consumers are billed for the instances that they run inside the shared Capacity Reservation .
Instance Limits All Capacity Reservation usage counts toward the Capacity Reservation owner 's On-Demand Instance limits .
This includes : • Unused reserved capacity • Usage by instances owned by the Capacity Reservation owner • Usage by instances owned by consumers 440 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance Lifecycle Instances launched into the shared capacity by consumers count towards the Capacity Reservation owner 's On-Demand Instance limit .
Consumers ' instance limits are a sum of their own On-Demand Instance limits and the capacity available in the shared Capacity Reservations to which they have access .
Instance Lifecycle By working with Amazon EC2 to manage your instances from the moment you launch them through their termination , you ensure that your customers have the best possible experience with the applications or sites that you host on your instances .
The following illustration represents the transitions between instance states .
The following table provides a brief description of each instance state and indicates whether it is billed or not .
Note The table indicates billing for instance usage only .
Some AWS resources , such as Amazon EBS volumes and Elastic IP addresses , incur charges regardless of the instance 's state .
For more information , see Avoiding Unexpected Charges in the AWS Billing and Cost Management User Guide .
Instance Description state Instance usage billing pending The instance is preparing to enter the running state .
An Not billed 441 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance Launch Instance Description state Instance usage billing instance enters the pending state when it launches for the ﬁrst time , or when it is started after being in the stopped state .
running The instance is running and ready for use .
Billed stoppingThe instance is preparing to be stopped or stophibernated .
Not billed if preparing to stop stopped The instance is shut down and can not be used .
The instance can be started at any time .
Not billed shuttingThe instance is preparing to down be terminated .
Not billed terminated The instance has been permanently deleted and can not be started .
Not billed Billed if preparing to hibernate Note Reserved Instances that applied to terminated instances are billed until the end of their term according to their payment option .
Instance Launch When you launch an instance , it enters the pending state .
The instance type that you speciﬁed at launch determines the hardware of the host computer for your instance .
We use the Amazon Machine Image ( AMI ) you speciﬁed at launch to boot the instance .
After the instance is ready for you , it enters the running state .
You can connect to your running instance and use it the way that you 'd use a computer sitting in front of you .
As soon as your instance transitions to the running state , you 're billed for each second , with a oneminute minimum , that you keep the instance running , even if the instance remains idle and you don't connect to it .
Instance Stop and Start ( Amazon EBS-Backed Instances Only ) If your instance fails a status check or is not running your applications as expected , and if the root volume of your instance is an Amazon EBS volume , you can stop and start your instance to try to ﬁx the problem .
442 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance Hibernate ( Amazon EBS-Backed Instances Only ) When you stop your instance , it enters the stopping state , and then the stopped state .
We don't charge usage or data transfer fees for your instance after you stop it , but we do charge for the storage for any Amazon EBS volumes .
While your instance is in the stopped state , you can modify certain attributes of the instance , including the instance type .
When you start your instance , it enters the pending state , and in most cases , we move the instance to a new host computer .
( Your instance might stay on the same host computer if there are no problems with the host computer . ) .
When you stop and start your instance , you lose any data on the instance store volumes on the previous host computer .
Your instance retains its private IPv4 address , which means that an Elastic IP address associated with the private IPv4 address or network interface is still associated with your instance .
Each time you transition an instance from stopped to running , we charge per second when the instance is running , with a minimum of one minute every time you start your instance .
We persist the instance 's Amazon EBS root volume and any attached Amazon EBS data volumes .
When you start your instance , the Amazon EBS root volume is restored to its previous state and the RAM contents are reloaded .
Previously attached data volumes are reattached and the instance retains its instance ID .
When you hibernate your instance , it enters the stopping state , and then the stopped state .
We don't charge usage for a hibernated instance when it is in the stopped state , but we do charge while it is in the stopping state , unlike when you stop an instance ( p. 442 ) without hibernating it .
We do n't charge usage for data transfer fees , but we do charge for the storage for any Amazon EBS volumes , including storage for the RAM data .
When you start your hibernated instance , it enters the pending state , and in most cases , we move the instance to a new host computer .
Your instance might stay on the same host computer if there are no problems with the host computer .
Your instance retains its private IPv4 address , which means that an Elastic IP address associated with the private IPv4 address or network interface is still associated with your instance .
We recommend that you use Amazon EC2 to reboot your instance instead of running the operating system reboot command from your instance .
Rebooting an instance is equivalent to rebooting an operating system .
The instance remains on the same host computer and maintains its public DNS name , private IP address , and any data on its instance store volumes .
It typically takes a few minutes for the reboot to complete , but the time it takes to reboot depends on the instance conﬁguration .
443 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance Retirement Instance Retirement An instance is scheduled to be retired when AWS detects the irreparable failure of the underlying hardware hosting the instance .
When an instance reaches its scheduled retirement date , it is stopped or terminated by AWS .
If your instance root device is an Amazon EBS volume , the instance is stopped , and you can start it again at any time .
If your instance root device is an instance store volume , the instance is terminated , and can not be used again .
Instance Termination When you 've decided that you no longer need an instance , you can terminate it .
As soon as the status of an instance changes to shutting-down or terminated , you stop incurring charges for that instance .
After you terminate an instance , it remains visible in the console for a short while , and then the entry is automatically deleted .
You can also describe a terminated instance using the CLI and API .
Resources ( such as tags ) are gradually disassociated from the terminated instance , therefore may no longer be visible on the terminated instance after a short while .
Each Amazon EBS-backed instance supports the InstanceInitiatedShutdownBehavior attribute , which controls whether the instance stops or terminates when you initiate shutdown from within the instance itself ( for example , by using the shutdown command on Linux ) .
The default behavior is to stop the instance .
You can modify the setting of this attribute while the instance is running or stopped .
Each Amazon EBS volume supports the DeleteOnTermination attribute , which controls whether the volume is deleted or preserved when you terminate the instance it is attached to .
The default is to delete the root device volume and preserve any other EBS volumes .
Your instance may stay on the same host computer if there are no problems with the host computer .
Your instance may stay on the same host computer if there are no problems with the host computer .
None Private and public IPv4 addresses These addresses stay the same The instance keeps its private IPv4 address .
The instance gets The instance keeps its private IPv4 address .
Terminate Elastic IP addresses ( IPv4 ) The Elastic IP address remains associated with the instance The Elastic IP address remains associated with the instance The Elastic IP address remains associated with the instance The Elastic IP address is disassociated from the instance IPv6 address The address stays the same The instance keeps its IPv6 address The instance keeps its IPv6 address None Instance store volumes The data is preserved The data is erased The data is erased The data is erased Root device volume The volume is preserved The volume is preserved The volume is preserved The volume is deleted by default RAM ( contents of memory ) The RAM is erased The RAM is erased The RAM is saved to a ﬁle on the root volume The RAM is erased Billing The instance billing hour does n't change .
You stop incurring charges for an instance as soon as its state changes to stopping .
Each time an instance transitions from stopped to running , we start a new instance billing period , billing a minimum of one minute every time you start your instance .
You incur charges while the instance is in the stopping state , but stop incurring charges when the instance is in the stopped state .
Each time an instance transitions from stopped to running , we start a new instance billing period , billing a minimum of one minute every time you start your instance .
You stop incurring charges for an instance as soon as its state changes to shutting-down .
Operating system shutdown commands always terminate an instance store-backed instance .
You can control whether operating system shutdown commands stop or terminate an Amazon EBS-backed instance .
Launch your instance An instance is a virtual server in the AWS Cloud .
The AMI provides the operating system , application server , and applications for your instance .
When you sign up for AWS , you can get started with Amazon EC2 for free using the AWS Free Tier .
You can use the free tier to launch and use a micro instance for free for 12 months .
If you launch an instance 445 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch that is not within the free tier , you incur the standard Amazon EC2 usage fees for the instance .
You can launch an instance using the following methods .
Using Amazon EC2 through the AWS CLI [ AWS Tools for Windows PowerShell ] Use an AMI that you select .
For information about how to create an Outpost , see Get Started with AWS Outposts in the AWS Outposts User Guide .
After you launch your instance , you can connect to it and use it .
When the instance state is running , the instance has started booting .
There might be a short time before you can connect to the instance .
The instance receives a public DNS name that you can use to contact the instance from the internet .
The instance also receives a private DNS name that other instances within the same VPC can use to contact the instance .
When you are ﬁnished with an instance , be sure to terminate it .
Launching an instance using the Launch Instance Wizard You can launch an instance using the launch instance wizard .
The launch instance wizard speciﬁes all the launch parameters required for launching an instance .
Where the launch instance wizard provides a 446 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch default value , you can accept the default or specify your own value .
At the very least , you need to select an AMI and a key pair to launch an instance .
Before you launch your instance , be sure that you are set up .
Important When you launch an instance that 's not within the AWS Free Tier , you are charged for the time that the instance is running , even if it remains idle .
Select a Region for the instance that meets your needs .
This choice is important because some Amazon EC2 resources can be shared between Regions , while others ca n't .
An AMI contains the information required to create a new instance .
Select the type of AMI to use in the left pane : Quick Start A selection of popular AMIs to help you get started quickly .
To select an AMI that is eligible for the free tier , choose Free tier only in the left pane .
These AMIs are marked Free tier eligible .
My AMIs The private AMIs that you own , or private AMIs that have been shared with you .
To view AMIs shared with you , choose Shared with me in the left pane .
AWS Marketplace An online store where you can buy software that runs on AWS , including AMIs .
447 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch Community AMIs The AMIs that AWS community members have made available for others to use .
To ﬁlter the list of AMIs by operating system , choose the appropriate check box under Operating system .
You can also ﬁlter by architecture and root device type .
Check the Root device type listed for each AMI .
Check the Virtualization type listed for each AMI .
Notice which AMIs are the type that you need , either hvm or paravirtual .
Choose an AMI that meets your needs , and then choose Select .
Step 2 : Choose an Instance Type On the Choose an Instance Type page , select the hardware conﬁguration and size of the instance to launch .
Larger instance types have more CPU and memory .
By default , the wizard displays current generation instance types , and selects the ﬁrst available instance type based on the AMI that you selected .
To view previous generation instance types , choose All generations from the ﬁlter list .
Note To set up an instance quickly for testing purposes , choose Review and Launch to accept the default conﬁguration settings , and launch your instance .
Step 3 : Conﬁgure Instance Details On the Conﬁgure Instance Details page , change the following settings as necessary ( expand Advanced Details to see all the settings ) , and then choose Next : Add Storage : • Number of instances : Enter the number of instances to launch .
Tip To ensure faster instance launches , break up large requests into smaller batches .
For example , create ﬁve separate launch requests for 100 instances each instead of one launch request for 500 instances .
• ( Optional ) To help ensure that you maintain the correct number of instances to handle demand on your application , you can choose Launch into Auto Scaling Group to create a launch conﬁguration and an Auto Scaling group .
Auto Scaling scales the number of instances in the group according to your speciﬁcations .
This adds and removes options from this page .
Set your maximum price , and optionally update the request type , interruption behavior , and request validity .
When you have ﬁnished , return to the wizard and choose Refresh to load your VPC in the list .
To launch the instance in an Availability Zone , select the subnet into which to launch your instance .
You can select No preference to let AWS choose a default subnet in any Availability Zone .
To create a 448 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch new subnet , choose Create new subnet to go to the Amazon VPC console .
When you are done , return to the wizard and choose Refresh to load your subnet in the list .
To launch the instance in a Local Zone , select a subnet that you created in the Local Zone .
To launch an instance in an Outpost , select a subnet in a VPC that you associated with an Outpost .
You can select Enable or Disable to override the subnet 's default setting .
Select Enable or Disable to override the subnet 's default setting .
This option is only available if you 've associated an IPv6 CIDR block with your VPC and subnet .
For more information , see Your VPC and Subnets in the Amazon VPC User Guide .
This option is only available if you 've selected an instance type that supports placement groups .
• Capacity Reservation : Specify whether to launch the instance into shared capacity or an existing Capacity Reservation .
Set the number of CPU cores and threads per core .
• Shutdown behavior : Select whether the instance should stop or terminate when shut down .
This option is only available if your instance meets the hibernation prerequisites .
• Monitoring : Select this check box to enable detailed monitoring of your instance using Amazon CloudWatch .
If the instance type supports this feature , select this check box to enable it .
• T2/T3 Unlimited : Select this check box to enable applications to burst beyond the baseline for as long as needed .
• File systems : Choose Add ﬁle system to mount one or more Amazon EFS ﬁle systems to your instance .
• Network interfaces : If you selected a speciﬁc subnet , you can specify up to two network interfaces for your instance : • For Network Interface , select New network interface to let AWS create a new interface , or select an existing , available network interface .
449 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch • For Secondary IP addresses , choose Add IP to assign more than one private IPv4 address to the selected network interface .
A secondary network interface can reside in a diﬀerent subnet of the VPC , provided it 's in the same Availability Zone as your instance .
If you specify more than one network interface , your instance can not receive a public IPv4 address .
If you have selected a kernel , you may need to select a speciﬁc RAM disk with the drivers to support it .
• Metadata accessible : You can enable or disable access to the instance metadata .
• Metadata version : If you enable access to the instance metadata , you can choose to require the use of Instance Metadata Service Version 2 when requesting instance metadata .
• Metadata token response hop limit : If you enable instance metadata , you can set the allowable number of network hops for the metadata token .
• User data : You can specify user data to conﬁgure an instance during launch , or to run a conﬁguration script .
To attach a ﬁle , select the As ﬁle option and browse for the ﬁle to attach .
Step 4 : Add Storage The AMI you selected includes one or more volumes of storage , including the root device volume .
On the Add Storage page , you can specify additional volumes to attach to the instance by choosing Add New Volume .
• Type : Select instance store or Amazon EBS volumes to associate with your instance .
The types of volume available in the list depend on the instance type you 've chosen .
• Device : Select from the list of available device names for the volume .
You can also search for available shared and public snapshots by typing text into the Snapshot ﬁeld .
Even if you have selected an AMI and instance that are eligible for the free tier , to stay within the free tier , you must stay under 30 GiB of total storage .
• Delete on Termination : For Amazon EBS volumes , select this check box to delete the volume when the instance is terminated .
• Encrypted : If the instance type supports EBS encryption , you can specify the encryption state of the volume .
If you have enabled encryption by default in this Region , the default CMK is selected 450 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch for you .
For Spot Instances , you can tag the Spot Instance request only .
Choose Add another tag to add more than one tag to your resources .
Choose Next : Conﬁgure Security Group when you are done .
Step 6 : Conﬁgure Security Group On the Conﬁgure Security Group page , use a security group to deﬁne ﬁrewall rules for your instance .
These rules specify which incoming network traﬃc is delivered to your instance .
Select or create a security group as follows , and then choose Review and Launch .
• To select an existing security group , choose Select an existing security group , and select your security group .
You ca n't edit the rules of an existing security group , but you can copy them to a new group by choosing Copy to new .
Then you can add rules as described in the next step .
The wizard automatically deﬁnes the launch-wizard-x security group and creates an inbound rule to allow you to connect to your instance over SSH ( port 22 ) .
To add a rule , choose Add Rule , select the protocol to open to network traﬃc , and then specify the source .
Choose My IP from the Source list to let the wizard add your computer 's public IP address .
However , if you are connecting through an ISP or from behind your ﬁrewall without a static IP address , you need to ﬁnd out the range of IP addresses used by client computers .
Warning Rules that enable all IP addresses ( 0.0.0.0/0 ) to access your instance over SSH or RDP are acceptable for this short exercise , but are unsafe for production environments .
You should authorize only a speciﬁc IP address or range of addresses to access your instance .
Step 7 : Review Instance Launch and Select Key Pair On the Review Instance Launch page , check the details of your instance , and make any necessary changes by choosing the appropriate Edit link .
In the Select an existing key pair or create a new key pair dialog box , you can choose an existing key pair , or create a new one .
For example , choose Choose an existing key pair , then select the key pair you created when getting set up .
To launch your instance , select the acknowledgment check box , then choose Launch Instances .
Important If you choose the Proceed without key pair option , you wo n't be able to connect to the instance unless you choose an AMI that is conﬁgured to allow users another way to log in .
On the conﬁrmation screen , choose Create status check alarms and follow the directions .
If the instance fails to launch or the state immediately goes to terminated instead of running , see Troubleshooting instance launch issues ( p. 1127 ) .
451 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch Launching an instance from a launch template You can create a launch template that contains the conﬁguration information to launch an instance .
Launch templates enable you to store launch parameters so that you do not have to specify them every time you launch an instance .
For example , a launch template can contain the AMI ID , instance type , and network settings that you typically use to launch instances .
When you launch an instance using the Amazon EC2 console , an AWS SDK , or a command line tool , you can specify the launch template to use .
For each launch template , you can create one or more numbered launch template versions .
Each version can have diﬀerent launch parameters .
When you launch an instance from a launch template , you can use any version of the launch template .
You can set any version of the launch template as the default version—by default , it 's the ﬁrst version of the launch template .
The following diagram shows a launch template with three versions .
The ﬁrst version speciﬁes the instance type , AMI ID , subnet , and key pair to use to launch the instance .
The second version is based on the ﬁrst version and also speciﬁes a security group for the instance .
The third version uses diﬀerent values for some of the parameters .
If you launched an instance from this launch template , the launch parameters from version 2 would be used if no other version were speciﬁed .
452 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch • Launch template parameters are optional .
However , you must ensure that your request to launch an instance includes all required parameters .
For example , if your launch template does not include an AMI ID , you must specify both the launch template and an AMI ID when you launch an instance .
• Launch template parameters are not validated when you create the launch template .
If you specify incorrect values for parameters , or if you do not use supported parameter combinations , no instances can launch using this launch template .
Ensure that you specify the correct values for the parameters and that you use supported parameter combinations .
• Launch template versions are numbered in the order in which they are created .
When you create a launch template version , you can not specify the version number yourself .
Using launch templates to control launch parameters A launch template can contain all or some of the parameters to launch an instance .
When you launch an instance using a launch template , you can override parameters that are speciﬁed in the launch template .
Or , you can specify additional parameters that are not in the launch template .
Note You can not remove launch template parameters during launch ( for example , you can not specify a null value for the parameter ) .
To remove a parameter , create a new version of the launch template without the parameter and use that version to launch the instance .
You must also have permissions to create or use the resources that are created or associated with the instance .
You can use resource-level permissions for the ec2 : RunInstances action to control the launch parameters that users can specify .
Alternatively , you can grant users permissions to launch an instance using a launch template .
This enables you to manage launch parameters in a launch template rather than in an IAM policy , and to use a launch template as an authorization vehicle for launching instances .
For example , you can specify that users can only launch instances using a launch template , and that they can only use a speciﬁc launch template .
You can also control the launch parameters that users can override in the launch template .
Controlling the use of launch templates By default , IAM users do not have permissions to work with launch templates .
You can create an IAM user policy that grants users permissions to create , modify , describe , and delete launch templates and launch template versions .
You can also apply resource-level permissions to some launch template actions to control a user 's ability to use speciﬁc resources for those actions .
You can not use resource-level permissions to control which resources users can specify in the launch template .
To restrict the resources that are used to launch an instance , ensure that you grant permissions to create launch templates and launch template versions only to appropriate administrators .
Creating a launch template Create a new launch template using parameters that you deﬁne , or use an existing launch template or an instance as the basis for a new launch template .
In the navigation pane , choose Launch Templates , and then choose Create launch template .
For Template version description , provide a brief description of the launch template version .
To tag the launch template on creation , expand Template tags , choose Add tag , and then enter a tag key and value pair .
To search through all available AMIs , choose Search for AMI .
• Instance type : Ensure that the instance type is compatible with the AMI that you 've speciﬁed .
If you choose VPC , specify the subnet in the Network interfaces section .
If you choose Classic , ensure that the speciﬁed instance type is supported in EC2-Classic and specify the Availability Zone for the instance .
• Security groups : One or more security groups to associate with the instance .
• Volume type : The instance store or Amazon EBS volumes with which to associate your instance .
The type of volume depends on the instance type that you 've chosen .
• Snapshot : The ID of the snapshot from which to create the volume .
• Delete on termination : For Amazon EBS volumes , whether to delete the volume when the instance is terminated .
• Encrypted : If the instance type supports EBS encryption , you can enable encryption for the volume .
If you have enabled encryption by default in this Region , encryption is enabled for you .
You can specify the ARN of any customer master key ( CMK ) that you created using the AWS Key Management Service .
If you specify a CMK , you must also use Encrypted to enable encryption .
If you leave the ﬁeld blank , AWS creates the primary network interface .
• Network interface : The ID of the network interface , or leave blank to let AWS create a new network interface .
If you 've entered an existing network interface for eth0 , the instance is launched in the subnet in which the network interface is located .
Leave blank to let AWS choose one for you .
• Security group ID : The ID of a security group in your VPC with which to associate the network interface .
• Delete on termination : Whether the network interface is deleted when the instance is deleted .
• Elastic Fabric Adapter : Indicates whether the network interface is an Elastic Fabric Adapter .
For Advanced details , expand the section to view the ﬁelds and specify any additional parameters for the instance .
Choose Request Spot Instances to request Spot Instances at the Spot price , capped at the On-Demand price , and choose Customize to change the default Spot Instance settings .
• Shutdown behavior : Whether the instance should stop or terminate when shut down .
This ﬁeld is only valid for instances that meet the hibernation prerequisites .
• Detailed CloudWatch monitoring : Whether to enable detailed monitoring of the instance using Amazon CloudWatch .
For more information , see Working with Amazon Elastic Inference in the Amazon Elastic Inference Developer Guide .
• T2/T3 Unlimited : Whether to enable applications to burst beyond the baseline for as long as needed .
455 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch • Placement group name : Specify a placement group in which to launch the instance .
Not all instance types can be launched in a placement group .
Not all instance types support this feature , and additional charges apply .
If you choose to launch the instance onto a Dedicated Host , you can specify whether to launch the instance into a host resource group or you can target a speciﬁc Dedicated Host .
If you have speciﬁed a kernel , you may need to specify a speciﬁc RAM disk with the drivers to support it .
• License Manager : You can launch instances against the speciﬁed license conﬁguration to track your license usage .
For more information , see Create a License Conﬁguration in the AWS License Manager User Guide .
• Metadata accessible : Whether to enable or disable access to the instance metadata .
• Metadata version : If you enable access to the instance metadata , you can choose to require the use of Instance Metadata Service Version 2 when requesting instance metadata .
• Metadata token response hop limit : If you enable instance metadata , you can set the allowable number of network hops for the metadata token .
• User data : You can specify user data to conﬁgure an instance during launch , or to run a conﬁguration script .
Old console To create a new launch template using deﬁned parameters using the console 1 .
In the navigation pane , choose Launch Templates , and then choose Create launch template .
To tag the launch template on creation , choose Show Tags , Add Tag , and then enter a tag key and value pair .
For Template version description , provide a brief description of the launch template version .
For Launch template contents , provide the following information : • AMI ID : An AMI from which to launch the instance .
To search through all available AMIs , choose Search for AMI .
456 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch • Instance type : Ensure that the instance type is compatible with the AMI that you 've speciﬁed .
If you choose VPC , specify the subnet in the Network interfaces section .
If you choose Classic , ensure that the speciﬁed instance type is supported in EC2-Classic and specify the Availability Zone for the instance .
• Security Groups : One or more security groups to associate with the instance .
If you leave the ﬁeld blank , AWS creates the primary network interface .
• Network interface : The ID of the network interface , or leave blank to let AWS create a new network interface .
If you 've entered an existing network interface for eth0 , the instance is launched in the subnet in which the network interface is located .
Leave blank to let AWS choose one for you .
• Security group ID : The ID of a security group in your VPC with which to associate the network interface .
• Delete on termination : Whether the network interface is deleted when the instance is deleted .
• Elastic Fabric Adapter : Indicates whether the network interface is an Elastic Fabric Adapter .
For Storage ( Volumes ) , specify volumes to attach to the instance besides the volumes speciﬁed by the AMI .
• Volume type : The instance store or Amazon EBS volumes with which to associate your instance .
The type of volume depends on the instance type that you 've chosen .
• Snapshot : The ID of the snapshot from which to create the volume .
• Delete on termination : For Amazon EBS volumes , whether to delete the volume when the instance is terminated .
457 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch • Encrypted : If the instance type supports EBS encryption , you can enable encryption for the volume .
If you have enabled encryption by default in this Region , encryption is enabled for you .
You can specify the ARN of any customer master key ( CMK ) that you created using the AWS Key Management Service .
If you specify a CMK , you must also use Encrypted to enable encryption .
For Advanced Details , expand the section to view the ﬁelds and specify any additional parameters for the instance .
Choose Request Spot instances to request Spot Instances at the Spot price , capped at the On-Demand price , and choose Customize Spot parameters to change the default Spot Instance settings .
• Shutdown behavior : Whether the instance should stop or terminate when shut down .
This ﬁeld is only valid for instances that meet the hibernation prerequisites .
• Monitoring : Whether to enable detailed monitoring of the instance using Amazon CloudWatch .
• T2/T3 Unlimited : Whether to enable applications to burst beyond the baseline for as long as needed .
Not all instance types can be launched in a placement group .
Not all instance types support this feature , and additional charges apply .
If you choose to launch the instance onto a Dedicated Host , you can specify whether to launch the instance into a host resource group or you can target a speciﬁc Dedicated Host .
If you have speciﬁed a kernel , you may need to specify a speciﬁc RAM disk with the drivers to support it .
• User data : You can specify user data to conﬁgure an instance during launch , or to run a conﬁguration script .
458 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch AWS CLI To create a launch template using the AWS CLI • Use the create-launch-template command .
In the navigation pane , choose Launch Templates , and then choose Create launch template .
For Template version description , provide a brief description of the launch template version .
To tag the launch template on creation , expand Template tags , choose Add tag , and then enter a tag key and value pair .
Expand Source template , and for Launch template namechoose a launch template on which to base the new launch template .
For Source template version , choose the launch template version on which to base the new launch template .
Adjust any launch parameters as required , and then choose Create launch template .
Old console To create a launch template from an existing launch template using the console 1 .
For Source template , choose a launch template on which to base the new launch template .
For Source template version , choose the launch template version on which to base the new launch template .
Adjust any launch parameters as required , and then choose Create launch template .
AWS CLI To get launch template data from an instance using the AWS CLI • Use the get-launch-template-data command and specify the instance ID .
You can use the output as a base to create a new launch template or launch template version .
When you create a launch template from an instance , the instance 's network interface IDs and IP addresses are not included in the template .
Managing launch template versions You can create launch template versions for a speciﬁc launch template , set the default version , and delete versions that you no longer require .
( Optional ) Expand Source template and select a version of the launch template to use as a base for the new launch template version .
The new launch template version inherits the launch parameters from this launch template version .
Modify the launch parameters as required , and choose Create launch template .
For Launch template name , select the name of the existing launch template from the list .
The new launch template version inherits the launch parameters from this launch template version .
Modify the launch parameters as required , and choose Create launch template .
You can specify a source version on which to base the new version .
The new version inherits the launch parameters from this version , and you can override parameters using -- launch-template-data .
The following example creates a new version based on version 1 of the launch template and speciﬁes a diﬀerent AMI ID .
When you launch an instance from a launch template and do not specify a version , the instance is launched using the parameters of the default version .
New console To set the default launch template version using the console 1 .
Select the launch template and choose Actions , Set default version .
For Template version , select the version number to set as the default version and choose Set as default version .
Old console To set the default launch template version using the console 1 .
Select the launch template and choose Actions , Set default version .
For Default version , select the version number and choose Set as default version .
AWS CLI To set the default launch template version using the AWS CLI • Use the modify-launch-template command and specify the version that you want to set as the default .
You can not replace the version number after you delete it .
You can not delete the default version of the launch template ; you must ﬁrst assign a diﬀerent version as the default .
Select the launch template and choose Actions , Delete template version .
Select the version to delete and choose Delete .
463 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch Old console To delete a launch template version using console 1 .
Select the launch template and choose Actions , Delete template version .
Select the version to delete and choose Delete launch template version .
AWS CLI To delete a launch template version using the AWS CLI • Use the delete-launch-template-versions command and specify the version numbers to delete .
You have the option to override or add launch parameters before you launch the instance .
You can not remove or edit these tags .
Select the launch template and choose Actions , Launch instance from template .
For Source template version , select the launch template version to use .
For Number of instances , specify the number of instances to launch .
( Optional ) You can override or add launch template parameters by changing and adding parameters in the Instance details section .
Select the launch template and choose Actions , Launch instance from template .
Select the launch template version to use .
( Optional ) You can override or add launch template parameters by changing and adding parameters in the Instance details section .
464 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch Choose Launch instance from template .
Optionally specify the launch template version to use .
The following example overrides the instance type that 's speciﬁed in the launch template ( if any ) .
In the following example , the instance is launched with the tag Owner=TeamA as well as any other tags that are speciﬁed in the launch template .
If the launch template has an existing tag with a key of Owner , the value is replaced with TeamA .
If the launch template has an existing volume deﬁned for /dev/xvdb , its values are replaced with the speciﬁed values .
Using launch templates with Amazon EC2 Auto Scaling You can create an Auto Scaling group and specify a launch template to use for the group .
When Amazon EC2 Auto Scaling launches instances in the Auto Scaling group , it uses the launch parameters deﬁned in the associated launch template .
For more information , see Creating an Auto Scaling Group Using a Launch Template in the Amazon EC2 Auto Scaling User Guide .
Before you can create an Auto Scaling group using a launch template , you must create a launch template that includes the parameters required to launch an instance in an Auto Scaling group , such as the ID of the AMI .
The new console provides guidance to help you create a template that you can use with Auto Scaling .
465 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch To create a launch template to use with Auto Scaling using the console 1 .
In the navigation pane , choose Launch Templates , and then choose Create launch template .
For Template version description , provide a brief description of the launch template version .
Under Auto Scaling guidance , select the checkbox to have Amazon EC2 provide guidance to help create a template to use with Auto Scaling .
Modify the launch parameters as required .
Because you selected Auto Scaling guidance , some ﬁelds are required and some ﬁelds are not available .
For considerations to keep in mind when creating a launch template , and for information about how to conﬁgure the launch parameters for Auto Scaling , see Creating a Launch Template for an Auto Scaling Group in the Amazon EC2 Auto Scaling User Guide .
( Optional ) To create an Auto Scaling group using this launch template , in the Next steps page , choose Create Auto Scaling group .
To create or update an Amazon EC2 Auto Scaling group with a launch template using the AWS CLI • Use the create-auto-scaling-group or the update-auto-scaling-group command and specify the -launch-template parameter .
Using launch templates with EC2 Fleet You can create an EC2 Fleet request and specify a launch template in the instance conﬁguration .
When Amazon EC2 fulﬁlls the EC2 Fleet request , it uses the launch parameters deﬁned in the associated launch template .
You can override some of the parameters that are speciﬁed in the launch template .
Use the -- launch-template-configs parameter to specify the launch template and any overrides for the launch template .
Using launch templates with Spot Fleet You can create a Spot Fleet request and specify a launch template in the instance conﬁguration .
When Amazon EC2 fulﬁlls the Spot Fleet request , it uses the launch parameters deﬁned in the associated launch template .
You can override some of the parameters that are speciﬁed in the launch template .
Use the LaunchTemplateConfigs parameter to specify the launch template and any overrides for the launch template .
Select the launch template and choose Actions , Delete template .
aws ec2 delete-launch-template -- launch-template-id lt-01238c059e3466abc Launching an instance using parameters from an existing instance The Amazon EC2 console provides a Launch More Like This wizard option that enables you to use a current instance as a base for launching other instances .
This option automatically populates the Amazon EC2 launch wizard with certain conﬁguration details from the selected instance .
Note The Launch More Like This wizard option does not clone your selected instance ; it only replicates some conﬁguration details .
To create a copy of your instance , ﬁrst create an AMI from it , then launch more instances from the AMI .
The following conﬁguration details are copied from the selected instance into the launch wizard : • AMI ID • Instance type • Availability Zone , or the VPC and subnet in which the selected instance is located • Public IPv4 address .
• Storage : The default storage conﬁguration is determined by the AMI and the instance type .
On the Instances page , select the instance you want to use .
The launch wizard opens on the Review Instance Launch page .
You can check the details of your instance , and make any necessary changes by clicking the appropriate Edit link .
When you are ready , choose Launch to select a key pair and launch your instance .
If the instance fails to launch or the state immediately goes to terminated instead of running , see Troubleshooting instance launch issues ( p. 1127 ) .
Launching a Linux instance from a backup With an Amazon EBS-backed Linux instance , you can back up the root device volume of the instance by creating a snapshot .
When you have a snapshot of the root device volume of an instance , you can terminate that instance and then later launch a new instance from the snapshot .
This can be useful if you do n't have the original AMI that you launched an instance from , but you need to be able to launch an instance using the same image .
Use the following procedure to create an AMI from the root volume of your instance using the console .
You specify the snapshot using the block device mapping .
To create an AMI from your root volume using the console 1 .
For Volumes , start typing the name or ID of the root volume , and then select it from the list of options .
Choose the snapshot that you just created , and then choose Actions , Create Image .
In the Create Image from EBS Snapshot dialog box , provide the following information and then choose Create .
• ( PV virtualization type only ) Kernel ID and RAM disk ID : Choose the AKI and ARI from the lists .
If you choose the default AKI or do n't choose an AKI , you are required to specify an AKI every time you launch an instance using this AMI .
In addition , your instance may fail the health checks if the default AKI is incompatible with the instance .
• ( Optional ) Block Device Mappings : Add volumes or expand the default size of the root volume for the AMI .
Choose the AMI that you just created , and then choose Launch .
Follow the wizard to launch your instance .
For more information about how to conﬁgure each step in the wizard , see Launching an instance using the Launch Instance Wizard ( p. 446 ) .
Launching an AWS Marketplace instance You can subscribe to an AWS Marketplace product and launch an instance from the product 's AMI using the Amazon EC2 launch wizard .
To cancel your subscription after launch , you ﬁrst have to terminate all instances running from it .
To launch an instance from the AWS Marketplace using the launch wizard 1 .
On the Choose an Amazon Machine Image ( AMI ) page , choose the AWS Marketplace category on the left .
Find a suitable AMI by browsing the categories , or using the search functionality .
Choose Select to choose your product .
You can view the pricing information , as well as any other information that the vendor has provided .
Note You are not charged for using the product until you have launched an instance with the AMI .
Take note of the pricing for each supported instance type , as you will be prompted to select an instance type on the next page of the wizard .
Additional taxes may also apply to the product .
On the Choose an Instance Type page , select the hardware conﬁguration and size of the instance to launch .
On the next pages of the wizard , you can conﬁgure your instance , add storage , and add tags .
Choose Next until you reach the Conﬁgure Security Group page .
The wizard creates a new security group according to the vendor 's speciﬁcations for the product .
We recommend that you adjust these rules to allow only a speciﬁc address or range of addresses to access your instance over those ports .
On the Review Instance Launch page , check the details of the AMI from which you 're about to launch the instance , as well as the other conﬁguration details you set up in the wizard .
Depending on the product you 've subscribed to , the instance may take a few minutes or more to launch .
You are ﬁrst subscribed to the product before your instance can launch .
If there are any problems with your credit card details , you will be asked to update your account details .
When the launch conﬁrmation page displays , choose View Instances to go to the Instances page .
Note You are charged the subscription price as long as your instance is running , even if it is idle .
If your instance is stopped , you may still be charged for storage .
When your instance is in the running state , you can connect to it .
To do this , select your instance in the list and choose Connect .
Follow the instructions in the dialog .
469 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch Important Check the vendor 's usage instructions carefully , as you may need to use a speciﬁc user name to log in to the instance .
If the instance fails to launch or the state immediately goes to terminated instead of running , see Troubleshooting instance launch issues ( p. 1127 ) .
Launching an AWS Marketplace AMI instance using the API and CLI To launch instances from AWS Marketplace products using the API or command line tools , ﬁrst ensure that you are subscribed to the product .
You can then launch an instance with the product 's AMI ID using the following methods : Method Documentation AWS CLI Use the run-instances command , or see the following topic for more information : Launching an Instance .
AWS Tools for Windows PowerShell Use the New-EC2Instance command , or see the following topic for more information : Launch an Amazon EC2 Instance Using Windows PowerShell Query API Use the RunInstances request .
In a single API call , a ﬂeet can launch multiple instance types across multiple Availability Zones , using the OnDemand Instance , Reserved Instance , and Spot Instance purchasing options together .
Using EC2 Fleet , you can : • Deﬁne separate On-Demand and Spot capacity targets and the maximum amount you ’ re willing to pay per hour • Specify the instance types that work best for your applications • Specify how Amazon EC2 should distribute your ﬂeet capacity within each purchasing option You can also set a maximum amount per hour that you ’ re willing to pay for your ﬂeet , and EC2 Fleet launches instances until it reaches the maximum amount .
When the maximum amount you 're willing to pay is reached , the ﬂeet stops launching instances even if it hasn ’ t met the target capacity .
The EC2 Fleet attempts to launch the number of instances that are required to meet the target capacity speciﬁed in your request .
If you speciﬁed a total maximum price per hour , it fulﬁlls the capacity until it reaches the maximum amount that you ’ re willing to pay .
The ﬂeet can also attempt to maintain its target Spot capacity if your Spot Instances are interrupted .
470 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch You can specify an unlimited number of instance types per EC2 Fleet .
Those instance types can be provisioned using both On-Demand and Spot purchasing options .
You can also specify multiple Availability Zones , specify diﬀerent maximum Spot prices for each instance , and choose additional Spot options for each ﬂeet .
Amazon EC2 uses the speciﬁed options to provision capacity when the ﬂeet launches .
While the ﬂeet is running , if Amazon EC2 reclaims a Spot Instance because of a price increase or instance failure , EC2 Fleet can try to replace the instances with any of the instance types that you specify .
This makes it easier to regain capacity during a spike in Spot pricing .
You can develop a ﬂexible and elastic resourcing strategy for each ﬂeet .
For example , within speciﬁc ﬂeets , your primary capacity can be OnDemand supplemented with less-expensive Spot capacity if available .
If you have Reserved Instances and you specify On-Demand Instances in your ﬂeet , EC2 Fleet uses your Reserved Instances .
You pay only for the EC2 instances that the ﬂeet launches for you .
EC2 Fleet limits The usual Amazon EC2 limits apply to instances launched by an EC2 Fleet , such as Spot request price limits , instance limits , and volume limits .
You can not request a limit increase for these limits .
T3 Spot Instances If you plan to use your T3 Spot Instances immediately and for a short duration , with no idle time for accruing CPU credits , we recommend that you launch your T3 Spot Instances in standard ( p. 212 ) mode to avoid paying higher costs .
If you use the instance for a short duration , your instance does n't have time to accrue CPU credits to pay down the surplus credits , and you are charged for the surplus credits when you terminate your instance .
Unlimited mode for T3 Spot Instances is suitable only if the instance runs for long enough to accrue CPU credits for bursting .
T2 Spot Instances Launch credits are meant to provide a productive initial launch experience for T2 instances by providing suﬃcient compute resources to conﬁgure the instance .
Repeated launches of T2 instances to access new launch credits is not permitted .
The EC2 Fleet attempts to launch the number of instances that are required to meet the target capacity that you specify in the ﬂeet request .
The request for Spot Instances is fulﬁlled if there is available capacity and the maximum price per hour for your request exceeds the Spot price .
The ﬂeet also attempts to maintain its target capacity if your Spot Instances are interrupted .
You can also set a maximum amount per hour that you ’ re willing to pay for your ﬂeet , and EC2 Fleet launches instances until it reaches the maximum amount .
When the maximum amount you 're willing to pay is reached , the ﬂeet stops launching instances even if it hasn ’ t met the target capacity .
The ﬂeet selects the Spot Instance pools that are used to fulﬁll the request , based on the launch speciﬁcations included in your request , and the conﬁguration of the request .
The Spot Instances come from the selected pools .
An EC2 Fleet enables you to provision large amounts of EC2 capacity that makes sense for your application based on number of cores or instances , or amount of memory .
The 472 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch ﬂeet determines the combination of Amazon EC2 options to launch that capacity at the absolute lowest cost .
Use the appropriate conﬁguration strategies to create an EC2 Fleet that meets your needs .
• Determine the instance types that meet your application requirements .
• If you plan to include Spot Instances in your EC2 Fleet , review Spot Best Practices before you create the ﬂeet .
Use these best practices when you plan your ﬂeet so that you can provision the instances at the lowest possible price .
You can set target capacity in instances or in custom units .
To calculate the price per unit , divide the price per instance hour by the number of units ( or weight ) that this instance represents .
If you are not using instance weighting , the default price per unit is the price per instance hour .
• Determine the maximum amount per hour that you ’ re willing to pay for your ﬂeet .
EC2 Fleet request types There are three types of EC2 Fleet requests : instant If you conﬁgure the request type as instant , EC2 Fleet places a synchronous one-time request for your desired capacity .
In the API response , it returns the instances that launched , along with errors for those instances that could not be launched .
request If you conﬁgure the request type as request , EC2 Fleet places an asynchronous one-time request for your desired capacity .
Thereafter , if capacity is diminished because of Spot interruptions , the 473 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch ﬂeet does not attempt to replenish Spot Instances , nor does it submit requests in alternative Spot Instance pools if capacity is unavailable .
maintain ( Default ) If you conﬁgure the request type as maintain , EC2 Fleet places an asynchronous request for your desired capacity , and maintains capacity by automatically replenishing any interrupted Spot Instances .
All three types of requests beneﬁt from an allocation strategy .
Allocation strategies for Spot Instances The allocation strategy for your EC2 Fleet determines how it fulﬁlls your request for Spot Instances from the possible Spot Instance pools represented by its launch speciﬁcations .
The following are the allocation strategies that you can specify in your ﬂeet : lowest-price The Spot Instances come from the pool with the lowest price .
diversified The Spot Instances are distributed across all pools .
capacity-optimized The Spot Instances come from the pool with optimal capacity for the number of instances that are launching .
InstancePoolsToUseCount The Spot Instances are distributed across the number of Spot pools that you specify .
This parameter is valid only when used in combination with lowest-price .
Maintaining target capacity After Spot Instances are terminated due to a change in the Spot price or available capacity of a Spot Instance pool , an EC2 Fleet of type maintain launches replacement Spot Instances .
If the allocation strategy is lowest-price , the ﬂeet launches replacement instances in the pool where the Spot price is currently the lowest .
If the allocation strategy is lowest-price in combination with InstancePoolsToUseCount , the ﬂeet selects the Spot pools with the lowest price and launches Spot Instances across the number of Spot pools that you specify .
If the allocation strategy is capacityoptimized , the ﬂeet launches replacement instances in the pool that has the most available Spot Instance capacity .
If the allocation strategy is diversified , the ﬂeet distributes the replacement Spot Instances across the remaining pools .
Conﬁguring EC2 Fleet for cost optimization To optimize the costs for your use of Spot Instances , specify the lowest-price allocation strategy so that EC2 Fleet automatically deploys the least expensive combination of instance types and Availability Zones based on the current Spot price .
Conﬁguring EC2 Fleet for cost optimization and diversiﬁcation To create a ﬂeet of Spot Instances that is both cheap and diversiﬁed , use the lowest-price allocation strategy in combination with InstancePoolsToUseCount .
EC2 Fleet automatically deploys the least 474 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch expensive combination of instance types and Availability Zones based on the current Spot price across the number of Spot pools that you specify .
This combination can be used to avoid the most expensive Spot Instances .
Conﬁguring EC2 Fleet for capacity optimization With Spot Instances , pricing changes slowly over time based on long-term trends in supply and demand , but capacity ﬂuctuates in real time .
The capacity-optimized strategy automatically launches Spot Instances into the most available pools by looking at real-time capacity data and predicting which are the most available .
This works well for workloads such as big data and analytics , image and media rendering , machine learning , and high performance computing that may have a higher cost of interruption associated with restarting work and checkpointing .
By oﬀering the possibility of fewer interruptions , the capacity-optimized strategy can lower the overall cost of your workload .
Choosing the appropriate allocation strategy You can optimize your ﬂeet based on your use case .
If your ﬂeet is small or runs for a short time , the probability that your Spot Instances will be interrupted is low , even with all of the instances in a single Spot Instance pool .
Therefore , the lowest-price strategy is likely to meet your needs while providing the lowest cost .
If your ﬂeet is large or runs for a long time , you can improve the availability of your ﬂeet by distributing the Spot Instances across multiple pools .
If the Spot price for one pool exceeds your maximum price for this pool , only 10 % of your ﬂeet is aﬀected .
Using this strategy also makes your ﬂeet less sensitive to increases in the Spot price in any one pool over time .
With the diversified strategy , the EC2 Fleet does not launch Spot Instances into any pools with a Spot price that is equal to or higher than the On-Demand price .
You can use a low or high number of Spot pools across which to allocate your Spot Instances .
For example , if you run batch processing , we recommend specifying a low number of Spot pools ( for example , InstancePoolsToUseCount=2 ) to ensure that your queue always has compute capacity while maximizing savings .
If your ﬂeet runs workloads that may have a higher cost of interruption associated with restarting work and checkpointing , then use the capacity-optimized strategy .
This strategy oﬀers the possibility of fewer interruptions , which can lower the overall cost of your workload .
Conﬁguring EC2 Fleet for On-Demand backup If you have urgent , unpredictable scaling needs , such as a news website that must scale during a major news event or game launch , we recommend that you specify alternative instance types for your OnDemand Instances , in the event that your preferred option does not have suﬃcient available capacity .
In this case , EC2 Fleet attempts to fulﬁll all of your target capacity using c5.2xlarge instances , but if there is insuﬃcient capacity , it automatically launches c4.2xlarge instances to fulﬁll the target capacity .
Prioritizing instance types for On-Demand capacity When EC2 Fleet attempts to fulﬁll your On-Demand capacity , it defaults to launching the lowestpriced instance type ﬁrst .
If AllocationStrategy is set to prioritized , EC2 Fleet uses priority to determine which instance type to use ﬁrst in fulﬁlling On-Demand capacity .
The priority is assigned to the launch template override , and the highest priority is launched ﬁrst .
Using Capacity Reservations for On-Demand Instances You can conﬁgure a ﬂeet to use On-Demand Capacity Reservations ﬁrst when launching On-Demand Instances by setting the usage strategy for Capacity Reservations to use-capacity-reservationsfirst .
When unused Capacity Reservations are used to fulﬁl On-Demand capacity : • The ﬂeet uses unused Capacity Reservations to fulﬁll On-Demand capacity up to the target OnDemand capacity .
You can only use unused On-Demand Capacity Reservations for ﬂeets of type instant .
The ﬂeet uses this as the default maximum price for each of its launch speciﬁcations .
You can optionally specify a maximum price in one or more launch speciﬁcations .
This price is speciﬁc to the launch speciﬁcation .
Any other launch speciﬁcations that do not include a speciﬁc maximum price still use the global maximum price .
Control spending EC2 Fleet stops launching instances when it has met one of the following parameters : the TotalTargetCapacity or the MaxTotalPrice ( the maximum amount you ’ re willing to pay ) .
To control the amount you pay per hour for your ﬂeet , you can specify the MaxTotalPrice .
When the maximum total price is reached , EC2 Fleet stops launching instances even if it hasn ’ t met the target capacity .
The following examples show two diﬀerent scenarios .
In the ﬁrst , EC2 Fleet stops launching instances when it has met the target capacity .
EC2 Fleet instance weighting When you create an EC2 Fleet , you can deﬁne the capacity units that each instance type would contribute to your application 's performance .
You can then adjust your maximum price for each launch speciﬁcation by using instance weighting .
By default , the price that you specify is per instance hour .
When you use the instance weighting feature , the price that you specify is per unit hour .
You can calculate your price per unit hour by dividing your price for an instance type by the number of units that it represents .
EC2 Fleet calculates the number of instances to launch by dividing the target capacity by the instance weight .
If the result is n't an integer , the ﬂeet rounds it up to the next integer , so that the size of your ﬂeet is not below its target capacity .
The ﬂeet can select any pool that you specify in your launch speciﬁcation , even if the capacity of the instances launched exceeds the requested target capacity .
The following table includes examples of calculations to determine the price per unit for an EC2 Fleet with a target capacity of 10 .
Set the target capacity for your EC2 Fleet either in instances ( the default ) or in the units of your choice , such as virtual CPUs , memory , storage , or throughput .
For each launch speciﬁcation , specify the weight , which is the number of units that the instance type represents toward the target capacity .
477 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch Instance weighting example Consider an EC2 Fleet request with the following conﬁguration : • A target capacity of 24 • A launch speciﬁcation with an instance type r3.2xlarge and a weight of 6 • A launch speciﬁcation with an instance type c3.xlarge and a weight of 5 The weights represent the number of units that instance type represents toward the target capacity .
With the lowestprice strategy , all four instances come from the pool that provides the lowest price per unit .
With the diversified strategy , the ﬂeet launches one instance in each of the three pools , and the fourth instance in whichever of the three pools provides the lowest price per unit .
Tutorial : Using EC2 Fleet with instance weighting This tutorial uses a ﬁctitious company called Example Corp to illustrate the process of requesting an EC2 Fleet using instance weighting .
Objective Example Corp , a pharmaceutical company , wants to use the computational power of Amazon EC2 for screening chemical compounds that might be used to ﬁght cancer .
Planning Example Corp ﬁrst reviews Spot Best Practices .
They want to maximize these resources for the application at the lowest possible price .
By considering the base for their application ( 60 GB of RAM and eight vCPUs ) as one unit , Example Corp decides that 20 times this amount would meet their needs .
So the company sets the target capacity of their EC2 Fleet request to 20 .
Instance Weights After determining the target capacity , Example Corp calculates instance weights .
Price per unit hour Example Corp uses the On-Demand price per instance hour as a starting point for their price .
They could also use recent Spot prices , or a combination of the two .
To calculate the price per unit hour , they divide their starting price per instance hour by the weight .
Verifying permissions Before creating an EC2 Fleet , Example Corp veriﬁes that it has an IAM role with the required permissions .
Fulﬁllment The allocation strategy determines which Spot Instance pools your Spot Instances come from .
With the lowest-price strategy ( which is the default strategy ) , the Spot Instances come from the pool with the lowest price per unit at the time of fulﬁllment .
If Example Corp used the diversified strategy , the Spot Instances would come from all three pools .
Tutorial : Using EC2 Fleet with On-Demand as the primary capacity This tutorial uses a ﬁctitious company called ABC Online to illustrate the process of requesting an EC2 Fleet with On-Demand as the primary capacity , and Spot capacity if available .
Objective ABC Online , a restaurant delivery company , wants to be able to provision Amazon EC2 capacity across EC2 instance types and purchasing options to achieve their desired scale , performance , and cost .
Planning ABC Online requires a ﬁxed capacity to operate during peak periods , but would like to beneﬁt from increased capacity at a lower price .
ABC Online determines the following requirements for their EC2 Fleet : 480 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch • On-Demand Instance capacity – ABC Online requires 15 On-Demand Instances to ensure that they can accommodate traﬃc at peak periods .
Verifying permissions Before creating an EC2 Fleet , ABC Online veriﬁes that it has an IAM role with the required permissions .
Fulﬁllment The allocation strategy determines that the On-Demand capacity is always fulﬁlled , while the balance of the target capacity is fulﬁlled as Spot if there is capacity and availability .
Managing an EC2 Fleet To use an EC2 Fleet , you create a request that includes the total target capacity , On-Demand capacity , Spot capacity , one or more launch speciﬁcations for the instances , and the maximum price that you are willing to pay .
The ﬂeet request must include a launch template that deﬁnes the information that the ﬂeet needs to launch an instance , such as an AMI , instance type , subnet or Availability Zone , and one or more security groups .
You can specify launch speciﬁcation overrides for the instance type , subnet , Availability Zone , and maximum price you 're willing to pay , and you can assign weighted capacity to each launch speciﬁcation override .
If your ﬂeet includes Spot Instances , Amazon EC2 can attempt to maintain your ﬂeet target capacity as Spot prices change .
An EC2 Fleet request remains active until it expires or you delete it .
When you delete a ﬂeet , you can specify whether deletion terminates the instances in that ﬂeet .
• active – The EC2 Fleet request has been validated and Amazon EC2 is attempting to maintain the target number of running instances .
The request remains in this state until it is modiﬁed or deleted .
The request remains in this state until the modiﬁcation is fully processed or the request is deleted .
This state does not apply to other request types .
Its existing instances continue to run until they are interrupted or terminated .
The request remains in this state until all instances are interrupted or terminated .
The request remains in this state until all instances are terminated .
The request is deleted two days after its instances are terminated .
The following illustration represents the transitions between the EC2 Fleet request states .
If you exceed your ﬂeet limits , the request is deleted immediately .
482 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch EC2 Fleet prerequisites To create an EC2 Fleet , the following prerequisites must be in place .
Launch template A launch template includes information about the instances to launch , such as the instance type , Availability Zone , and the maximum price that you are willing to pay .
Ensure that this role exists before you use the AWS CLI or an API to create an EC2 Fleet .
Note An instant EC2 Fleet does not require this role .
To create the role , use the IAM console as follows .
For Select type of trusted entity , choose AWS service .
If you no longer need to use EC2 Fleet , we recommend that you delete the AWSServiceRoleForEC2Fleet role .
After this role is deleted from your account , you can create the role again if you create another ﬂeet .
Granting access to CMKs for use with encrypted AMIs and EBS snapshots If you specify an encrypted AMI ( p. 149 ) or an encrypted Amazon EBS snapshot ( p. 1010 ) in your EC2 Fleet and you use a customer managed customer master key ( CMK ) for encryption , you must grant the AWSServiceRoleForEC2Fleet role permission to use the CMK so that Amazon EC2 can launch instances on your behalf .
To do this , you must add a grant to the CMK , as shown in the following procedure .
When providing permissions , grants are an alternative to key policies .
For more information , see Using Grants and Using Key Policies in AWS KMS in the AWS Key Management Service Developer Guide .
To grant the AWSServiceRoleForEC2Fleet role permissions to use the CMK • Use the create-grant command to add a grant to the CMK and to specify the principal ( the AWSServiceRoleForEC2Fleet service-linked role ) that is given permission to perform the operations 483 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch that the grant permits .
The CMK is speciﬁed by the key-id parameter and the ARN of the CMK .
On the Create policy page , choose the JSON tab , replace the text with the following , and choose Review policy .
To limit the user to speciﬁc Amazon EC2 API actions , specify those actions instead .
An IAM user must have permission to call the iam : ListRoles action to enumerate existing IAM roles , the iam : PassRole action to specify the EC2 Fleet role , and the iam : ListInstanceProfiles action to enumerate existing instance proﬁles .
In the navigation pane , choose Users and select the user .
Select the policy that you created earlier and choose Next : Review .
EC2 Fleet health checks EC2 Fleet checks the health status of the instances in the ﬂeet every two minutes .
The health status of an instance is either healthy or unhealthy .
The ﬂeet determines the health status of an instance using the status checks provided by Amazon EC2 .
If the status of either the instance status check or the system status check is impaired for three consecutive health checks , the health status of the instance is unhealthy .
You can conﬁgure your EC2 Fleet to replace unhealthy instances .
After enabling health check replacement , an instance is replaced after its health status is reported as unhealthy .
The ﬂeet could go below its target capacity for up to a few minutes while an unhealthy instance is being replaced .
• You can conﬁgure your EC2 Fleet to replace unhealthy instances only when you create it .
• IAM users can use health check replacement only if they have permission to call the ec2 : DescribeInstanceStatus action .
Generating an EC2 Fleet JSON conﬁguration ﬁle To create an EC2 Fleet , you need only specify the launch template , total target capacity , and whether the default purchasing option is On-Demand or Spot .
If you do not specify a parameter , the ﬂeet uses the default value .
To view the full list of ﬂeet conﬁguration parameters , you can generate a JSON ﬁle as follows .
AllocationStrategy ( for SpotOptions ) ( Optional ) Indicates how to allocate the Spot Instance target capacity across the Spot Instance pools speciﬁed by the EC2 Fleet .
Specify the allocation strategy that meets your needs .
By default , the Spot service terminates Spot Instances when they are interrupted .
If the ﬂeet type is maintain , you can specify that the Spot service hibernates or stops Spot Instances when they are interrupted .
InstancePoolsToUseCount The number of Spot pools across which to allocate your target Spot capacity .
EC2 Fleet selects the cheapest Spot pools and evenly allocates your target Spot capacity across the number of Spot pools that you specify .
SingleInstanceType Indicates that the ﬂeet uses a single instance type to launch all Spot Instances in the ﬂeet .
SingleAvailabilityZone Indicates that the ﬂeet launches all Spot Instances into a single Availability Zone .
MaxTotalPrice The maximum amount per hour for Spot Instances that you 're willing to pay .
MinTargetCapacity The minimum target capacity for Spot Instances in the ﬂeet .
If the minimum target capacity is not reached , the ﬂeet launches no instances .
AllocationStrategy ( for OnDemandOptions ) The order of the launch template overrides to use in fulﬁlling On-Demand capacity .
If you specify prioritized , EC2 Fleet uses the priority that you assigned to each launch template override , launching the highest priority ﬁrst .
SingleInstanceType Indicates that the ﬂeet uses a single instance type to launch all On-Demand Instances in the ﬂeet .
SingleAvailabilityZone Indicates that the ﬂeet launches all On-Demand Instances into a single Availability Zone .
MaxTotalPrice The maximum amount per hour for On-Demand Instances that you 're willing to pay .
MinTargetCapacity The minimum target capacity for On-Demand Instances in the ﬂeet .
If the minimum target capacity is not reached , the ﬂeet launches no instances .
487 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch ExcessCapacityTerminationPolicy ( Optional ) Indicates whether running instances should be terminated if the total target capacity of the EC2 Fleet is decreased below the current size of the EC2 Fleet .
Valid values are notermination and termination .
LaunchTemplateId The ID of the launch template to use .
You must specify either the launch template ID or launch template name .
LaunchTemplateName The name of the launch template to use .
You must specify either the launch template ID or launch template name .
MaxPrice ( Optional ) The maximum price per unit hour that you are willing to pay for a Spot Instance .
You can use the default maximum price ( the OnDemand price ) or specify the maximum price that you are willing to pay .
Your Spot Instances are not launched if your maximum price is lower than the Spot price for the instance types that you speciﬁed .
SubnetId ( Optional ) The ID of the subnet in which to launch the instances .
When you are done , return to the JSON ﬁle and enter the new subnet ID .
The default is to let AWS choose the zones for your instances .
Specify one or more Availability Zones .
If you have more than one subnet in a zone , specify the appropriate subnet .
To add subnets , go to the Amazon VPC console .
When you are done , return to the JSON ﬁle and enter the new subnet ID .
WeightedCapacity ( Optional ) The number of units provided by the speciﬁed instance type .
Priority The priority for the launch template override .
If AllocationStrategy is set to prioritized , EC2 Fleet uses priority to determine which launch template override to use ﬁrst in fulﬁlling On-Demand 488 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch capacity .
The highest priority is launched ﬁrst .
If no number is set , the override has the lowest priority .
TotalTargetCapacity The number of instances to launch .
You can choose instances or performance characteristics that are important to your application workload , such as vCPUs , memory , or storage .
If the request type is maintain , you can specify a target capacity of 0 and add capacity later .
This number must be less than the TotalTargetCapacity .
This number must be less than the TotalTargetCapacity .
DefaultTargetCapacityType If the value for TotalTargetCapacity is higher than the combined values for OnDemandTargetCapacity and SpotTargetCapacity , the diﬀerence is launched as the instance purchasing option speciﬁed here .
To keep them running after your request expires , do not enter a value for this parameter .
Type ( Optional ) Indicates whether the EC2 Fleet submits a synchronous one-time request for your desired capacity ( instant ) , or an asynchronous one-time request for your desired capacity , but with no attempt maintain the capacity or to submit requests in alternative capacity pools if capacity is unavailable ( request ) , or submits an asynchronous request for your desired capacity and continues to maintain your desired capacity by replenishing interrupted Spot Instances ( maintain ) .
ReplaceUnhealthyInstances ( Optional ) To replace unhealthy instances in an EC2 Fleet that is conﬁgured to maintain the ﬂeet , enter true .
The value for ResourceType must be fleet , otherwise the ﬂeet request fails .
Creating an EC2 Fleet When you create an EC2 Fleet , you must specify a launch template that includes information about the instances to launch , such as the instance type , Availability Zone , and the maximum price you are willing to pay .
489 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch You can create an EC2 Fleet that includes multiple launch speciﬁcations that override the launch template .
When you create an EC2 Fleet , use a JSON ﬁle to specify information about the instances to launch .
EC2 Fleets can only be created using the AWS CLI .
The following is example output for a ﬂeet of type request or maintain .
Tags assigned to the ﬂeet request are not assigned to the instances launched by the ﬂeet .
The value for ResourceType must be fleet .
If you specify another value , the ﬂeet request fails .
To tag instances launched by an EC2 Fleet To tag instances when they are launched by the ﬂeet , specify the tags in the launch template ( p. 453 ) that is referenced in the EC2 Fleet request .
The On-Demand Instances run until you terminate them , and the Spot Instances run until they are interrupted or you terminate them .
The returned list of running instances is refreshed periodically and might be out of date .
You can only modify an EC2 Fleet that is of type maintain .
You can not modify an EC2 Fleet of type request or instant .
• excess-capacity-termination-policy – Whether running instances should be terminated if the total target capacity of the EC2 Fleet is decreased below the current size of the ﬂeet .
When you increase the target capacity , the EC2 Fleet launches the additional instances according to the instance purchasing option speciﬁed for DefaultTargetCapacityType , which are either On-Demand Instances or Spot Instances .
If the DefaultTargetCapacityType is spot , the EC2 Fleet launches the additional Spot Instances according to its allocation strategy .
If the allocation strategy is lowest-price , the ﬂeet launches the instances from the lowest-priced Spot Instance pool in the request .
If the allocation strategy is diversified , the ﬂeet distributes the instances across the pools in the request .
When you decrease the target capacity , the EC2 Fleet deletes any open requests that exceed the new target capacity .
You can request that the ﬂeet terminate instances until the size of the ﬂeet reaches the new target capacity .
If the allocation strategy is lowest-price , the ﬂeet terminates the instances with the highest price per unit .
If the allocation strategy is diversified , the ﬂeet terminates instances across the pools .
Alternatively , you can request that EC2 Fleet keep the ﬂeet at its current size , but not replace any Spot Instances that are interrupted or any instances that you terminate manually .
494 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch When an EC2 Fleet terminates a Spot Instance because the target capacity was decreased , the instance receives a Spot Instance interruption notice .
You must specify whether the EC2 Fleet must terminate its instances .
If you specify that the instances must be terminated when the ﬂeet is deleted , it enters the deleted_terminating state .
Otherwise , it enters the deleted_running state , and the instances continue to run until they are interrupted or you terminate them manually .
You can only delete ﬂeets of type request and maintain .
The launch template is identiﬁed by its launch template ID and version number .
The target capacity for the ﬂeet is 2 instances , and the default purchasing option is spot , which results in the ﬂeet launching 2 Spot Instances .
The launch template is identiﬁed by its launch template ID and version number .
The default purchasing option is spot .
The ﬂeet launches 1 On-Demand Instance as speciﬁed , but needs to launch one more instance to fulﬁll the total target capacity .
The purchasing option for the diﬀerence is calculated as TotalTargetCapacity – OnDemandTargetCapacity = DefaultTargetCapacityType , which results in the ﬂeet launching 1 Spot Instance .
The three launch speciﬁcations , which override the launch template , have diﬀerent instance types but the same weighted capacity and subnet .
The total target capacity is 2 instances and the default purchasing option is spot .
The EC2 Fleet launches 2 Spot Instances using the instance type of the launch speciﬁcation with the lowest price .
And if multiple instance pools have unused Capacity Reservations , the chosen On-Demand allocation strategy is applied .
The number of Capacity Reservations in each pool is indicated by AvailableInstanceCount .
The OnDemand allocation strategy is prioritized , and the usage strategy for Capacity Reservations is usecapacity-reservations-first .
Note The ﬂeet type must be instant .
Capacity Reservations are not supported for other ﬂeet types .
And if the number of unused Capacity Reservations is less than the On-Demand target capacity , the remaining On-Demand target capacity is launched according to the chosen On-Demand allocation strategy .
The number of Capacity Reservations in each pool is indicated by AvailableInstanceCount .
The OnDemand allocation strategy is prioritized , and the usage strategy for Capacity Reservations is usecapacity-reservations-first .
Note The ﬂeet type must be instant .
Capacity Reservations are not supported for other ﬂeet types .
The Capacity Reservations are used ﬁrst to launch 5 On-Demand Instances plus an additional On-Demand Instance is launched according to the OnDemand allocation strategy , which is prioritized in this example .
In this example , you should see the following response , which shows that all of the Capacity Reservations in all of the pools were used .
And if multiple instance pools have unused Capacity Reservations , the chosen On-Demand allocation strategy is applied .
The number of Capacity Reservations in each pool is indicated by AvailableInstanceCount .
Capacity Reservations are not supported for other ﬂeet types .
And if the number of unused Capacity Reservations is less than the On-Demand target capacity , the remaining On-Demand target capacity is launched according to the chosen On-Demand allocation strategy .
504 Amazon Elastic Compute Cloud User Guide for Linux Instances Launch In this example , there are 15 available unused Capacity Reservations .
The number of Capacity Reservations in each pool is indicated by AvailableInstanceCount .
Capacity Reservations are not supported for other ﬂeet types .
The Capacity Reservations are used ﬁrst to launch 5 On-Demand Instances plus an additional On-Demand Instance is launched according to the On-Demand allocation strategy , which is lowest-price in this example .
In this example , you should see the following response , which shows that all of the Capacity Reservations in all of the pools were used .
To connect to a Windows instance , see Connecting to Your Windows Instance in the Amazon EC2 User Guide for Windows Instances .
Connection Options The operating system of your local computer determines the options that you have to connect from your local computer to your Linux instance .
However , it is no longer supported on many browsers .
You can get the ID of your instance using the Amazon EC2 console ( from the Instance ID column ) .
You can get the public DNS for your instance using the Amazon EC2 console .
Your local computer 508 Amazon Elastic Compute Cloud User Guide for Linux Instances Connect must have an IPv6 address and must be conﬁgured to use IPv6 .
You can get the IPv6 address of your instance using the Amazon EC2 console .
• Get the default user name for the AMI that you used to launch your instance : • For Amazon Linux 2 or the Amazon Linux AMI , the user name is ec2-user .
Enable Inbound Traﬃc to Your Instance • Enable inbound SSH traﬃc from your IP address to your instance .
Ensure that the security group associated with your instance allows incoming SSH traﬃc from your IP address .
The default security group for the VPC does not allow incoming SSH traﬃc by default .
The security group created by the launch instance wizard enables SSH traﬃc by default .
Locate the Private Key • Locate the private key and verify permissions Get the fully-qualiﬁed path to the location on your computer of the .pem ﬁle for the key pair that you speciﬁed when you launched the instance .
For more information about how you created your key pair , see Creating a Key Pair Using Amazon EC2 .
In a command line shell , change directories to the location of the private key ﬁle that you created when you launched the instance .
Use the following command to set the permissions of your private key ﬁle so that only you can read it .
chmod 400 /path/my-key-pair.pem If you do not set these permissions , then you can not connect to your instance using this key pair .
( Optional ) Get the Instance Fingerprint To protect yourself from man-in-the-middle attacks , you can verify the RSA key ﬁngerprint when you connect to your instance .
Verifying the ﬁngerprint is useful if you 've launched your instance from a public AMI from a third party .
509 Amazon Elastic Compute Cloud User Guide for Linux Instances Connect First you get the instance ﬁngerprint .
Then , when you connect to the instance , you are prompted to verify the ﬁngerprint .
You can compare the ﬁngerprint you obtained with the ﬁngerprint displayed for veriﬁcation .
If they match , you can conﬁdently connect to your instance .
Prerequisites for getting the instance ﬁngerprint : • To get the instance ﬁngerprint , you must use the AWS CLI .
For information about installing the AWS CLI , see Installing the AWS Command Line Interface in the AWS Command Line Interface User Guide .
• The instance must be in the running state , not the pending state .
The SSH HOST KEY FINGERPRINTS section is only available after the ﬁrst boot of the instance .
Connecting to Your Linux Instance Using SSH After you launch your instance , you can connect to it and use it the way that you 'd use a computer sitting in front of you .
The following instructions explain how to connect to your instance using an SSH client .
Prerequisites Before you connect to your Linux instance , complete the following prerequisites .
Verify that the instance is ready After you launch an instance , it can take a few minutes for the instance to be ready so that you can connect to it .
Check that your instance has passed its status checks .
You can view this information in the Status Checks column on the Instances page .
Install an SSH client on your local computer as needed Your local computer might have an SSH client installed by default .
You can verify this by typing ssh at the command line .
If your compute does n't recognize the command , you can install an SSH client .
510 Amazon Elastic Compute Cloud User Guide for Linux Instances Connect • Earlier versions of Windows - Download and install OpenSSH .
Connect to Your Linux Instance using an SSH Client Use the following procedure to connect to your Linux instance using an SSH client .
In a terminal window , use the ssh command to connect to the instance .
You specify the path and ﬁle name of the private key ( .pem ) , the user name for your AMI , and the public DNS name or IPv6 address for your instance .
Transferring Files to Linux Instances from Linux Using SCP One way to transfer ﬁles between your local computer and a Linux instance is to use the secure copy protocol ( SCP ) .
This section describes how to transfer ﬁles with SCP .
The procedure is similar to the procedure for connecting to an instance with SSH .
Prerequisites • Verify the general prerequisites for transferring ﬁles to your instance .
511 Amazon Elastic Compute Cloud User Guide for Linux Instances Connect The general prerequisites for transferring ﬁles to an instance are the same as the general prerequisites for connecting to an instance .
• Install an SCP client Most Linux , Unix , and Apple computers include an SCP client by default .
If yours does n't , the OpenSSH project provides a free implementation of the full suite of SSH tools , including an SCP client .
The following procedure steps you through using SCP to transfer a ﬁle .
If you 've already connected to the instance with SSH and have veriﬁed its ﬁngerprints , you can start with the step that contains the SCP command ( step 4 ) .
For example , if the name of the private key ﬁle is my-key-pair , the ﬁle to transfer is SampleFile.txt , the user name is ec2-user , and the public DNS name of the instance is ec2-198-51-100-1.compute-1.amazonaws.com , use the following command to copy the ﬁle to the ec2-user home directory .
To transfer ﬁles in the other direction ( from your Amazon EC2 instance to your local computer ) , reverse the order of the host parameters .
With EC2 Instance Connect , you use AWS Identity and Access Management ( IAM ) policies and principals to control SSH access to your instances , removing the need to share and manage SSH keys .
You can use Instance Connect to connect to your Linux instances using a browser-based client , the Amazon EC2 Instance Connect CLI , or the SSH client of your choice .
An IAM policy attached to your IAM user authorizes your IAM user to push the public key to the instance metadata .
The SSH daemon uses AuthorizedKeysCommand and AuthorizedKeysCommandUser , which are conﬁgured when Instance Connect is installed , to look up the public key from the instance metadata for authentication , and connects you to the instance .
For other supported Linux distributions , you must set up Instance Connect for every instance that will support using Instance Connect .
Prerequisites • Verify the general prerequisites for connecting to your instance using SSH .
Your local computer most likely has an SSH client installed by default .
You can check for an SSH client by typing ssh at the command line .
If your local computer does n't recognize the command , you can install an SSH client .
For information about installing an SSH client on Windows 10 , see OpenSSH in Windows .
To conﬁgure the IAM permissions , you must use the AWS CLI .
For more information about installing the AWS CLI , see Installing the AWS CLI in the AWS Command Line Interface User Guide .
To install EC2 Instance Connect on an Ubuntu instance , you must use the AWS CLI on the instance .
For more information about installing the AWS CLI , see Installing the AWS CLI in the AWS Command Line Interface User Guide .
Step 1 : Conﬁgure Network Access to an Instance You must conﬁgure the following network access to your instance so that you can install EC2 Instance Connect and enable your users to connect to your instance : • Ensure that the security group associated with your instance allows inbound SSH traﬃc ( p. 894 ) on port 22 from your IP address .
The default security group for the VPC does not allow incoming SSH traﬃc by default .
The security group created by the launch wizard allows incoming SSH traﬃc by default .
• ( Browser-based client ) We recommend that your instance allows inbound SSH traﬃc from the recommended IP block published for the service .
Use the EC2_INSTANCE_CONNECT ﬁlter for the service parameter to get the IP address ranges in the EC2 Instance Connect subset .
For more information , see AWS IP Address Ranges in the Amazon Web Services General Reference .
The procedure for installing EC2 Instance Connect is diﬀerent for instances launched using Amazon Linux 2 and Ubuntu .
514 Amazon Elastic Compute Cloud User Guide for Linux Instances Connect Amazon Linux 2 To install EC2 Instance Connect on an instance launched with Amazon Linux 2 1 .
Connect to your instance using SSH .
Use the SSH key pair that was assigned to your instance when you launched it and the default user name of the AMI that you used to launch your instance .
Use the sudo less command to check that the /etc/ssh/sshd_config ﬁle was correctly updated as follows : [ ec2-user ~ ] $ sudo less /etc/ssh/sshd_config Instance Connect was successfully installed if the AuthorizedKeysCommand and AuthorizedKeysCommandUser lines in the /etc/ssh/sshd_config ﬁle contain the following values : AuthorizedKeysCommand /opt/aws/bin/eic_run_authorized_keys % u % f AuthorizedKeysCommandUser ec2-instance-connect • AuthorizedKeysCommand sets the eic_run_authorized_keys ﬁle to look up the keys from the instance metadata • AuthorizedKeysCommandUser sets the system user as ec2-instance-connect Note If you previously conﬁgured AuthorizedKeysCommand and AuthorizedKeysCommandUser , the Instance Connect installation will not change the values and you will not be able to use Instance Connect .
515 Amazon Elastic Compute Cloud User Guide for Linux Instances Connect Ubuntu To install EC2 Instance Connect on an instance launched with Ubuntu 16.04 or later 1 .
Connect to your instance using SSH .
Use the SSH key pair that was assigned to your instance when you launched it and use the default user name of the AMI that you used to launch your instance .
For an Ubuntu AMI , the user name is ubuntu .
For Ubuntu , use the apt-get update command to update all the packages on your instance .
Install the Instance Connect package on your instance .
Use the sudo less command to check that the /lib/systemd/system/ssh.service.d/ ec2-instance-connect.conf was correctly updated as follows : ubuntu : ~ $ sudo less /lib/systemd/system/ssh.service.d/ec2-instance-connect.conf Instance Connect was successfully installed if the AuthorizedKeysCommand and AuthorizedKeysCommandUser lines in the /lib/systemd/system/ssh.service.d/ec2instance-connect.conf ﬁle contain the following values : AuthorizedKeysCommand /usr/share/ec2-instance-connect/eic_run_authorized_keys % u % f AuthorizedKeysCommandUser ec2-instance-connect • AuthorizedKeysCommand sets the eic_run_authorized_keys ﬁle to look up the keys from the instance metadata • AuthorizedKeysCommandUser sets the system user as ec2-instance-connect 516 Amazon Elastic Compute Cloud User Guide for Linux Instances Connect Note If you previously conﬁgured AuthorizedKeysCommand and AuthorizedKeysCommandUser , the Instance Connect installation will not change the values and you will not be able to use Instance Connect .
Note There is no need to install the EC2 Instance Connect CLI if users will only use the browser-based client or an SSH client to connect to an instance .
To install the EC2 Instance Connect CLI package Use pip to install the ec2instanceconnectcli package .
$ pip install ec2instanceconnectcli Step 4 : Conﬁgure IAM Permissions for EC2 Instance Connect For your IAM users to connect to an instance using EC2 Instance Connect , you must grant them permission to push the public key to the instance .
For more information , see Actions , Resources , and Condition Keys for Amazon EC2 Instance Connect in the IAM User Guide .
The following instructions explain how to create the policy and attach it using the AWS CLI .
For instructions that use the AWS Management Console , see Creating IAM Policies ( Console ) and Adding Permissions by Attaching Policies Directly to the User in the IAM User Guide .
Limitation We currently do not support tag-based authorization for Instance Connect .
This grants an IAM user permission to push the public key to an instance .
Otherwise , all IAM users with this permission can connect to all EC2 instances .
This speciﬁes the name of the OS user that can push the public key to an instance .
Use the default user name for the AMI that you used to launch the instance .
This is required when using the EC2 Instance Connect CLI because the wrapper calls this action .
IAM users might already have permission to call this action from another policy .
The following is an example policy document .
You can omit the statement for the ec2 : DescribeInstances action if your users will only use an SSH client to connect to your 517 Amazon Elastic Compute Cloud User Guide for Linux Instances Connect instances .
You can replace the speciﬁed instances in Resource to grant users access to all EC2 instances using EC2 Instance Connect .
Use the attach-user-policy command to attach the managed policy to the speciﬁed IAM user .
• To connect using the EC2 Instance Connect CLI , your instance does not need to have a public IPv4 address because the private IP address can be used .
If your instance has both a public and private IP address , the API ﬁrst tries to connect using the public IP address .
518 Amazon Elastic Compute Cloud User Guide for Linux Instances Connect • EC2 Instance Connect does not support connecting using an IPv6 address .
There is no need to install an SSH client if users only use the console or the EC2 Instance Connect CLI to connect to an instance .
Your local computer most likely has an SSH client installed by default .
You can check for an SSH client by typing ssh at the command line .
If your local computer doesn't recognize the command , you can install an SSH client .
For information about installing an SSH client on Windows 10 , see OpenSSH in Windows .
There is no need to install the EC2 Instance Connect CLI if users only use the console or an SSH client to connect to an instance .
Connect Using the Browser-based Client You can connect to an instance using the browser-based client by selecting the instance from the Amazon EC2 console and choosing to connect using EC2 Instance Connect .
Instance Connect handles the permissions and provides a successful connection .
Select the instance and choose Connect .
Connect Using the EC2 Instance Connect CLI You can connect to an instance using the EC2 Instance Connect CLI by providing only the instance ID , while the Instance Connect CLI performs the following three actions in one call : it generates a one-timeuse SSH public key , pushes the key to the instance where it remains for 60 seconds , and connects the user to the instance .
You can use basic SSH/SFTP commands with the Instance Connect CLI .
Amazon Linux 2 To connect to an instance using the EC2 Instance Connect CLI Use the mssh command with the instance ID as follows .
You do not need to specify the user name for the AMI .
$ mssh i-001234a4bf70dec41EXAMPLE Ubuntu To connect to an instance using the EC2 Instance Connect CLI 519 Amazon Elastic Compute Cloud User Guide for Linux Instances Connect Use the mssh command with the instance ID and the default user name for the Ubuntu AMI as follows .
You must specify the user name for the AMI or you get the following error : Authentication failed .
$ mssh ubuntu @ i-001234a4bf70dec41EXAMPLE Connect Using Your Own Key and SSH Client You can use your own SSH key and connect to your instance from the SSH client of your choice while using the EC2 Instance Connect API .
This enables you to beneﬁt from the Instance Connect capability to push a public key to the instance .
Requirement The supported RSA key types are OpenSSH and SSH2 .
To connect to your instance using your own key and any SSH client 1 .
Push your SSH public key to the instance .
Use the send-ssh-public-key command to push your SSH public key to the instance .
If you launched your instance using Amazon Linux 2 , the default user name for the AMI is ec2-user .
If you launched your instance using Ubuntu , the default user name for the AMI is ubuntu .
Connect to the instance using your private key .
Use the ssh command to connect to the instance using the private key before the public key is removed from the instance metadata ( you have 60 seconds before it is removed ) .
Specify the private key that corresponds to the public key , the default user name for the AMI that you used to launch your instance , and the instance 's public DNS .
If the sshd conﬁguration matches what it was set to when you installed EC2 Instance Connect , uninstalling ec2-instance-connect also removes the sshd conﬁguration .
If you modiﬁed the sshd conﬁguration after installing EC2 Instance Connect , you must update it manually .
520 Amazon Elastic Compute Cloud User Guide for Linux Instances Connect Amazon Linux 2 You can uninstall EC2 Instance Connect on Amazon Linux 2 2.0.20190618 or later , where EC2 Instance Connect is preconﬁgured .
Connect to your instance using SSH .
Specify the SSH key pair you used for your instance when you launched it and the default user name for the Amazon Linux 2 AMI , which is ec2-user .
For example , the following ssh command connects to the instance with the public DNS name ec2-a-b-c-d.us-west-2.compute.amazonaws.com , using the key pair my_ec2_private_key.pem .
Connect to your instance using SSH .
Specify the SSH key pair you used for your instance when you launched it and the default user name for the Ubuntu AMI , which is ubuntu .
For example , the following ssh command connects to the instance with the public DNS name ec2-a-b-c-d.us-west-2.compute.amazonaws.com , using the key pair my_ec2_private_key.pem .
ubuntu : ~ $ sudo apt-get remove ec2-instance-connect Connecting to Your Linux Instance from Windows Using PuTTY After you launch your instance , you can connect to it and use it the way that you 'd use a computer sitting in front of you .
The following instructions explain how to connect to your instance using PuTTY , a free SSH client for Windows .
If you receive an error while attempting to connect to your instance , see Troubleshooting Connecting to Your Instance .
Prerequisites Before you connect to your Linux instance using PuTTY , complete the following prerequisites .
Verify that the instance is ready After you launch an instance , it can take a few minutes for the instance to be ready so that you can connect to it .
Check that your instance has passed its status checks .
You can view this information in the Status Checks column on the Instances page .
521 Amazon Elastic Compute Cloud User Guide for Linux Instances Connect Verify the general prerequisites for connecting to your instance For more information , see General Prerequisites for Connecting to Your Instance ( p. 508 ) .
Install PuTTY on your local computer Download and install PuTTY from the PuTTY download page .
If you already have an older version of PuTTY installed , we recommend that you download the latest version .
Be sure to install the entire suite .
Convert your private key using PuTTYgen Locate the private key ( .pem ﬁle ) for the key pair that you speciﬁed when you launched the instance .
For more information , follow the steps in the next section .
Convert Your Private Key Using PuTTYgen PuTTY does not natively support the private key format for SSH keys .
PuTTY provides a tool named PuTTYgen , which converts keys to the required format for PuTTY .
To locate your .pem ﬁle , choose the option to display ﬁles of all types .
Select your .pem ﬁle for the key pair that you speciﬁed when you launched your instance and choose Open .
To save the key in the format that PuTTY can use , choose Save private key .
Even if your private key is discovered , it ca n't be used without the passphrase .
The downside to using a passphrase is that it makes automation harder because human intervention is needed to log on to an instance , or to copy ﬁles to an instance .
Specify the same name for the key that you used for the key pair ( for example , my-key-pair ) and choose Save .
Your private key is now in the correct format for use with PuTTY .
You can now connect to your instance using PuTTY 's SSH client .
Connecting to Your Linux Instance Use the following procedure to connect to your Linux instance using PuTTY .
You need the .ppk ﬁle that you created for your private key .
For more information , see Convert Your Private Key Using 522 Amazon Elastic Compute Cloud User Guide for Linux Instances Connect PuTTYgen ( p. 522 ) in the preceding section .
If you receive an error while attempting to connect to your instance , see Troubleshooting Connecting to Your Instance .
For user_name , be sure to specify the appropriate user name for your AMI .
This is useful to avoid disconnecting from your instance due to session inactivity .
In the Category pane , choose Connection , and then enter the required interval in the Seconds between keepalives ﬁeld .
( Optional ) If you plan to start this session again later , you can save the session information for future use .
If this is the ﬁrst time you have connected to this instance , PuTTY displays a security alert dialog box that asks whether you trust the host to which you are connecting .
A window opens and you are connected to your instance .
Note If you speciﬁed a passphrase when you converted your private key to PuTTY 's format , you must provide that passphrase when you log in to the instance .
If you receive an error while attempting to connect to your instance , see Troubleshooting Connecting to Your Instance .
Transferring Files to Your Linux Instance Using the PuTTY Secure Copy Client The PuTTY Secure Copy client ( PSCP ) is a command line tool that you can use to transfer ﬁles between your Windows computer and your Linux instance .
You also need the public DNS address of your Linux instance .
WinSCP allows you to drag and drop ﬁles from 524 Amazon Elastic Compute Cloud User Guide for Linux Instances Connect your Windows machine to your Linux instance or synchronize entire directory structures between the two systems .
You also need the public DNS address of your Linux instance .
At the WinSCP login screen , for Host name , enter the public DNS hostname or public IPv4 address for your instance .
For User name , enter the default user name for your AMI .
Specify the private key for your instance .
button to browse for the ﬁle .
To open the advanced site settings , for newer versions of WinSCP , choose Advanced .
For Remote directory , enter the path for the directory to which to add ﬁles .
To open the advanced site settings for newer versions of WinSCP , choose Advanced .
To add the host ﬁngerprint to the host cache , choose Yes .
After the connection is established , in the connection window your Linux instance is on the right and your local machine is on the left .
You can drag and drop ﬁles directly into the remote ﬁle system from your local machine .
If you receive a `` Can not execute SCP to start transfer '' error , you must ﬁrst install scp on your Linux instance .
For Amazon Linux variants , such as the Amazon ECS-optimized AMI , use the following command to install scp .
[ ec2-user ~ ] $ sudo yum install -y openssh-clients Connecting to Your Linux Instance from Windows Using Windows Subsystem for Linux After you launch your instance , you can connect to it and use it the way that you 'd use a computer sitting in front of you .
The following instructions explain how to connect to your instance using a Linux distribution on the Windows Subsystem for Linux ( WSL ) .
WSL is a free download and enables you to run native Linux command line tools directly on Windows , alongside your traditional Windows desktop , without the overhead of a virtual machine .
527 Amazon Elastic Compute Cloud User Guide for Linux Instances Connect By installing WSL , you can use a native Linux environment to connect to your Linux EC2 instances instead of using PuTTY or PuTTYgen .
The Linux environment makes it easier to connect to your Linux instances because it comes with a native SSH client that you can use to connect to your Linux instances and change the permissions of the .pem key ﬁle .
The Amazon EC2 console provides the SSH command for connecting to the Linux instance , and you can get verbose output from the SSH command for troubleshooting .
For more information , see the Windows Subsystem for Linux Documentation .
Note After you 've installed the WSL , all the prerequisites and steps are the same as those described in Connecting to Your Linux Instance Using SSH ( p. 510 ) , and the experience is just like using native Linux .
If you receive an error while attempting to connect to your instance , see Troubleshooting Connecting to Your Instance .
Verify that the instance is ready After you launch an instance , it can take a few minutes for the instance to be ready so that you can connect to it .
Check that your instance has passed its status checks .
You can view this information in the Status Checks column on the Instances page .
Install the Windows Subsystem for Linux ( WSL ) and a Linux distribution on your local computer Install the WSL and a Linux distribution using the instructions in the Windows 10 Installation Guide .
The example in the instructions installs the Ubuntu distribution of Linux , but you can install any distribution .
You are prompted to restart your computer for the changes to take eﬀect .
Copy the private key from Windows to WSL In a WSL terminal window , copy the .pem ﬁle ( for the key pair that you speciﬁed when you launched the instance ) from Windows to WSL .
Note the fully-qualiﬁed path to the .pem ﬁle on WSL to use when connecting to your instance .
For information about how to specify the path to your Windows hard drive , see How do I access my C drive ?
cp /mnt/ < Windows drive letter > /path/my-key-pair.pem ~/WSL-path/my-key-pair.pem Connect to Your Linux Instance using WSL Use the following procedure to connect to your Linux instance using the Windows Subsystem for Linux ( WSL ) .
If you receive an error while attempting to connect to your instance , see Troubleshooting Connecting to Your Instance .
528 Amazon Elastic Compute Cloud User Guide for Linux Instances Connect To connect to your instance using SSH 1 .
In a terminal window , use the ssh command to connect to the instance .
For more information about ﬁnding the user name for an AMI and the DNS name for an instance , see Get Information About Your Instance ( p. 508 ) .
Transferring Files to Linux Instances from Linux Using SCP One way to transfer ﬁles between your local computer and a Linux instance is to use the secure copy protocol ( SCP ) .
This section describes how to transfer ﬁles with SCP .
The procedure is similar to the procedure for connecting to an instance with SSH .
Prerequisites • Verify the general prerequisites for transferring ﬁles to your instance .
The general prerequisites for transferring ﬁles to an instance are the same as the general prerequisites for connecting to an instance .
• Install an SCP client Most Linux , Unix , and Apple computers include an SCP client by default .
If yours does n't , the OpenSSH project provides a free implementation of the full suite of SSH tools , including an SCP client .
529 Amazon Elastic Compute Cloud User Guide for Linux Instances Connect The following procedure steps you through using SCP to transfer a ﬁle .
If you 've already connected to the instance with SSH and have veriﬁed its ﬁngerprints , you can start with the step that contains the SCP command ( step 4 ) .
To transfer ﬁles in the other direction ( from your Amazon EC2 instance to your local computer ) , reverse the order of the host parameters .
Connecting to Your Linux Instance Using Session Manager Session Manager is a fully managed AWS Systems Manager capability that lets you manage your Amazon EC2 instances through an interactive one-click browser-based shell or through the AWS CLI .
You can use Session Manager to start a session with an instance in your account .
After the session is started , you can run bash commands as you would through any other connection type .
For more information about Session Manager , see AWS Systems Manager Session Manager in the AWS Systems Manager User Guide .
Before attempting to connect to an instance using Session Manager , ensure that the necessary setup steps have been completed .
For more information and instructions , see Getting Started with Session Manager .
Select the instance and choose Connect .
Troubleshooting If you receive an error that you ’ re not authorized to perform one or more Systems Manager actions ( ssm : command-name ) , then you must update your policies to allow you to start sessions from the Amazon EC2 console .
For more information , see Quickstart Default IAM Policies for Session Manager in the AWS Systems Manager User Guide .
Stop and start your instance You can stop and start your instance if it has an Amazon EBS volume as its root device .
When you stop an instance , we shut it down .
We do n't charge usage for a stopped instance , or data transfer fees , but we do charge for the storage for any Amazon EBS volumes .
Each time you start a stopped instance we charge a minimum of one minute for usage .
After one minute , we charge only for the seconds you use .
For example , if you run an instance for 20 seconds and then stop it , we charge for a full one minute .
While the instance is stopped , you can treat its root volume like any other volume , and modify it ( for example , repair ﬁle system problems or update software ) .
You just detach the volume from the stopped 531 Amazon Elastic Compute Cloud User Guide for Linux Instances Stop and Start instance , attach it to a running instance , make your changes , detach it from the running instance , and then reattach it to the stopped instance .
Make sure that you reattach it using the storage device name that 's speciﬁed as the root device in the block device mapping for the instance .
If you decide that you no longer need an instance , you can terminate it .
As soon as the state of an instance changes to shutting-down or terminated , we stop charging for that instance .
To verify the root device type of your instance , describe the instance and check whether the device type of its root volume is ebs ( Amazon EBS-backed instance ) or instance store ( instance store-backed instance ) .
When you stop a running instance , the following happens : • The instance performs a normal shutdown and stops running ; its status changes to stopping and then stopped .
• Any Amazon EBS volumes remain attached to the instance , and their data persists .
• Any data stored in the RAM of the host computer or the instance store volumes of the host computer is gone .
We release the public IPv4 address and assign a new one when you start it .
With EC2-Classic , an Elastic IP address is dissociated from your instance when you stop it .
• When you stop and start a Windows instance , the EC2Conﬁg service performs tasks on the instance , such as changing the drive letters for any attached Amazon EBS volumes .
For more information about these defaults and how you can change them , see Conﬁguring a Windows instance using the EC2Conﬁg service in the Amazon EC2 User Guide for Windows Instances .
• If your instance is in an Auto Scaling group , the Amazon EC2 Auto Scaling service marks the stopped instance as unhealthy , and may terminate it and launch a replacement instance .
For more information , see Health Checks for Auto Scaling Instances in the Amazon EC2 Auto Scaling User Guide .
You must link the instance to the VPC again after starting it .
You can modify the following attributes of an instance only when it is stopped : 532 Amazon Elastic Compute Cloud User Guide for Linux Instances Stop and Start • Instance type • User data • Kernel • RAM disk If you try to modify these attributes while the instance is running , Amazon EC2 returns the IncorrectInstanceState error .
What happens when you stop an instance ( API ) When an EC2 instance is stopped using the stop-instances command , the following is registered at the OS level : • The API request will send a button press event to the guest .
• Various system services will be stopped as a result of the button press event .
Graceful shutdown is triggered by the ACPI shutdown button press event from the hypervisor .
• The instance will shut down when the graceful shutdown process exits .
There is no conﬁgurable OS shutdown time .
• If the instance OS does not shut down cleanly within four minutes , a hard reboot is performed .
Stopping and starting your instances You can stop and start your Amazon EBS-backed instance using the console or the command line .
You can change this behavior so that it terminates instead .
If Stop is disabled , either the instance is already stopped or its root device is an instance store volume .
Warning When you stop an instance , the data on any instance store volumes is erased .
To keep data from instance store volumes , be sure to back it up to persistent storage .
It can take a few minutes for the instance to stop .
While your instance is stopped , you can modify certain instance attributes .
It can take a few minutes for the instance to enter the running state .
To stop and start an Amazon EBS-backed instance using the command line You can use one of the following commands .
You ca n't use the AWS Management Console to modify the DeleteOnTermination , kernel , or RAM disk attributes .
To modify an instance attribute using the command line You can use one of the following commands .
Hibernation saves the contents from the instance memory ( RAM ) to your Amazon EBS root volume .
We persist the instance 's Amazon EBS root volume and any attached Amazon EBS data volumes .
When you start your instance : • The Amazon EBS root volume is restored to its previous state • The RAM contents are reloaded • The processes that were previously running on the instance are resumed • Previously attached data volumes are reattached and the instance retains its instance ID You can hibernate an instance only if it 's enabled for hibernation ( p. 539 ) and it meets the hibernation prerequisites ( p. 536 ) .
If an instance or application takes a long time to bootstrap and build a memory footprint to become fully productive , you can use hibernation to pre-warm the instance .
Hibernate it , ready to be resumed to the same state as needed .
We do n't charge usage for a hibernated instance when it is in the stopped state .
We do charge for instance usage while the instance is in the stopping state , when the contents of the RAM are transferred to the Amazon EBS root volume .
However , we do charge for storage of any Amazon EBS volumes , including storage for the RAM contents .
If you no longer need an instance , you can terminate it at any time , including when it is in a stopped ( hibernated ) state .
Note For information about using hibernation on Windows instances , see Hibernate Your Windows Instance in the Amazon EC2 User Guide for Windows Instances .
The hibernation freezes all of the processes , saves the contents of the RAM to the Amazon EBS root volume , and then performs a regular shutdown .
• After the shutdown is complete , the instance moves to the stopped state .
• Any Amazon EBS volumes remain attached to the instance , and their data persists , including the saved contents of the RAM .
This is also what happens when you stop and start an instance .
535 Amazon Elastic Compute Cloud User Guide for Linux Instances Hibernate • When you start the instance , the instance boots up and the operating system reads in the contents of the RAM from the Amazon EBS root volume , before unfreezing processes to resume its state .
We release the public IPv4 address and assign a new one when you start it .
With EC2-Classic , an Elastic IP address is disassociated from your instance when you hibernate it .
You must link the instance to the VPC again after starting it .
Support for other versions of Ubuntu and other operating systems is coming soon .
For information about the supported AMIs for Windows , see Hibernation prerequisites in the Amazon EC2 User Guide for Windows Instances .
• Amazon EBS root volume size - must be large enough to store the RAM contents and accommodate your expected usage , for example , OS or applications .
If you enable hibernation , space is allocated on the root volume at launch to store the RAM .
• Amazon EBS root volume encryption - To use hibernation , the root volume must be encrypted to ensure the protection of sensitive content that is in memory at the time of hibernation .
When RAM data is moved to the Amazon EBS root volume , it is always encrypted .
Encryption of the root volume is enforced at instance launch .
Use one of the following three options to ensure that the root volume is an encrypted Amazon EBS volume : • EBS “ single-step ” encryption : In a single run-instances API call , you can launch encrypted EBSbacked EC2 instances from an unencrypted AMI and also enable hibernation at the same time .
• EBS encryption by default : You can enable EBS encryption by default to ensure all new EBS volumes created in your AWS account are encrypted .
This way , you can enable hibernation for your instances without specifying encryption intent at instance launch .
536 Amazon Elastic Compute Cloud User Guide for Linux Instances Hibernate • Encrypted AMI : You can enable EBS encryption by using an encrypted AMI to launch your instance .
If your AMI does not have an encrypted root snapshot , you can copy it to a new AMI and request encryption .
It is not available for Spot Instances .
Limitations • The following actions are not supported for hibernation : • Changing the instance type or size of a hibernated instance • Creating snapshots or AMIs from instances for which hibernation is enabled • Creating snapshots or AMIs from hibernated instances • You ca n't stop or hibernate instance store-backed instances .
• You can not hibernate an instance that is in an Auto Scaling group or used by Amazon ECS .
If your instance is in an Auto Scaling group and you try to hibernate it , the Amazon EC2 Auto Scaling service marks the stopped instance as unhealthy , and may terminate it and launch a replacement instance .
For more information , see Health Checks for Auto Scaling Instances in the Amazon EC2 Auto Scaling User Guide .
• We do not support keeping an instance hibernated for more than 60 days .
To keep the instance for longer than 60 days , you must start the hibernated instance , stop the instance , and start it .
• We constantly update our platform with upgrades and security patches , which can conﬂict with existing hibernated instances .
We notify you about critical updates that require a start for hibernated instances so that we can perform a shutdown or a reboot to apply the necessary upgrades and security patches .
Conﬁguring an Existing AMI to Support Hibernation To hibernate an instance that was launched using your own AMI , you must ﬁrst conﬁgure your AMI to support hibernation .
If you use one of the supported AMIs ( p. 536 ) ( except Ubuntu 16.04 LTS ) , or if you create an AMI based on one of the supported AMIs , you do not need to conﬁgure it to support hibernation .
These AMIs are preconﬁgured to support hibernation .
Update to the latest kernel to 4.14.138-114.102 or later using the following command .
Install the ec2-hibinit-agent package from the repositories using the following command .
Reboot the instance using the following command .
Conﬁrm that the kernel version is updated to 4.14.138-114.102 or later using the following command .
Stop the instance and create an AMI .
Amazon Linux To conﬁgure an Amazon Linux AMI to support hibernation 1 .
Update to the latest kernel to 4.14.77-70.59 or later using the following command .
Install the ec2-hibinit-agent package from the repositories using the following command .
Reboot the instance using the following command .
Conﬁrm that the kernel version is updated to 4.14.77-70.59 or greater using the following command .
Stop the instance and create an AMI .
Update to the latest kernel to 4.15.0-1044 or later using the following commands .
Install the ec2-hibinit-agent package from the repositories using the following command .
Reboot the instance using the following command .
Conﬁrm that the kernel version is updated to 4.15.0-1044 or later using the following command .
Update to the latest kernel to 4.15.0-1058-aws or later using the following commands .
The package will continue to receive regular updates until standard support for Ubuntu 16.04 LTS ends in April 2021 , and will receive additional security updates until the Extended Security Maintenance support ends in 2024 .
For more information , see Amazon EC2 Hibernation for Ubuntu 16.04 LTS now available on the Canonical Ubuntu Blog .
Install the ec2-hibinit-agent package from the repositories using the following command .
Reboot the instance using the following command .
Conﬁrm that the kernel version is updated to 4.15.0-1058-aws or later using the following command .
To enable hibernation , you must do it while launching the instance .
Important You ca n't enable or disable hibernation for an instance after you launch it .
On the Choose an Amazon Machine Image ( AMI ) page , select an AMI that supports hibernation .
On the Conﬁgure Instance Details page , for Stop - Hibernate Behavior , select the Enable hibernation as an additional stop behavior check box .
Continue as prompted by the wizard .
When you 've ﬁnished reviewing your options on the Review Instance Launch page , choose Launch .
AWS CLI To enable hibernation using the AWS CLI Use the run-instances command to launch an instance .
Enabled indicates that the instance is enabled for hibernation .
AWS CLI To view if an instance is enabled for hibernation using the AWS CLI Use the describe-instances command and specify the -- filters `` Name=hibernationoptions.configured , Values=true '' parameter to ﬁlter instances that are enabled for hibernation .
Disabling KASLR on an Instance ( Ubuntu only ) To run hibernation on a newly launched instance with Ubuntu 16.04 LTS - Xenial or Ubuntu 18.04 LTS Bionic released with serial 20190722.1 or later , we recommend disabling KASLR ( Kernel Address Space Layout Randomization ) .
KASLR is a standard Linux kernel security feature that helps to mitigate exposure to and ramiﬁcations of yetundiscovered memory access vulnerabilities by randomizing the base address value of the kernel .
With KASLR enabled , there is a possibility that the instance might not resume after it has been hibernated .
To disable KASLR on an instance launched with Ubuntu 1 .
Connect to your instance using SSH .
Edit the GRUB_CMDLINE_LINUX_DEFAULT line to append the nokaslr option to its end , as shown in the following example .
Save the ﬁle and exit your editor .
Run the following command to rebuild the grub conﬁguration .
Conﬁrm that nokaslr has been added when running the following command .
541 Amazon Elastic Compute Cloud User Guide for Linux Instances Hibernate Console To hibernate an Amazon EBS-backed instance using the console 1 .
It can take a few minutes for the instance to hibernate .
The Instance State changes to Stopping while the instance is hibernating , and then Stopped when the instance has hibernated .
AWS CLI To hibernate an Amazon EBS-backed instance using the AWS CLI Use the stop-instances command and specify the -- hibernate parameter .
Select the instance and , in the details pane , inspect State transition reason message .
The message Client.UserInitiatedHibernate : User initiated hibernate indicates that hibernation was initiated on the instance .
AWS CLI To view if hibernation was initiated on an instance using the AWS CLI Use the describe-instances command and specify the state-reason-code ﬁlter to see the instances on which hibernation was initiated .
`` StateReason '' : { 542 Amazon Elastic Compute Cloud User Guide for Linux Instances Hibernate } '' Code '' : `` Client.UserInitiatedHibernate '' AWS Tools for Windows PowerShell To view if hibernation was initiated on an instance using the AWS Tools for Windows PowerShell Use the Get-EC2Instance command and specify the state-reason-code ﬁlter to see the instances on which hibernation was initiated .
Starting a Hibernated Instance Start a hibernated instance by starting it in the same way that you would start a stopped instance .
It can take a few minutes for the instance to enter the running state .
AWS CLI To start a hibernated instance using the AWS CLI Use the start-instances command .
Start-EC2Instance -InstanceId i-1234567890abcdef0 Troubleshooting Hibernation Use this information to help diagnose and ﬁx issues that you might encounter when hibernating an instance .
Ca n't hibernate immediately after launch If you try to hibernate an instance too quickly after you 've launched it , you get an error .
You must wait for about two minutes after launch before hibernating .
543 Amazon Elastic Compute Cloud User Guide for Linux Instances Reboot Takes too long to transition from stopping to stopped , and memory state not restored after start If it takes a long time for your hibernating instance to transition from the stopping state to stopped , and if the memory state is not restored after you start , this could indicate that hibernation was not properly conﬁgured .
Check the instance system log and look for messages that are related to hibernation .
If the log lines indicate a failure or the log lines are missing , there was most likely a failure conﬁguring hibernation at launch .
For example , the following message indicates that the instance root volume is not large enough : hibinit-agent : Insufficient disk space .
Can not create setup for hibernation .
If you do not see any logs from these processes , your AMI might not support hibernation .
If you used your own AMI , make sure that you followed the instructions for Conﬁguring an Existing AMI to Support Hibernation ( p. 537 ) .
Instance `` stuck '' in the stopping state If you hibernated your instance and it appears `` stuck '' in the stopping state , you can forcibly stop it .
Reboot Your Instance An instance reboot is equivalent to an operating system reboot .
In most cases , it takes only a few minutes to reboot your instance .
We might schedule your instance for a reboot for necessary maintenance , such as to apply updates that require a reboot .
No action is required on your part ; we recommend that you wait for the reboot to occur within its scheduled window .
We recommend that you use the Amazon EC2 console , a command line tool , or the Amazon EC2 API to reboot your instance instead of running the operating system reboot command from your instance .
If you use the Amazon EC2 console , a command line tool , or the Amazon EC2 API to reboot your instance , we perform a hard reboot if the instance does not cleanly shut down within four minutes .
If you use AWS CloudTrail , then using Amazon EC2 to reboot your instance also creates an API record of when your instance was rebooted .
To reboot an instance using the command line You can use one of the following commands .
When an instance reaches its scheduled retirement date , it is stopped or terminated by AWS .
If your instance root device is an Amazon EBS volume , the instance is stopped , and you can start it again at any time .
Starting the stopped instance migrates it to new hardware .
If your instance root device is an instance store volume , the instance is terminated , and can not be used again .
Identifying Instances Scheduled for Retirement If your instance is scheduled for retirement , you 'll receive an email prior to the event with the instance ID and retirement date .
This email is sent to the address that 's associated with your account ; the same email address that you use to log in to the AWS Management Console .
If you use an email account that you do not check regularly , then you can use the Amazon EC2 console or the command line to determine if any of your instances are scheduled for retirement .
To update the contact information for your account , go to the Account Settings page .
To identify instances scheduled for retirement using the console 1 .
Under Scheduled Events , you can see the events associated with your Amazon EC2 instances and volumes , organized by Region .
If you have an instance with a scheduled event listed , select its link below the Region name to go to the Events page .
The Events page lists all resources with events associated with them .
To view instances that are scheduled for retirement , select Instance resources from the ﬁrst ﬁlter list , and then Instance stop or retirement from the second ﬁlter list .
If the ﬁlter results show that an instance is scheduled for retirement , select it , and note the date and time in the Start time ﬁeld in the details pane .
This is your instance retirement date .
545 Amazon Elastic Compute Cloud User Guide for Linux Instances Retire To identify instances scheduled for retirement using the command line You can use one of the following commands .
The action you take depends on whether your instance root device is an Amazon EBS volume , or an instance store volume .
If you do not know what your instance root device type is , you can ﬁnd out using the Amazon EC2 console or the command line .
Determining Your Instance Root Device Type To determine your instance root device type using the console 1 .
In the Resource Id column , select the instance ID to go to the Instances page .
Select the instance and locate the Root device type ﬁeld in the Description tab .
To determine your instance root device type using the command line You can use one of the following commands .
• describe-instances ( AWS CLI ) • Get-EC2Instance ( AWS Tools for Windows PowerShell ) Managing Instances Scheduled for Retirement You can perform one of the actions listed below in order to preserve the data on your retiring instance .
It 's important that you take this action before the instance retirement date to prevent unforeseen downtime and data loss .
Warning If your instance store-backed instance passes its retirement date , it is terminated and you can not recover the instance or any data that was stored on it .
Regardless of the root device of your instance , the data on instance store volumes is lost when the instance is retired , even if they are attached to an EBS-backed instance .
Instance Root Device Type Action EBS Create an EBS-backed AMI from your instance so that you have a backup .
Wait for the scheduled retirement date - when the instance is stopped - or stop the instance yourself before the retirement date .
You can start the instance again at any time .
For more information about stopping and starting your instance , and what to expect when your instance is stopped , 546 Amazon Elastic Compute Cloud User Guide for Linux Instances Terminate Instance Root Device Type Action such as the eﬀect on public , private and Elastic IP addresses associated with your instance , see Stop and start your instance ( p. 531 ) .
Instance store Create an instance store-backed AMI from your instance using the AMI tools , and launch a replacement instance .
Instance store Convert your instance to an EBS-backed instance by transferring your data to an EBS volume , taking a snapshot of the volume , and then creating an AMI from the snapshot .
You can launch a replacement instance from your new AMI .
Terminate Your Instance You can delete your instance when you no longer need it .
This is referred to as terminating your instance .
As soon as the state of an instance changes to shutting-down or terminated , you stop incurring charges for that instance .
You ca n't connect to or start an instance after you 've terminated it .
However , you can launch additional instances using the same AMI .
You can not delete the terminated instance entry yourself .
After an instance is terminated , resources such as tags and volumes are gradually disassociated from the instance and may no longer be visible on the terminated instance after a short while .
When an instance terminates , the data on any instance store volumes associated with that instance is deleted .
By default , Amazon EBS root device volumes are automatically deleted when the instance terminates .
However , by default , any additional EBS volumes that you attach at launch , or any EBS volumes that you attach to an existing instance persist even after the instance terminates .
This behavior is controlled 547 Amazon Elastic Compute Cloud User Guide for Linux Instances Terminate by the volume 's DeleteOnTermination attribute , which you can modify .
You can prevent an instance from being terminated accidentally by someone using the AWS Management Console , the CLI , and the API .
This feature is available for both Amazon EC2 instance storebacked and Amazon EBS-backed instances .
Each instance has a DisableApiTermination attribute with the default value of false ( the instance can be terminated through Amazon EC2 ) .
You can modify this instance attribute while the instance is running or stopped ( in the case of Amazon EBS-backed instances ) .
You can control whether an instance should stop or terminate when shutdown is initiated from the instance using an operating system command for system shutdown .
If you run a script on instance termination , your instance might have an abnormal termination , because we have no way to ensure that shutdown scripts run .
Amazon EC2 attempts to shut an instance down cleanly and run any system shutdown scripts ; however , certain events ( such as hardware failure ) may prevent these system shutdown scripts from running .
What Happens When You Terminate an Instance ( API ) When an EC2 instance is terminated using the terminate-instances command , the following is registered at the OS level : • The API request will send a button press event to the guest .
• Various system services will be stopped as a result of the button press event .
Graceful shutdown is triggered by the ACPI shutdown button press event from the hypervisor .
• The instance will shut down when the graceful shutdown process exits .
There is no conﬁgurable OS shutdown time .
Terminating an Instance You can terminate an instance using the AWS Management Console or the command line .
Before you terminate the instance , verify that you wo n't lose any data by checking that your Amazon EBS volumes wo n't be deleted on termination and that you 've copied any data that you need from your instance store volumes to Amazon EBS or Amazon S3 .
To terminate an instance using the command line You can use one of the following commands .
To prevent your instance from being accidentally terminated using Amazon EC2 , you can enable termination protection for the instance .
The DisableApiTermination attribute controls whether the instance can be terminated using the console , CLI , or API .
By default , termination protection is disabled for your instance .
You can set the value of this attribute when you launch the instance , while the instance is running , or while the instance is stopped ( for Amazon EBS-backed instances ) .
The DisableApiTermination attribute does not prevent you from terminating an instance by initiating shutdown from the instance ( using an operating system command for system shutdown ) when the InstanceInitiatedShutdownBehavior attribute is set .
Limitations You ca n't enable termination protection for Spot Instances—a Spot Instance is terminated when the Spot price exceeds the amount you 're willing to pay for Spot Instances .
However , you can prepare your application to handle Spot Instance interruptions .
The DisableApiTermination attribute does not prevent Amazon EC2 Auto Scaling from terminating an instance .
For instances in an Auto Scaling group , use the following Amazon EC2 Auto Scaling features instead of Amazon EC2 termination protection : • To prevent instances that are part of an Auto Scaling group from terminating on scale in , use instance protection .
For more information , see Instance Protection in the Amazon EC2 Auto Scaling User Guide .
For more information , see Suspending and Resuming Scaling Processes in the Amazon EC2 Auto Scaling User Guide .
For more information , see Customizing the Termination Policy in the Amazon EC2 Auto Scaling User Guide .
To enable termination protection for an instance at launch time 1 .
On the dashboard , choose Launch Instance and follow the directions in the wizard .
On the Conﬁgure Instance Details page , select the Enable termination protection check box .
To enable or disable termination protection using the command line You can use one of the following commands .
You can change this behavior using the InstanceInitiatedShutdownBehavior attribute for the instance so that it terminates instead .
You can update this attribute while the instance is running or stopped .
You can update the InstanceInitiatedShutdownBehavior attribute using the Amazon EC2 console or the command line .
The InstanceInitiatedShutdownBehavior attribute only applies when you perform a shutdown from the operating system of the instance itself ; it does not apply when you stop an instance using the StopInstances API or the Amazon EC2 console .
To change the shutdown behavior of an instance using the console 1 .
The current behavior is already selected .
To change the behavior , select an option from the Shutdown behavior list , and then choose Apply .
To change the shutdown behavior of an instance using the command line You can use one of the following commands .
• modify-instance-attribute ( AWS CLI ) • Edit-EC2InstanceAttribute ( AWS Tools for Windows PowerShell ) 550 Amazon Elastic Compute Cloud User Guide for Linux Instances Terminate Preserving Amazon EBS Volumes on Instance Termination When an instance terminates , Amazon EC2 uses the value of the DeleteOnTermination attribute for each attached Amazon EBS volume to determine whether to preserve or delete the volume .
The default value for the DeleteOnTermination attribute diﬀers depending on whether or not the volume is a root volume of an instance .
By default , the DeletionOnTermination attribute for the root volume of an instance is set to true .
Therefore , the default is to delete the root volume of an instance when the instance terminates .
The DeletionOnTermination attribute can be set by the creator of an AMI as well as by the person who launches an instance .
When the attribute is changed by the creator of an AMI or by the person who launches an instance , the new setting overrides the original AMI default setting .
We recommend that you verify the default setting for the DeletionOnTermination attribute after you launch an instance with an AMI .
By default , when you attach an EBS volume to an instance , its DeleteOnTermination attribute is set to false .
After the instance terminates , you can take a snapshot of the preserved volume or attach it to another instance .
You must delete a volume to avoid incurring further charges .
To verify the value of the DeleteOnTermination attribute for an EBS volume that is in use , look at the instance 's block device mapping .
You can change the value of the DeleteOnTermination attribute for a volume when you launch the instance or while the instance is running .
Examples • Changing the Root Volume to Persist at Launch Using the Console ( p. 551 ) • Changing the Root Volume to Persist at Launch Using the Command Line ( p. 551 ) • Changing the Root Volume of a Running Instance to Persist Using the Command Line ( p. 552 ) Changing the Root Volume to Persist at Launch Using the Console Using the console , you can change the DeleteOnTermination attribute when you launch an instance .
To change this attribute for a running instance , you must use the command line .
To change the root volume of an instance to persist at launch using the console 1 .
On the Choose an Amazon Machine Image ( AMI ) page , choose an AMI and choose Select .
Follow the wizard to complete the Choose an Instance Type and Conﬁgure Instance Details pages .
On the Add Storage page , deselect the Delete On Termination check box for the root volume .
Complete the remaining wizard pages , and then choose Launch .
You can verify the setting by viewing details for the root device volume on the instance 's details pane .
Next to Block devices , choose the entry for the root device volume .
If you change the default behavior , Delete on termination is False .
Changing the Root Volume to Persist at Launch Using the Command Line When you launch an EBS-backed instance , you can use one of the following commands to change the root device volume to persist .
552 Amazon Elastic Compute Cloud User Guide for Linux Instances Recover Recover Your Instance You can create an Amazon CloudWatch alarm that monitors an Amazon EC2 instance and automatically recovers the instance if it becomes impaired due to an underlying hardware failure or a problem that requires AWS involvement to repair .
Terminated instances can not be recovered .
A recovered instance is identical to the original instance , including the instance ID , private IP addresses , Elastic IP addresses , and all instance metadata .
If the impaired instance is in a placement group , the recovered instance runs in the placement group .
When the StatusCheckFailed_System alarm is triggered , and the recover action is initiated , you will be notiﬁed by the Amazon SNS topic that you selected when you created the alarm and associated the recover action .
During instance recovery , the instance is migrated during an instance reboot , and any data that is in-memory is lost .
When the process is complete , information is published to the SNS topic you 've conﬁgured for the alarm .
Anyone who is subscribed to this SNS topic will receive an email notiﬁcation that includes the status of the recovery attempt and any further instructions .
You will notice an instance reboot on the recovered instance .
Examples of problems that cause system status checks to fail include : • Loss of network connectivity • Loss of system power • Software issues on the physical host • Hardware issues on the physical host that impact network reachability If your instance has a public IPv4 address , it retains the public IPv4 address after recovery .
• The instance has an attached instance store storage , which is an unsupported conﬁguration for automatic instance recovery .
• There is an ongoing Service Health Dashboard event that prevented the recovery process from successfully executing .
• The instance has reached the maximum daily allowance of three recovery attempts .
The automatic recovery process attempts to recover your instance for up to three separate failures per day .
If the instance system status check failure persists , we recommend that you manually stop and start the instance .
553 Amazon Elastic Compute Cloud User Guide for Linux Instances Conﬁgure Instances Your instance may subsequently be retired if automatic recovery fails and a hardware degradation is determined to be the root cause for the original system status check failure .
Conﬁguring Your Amazon Linux Instance After you have successfully launched and logged into your Amazon Linux instance , you can make changes to it .
There are many diﬀerent ways you can conﬁgure an instance to meet the needs of a speciﬁc application .
The following are some common tasks to help get you started .
However , many more software packages are available in various software repositories , and even more packages are available for you to build from source code .
Amazon Linux instances come pre-conﬁgured with an ec2-user account , but you may want to add other user accounts that do not have super-user privileges .
The default time conﬁguration for Amazon Linux instances uses Amazon Time Sync Service to set the system time on an instance .
The default time zone is UTC .
For more information on setting the time zone for an instance or using your own time server , see Setting the Time for Your Linux Instance ( p. 568 ) .
If you have your own network with a domain name registered to it , you can change the hostname of an instance to identify itself as part of that domain .
You can also change the system prompt to show a more meaningful name without changing the hostname settings .
You can conﬁgure an instance to use a dynamic DNS service provider .
When you launch an instance in Amazon EC2 , you have the option of passing user data to the instance that can be used to perform common conﬁguration tasks and even run scripts after the instance starts .
Managing Software on Your Linux Instance The base distribution of Amazon Linux contains many software packages and utilities that are required for basic server operations .
However , many more software packages are available in various software repositories , and even more packages are available for you to build from source code .
Many packages in a Linux distribution are updated frequently to ﬁx bugs , add features , and protect against security exploits .
By default , Amazon Linux instances launch with the following repositories enabled : • Amazon Linux 2 : amzn2-core and amzn2extra-docker • Amazon Linux AMI : amzn-main and amzn-updates While there are many packages available in these repositories that are updated by Amazon Web Services , there may be a package that you wish to install that is contained in another repository .
Not all software is available in software packages stored in repositories ; some software must be compiled on an instance from its source code .
Amazon Linux instances manage their software using the yum package manager .
The yum package manager can install , remove , and update software , as well as manage all of the dependencies for each package .
Debian-based Linux distributions , like Ubuntu , use the apt-get command and dpkg package manager , so the yum examples in the following sections do not work for those distributions .
Updating Instance Software It is important to keep software up-to-date .
Many packages in a Linux distribution are updated frequently to ﬁx bugs , add features , and protect against security exploits .
When you ﬁrst launch and connect to an Amazon Linux instance , you may see a message asking you to update software packages for security purposes .
This section shows how to update an entire system , or just a single package .
Important This information applies to Amazon Linux .
For information about other distributions , see their speciﬁc documentation .
To update all packages on an Amazon Linux instance 1 .
Sometimes you may experience a network interruption that can disconnect the SSH connection to your instance .
A screen session allows you to continue running the update even if your connection is interrupted , and you can reconnect to the session later without problems .
Execute the screen command to begin the session .
If your session is disconnected , log back into your instance and list the available screens .
c. Reconnect to the screen using the screen -r command and the process ID from the previous command .
Optionally , you can add the -- security ﬂag to apply only security updates .
Updating all of the packages on a system can take several minutes .
The yum output shows the status of the update while it is running .
( Optional ) Reboot your instance to ensure that you are using the latest packages and libraries from your update ; kernel updates are not loaded until a reboot occurs .
Updates to any glibc libraries should also be followed by a reboot .
For updates to packages that control services , it may be suﬃcient to restart the services to pick up the updates , but a system reboot ensures that all previous package and library updates are complete .
To update a single package on an Amazon Linux instance Use this procedure to update a single package ( and its dependencies ) and not the entire system .
Run the yum update command with the name of the package you would like to update .
Sometimes there will be more than one package listed if there are package dependencies that must be resolved .
The yum output shows the status of the update while it is running .
( Optional ) Reboot your instance to ensure that you are using the latest packages and libraries from your update ; kernel updates are not loaded until a reboot occurs .
Updates to any glibc libraries should also be followed by a reboot .
For updates to packages that control services , it may be suﬃcient to restart the services to pick up the updates , but a system reboot ensures that all previous package and library updates are complete .
While there are many packages available in these repositories that are updated by Amazon Web Services , there may be a package that you wish to install that is contained in another repository .
Important This information applies to Amazon Linux .
For information about other distributions , see their speciﬁc documentation .
556 Amazon Elastic Compute Cloud User Guide for Linux Instances Managing Software To install a package from a diﬀerent repository with yum , you need to add the repository information to the /etc/yum.conf ﬁle or to its own repository.repo ﬁle in the /etc/yum.repos.d directory .
You can do this manually , but most yum repositories provide their own repository.repo ﬁle at their repository URL .
To determine what yum repositories are already installed • List the installed yum repositories with the following command : [ ec2-user ~ ] $ yum repolist all The resulting output lists the installed repositories and reports the status of each .
Enabled repositories display the number of packages they contain .
This will vary depending on the repository you are adding .
The following command enables the Extra Packages for Enterprise Linux ( EPEL ) repository from the Fedora project .
By default , this repository is present in /etc/yum.repos.d on Amazon Linux AMI instances , but it is not enabled .
Finding Software Packages on Amazon Linux You can use the yum search command to search the descriptions of packages that are available in your conﬁgured repositories .
This is especially helpful if you do n't know the exact name of the package you 557 Amazon Elastic Compute Cloud User Guide for Linux Instances Managing Software want to install .
Simply append the keyword search to the command ; for multiple word searches , wrap the search query with quotation marks .
Important This information applies to Amazon Linux .
For information about other distributions , see their speciﬁc documentation .
Your job is to find kitten .
mlocate.x86_64 : An utility for finding files by name ocaml-findlib.x86_64 : Objective CAML package manager and build helper perl-Devel-Cycle.noarch : Find memory cycles in objects perl-Devel-EnforceEncapsulation.noarch : Find access violations to blessed objects perl-File-Find-Rule-Perl.noarch : Common rules for searching for Perl things perl-File-HomeDir.noarch : Find your home and other directories on any platform perl-IPC-Cmd.noarch : Finding and running system commands made easy perl-Perl-MinimumVersion.noarch : Find a minimum required version of perl for Perl code texlive-xesearch.noarch : A string finder for XeTeX valgrind.x86_64 : Tool for finding memory management bugs in programs valgrind.i686 : Tool for finding memory management bugs in programs The following is example output for Amazon Linux .
If you do n't see the expected package , simplify your search to one keyword and then scan the results .
You can also try keyword synonyms to broaden your search .
558 Amazon Elastic Compute Cloud User Guide for Linux Instances Managing Software Important This information applies to Amazon Linux .
For information about other distributions , see their speciﬁc documentation .
To install a package from a repository , use the yum install package command , replacing package with the name of the software to install .
[ ec2-user ~ ] $ sudo yum install links You can also use yum install to install RPM package ﬁles that you have downloaded from the Internet .
To do this , simply append the path name of an RPM ﬁle to the installation command instead of a repository package name .
You may eventually discover a software package that you need to compile yourself , from its source code .
For your system to be able to compile software , you need to install several development tools , such as make , gcc , and autoconf .
Important This information applies to Amazon Linux .
For information about other distributions , see their speciﬁc documentation .
Because software compilation is not a task that every Amazon EC2 instance requires , these tools are not installed by default , but they are available in a package group called `` Development Tools '' that is easily added to an instance with the yum groupinstall command .
You can decompress these archives with the tar command .
[ ec2-user ~ ] $ tar -xzf software.tar.gz After you have decompressed and unarchived the source code package , you should look for a README or INSTALL ﬁle in the source code directory that can provide you with further instructions for compiling and installing the source code .
To retrieve source code for Amazon Linux packages Amazon Web Services provides the source code for maintained packages .
You can download the source code for any installed packages with the yumdownloader -- source command .
• Run the yumdownloader -- source package command to download the source code for package .
For example , to download the source code for the htop package , enter the following command .
Managing User Accounts on Your Linux Instance Each Linux instance launches with a default Linux system user account .
The default user name is determined by the AMI that was speciﬁed when you launched the instance .
For Debian , the user name is admin or root .
Note Linux system users should not be confused with AWS Identity and Access Management ( IAM ) users .
For more information , see IAM Users and Groups in the IAM User Guide .
However , you may choose to add user accounts so that individuals can have their own ﬁles and workspaces .
Furthermore , creating user accounts for new users is much more secure than granting multiple ( possibly inexperienced ) users access to the default user account , because the default user account can cause a lot of damage to a system when used improperly .
To enable users SSH access to your EC2 instance using a Linux system user account , you must share the SSH key with the user .
Alternatively , you can use EC2 Instance Connect to provide access to users without the need to share and manage SSH keys .
Creating a User Account First create the user account , and then add the SSH public key that allows the user to connect to and log into the instance .
You must provide the .pem ﬁle to the user for whom you are creating the user account .
They must use this ﬁle to connect to the instance .
Retrieve the public key from the key pair that you created in the previous step .
Use the adduser command to create the user account and add it to the system ( with an entry in the /etc/passwd ﬁle ) .
In this example , the user account is named newuser .
Switch to the new account so that the directory and ﬁle that you create will have the proper ownership .
Add the SSH public key to the user account .
First create a directory in the user 's home directory for the SSH key ﬁle , then create the key ﬁle , and ﬁnally paste the public key into the key ﬁle , as described in the following sub-steps .
Important Ensure that you paste the public key in one continuous line .
The public key must not be split over multiple lines .
The user should now be able to log into the newuser account on your instance , using the private key that corresponds to the public key that you added to the authorized_keys ﬁle .
Removing a User Account If a user account is no longer needed , you can remove that account so that it can no longer be used .
Use the userdel command to remove the user account from the system .
However , if your application would beneﬁt from reduced latency at the cost of higher single- or dual-core frequencies , or from consistent performance at lower frequencies as opposed to bursty Turbo Boost frequencies , consider experimenting with the C-state or P-state settings that are available to these instances .
The following sections describe the diﬀerent processor state conﬁgurations and how to monitor the eﬀects of your conﬁguration .
These procedures were written for , and apply to Amazon Linux ; however , they may also work for other Linux distributions with a Linux kernel version of 3.9 or newer .
For more information about other Linux distributions and processor state control , see your system-speciﬁc documentation .
Note The examples on this page use the turbostat utility ( which is available on Amazon Linux by default ) to display processor frequency and C-state information , and the stress command ( which can be installed by running sudo yum install -y stress ) to simulate a workload .
This conﬁguration provides the highest performance with lower variability .
Allowing inactive cores to enter deeper sleep states provides the thermal headroom required for single or dual core processes to reach their maximum Turbo Boost potential .
The following example shows a c4.8xlarge instance with two cores actively performing work reaching their maximum processor Turbo Boost frequency .
In the following example , all 18 cores are actively performing work , so there is no headroom for maximum Turbo Boost , but they are all running at the `` all core Turbo Boost '' speed of 3.2 GHz .
You may want to control C-states to tune your system for latency versus performance .
Putting cores to sleep takes time , and although a sleeping core allows more headroom for another core to boost to a higher frequency , it takes time for that sleeping core to wake back up and perform work .
For example , if a core that is assigned to handle network packet interrupts is asleep , there may be a delay in servicing that interrupt .
You can conﬁgure the system to not use deeper C-states , which reduces the processor reaction latency , but that in turn also reduces the headroom available to other cores for Turbo Boost .
A common scenario for disabling deeper sleep states is a Redis database application , which stores the database in system memory for the fastest possible query response time .
Save the ﬁle and exit your editor .
Run the following command to rebuild the boot conﬁguration .
Reboot your instance to enable the new kernel option .
Edit the kernel line of the ﬁrst entry and add the intel_idle.max_cstate=1 option to set C1 as the deepest C-state for idle cores .
Save the ﬁle and exit your editor .
Reboot your instance to enable the new kernel option .
Although the working cores are not reaching their maximum Turbo Boost frequency , the inactive cores will be much faster to respond to new requests than they would be in the deeper C6 C-state .
Baseline Performance with the Lowest Variability You can reduce the variability of processor frequency with P-states .
But you may want to tune your system for consistent performance rather than bursty performance that can happen when Turbo Boost frequencies are enabled .
Intel Advanced Vector Extensions ( AVX or AVX2 ) workloads can perform well at lower frequencies , and AVX instructions can use more power .
Running the processor at a lower frequency , by disabling Turbo Boost , can reduce the amount of power used and keep the speed more consistent .
This section describes how to limit deeper sleep states and disable Turbo Boost ( by requesting the P1 Pstate ) to provide low-latency and the lowest processor speed variability for these types of workloads .
To limit deeper sleep states and disable Turbo Boost on Amazon Linux 2 1 .
Save the ﬁle and exit your editor .
Run the following command to rebuild the boot conﬁguration .
Reboot your instance to enable the new kernel option .
When you need the low processor speed variability that the P1 P-state provides , execute the following command to disable Turbo Boost .
When your workload is ﬁnished , you can re-enable Turbo Boost with the following command .
Edit the kernel line of the ﬁrst entry and add the intel_idle.max_cstate=1 option to set C1 as the deepest C-state for idle cores .
Save the ﬁle and exit your editor .
Reboot your instance to enable the new kernel option .
When you need the low processor speed variability that the P1 P-state provides , execute the following command to disable Turbo Boost .
When your workload is ﬁnished , you can re-enable Turbo Boost with the following command .
Setting the Time for Your Linux Instance A consistent and accurate time reference is crucial for many server tasks and processes .
Most system logs include a time stamp that you can use to determine when problems occur and in what order the events take place .
If you use the AWS CLI or an AWS SDK to make requests from your instance , these tools sign requests on your behalf .
If your instance 's date and time are not set correctly , the date in the signature may not match the date of the request , and AWS rejects the request .
Amazon provides the Amazon Time Sync Service , which is accessible from all EC2 instances , and is also used by other AWS services .
This service uses a ﬂeet of satellite-connected and atomic reference clocks in each Region to deliver accurate current time readings of the Coordinated Universal Time ( UTC ) global standard through Network Time Protocol ( NTP ) .
The Amazon Time Sync Service automatically smooths any leap seconds that are added to UTC .
The Amazon Time Sync Service is available through NTP at the 169.254.169.123 IP address for any instance running in a VPC .
Your instance does not require access to the internet , and you do not have to conﬁgure your security group rules or your network ACL rules to allow access .
The latest versions of Amazon Linux 2 and Amazon Linux AMIs synchronize with the Amazon Time Sync Service by default .
Use the following procedures to conﬁgure the Amazon Time Sync Service on your instance using the chrony client .
An instance needs access to the internet for the external NTP time sources to work .
Conﬁguring the Amazon Time Sync Service on Amazon Linux AMI Note On Amazon Linux 2 , the default chrony conﬁguration is already set up to use the Amazon Time Sync Service IP address .
With the Amazon Linux AMI , you must edit the chrony conﬁguration ﬁle to add a server entry for the Amazon Time Sync Service .
To conﬁgure your instance to use the Amazon Time Sync Service 1 .
Connect to your instance and uninstall the NTP service .
Verify that the ﬁle includes the following line : server 169.254.169.123 prefer iburst minpoll 4 maxpoll 4 568 Amazon Elastic Compute Cloud User Guide for Linux Instances Setting the Time If the line is present , then the Amazon Time Sync Service is already conﬁgured and you can go to the next step .
If not , add the line after any other server or pool statements that are already present in the ﬁle , and save your changes .
Use the chkconfig command to conﬁgure chronyd to start at each system boot .
Verify that chrony is using the 169.254.169.123 IP address to synchronize the time .
Verify the time synchronization metrics that are reported by chrony .
To conﬁgure your instance to use the Amazon Time Sync Service 1 .
Connect to your instance and use apt to install the chrony package .
Add the following line before any other server or pool statements that are already present in the ﬁle , and save your changes : server 169.254.169.123 prefer iburst minpoll 4 maxpoll 4 3 .
Verify that chrony is using the 169.254.169.123 IP address to synchronize the time .
Verify the time synchronization metrics that are reported by chrony .
Verify that the ﬁle contains the following line : server 169.254.169.123 prefer iburst minpoll 4 maxpoll 4 If this line is not present , add it .
Comment out any other server or pool lines .
Open yast and enable the chrony service .
Changing the Time Zone on Amazon Linux Amazon Linux instances are set to the UTC ( Coordinated Universal Time ) time zone by default , but you may wish to change the time on an instance to the local time or to another time zone in your network .
Important This information applies to Amazon Linux .
For information about other distributions , see their speciﬁc documentation .
Identify the time zone to use on the instance .
Browse the directory structure at that location to ﬁnd a ﬁle for your time zone .
Mideast MST MST7MDT Navajo posixrules PRC PST8PDT right US UTC WET W-SU Some of the entries at this location are directories ( such as America ) , and these directories contain time zone ﬁles for speciﬁc cities .
571 Amazon Elastic Compute Cloud User Guide for Linux Instances Optimizing CPU Options a .
You need to use sudo with your editor command because /etc/sysconfig/clock is owned by root .
Locate the ZONE entry , and change it to the time zone ﬁle ( omitting the /usr/share/ zoneinfo section of the path ) .
This entry is for the hardware clock , and does not need to be adjusted when you 're setting a diﬀerent time zone on your instance .
Save the ﬁle and exit the text editor .
Create a symbolic link between /etc/localtime and your time zone ﬁle so that the instance ﬁnds the time zone ﬁle when it references local time information .
Reboot the system to pick up the new time zone information in all services and applications .
An instance has a default number of CPU cores , which varies according to instance type .
For example , an m5.xlarge instance type has two CPU cores and two threads per core by default—four vCPUs in total .
In most cases , there is an Amazon EC2 instance type that has a combination of memory and number of vCPUs to suit your workloads .
However , you can specify the following CPU options to optimize your instance for speciﬁc workloads or business needs : • Number of CPU cores : You can customize the number of CPU cores for the instance .
You might do this to potentially optimize the licensing costs of your software with an instance that has suﬃcient amounts of RAM for memory-intensive workloads but fewer CPU cores .
You can specify these CPU options during instance launch .
There is no additional or reduced charge for specifying CPU options .
You 're charged the same as instances that are launched with default CPU options .
• When you launch an instance , you must specify both the number of CPU cores and threads per core in the request .
• The number of vCPUs for the instance is the number of CPU cores multiplied by the threads per core .
To specify a custom number of vCPUs , you must specify a valid number of CPU cores and threads per core for the instance type .
You can not exceed the default number of vCPUs for the instance .
• When you change the instance type ( p. 269 ) of an existing instance , the CPU options automatically change to the default CPU options for the new instance type .
CPU Cores and Threads Per CPU Core Per Instance Type The following tables list the instance types that support specifying CPU options .
For each type , the table shows the default and supported number of CPU cores and threads per core .
On the Conﬁgure Instance Details page , for CPU options , choose Specify CPU options .
For Core count , choose the number of required CPU cores .
Continue as prompted by the wizard .
When you 've ﬁnished reviewing your options on the Review Instance Launch page , choose Launch .
585 Amazon Elastic Compute Cloud User Guide for Linux Instances Optimizing CPU Options To specify a custom number of vCPUs during instance launch ( console ) The following example launches an r4.4xlarge instance with six vCPUs .
On the Conﬁgure Instance Details page , for CPU options , choose Specify CPU options .
Continue as prompted by the wizard .
When you 've ﬁnished reviewing your options on the Review Instance Launch page , choose Launch .
To specify a custom number of vCPUs during instance launch ( AWS CLI ) The following example launches an r4.4xlarge instance with six vCPUs .
Use the run-instances AWS CLI command and specify the number of CPU cores and number of threads in the -- cpu-options parameter .
You can specify three CPU cores and two threads per core to get six vCPUs .
Choose Description and view the Number of vCPUs ﬁeld .
To view the core count and threads per core , choose the Number of vCPUs ﬁeld value .
In the output that 's returned , the CoreCount ﬁeld indicates the number of cores for the instance .
The ThreadsPerCore ﬁeld indicates the number of threads per core .
Alternatively , connect to your instance and use a tool such as lscpu to view the CPU information for your instance .
You can use AWS Conﬁg to record , assess , audit , and evaluate conﬁguration changes for instances , including terminated instances .
For more information , see Getting Started with AWS Conﬁg in the AWS Conﬁg Developer Guide .
Changing the Hostname of Your Linux Instance When you launch an instance , it is assigned a hostname that is a form of the private , internal IPv4 address .
Part of this hostname is displayed at the shell prompt when you log into your instance ( for example , ip-12-34-56-78 ) .
Each time you stop and restart your Amazon EC2 instance ( unless you are using an Elastic IP address ) , the public IPv4 address changes , and so does your public DNS name , system hostname , and shell prompt .
Important This information applies to Amazon Linux .
For information about other distributions , see their speciﬁc documentation .
Changing the System Hostname If you have a public DNS name registered for the IP address of your instance ( such as webserver.mydomain.com ) , you can set the system hostname so your instance identiﬁes itself as a part of that domain .
This also changes the shell prompt so that it displays the ﬁrst portion of this name instead of the hostname supplied by AWS ( for example , ip-12-34-56-78 ) .
If you do not have a public DNS name registered , you can still change the hostname , but the process is a little diﬀerent .
To change the system hostname to a public DNS name Follow this procedure if you already have a public DNS name registered .
587 Amazon Elastic Compute Cloud User Guide for Linux Instances Changing the Hostname 1 .
Reboot the instance to pick up the new hostname .
Log into your instance and verify that the hostname has been updated .
and the hostname command should show the fully-qualiﬁed domain name .
Open the /etc/hosts ﬁle in your favorite text editor and change the entry beginning with 127.0.0.1 to match the example below , substituting your own hostname .
Reboot the instance to pick up the new hostname .
Log into your instance and verify that the hostname has been updated .
and the hostname command should show the fully-qualiﬁed domain name .
[ ec2-user @ webserver ~ ] $ hostname 588 Amazon Elastic Compute Cloud User Guide for Linux Instances Changing the Hostname webserver.localdomain Changing the Shell Prompt Without Aﬀecting the Hostname If you do not want to modify the hostname for your instance , but you would like to have a more useful system name ( such as webserver ) displayed than the private name supplied by AWS ( for example , ip-12-34-56-78 ) , you can edit the shell prompt conﬁguration ﬁles to display your system nickname instead of the hostname .
Create a ﬁle in /etc/profile.d that sets the environment variable called NICKNAME to the value you want in the shell prompt .
For example , to set the system nickname to webserver , run the following command .
You need to use sudo with the editor command because /etc/bashrc and /etc/bash.bashrc are owned by root .
Edit the ﬁle and change the shell prompt variable ( PS1 ) to display your nickname instead of the hostname .
more virtual machines ) ✔ and console windows Change the \h ( the symbol for hostname ) in that line to the value of the NICKNAME variable .
( Optional ) To set the title on shell windows to the new nickname , complete the following steps .
Make the ﬁle executable using the following command .
You need to use sudo with the editor command because /etc/sysconfig/bashprompt-xterm is owned by root .
Log out and then log back in to pick up the new nickname value .
Changing the Hostname on Other Linux Distributions The procedures on this page are intended for use with Amazon Linux only .
Setting Up Dynamic DNS on Your Linux Instance When you launch an EC2 instance , it is assigned a public IP address and a public DNS ( Domain Name System ) name that you can use to reach it from the Internet .
Because there are so many hosts in the Amazon Web Services domain , these public names must be quite long for each name to remain unique .
Dynamic DNS services provide custom DNS host names within their domain area that can be easy to remember and that can also be more relevant to your host 's use case ; some of these services are also free of charge .
You can use a dynamic DNS provider with Amazon EC2 and conﬁgure the instance to update the IP address associated with a public DNS name each time the instance starts .
There are many diﬀerent providers to choose from , and the speciﬁc details of choosing a provider and registering a name with them are outside the scope of this guide .
Important This information applies to Amazon Linux .
For information about other distributions , see their speciﬁc documentation .
Sign up with a dynamic DNS service provider and register a public DNS name with their service .
This procedure uses the free service from noip.com/free as an example .
Conﬁgure the dynamic DNS update client .
After you have a dynamic DNS service provider and a public DNS name registered with their service , point the DNS name to the IP address for your instance .
Many providers ( including noip.com ) allow you to do this manually from your account page on their website , but many also support software update clients .
If an update client is running on your EC2 instance , your dynamic DNS record is updated each time the IP address changes , as after a shutdown and restart .
Enable the Extra Packages for Enterprise Linux ( EPEL ) repository to gain access to the noip2 client .
Note Amazon Linux instances have the GPG keys and repository information for the EPEL repository installed by default ; however , Red Hat and CentOS instances must ﬁrst install the epel-release package before you can enable the EPEL repository .
Enter the login and password information when prompted and answer the subsequent questions to conﬁgure the client .
Verify that the update client has set the correct IP address for your dynamic DNS name .
Allow a few minutes for the DNS records to update , and then try to connect to your instance using SSH with the public DNS name that you conﬁgured in this procedure .
Running Commands on Your Linux Instance at Launch When you launch an instance in Amazon EC2 , you have the option of passing user data to the instance that can be used to perform common automated conﬁguration tasks and even run scripts after the instance starts .
You can also pass this data into the launch wizard as plain text , as a ﬁle ( this is useful for launching instances using the command line tools ) , or as base64-encoded text ( for API calls ) .
If you are interested in more complex automation scenarios , consider using AWS CloudFormation and AWS OpsWorks .
For more information , see the AWS CloudFormation User Guide and the AWS OpsWorks User Guide .
For information about running commands on your Windows instance at launch , see Running Commands on Your Windows Instance at Launch and Managing Windows Instance Conﬁguration in the Amazon EC2 User Guide for Windows Instances .
591 Amazon Elastic Compute Cloud User Guide for Linux Instances Running Commands at Launch In the following examples , the commands from the Install a LAMP Web Server on Amazon Linux 2 ( p. 34 ) are converted to a shell script and a set of cloud-init directives that executes when the instance launches .
In each example , the following tasks are executed by the user data : • The distribution software packages are updated .
• The httpd service is started and turned on via systemctl .
• The appropriate ownership and ﬁle permissions are set for the web directory and the ﬁles contained within it .
• A simple web page is created to test the web server and PHP engine .
Also , these instructions are intended for use with Amazon Linux 2 , and the commands and directives may not work for other Linux distributions .
For more information about other distributions , such as their support for cloud-init , see their speciﬁc documentation .
User Data and Shell Scripts If you are familiar with shell scripting , this is the easiest and most complete way to send instructions to an instance at launch .
Adding these tasks at boot time adds to the amount of time it takes to boot the instance .
You should allow a few minutes of extra time for the tasks to complete before you test that the user script has ﬁnished successfully .
Important By default , user data scripts and cloud-init directives run only during the boot cycle when you ﬁrst launch an instance .
You can update your conﬁguration to ensure that your user data scripts and cloud-init directives run every time you restart your instance .
For more information , see How can I execute user data with every restart of my EC2 instance ?
Scripts entered as user data are executed as the root user , so do not use the sudo command in the script .
Remember that any ﬁles you create will be owned by root ; if you need non-root users to have ﬁle access , you should modify the permissions accordingly in the script .
Also , because the script is not run interactively , you can not include commands that require user feedback ( such as yum update without the -y ﬂag ) .
592 Amazon Elastic Compute Cloud User Guide for Linux Instances Running Commands at Launch The cloud-init output log ﬁle ( /var/log/cloud-init-output.log ) captures console output so it is easy to debug your scripts following a launch if the instance does not behave the way you intended .
The script is not deleted after it is run .
Be sure to delete the user data scripts from /var/lib/cloud/instances/instance-id/ before you create an AMI from the instance .
Otherwise , the script will exist in this directory on any instance launched from the AMI .
User Data and the Console You can specify instance user data when you launch the instance .
If the root volume of the instance is an EBS volume , you can also stop the instance and update its user data .
Specify Instance User Data at Launch Follow the procedure for launching an instance at Launching an instance using the Launch Instance Wizard ( p. 446 ) , but when you get to the section called “ Step 3 : Conﬁgure Instance Details ” ( p. 448 ) in that procedure , copy your shell script in the User data ﬁeld , and then complete the launch procedure .
In the example script below , the script creates and conﬁgures our web server .
For our example , in a web browser , enter the URL of the PHP test ﬁle the script created .
This URL is the public DNS address of your instance followed by a forward slash and the ﬁle name .
If you are unable to see the PHP information page , check that the security group you are using contains a rule to allow HTTP ( port 80 ) traﬃc .
( Optional ) If your script did not accomplish the tasks you were expecting it to , or if you just want to verify that your script completed without errors , examine the cloud-init output log ﬁle at /var/log/ cloud-init-output.log and look for error messages in the output .
593 Amazon Elastic Compute Cloud User Guide for Linux Instances Running Commands at Launch View and Update the Instance User Data To modify instance user data 1 .
Warning When you stop an instance , the data on any instance store volumes is erased .
To keep data from instance store volumes , be sure to back it up to persistent storage .
It can take a few minutes for the instance to stop .
You ca n't change the user data if the instance is running , but you can view it .
The new user data is visible on your instance after you restart it ; however , user data scripts are not executed .
User Data and cloud-init Directives The cloud-init package conﬁgures speciﬁc aspects of a new Amazon Linux instance when it is launched ; most notably , it conﬁgures the .ssh/authorized_keys ﬁle for the ec2-user so you can log in with your own private key .
The cloud-init user directives can be passed to an instance at launch the same way that a script is passed , although the syntax is diﬀerent .
Important By default , user data scripts and cloud-init directives run only during the boot cycle when you ﬁrst launch an instance .
You can update your conﬁguration to ensure that your user data scripts and cloud-init directives run every time you restart your instance .
For more information , see How can I execute user data with every restart of my EC2 instance ?
Adding these tasks at boot time adds to the amount of time it takes to boot an instance .
You should allow a few minutes of extra time for the tasks to complete before you test that your user data directives have completed .
The ✔cloud-config line at the top is required in order to identify the commands as cloud-init directives .
Allow enough time for the instance to launch and execute the directives in your user data , and then check to see that your directives have completed the tasks you intended .
For our example , in a web browser , enter the URL of the PHP test ﬁle the directives created .
This URL is the public DNS address of your instance followed by a forward slash and the ﬁle name .
If you are unable to see the PHP information page , check that the security group you are using contains a rule to allow HTTP ( port 80 ) traﬃc .
( Optional ) If your directives did not accomplish the tasks you were expecting them to , or if you just want to verify that your directives completed without errors , examine the output log ﬁle at / var/log/cloud-init-output.log and look for error messages in the output .
User Data and the AWS CLI You can use the AWS CLI to specify , modify , and view the user data for your instance .
On Windows , you can use the AWS Tools for Windows PowerShell instead of using the AWS CLI .
For more information , see User Data and the Tools for Windows PowerShell in the Amazon EC2 User Guide for Windows Instances .
Example : Specify User Data at Launch To specify user data when you launch your instance , use the run-instances command with the -- userdata parameter .
Before you can use this ﬁle with the AWS CLI , you must remove the ﬁrst ( BEGIN CERTIFICATE ) and last ( END CERTIFICATE ) lines .
Note that the encoded output is stored in a ﬁle and the decoded output is stored in another ﬁle .
✔ ! /bin/bash yum update -y service httpd start chkconfig httpd on Instance metadata and user data Instance metadata is data about your instance that you can use to conﬁgure or manage the running instance .
You can also use instance metadata to access user data that you speciﬁed when launching your instance .
You can build generic AMIs and use user data to modify the conﬁguration ﬁles supplied at launch time .
For example , if you run web servers for various small businesses , they can all use the same generic AMI and retrieve their content from the Amazon S3 bucket that you specify in the user data at launch .
To add a new customer at any time , create a bucket for the customer , add their content , and launch your AMI with the unique bucket name provided to your code in the user data .
If you launch more than one instance at the same time , the user data is available to all instances in that reservation .
Each instance that is part of the same reservation has a unique ami-launch-index number , allowing you to write code that controls what to do .
For example , the ﬁrst host might elect itself as an initial master node in a cluster .
EC2 instances can also include dynamic data , such as an instance identity document that is generated when the instance is launched .
Important Although you can only access instance metadata and user data from within the instance itself , the data is not protected by authentication or cryptographic methods .
Anyone who has direct access to the instance , and potentially any software running on the instance , can view its metadata .
The instance metadata service distinguishes between IMDSv1 and IMDSv2 requests based on whether , for any given request , either the PUT or GET headers , which are unique to IMDSv2 , are present in that request .
You can conﬁgure the instance metadata service on each instance such that local code or users must use IMDSv2 .
During the speciﬁed duration , you can use the same session token for subsequent requests .
After the speciﬁed duration expires , you must create a new session token to use for future requests .
In the following example command , which gets the ID of the AMI used to launch the instance , the token that is stored in $ TOKEN in the previous example is reused .
The PUT request returns a token that must be included in subsequent GET requests to the instance metadata service .
Include the token in all GET requests to the instance metadata service .
When token usage is set to required , requests without a valid token or with an expired token receive a 401 - Unauthorized HTTP error code .
For information about changing the token usage requirement , see modify-instancemetadata-options in the AWS CLI Command Reference .
The token is not valid on other EC2 instances and will be rejected if you attempt to use it outside of the instance on which it was generated .
The TTL speciﬁes the length of time that the token is valid and , therefore , the duration of the session .
598 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance metadata and user data • After a token expires , to continue accessing instance metadata , you must create a new session using another PUT .
For a small number of requests , it might be easier to generate and immediately use a token each time you need to access the instance metadata service .
But for eﬃciency , you can specify a longer duration for the token and reuse it rather than having to write a PUT request every time you need to request instance metadata .
There is no practical limit on the number of concurrent tokens , each representing its own session .
HTTP GET and HEAD methods are allowed in IMDSv2 instance metadata requests .
PUT requests are rejected if they contain an X-Forwarded-For header .
You can adjust the hop limit using the modify-instance-metadata-options command if you need to make it larger .
For example , you might need a larger hop limit for backward compatibility with container services running on the instance .
If you choose to migrate to using IMDSv2 , we recommend that you use the following tools and transition path .
Tools for helping with the transition to IMDSv2 If your software uses IMDSv1 , use the following tools to help reconﬁgure your software to use IMDSv2 .
To use IMDSv2 , make sure that your EC2 instances have the latest versions of the AWS SDKs and CLIs .
For information about updating the CLI , see Upgrading to the latest version of the AWS CLI in the AWS Command Line Interface User Guide .
The MetadataNoToken CloudWatch metric tracks the number of calls to the instance metadata service that are using IMDSv1 .
By tracking this metric to zero , you can determine if and when all of your software has been upgraded to use IMDSv2 .
For new instances , you can use the run-instances CLI command ( or the RunInstances API ) and the metadata-options parameter to launch new instances that require the use of IMDSv2 .
To require the use of IMDSv2 on all new instances launched by Auto Scaling groups , your Auto Scaling groups must use launch templates .
For Auto Scaling groups that use launch conﬁgurations , replace the launch conﬁgurations with launch templates .
After you replace a launch conﬁguration with a launch template , the Auto Scaling group launches new instances using the new launch template , but existing instances are not aﬀected .
Use the modify-instance-metadata-options CLI command ( or the ModifyInstanceMetadataOptions API ) to require the use of IMDSv2 on the existing instances , or terminate the instances and the Auto Scaling group will launch new replacement instances with the instance metadata options settings that are deﬁned in the launch template .
• IAM policies and SCPs : You can use an IAM condition to enforce that IAM users ca n't launch an instance unless it uses IMDSv2 .
You can also use IAM conditions to enforce that IAM users ca n't modify running instances to re-enable IMDSv1 , and to enforce that the instance metadata service is available on the instance .
599 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance metadata and user data The ec2 : MetadataHttpTokens , ec2 : MetadataHttpPutResponseHopLimit , and ec2 : MetadataHttpEndpoint IAM condition keys can be used to control the use of the RunInstances and the ModifyInstanceMetadataOptions API and corresponding CLI .
If a policy is created , and a parameter in the API call does not match the state speciﬁed in the policy using the condition key , the API or CLI call fails with an UnauthorizedOperation response .
These condition keys can be used either in IAM policies or AWS Organizations service control policies ( SCPs ) .
Furthermore , you can choose an additional layer of protection to enforce the change from IMDSv1 to IMDSv2 .
At the access management layer with respect to the APIs called via EC2 Role credentials , you can use a new condition key in either IAM policies or AWS Organizations service control policies ( SCPs ) .
The same thing can be achieved more broadly with that condition required by an SCP .
This ensures that credentials delivered via IMDSv1 can not actually be used to call APIs because any API calls not matching the speciﬁed condition will receive an UnauthorizedOperation error .
For more information , see Service Control Policies in the AWS Organizations User Guide .
Recommended path to requiring IMDSv2 access Using the above tools , we recommend that you follow this path for transitioning to IMDSv2 : Step 1 : At the start Update the SDKs , CLIs , and your software that use Role credentials on their EC2 instances to IMDSv2compatible versions .
For information about updating the CLI , see Upgrading to the latest version of the AWS CLI in the AWS Command Line Interface User Guide .
Then , change your software that directly accesses instance metadata ( in other words , that does not use an SDK ) using the IMDSv2 requests .
Step 2 : During the transition Track your transition progress by using the CloudWatch metric MetadataNoToken .
This metric shows the number of calls to the instance metadata service that are using IMDSv1 on your instances .
Step 3 : When everything is ready on all instances Everything is ready on all instances when the CloudWatch metric MetadataNoToken records zero IMDSv1 usage .
You can make these changes on running instances ; you do not need to restart your instances .
Specifying instance metadata options is available only through the API or AWS CLI ; it is currently not available via the AWS Management Console .
If a policy is created , and a 600 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance metadata and user data parameter in the API call does not match the state speciﬁed in the policy using the condition key , the API or CLI call fails with an UnauthorizedOperation response .
Conﬁguring the instance metadata options Instance metadata options allow you to conﬁgure new or existing instances to do the following : • Require the use of IMDSv2 when requesting instance metadata • Specify the PUT response hop limit • Turn oﬀ access to instance metadata You can also use IAM condition keys in an IAM policy or SCP to do the following : • Allow an instance to launch only if it 's conﬁgured to require the use of IMDSv2 • Restrict the number of allowed hops • Turn oﬀ access to instance metadata To conﬁgure the instance metadata options on new or existing instances , you use the AWS SDK or CLI .
Note You should proceed cautiously and conduct careful testing before making any changes .
Take note of the following : • If you enforce the use of IMDSv2 , applications or agents that use IMDSv1 for instance metadata access will break .
• If you turn oﬀ all access to instance metadata , applications or agents that rely on instance metadata access to function will break .
You can also create an IAM policy that prevents users from launching new instances unless they require IMDSv2 on the new instance .
Because the secure token header is set to required for metadata retrieval requests , this opts in the instance to require using IMDSv2 when requesting instance metadata .
Conﬁguring instance metadata options for existing instances You can require the use IMDSv2 on an existing instance .
You can also change the PUT response hop limit and turn oﬀ access to instance metadata on an existing instance .
You can also create an IAM policy that prevents users from modifying the instance metadata options on an existing instance .
To require the use of IMDSv2 on an existing instance For existing instances , you can opt in to require that IMDSv2 is used when requesting instance metadata .
Use the modifyinstance-metadata-options CLI command and set the http-put-response-hop-limit parameter to the required number of hops .
You can reverse this change at any time by enabling the HTTP endpoint .
602 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance metadata and user data Retrieving instance metadata Because your instance metadata is available from your running instance , you do not need to use the Amazon EC2 console or the AWS CLI .
This can be helpful when you 're writing scripts to run from your instance .
For example , you can access the local IP address of your instance from instance metadata to manage a connection to an external application .
Instance metadata is divided into categories .
To view all categories of instance metadata from within a running instance , use the following URI .
Note that you are not billed for HTTP requests used to retrieve instance metadata and user data .
By default , you can use both instance metadata services .
You can use a tool such as cURL , as shown in the following example .
These versions do not necessarily correlate with an Amazon EC2 API version .
The earlier versions are available to you in case you have scripts that rely on the structure and information present in a previous version .
The IMDSv2 requests use the stored token that was created in the preceding example command , assuming it has not expired .
If you 're using the instance metadata service to retrieve AWS security credentials , avoid querying for credentials during every transaction or concurrently from a high number of threads or processes , as this might lead to throttling .
Instead , we recommend that you cache the credentials until they start approaching their expiry time .
If you are throttled while accessing the instance metadata service , retry your query with an exponential backoﬀ strategy .
608 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance metadata and user data Limiting instance metadata service access You can consider using local ﬁrewall rules to disable access from some or all processes to the instance metadata service .
Using iptables to limit access The following example uses Linux iptables and its owner module to prevent the Apache webserver ( based on its default installation user ID of apache ) from accessing 169.254.169.254 .
Allow rules might be easier to manage from a security perspective , because they require you to make a decision about what software needs access to instance metadata .
If you use allow rules , it 's less likely you will accidentally allow software to access the metadata service ( that you did not intend to have access ) if you later change the software or conﬁguration on an instance .
You can also combine group usage with allow rules , so that you can add and remove users from a permitted group without needing to change the ﬁrewall rule .
The following example prevents access to the instance metadata service by all processes , except for processes running in the user account trustworthy-user .
They can be made to be persistent by using OS features , not described here .
• The iptables owner module only matches group membership if the group is the primary group of a given local user .
Using PF or IPFW to limit access If you are using FreeBSD or OpenBSD , you can also consider using PF or IPFW .
The following examples limit access to the instance metadata service to just the root user .
PF $ block out inet proto tcp from any to 169.254.169.254 $ pass out inet proto tcp from any to 169.254.169.254 user root IPFW $ allow tcp from any to 169.254.169.254 uid root $ deny tcp from any to 169.254.169.254 609 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance metadata and user data Note The order of the PF and IPFW commands matter .
PF defaults to last matching rule and IPFW defaults to ﬁrst matching rule .
Working with instance user data When working with instance user data , keep the following in mind : • User data must be base64-encoded .
If you retrieve the data using instance metadata or the console , it 's decoded for you automatically .
• User data is treated as opaque data : what you give is what you get back .
It is up to the instance to be able to interpret it .
• If you stop an instance , modify its user data , and start the instance , the updated user data is not executed when you start the instance .
Specify instance user data at launch You can specify user data when you launch an instance .
Modify instance user data You can modify user data for an instance in the stopped state if the root volume is an EBS volume .
Retrieve instance user data To retrieve user data from within a running instance , use the following URI .
This example returns user data that was provided as comma-separated text .
Example : AMI launch index value This example demonstrates how you can use both user data and instance metadata to conﬁgure your instances .
611 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance metadata and user data Alice wants to launch four instances of her favorite database AMI , with the ﬁrst acting as master and the remaining three acting as replicas .
When she launches them , she wants to add user data about the replication strategy for each replicant .
She is aware that this data will be available to all four instances , so she needs to structure the user data in a way that allows each instance to recognize which parts are applicable to it .
She can do this using the ami-launch-index instance metadata value , which will be unique for each instance .
Here is the user data that Alice has constructed .
Alice decides to provide this data as an ASCII string with a pipe symbol ( | ) delimiting the data for the separate instances .
Finally , Alice uses the cut command to extract the portion of the user data that is applicable to that instance .
Important Some of the category names in the following table are placeholders for data that is unique to your instance .
For example , mac represents the MAC address for the network interface .
You must replace the placeholders with the actual values .
Data Description Version introduced ami-id The AMI ID used to launch the instance .
1.0 ami-launch-index If you started more than one instance at the same time , this value indicates the order in which the instance was launched .
1.0 614 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance metadata and user data Data Description Version introduced ami-manifest-path The path to the AMI manifest ﬁle in Amazon S3 .
If you used an Amazon EBS-backed AMI to launch the instance , the returned result is unknown .
1.0 ancestor-ami-ids The AMI IDs of any instances that were rebundled to create this AMI .
This value will only exist if the AMI manifest ﬁle contained an ancestor-amis key .
Amazon EBS volumes are only available in metadata if they were present at launch time or when the instance was last started .
The number of instance store volumes in the block device mapping might not match the actual number of instance store volumes for the instance .
The instance type determines the number of instance store volumes that are available to an instance .
If the number of instance store volumes in a block device mapping exceeds the number available to an instance , the additional instance store volumes are ignored .
2007-12-15 elastic-gpus/ associations/elastic-gpu-id If there is an Elastic GPU attached to the instance , contains a JSON string with information about the Elastic GPU , including its ID and connection information .
2016-11-30 615 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance metadata and user data Data Description Version introduced elastic-inference/ associations/eia-id If there is an Elastic Inference accelerator attached to the instance , contains a JSON string with information about the Elastic Inference accelerator , including its ID and type .
2018-11-29 events/maintenance/history If there are completed or canceled maintenance events for the instance , contains a JSON string with information about the events .
In cases where multiple network interfaces are present , this refers to the eth0 device ( the device for which the device number is 0 ) .
1.0 iam/info If there is an IAM role associated with the instance , contains information about the last time the instance proﬁle was updated , including the instance 's LastUpdated date , InstanceProﬁleArn , and InstanceProﬁleId .
2012-01-12 identity-credentials/ec2/ info [ Reserved for internal use only ] Information about the credentials that AWS uses to identify an instance to the rest of the Amazon EC2 infrastructure .
2018-05-23 616 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance metadata and user data Data Description Version introduced instance-action Notiﬁes the instance that it should reboot in preparation for bundling .
In cases where multiple network interfaces are present , this refers to the eth0 device ( the device for which the device number is 0 ) .
In cases where multiple network interfaces are present , this refers to the eth0 device ( the device for which the device number is 0 ) .
In cases where multiple network interfaces are present , this refers to the eth0 device ( the device for which the device number is 0 ) .
This category corresponds to the DeviceIndex and device-index ﬁelds that are used by the Amazon EC2 API and the EC2 commands for the AWS CLI .
2016-06-30 617 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance metadata and user data Data Description Version introduced network/interfaces/macs/ mac/local-hostname The interface 's local hostname .
Traﬃc on an interface is always billed to the interface owner .
This category is only returned if the enableDnsHostnames attribute is set to true .
For more information , see Using DNS with Your VPC .
network/interfaces/macs/ mac/security-group-ids The IDs of the security groups to which the network interface belongs .
2008-02-01 618 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance metadata and user data Data Description Version introduced product-codes AWS Marketplace product codes associated with the instance , if any .
This category is only returned if the enableDnsHostnames attribute is set to true .
For more information , see Using DNS with Your VPC in the Amazon VPC User Guide .
If an Elastic IP address is associated with the instance , the value returned is the Elastic IP address .
Only available if supplied at instance launch time .
This item is present only if the Spot Instance has been marked for hibernate , stop , or terminate .
619 2014-02-25 2016-11-15 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance metadata and user data Data Description Version introduced spot/termination-time The approximate time , in UTC , that the operating system for your Spot Instance will receive the shutdown signal .
The termination-time item is not set to a time if you terminated the Spot Instance yourself .
2014-11-05 Dynamic data categories The following table lists the categories of dynamic data .
Data Description Version introduced fws/instancemonitoring Value showing whether the customer has enabled detailed one-minute monitoring in CloudWatch .
2009-04-04 instance-identity/ signature Data that can be used by other parties to verify its origin and authenticity .
2009-04-04 Instance identity documents An instance identity document is a JSON ﬁle that describes an instance .
The instance identity document is accompanied by a signature and a PKCS7 signature , which can be used to verify the accuracy , origin , and authenticity of the information provided in the document .
It validates the attributes of the instances , such as the instance size , instance type , operating system , and AMI .
Important Due to the dynamic nature of instance identity documents and signatures , we recommend retrieving the instance identity document and signature regularly .
Obtaining the instance identity document and signatures To retrieve the instance identity document , use the following command from your running instance .
The AWS public certiﬁcate for the Regions provided by an AWS account is as follows .
Add the contents of the document from your instance metadata to the temporary document ﬁle .
Copy and paste the contents of the AWS public certiﬁcate above to the ﬁle and save it .
Use the OpenSSL tools to verify the signature as follows .
Amazon EI accelerators come in multiple sizes and are a cost-eﬀective method to build intelligent capabilities into applications running on Amazon EC2 instances .
624 Amazon Elastic Compute Cloud User Guide for Linux Instances Identify Instances Amazon EI distributes model operations deﬁned by TensorFlow , Apache MXNet , and the Open Neural Network Exchange ( ONNX ) format through MXNet between low-cost , DL inference accelerators and the CPU of the instance .
For more information about Amazon Elastic Inference , see the Amazon EI Developer Guide .
Identify EC2 Linux Instances Your application might need to determine whether it is running on an EC2 instance .
For information about identifying Windows instances , see Identify EC2 Windows Instances in the Amazon EC2 User Guide for Windows Instances .
Inspecting the Instance Identity Document For a deﬁnitive and cryptographically veriﬁed method of identifying an EC2 instance , check the instance identity document , including its signature .
Inspecting the System UUID You can get the system UUID and look for the presence of the characters `` ec2 '' or `` EC2 '' in the beginning octet of the UUID .
This method to determine whether a system is an EC2 instance is quick but potentially inaccurate because there is a small chance that a system that is not an EC2 instance could have a UUID that starts with these characters .
You can use the dmidecode tool to return the UUID .
You should collect monitoring data from all of the parts in your AWS solutions so that you can more easily debug a multipoint failure if one occurs .
After you have deﬁned your monitoring goals and have created your monitoring plan , the next step is to establish a baseline for normal Amazon EC2 performance in your environment .
You should measure Amazon EC2 performance at various times and under diﬀerent load conditions .
You can compare current Amazon EC2 performance to this historical data to help you to identify normal performance patterns and performance anomalies , and devise methods to address them .
When performance falls outside your established baseline , you might need to reconﬁgure or optimize the instance to reduce CPU utilization , improve disk I/O , or reduce network traﬃc .
You can conﬁgure some of these tools to do the monitoring for you , while some of the tools require manual intervention .
Topics • Automated Monitoring Tools ( p. 628 ) • Manual Monitoring Tools ( p. 629 ) Automated Monitoring Tools You can use the following automated monitoring tools to watch Amazon EC2 and report back to you when something is wrong : • System Status Checks - monitor the AWS systems required to use your instance to ensure they are working properly .
These checks detect problems with your instance that require AWS involvement to repair .
When a system status check fails , you can choose to wait for AWS to ﬁx the issue or you can resolve it yourself ( for example , by stopping and restarting or terminating and replacing an instance ) .
Examples of problems that cause system status checks to fail include : • Loss of network connectivity • Loss of system power • Software issues on the physical host • Hardware issues on the physical host that impact network reachability For more information , see Status Checks for Your Instances ( p. 630 ) .
• Instance Status Checks - monitor the software and network conﬁguration of your individual instance .
These checks detect problems that require your involvement to repair .
When an instance status check fails , typically you will need to address the problem yourself ( for example , by rebooting the instance or by making modiﬁcations in your operating system ) .
• Amazon CloudWatch Alarms - watch a single metric over a time period you specify , and perform one or more actions based on the value of the metric relative to a given threshold over a number of time periods .
The action is a notiﬁcation sent to an Amazon Simple Notiﬁcation Service ( Amazon 628 Amazon Elastic Compute Cloud User Guide for Linux Instances Manual Monitoring Tools SNS ) topic or Amazon EC2 Auto Scaling policy .
Alarms invoke actions for sustained state changes only .
CloudWatch alarms will not invoke actions simply because they are in a particular state ; the state must have changed and been maintained for a speciﬁed number of periods .
• Amazon CloudWatch Events - automate your AWS services and respond automatically to system events .
Events from AWS services are delivered to CloudWatch Events in near real time , and you can specify automated actions to take when an event matches a rule you write .
For more information , see the Amazon CloudWatch Logs User Guide .
For more information , see Monitoring Memory and Disk Metrics for Amazon EC2 Linux Instances .
• AWS Management Pack for Microsoft System Center Operations Manager - links Amazon EC2 instances and the Windows or Linux operating systems running inside them .
The AWS Management Pack is an extension to Microsoft System Center Operations Manager .
It uses a designated computer in your datacenter ( called a watcher node ) and the Amazon Web Services APIs to remotely discover and collect information about your AWS resources .
For more information , see AWS Management Pack for Microsoft System Center .
Manual Monitoring Tools Another important part of monitoring Amazon EC2 involves manually monitoring those items that the monitoring scripts , status checks , and CloudWatch alarms do n't cover .
The Amazon EC2 and CloudWatch console dashboards provide an at-a-glance view of the state of your Amazon EC2 environment .
• Amazon EC2 Dashboard shows : • Service Health and Scheduled Events by Region • Instance state • Status checks • Alarm status • Instance metric details ( In the navigation pane choose Instances , select an instance , and choose the Monitoring tab ) • Volume metric details ( In the navigation pane choose Volumes , select a volume , and choose the Monitoring tab ) • Amazon CloudWatch Dashboard shows : • Current alarms and status • Graphs of alarms and resources • Service health status In addition , you can use CloudWatch to do the following : • Graph Amazon EC2 monitoring data to troubleshoot issues and discover trends • Search and browse all your AWS resource metrics • Create and edit alarms to be notiﬁed of problems • See at-a-glance overviews of your alarms and AWS resources Best Practices for Monitoring Use the following best practices for monitoring to help you with your Amazon EC2 monitoring tasks .
629 Amazon Elastic Compute Cloud User Guide for Linux Instances Monitoring the Status of Your Instances • Make monitoring a priority to head oﬀ small problems before they become big ones .
• Create and implement a monitoring plan that collects monitoring data from all of the parts in your AWS solution so that you can more easily debug a multi-point failure if one occurs .
Monitoring the Status of Your Instances You can monitor the status of your instances by viewing status checks and scheduled events for your instances .
A status check gives you the information that results from automated checks performed by Amazon EC2 .
These automated checks detect whether speciﬁc issues are aﬀecting your instances .
The status check information , together with the data provided by Amazon CloudWatch , gives you detailed operational visibility into each of your instances .
You can also see status of speciﬁc events that are scheduled for your instances .
The status of events provides information about upcoming activities that are planned for your instances , such as rebooting or retirement .
They also provide the scheduled start and end time of each event .
Amazon EC2 performs automated checks on every running EC2 instance to identify hardware and software issues .
You can view the results of these status checks to identify speciﬁc and detectable problems .
The event status data augments the information that Amazon EC2 already provides about the state of each instance ( such as pending , running , stopping ) and the utilization metrics that Amazon CloudWatch monitors ( CPU utilization , network traﬃc , and disk activity ) .
If all checks pass , the overall status of the instance is OK .
If one or more checks fail , the overall status is impaired .
Status checks are built into Amazon EC2 , so they can not be disabled or deleted .
When a status check fails , the corresponding CloudWatch metric for status checks is incremented .
You can use these metrics to create CloudWatch alarms that are triggered based on the result of the status checks .
For example , you can create an alarm to warn you if status checks fail on a speciﬁc instance .
630 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance Status Checks You can also create an Amazon CloudWatch alarm that monitors an Amazon EC2 instance and automatically recovers the instance if it becomes impaired due to an underlying issue .
System Status Checks Monitor the AWS systems on which your instance runs .
These checks detect underlying problems with your instance that require AWS involvement to repair .
When a system status check fails , you can choose to wait for AWS to ﬁx the issue , or you can resolve it yourself .
For instances backed by Amazon EBS , you can stop and start the instance yourself , which in most cases results in the instance being migrated to a new host .
For instances backed by instance store , you can terminate and replace the instance .
The following are examples of problems that can cause system status checks to fail : • Loss of network connectivity • Loss of system power • Software issues on the physical host • Hardware issues on the physical host that impact network reachability Instance Status Checks Monitor the software and network conﬁguration of your individual instance .
These checks detect problems that require your involvement to repair .
When an instance status check fails , you typically must address the problem yourself ( for example , by rebooting the instance or by making instance conﬁguration changes ) .
The following are examples of problems that can cause instance status checks to fail : • Failed system status checks • Incorrect networking or startup conﬁguration • Exhausted memory • Corrupted ﬁle system • Incompatible kernel Viewing Status Checks Amazon EC2 provides you with several ways to view and work with status checks .
Viewing Status Using the Console You can view status checks using the AWS Management Console .
On the Instances page , the Status Checks column lists the operational status of each instance .
To view the status of a speciﬁc instance , select the instance , and then choose the Status Checks tab .
If you have an instance with a failed status check and the instance has been unreachable for over 20 minutes , choose AWS Support to submit a request for assistance .
To review the CloudWatch metrics for status checks , select the instance , and then choose the Monitoring tab .
To view the status of all instances , use the following command .
aws ec2 describe-instance-status To get the status of all instances with an instance status of impaired , use the following command .
Reporting Instance Status You can provide feedback if you are having problems with an instance whose status is not shown as impaired , or if you want to send AWS additional details about the problems you are experiencing with an impaired instance .
We use reported feedback to identify issues impacting multiple customers , but do not respond to individual account issues .
Providing feedback does not change the status check results that you currently see for the instance .
Select the instance , choose the Status Checks tab , and choose Submit feedback .
Complete the Report Instance Status form , and then choose Submit .
Reporting Status Feedback Using the Command Line Use the following report-instance-status ( AWS CLI ) command to send feedback about the status of an impaired instance .
Creating a Status Check Alarm Using the Console Use the following procedure to conﬁgure an alarm that sends you a notiﬁcation by email , or stops , terminates , or recovers an instance when it fails a status check .
Select the instance , choose the Status Checks tab , and choose Create Status Check Alarm .
633 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance Status Checks 4 .
Choose an existing SNS topic , or choose create topic to create a new one .
If creating a new topic , in With these recipients , enter your email address and the addresses of any additional recipients , separated by commas .
In Whenever , select the status check that you want to be notiﬁed about .
If you selected Recover this instance in the previous step , select Status Check Failed ( System ) .
In For at least , set the number of periods you want to evaluate and in consecutive periods , select the evaluation period duration before triggering the alarm and sending an email .
( Optional ) In Name of alarm , replace the default name with another name for the alarm .
Important If you added an email address to the list of recipients or created a new topic , Amazon SNS sends a subscription conﬁrmation email message to each new address .
Each recipient must conﬁrm the subscription by choosing the link contained in that message .
Alert notiﬁcations are sent only to conﬁrmed addresses .
If you need to make changes to an instance status alarm , you can edit it .
In the Alarm Details dialog box , choose the name of the alarm .
In the Edit Alarm dialog box , make the desired changes , and then choose Save .
Creating a Status Check Alarm Using the AWS CLI In the following example , the alarm publishes a notiﬁcation to an SNS topic , arn : aws : sns : uswest-2:111122223333 : my-sns-topic , when the instance fails either the instance check or system status check for at least two consecutive periods .
The CloudWatch metric used is StatusCheckFailed .
Select an existing SNS topic or create a new one .
For more information , see Using the AWS CLI with Amazon SNS in the AWS Command Line Interface User Guide .
Use the following list-metrics command to view the available Amazon CloudWatch metrics for Amazon EC2 .
The evaluation period is the number 634 Amazon Elastic Compute Cloud User Guide for Linux Instances Scheduled Events of consecutive periods for which the value of the metric must be compared to the threshold .
The alarm actions are the actions to perform when this alarm is triggered .
This example conﬁgures the alarm to send an email using Amazon SNS .
These events do not occur frequently .
If one of your instances will be aﬀected by a scheduled event , AWS sends an email to the email address that 's associated with your AWS account prior to the scheduled event .
The email provides details about the event , including the start and end date .
Depending on the event , you might be able to take action to control the timing of the event .
To update the contact information for your account so that you can be sure to be notiﬁed about scheduled events , go to the Account Settings page .
Applies only to instances backed by Amazon EBS .
• Instance retirement : At the scheduled time , the instance is stopped if it is backed by Amazon EBS , or terminated if it is backed by instance store .
• System maintenance : At the scheduled time , the instance might be temporarily aﬀected by network maintenance or power maintenance .
Viewing Scheduled Events In addition to receiving notiﬁcation of scheduled events in email , you can check for scheduled events using one of the following methods .
New console To view scheduled events for your instances using the console 1 .
You can view scheduled events in the following screens : • In the navigation pane , choose Events .
Any resources with an associated event are displayed .
Any resources with an associated event are displayed under Scheduled Events .
For example , in the navigation pane , choose Instances and select an instance .
If the instance has an associated instance stop or instance retirement event , it is displayed in the lower pane .
Old console To view scheduled events for your instances using the console 1 .
You can view scheduled events in the following screens : • In the navigation pane , choose Events .
Any resources with an associated event are displayed .
You can ﬁlter by resource type , or by speciﬁc event types .
You can select the resource to view details .
Any resources with an associated event are displayed under Scheduled Events .
For example , in the navigation pane , choose Instances and select an instance .
If the instance has an associated instance stop or instance retirement event , it is displayed in the lower pane .
AWS CLI To view scheduled events for your instances using the AWS CLI Use the describe-instance-status command .
Code Description NotBefore : instance-stop : The instance is running on degraded hardware : 5/23/2015 12:00:00 AM Instance metadata To view scheduled events for your instances using instance metadata You can retrieve information about active maintenance events for your instances from the instance metadata ( p. 597 ) using Instance Metadata Service Version 2 or Instance Metadata Service Version 1 .
If the root device is an EBS volume , the instance is scheduled to stop .
If the root device is an instance store volume , the instance is scheduled to terminate .
Important Any data stored on instance store volumes is lost when an instance is stopped or terminated .
This includes instance store volumes that are attached to an instance that has an EBS volume as the root device .
Be sure to save data from your instance store volumes that you might need later before the instance is stopped or terminated .
Actions for Instances Backed by Amazon EBS You can wait for the instance to stop as scheduled .
Alternatively , you can stop and start the instance yourself , which migrates it to a new host .
For more information about stopping your instance , in addition 639 Amazon Elastic Compute Cloud User Guide for Linux Instances Scheduled Events to information about the changes to your instance conﬁguration when it 's stopped , see Stop and start your instance ( p. 531 ) .
You can automate an immediate stop and start in response to a scheduled instance stop event .
For more information , see Automating Actions for EC2 Instances in the AWS Health User Guide .
Actions for Instances Backed by Instance Store We recommend that you launch a replacement instance from your most recent AMI and migrate all necessary data to the replacement instance before the instance is scheduled to terminate .
Then , you can terminate the original instance , or wait for it to terminate as scheduled .
Working with Instances Scheduled for Reboot When AWS must perform tasks such as installing updates or maintaining the underlying host , it can schedule the instance or the underlying host for a reboot .
If you stop your linked EC2-Classic instance ( p. 813 ) , it is automatically unlinked from the VPC and the VPC security groups are no longer associated with the instance .
You can link your instance to the VPC again after you 've restarted it .
Viewing the Reboot Event Type You can view whether a reboot event is an instance reboot or a system reboot using one of the following methods .
New console To view the type of scheduled reboot event using the console 1 .
For each instance , view the value in the Event type column .
Old console To view the type of scheduled reboot event using the console 1 .
Choose Instance resources from the ﬁlter list .
For each instance , view the value in the Event Type column .
AWS CLI To view the type of scheduled reboot event using the AWS CLI Use the describe-instance-status command .
After your instance is rebooted , the scheduled event is cleared and the event 's description is updated .
The pending maintenance to the underlying host is completed , and you can begin using your instance again after it has fully booted .
Actions for System Reboot It is not possible for you to reboot the system yourself .
You can wait for the system reboot to occur during its scheduled maintenance window , or you can reschedule ( p. 642 ) the system reboot to a date and time that suits you .
After the system reboot has occurred , the instance retains its IP address and DNS name , and any data on local instance store volumes is preserved .
After the system reboot is complete , the scheduled event for the instance is cleared , and you can verify that the software on your instance is operating as expected .
Alternatively , if it is necessary to maintain the instance at a diﬀerent time and you ca n't reschedule the system reboot , then you can stop and start an Amazon EBS-backed instance , which migrates it to a new host .
However , the data on the local instance store volumes is not preserved .
You can also automate an immediate instance stop and start in response to a scheduled system reboot event .
For more information , see Automating Actions for EC2 Instances in the AWS Health User Guide .
For an instance store-backed instance , if you ca n't reschedule the system reboot , then you can launch a replacement instance from your most recent AMI , migrate all necessary data to the replacement instance before the scheduled maintenance window , and then terminate the original instance .
Working with Instances Scheduled for Maintenance When AWS must maintain the underlying host for an instance , it schedules the instance for maintenance .
There are two types of maintenance events : network maintenance and power maintenance .
During network maintenance , scheduled instances lose network connectivity for a brief period of time .
Normal network connectivity to your instance is restored after maintenance is complete .
After your instance has rebooted ( this normally takes a few minutes ) , verify that your application is working as expected .
At this point , your instance should no longer have a scheduled event associated with it , or if it does , the description of the scheduled event begins with [ Completed ] .
It sometimes takes up to 1 hour for the instance status description to refresh .
Completed maintenance events are displayed on the Amazon EC2 console dashboard for up to a week .
Actions for Instances Backed by Amazon EBS 641 Amazon Elastic Compute Cloud User Guide for Linux Instances Scheduled Events You can wait for the maintenance to occur as scheduled .
For more information about stopping your instance , in addition to information about the changes to your instance conﬁguration when it 's stopped , see Stop and start your instance ( p. 531 ) .
You can automate an immediate stop and start in response to a scheduled maintenance event .
For more information , see Automating Actions for EC2 Instances in the AWS Health User Guide .
Actions for Instances Backed by Instance Store You can wait for the maintenance to occur as scheduled .
Alternatively , if you want to maintain normal operation during a scheduled maintenance window , you can launch a replacement instance from your most recent AMI , migrate all necessary data to the replacement instance before the scheduled maintenance window , and then terminate the original instance .
Rescheduling a Scheduled Event You can reschedule an event so that it occurs at a speciﬁc date and time that suits you .
Only events that have a deadline date can be rescheduled .
You can reschedule an event using one of the following methods .
New console To reschedule an event using the console 1 .
Only events that have an event deadline date , indicated by a value for Deadline , can be rescheduled .
If one of the selected events does not have a deadline date , Actions , Schedule event is disabled .
For New start time , enter a new date and time for the event .
The new date and time must occur before the Event deadline .
It might take 1-2 minutes for the updated event start time to be reﬂected in the console .
Old console To reschedule an event using the console 1 .
Choose Instance resources from the ﬁlter list .
Only events that have an event deadline date , indicated by a value for Event Deadline , can be rescheduled .
For Event start time , enter a new date and time for the event .
The new date and time must occur before the Event Deadline .
It might take 1-2 minutes for the updated event start time to be reﬂected in the console .
642 Amazon Elastic Compute Cloud User Guide for Linux Instances Monitoring Your Instances Using CloudWatch AWS CLI To reschedule an event using the AWS CLI 1 .
Only events that have an event deadline date , indicated by a value for NotBeforeDeadline , can be rescheduled .
Use the describe-instance-status command to view the NotBeforeDeadline parameter value .
Specify the new event start time using the not-before parameter .
The new event start time must fall before the NotBeforeDeadline .
Limitations • Only events with an event deadline date can be rescheduled .
The event can be rescheduled up to the event deadline date .
The Deadline column in the console and the NotBeforeDeadline ﬁeld in the AWS CLI indicate if the event has a deadline date .
• Only events that have not yet started can be rescheduled .
The Start time column in the console and the NotBefore ﬁeld in the AWS CLI indicate the event start time .
Events that are scheduled to start in the next 5 minutes can not be rescheduled .
• The new event start time must be at least 60 minutes from the current time .
• If you reschedule multiple events using the console , the event deadline date is determined by the event with the earliest event deadline date .
Monitoring Your Instances Using CloudWatch You can monitor your instances using Amazon CloudWatch , which collects and processes raw data from Amazon EC2 into readable , near real-time metrics .
These statistics are recorded for a period of 15 months , so that you can access historical information and gain a better perspective on how your web application or service is performing .
643 Amazon Elastic Compute Cloud User Guide for Linux Instances Enable Detailed Monitoring By default , Amazon EC2 sends metric data to CloudWatch in 5-minute periods .
To send metric data for your instance to CloudWatch in 1-minute periods , you can enable detailed monitoring on the instance .
The Amazon EC2 console displays a series of graphs based on the raw data from Amazon CloudWatch .
Depending on your needs , you might prefer to get data for your instances from Amazon CloudWatch instead of the graphs in the console .
For more information about Amazon CloudWatch , see the Amazon CloudWatch User Guide .
You can optionally enable detailed monitoring .
The following table describes basic and detailed monitoring for instances .
Monitoring Type Description Basic Data is available automatically in 5-minute periods at no charge .
Detailed Data is available in 1-minute periods for an additional cost .
To get this level of data , you must speciﬁcally enable it for the instance .
For the instances where you 've enabled detailed monitoring , you can also get aggregated data across groups of similar instances .
For information about pricing , see the Amazon CloudWatch product page .
Enabling Detailed Monitoring You can enable detailed monitoring on an instance as you launch it or after the instance is running or stopped .
Enabling detailed monitoring on an instance does not aﬀect the monitoring of the EBS volumes attached to the instance .
644 Amazon Elastic Compute Cloud User Guide for Linux Instances List Available Metrics 4 .
To enable detailed monitoring when launching an instance ( console ) When launching an instance using the AWS Management Console , select the Monitoring check box on the Conﬁgure Instance Details page .
To enable detailed monitoring for an existing instance ( AWS CLI ) Use the following monitor-instances command to enable detailed monitoring for the speciﬁed instances .
Disabling Detailed Monitoring You can disable detailed monitoring on an instance as you launch it or after the instance is running or stopped .
To disable detailed monitoring ( AWS CLI ) Use the following unmonitor-instances command to disable detailed monitoring for the speciﬁed instances .
You can use the AWS Management Console , the AWS CLI , or an API to list the metrics that Amazon EC2 sends to CloudWatch .
By default , each data point covers the 5 minutes that follow the start time of activity for the instance .
If you 've enabled detailed monitoring , each data point covers the next minute of activity from the start time .
Metric Description CPUUtilization The percentage of allocated EC2 compute units that are currently in use on the instance .
This metric identiﬁes the processing power required to run an application on a selected instance .
Depending on the instance type , tools in your operating system can show a lower percentage than CloudWatch when the instance is not allocated a full processor core .
Units : Percent DiskReadOps Completed read operations from all instance store volumes available to the instance in a speciﬁed period of time .
To calculate the average I/O operations per second ( IOPS ) for the period , divide the total operations in the period by the number of seconds in that period .
If there are no instance store volumes , either the value is 0 or the metric is not reported .
Units : Count DiskWriteOps Completed write operations to all instance store volumes available to the instance in a speciﬁed period of time .
To calculate the average I/O operations per second ( IOPS ) for the period , divide the total operations in the period by the number of seconds in that period .
If there are no instance store volumes , either the value is 0 or the metric is not reported .
Units : Count DiskReadBytes Bytes read from all instance store volumes available to the instance .
This metric is used to determine the volume of the data the application reads from the hard disk of the instance .
This can be used to determine the speed of the application .
The number reported is the number of bytes received during the period .
If you are using basic ( ﬁve-minute ) monitoring , you 646 Amazon Elastic Compute Cloud User Guide for Linux Instances List Available Metrics Metric Description can divide this number by 300 to ﬁnd Bytes/second .
If there are no instance store volumes , either the value is 0 or the metric is not reported .
Units : Bytes DiskWriteBytes Bytes written to all instance store volumes available to the instance .
This metric is used to determine the volume of the data the application writes onto the hard disk of the instance .
This can be used to determine the speed of the application .
The number reported is the number of bytes received during the period .
If there are no instance store volumes , either the value is 0 or the metric is not reported .
Units : Bytes NetworkIn The number of bytes received on all network interfaces by the instance .
This metric identiﬁes the volume of incoming network traﬃc to a single instance .
The number reported is the number of bytes received during the period .
Units : Bytes NetworkOut The number of bytes sent out on all network interfaces by the instance .
This metric identiﬁes the volume of outgoing network traﬃc from a single instance .
The number reported is the number of bytes sent during the period .
Units : Bytes NetworkPacketsIn The number of packets received on all network interfaces by the instance .
This metric identiﬁes the volume of incoming traﬃc in terms of the number of packets on a single instance .
This metric is available for basic monitoring only .
Units : Count Statistics : Minimum , Maximum , Average 647 Amazon Elastic Compute Cloud User Guide for Linux Instances List Available Metrics Metric Description NetworkPacketsOut The number of packets sent out on all network interfaces by the instance .
This metric identiﬁes the volume of outgoing traﬃc in terms of the number of packets on a single instance .
This metric is available for basic monitoring only .
Units : Count Statistics : Minimum , Maximum , Average MetadataNoToken The number of times the instance metadata service was succesfully accessed using a method that does not use a token .
This metric is used to determine if there are any processes accessing instance metadata that are using Instance Metadata Service Version 1 , which does not use a token .
Metric Description CPUCreditUsage The number of CPU credits spent by the instance for CPU utilization .
One CPU credit equals one vCPU running at 100 % utilization for one minute or an equivalent combination of vCPUs , utilization , and time ( for example , one vCPU running at 50 % utilization for two minutes or two vCPUs running at 25 % utilization for two minutes ) .
If you specify a period greater than ﬁve minutes , use the Sum statistic instead of the Average statistic .
Units : Credits ( vCPU-minutes ) CPUCreditBalance The number of earned CPU credits that an instance has accrued since it was launched or started .
For T2 Standard , the CPUCreditBalance also includes the number of launch credits that have been accrued .
Credits are accrued in the credit balance after they are earned , and removed from the credit balance when they are spent .
After the limit is reached , any new credits that are earned are discarded .
The credits in the CPUCreditBalance are available for the instance to spend to burst beyond its baseline CPU utilization .
648 Amazon Elastic Compute Cloud User Guide for Linux Instances List Available Metrics Metric Description When an instance is running , credits in the CPUCreditBalance do not expire .
Units : Credits ( vCPU-minutes ) CPUSurplusCreditBalance The number of surplus credits that have been spent by an unlimited instance when its CPUCreditBalance value is zero .
The CPUSurplusCreditBalance value is paid down by earned CPU credits .
If the number of surplus credits exceeds the maximum number of credits that the instance can earn in a 24-hour period , the spent surplus credits above the maximum incur an additional charge .
Units : Credits ( vCPU-minutes ) CPUSurplusCreditsCharged The number of spent surplus credits that are not paid down by earned CPU credits , and which thus incur an additional charge .
Spent surplus credits are charged when any of the following occurs : • The spent surplus credits exceed the maximum number of credits that the instance can earn in a 24-hour period .
Spent surplus credits above the maximum are charged at the end of the hour .
Metric Description EBSReadOps Completed read operations from all Amazon EBS volumes attached to the instance in a speciﬁed period of time .
649 Amazon Elastic Compute Cloud User Guide for Linux Instances List Available Metrics Metric Description To calculate the average read I/O operations per second ( Read IOPS ) for the period , divide the total operations in the period by the number of seconds in that period .
Unit : Count EBSWriteOps Completed write operations to all EBS volumes attached to the instance in a speciﬁed period of time .
To calculate the average write I/O operations per second ( Write IOPS ) for the period , divide the total operations in the period by the number of seconds in that period .
Unit : Count EBSReadBytes Bytes read from all EBS volumes attached to the instance in a speciﬁed period of time .
The number reported is the number of bytes read during the period .
Unit : Bytes EBSWriteBytes Bytes written to all EBS volumes attached to the instance in a speciﬁed period of time .
The number reported is the number of bytes written during the period .
Provides information about the percentage of I/O credits remaining in the burst bucket .
This metric is available for basic monitoring only .
The Sum statistic is not applicable to this metric .
Unit : Percent 650 Amazon Elastic Compute Cloud User Guide for Linux Instances List Available Metrics Metric Description EBSByteBalance % Available only for the smaller instance sizes .
Provides information about the percentage of throughput credits remaining in the burst bucket .
This metric is available for basic monitoring only .
The Sum statistic is not applicable to this metric .
Status Check Metrics The AWS/EC2 namespace includes the following status check metrics .
For a newly-launched instance , status check metric data is only available after the instance has completed the initialization state ( within a few minutes of the instance entering the running state ) .
For more information about EC2 status checks , see Status Checks For Your Instances .
Metric Description StatusCheckFailed Reports whether the instance has passed both the instance status check and the system status check in the last minute .
Units : Count StatusCheckFailed_Instance Reports whether the instance has passed the instance status check in the last minute .
Units : Count StatusCheckFailed_System Reports whether the instance has passed the system status check in the last minute .
Units : Count 651 Amazon Elastic Compute Cloud User Guide for Linux Instances List Available Metrics Traﬃc Mirroring Metrics The AWS/EC2 namespace includes metrics for mirrored traﬃc .
For more information , see Monitoring Mirrored Traﬃc Using Amazon CloudWatch in the Amazon VPC Traﬃc Mirroring Guide .
Amazon EC2 Metric Dimensions You can use the following dimensions to reﬁne the metrics listed in the previous tables .
Dimension Description AutoScalingGroupName This dimension ﬁlters the data you request for all instances in a speciﬁed capacity group .
An Auto Scaling group is a collection of instances you deﬁne if you 're using Auto Scaling .
This dimension is available only for Amazon EC2 metrics when the instances are in such an Auto Scaling group .
Available for instances with Detailed or Basic Monitoring enabled .
ImageId This dimension ﬁlters the data you request for all instances running this Amazon EC2 Amazon Machine Image ( AMI ) .
Available for instances with Detailed Monitoring enabled .
InstanceId This dimension ﬁlters the data you request for the identiﬁed instance only .
This helps you pinpoint an exact instance from which to monitor data .
InstanceType This dimension ﬁlters the data you request for all instances running with this speciﬁed instance type .
This helps you categorize your data by the type of instance running .
For example , you might compare data from an m1.small instance and an m1.large instance to determine which has the better business value for your application .
Available for instances with Detailed Monitoring enabled .
Amazon EC2 Usage Metrics You can use CloudWatch usage metrics to provide visibility into your account 's usage of resources .
Use these metrics to visualize your current service usage on CloudWatch graphs and dashboards .
You can conﬁgure alarms that alert you when your usage approaches a service quota .
For more information about CloudWatch integration with service quotas , see Service Quotas Integration and Usage Metrics .
Metric Description ResourceCount The number of the speciﬁed resources running in your account .
The resources are deﬁned by the dimensions associated with the metric .
The most useful statistic for this metric is MAXIMUM , which represents the maximum number of resources used during the 1minute period .
652 Amazon Elastic Compute Cloud User Guide for Linux Instances List Available Metrics The following dimensions are used to reﬁne the usage metrics that are published by Amazon EC2 .
Dimension Description Service The name of the AWS service containing the resource .
Type The type of entity that is being reported .
Resource The type of resource that is running .
Currently , the only valid value for Amazon EC2 usage metrics is vCPU , which returns information on instances that are running .
Class The class of resource being tracked .
The values for this dimension deﬁne the ﬁrst letter of the instance types that are reported by the metric .
653 Amazon Elastic Compute Cloud User Guide for Linux Instances List Available Metrics 4 .
654 Amazon Elastic Compute Cloud User Guide for Linux Instances List Available Metrics 5 .
To ﬁlter by resource , choose the resource ID and then choose Add to search .
To ﬁlter by metric , choose the metric name and then choose Add to search .
Listing Metrics Using the AWS CLI Use the list-metrics command to list the CloudWatch metrics for your instances .
To list all the available metrics for Amazon EC2 ( AWS CLI ) The following example speciﬁes the AWS/EC2 namespace to view all the metrics for Amazon EC2 .
aws cloudwatch list-metrics -- namespace AWS/EC2 -- metric-name CPUUtilization Get Statistics for Metrics for Your Instances You can get statistics for the CloudWatch metrics for your instances .
CloudWatch provides statistics based on the metric data points provided by your custom data or provided by other services in AWS to CloudWatch .
Aggregations are made using the namespace , metric name , dimensions , and the data point unit of measure , within the time period you specify .
The following table describes the available statistics .
Statistic Description Minimum The lowest value observed during the speciﬁed period .
You can use this value to determine low volumes of activity for your application .
656 Amazon Elastic Compute Cloud User Guide for Linux Instances Get Statistics for Metrics Statistic Description Maximum The highest value observed during the speciﬁed period .
You can use this value to determine high volumes of activity for your application .
Sum All values submitted for the matching metric added together .
This statistic can be useful for determining the total volume of a metric .
Average The value of Sum / SampleCount during the speciﬁed period .
By comparing this statistic with the Minimum and Maximum , you can determine the full scope of a metric and how close the average use is to the Minimum and Maximum .
This comparison helps you to know when to increase or decrease your resources as needed .
SampleCount The count ( number ) of data points used for the statistical calculation .
Get Statistics for a Speciﬁc Instance The following examples show you how to use the AWS Management Console or the AWS CLI to determine the maximum CPU utilization of a speciﬁc EC2 instance .
Requirements • You must have the ID of the instance .
You can get the instance ID using the AWS Management Console or the describe-instances command .
657 Amazon Elastic Compute Cloud User Guide for Linux Instances Get Statistics for Metrics 4 .
658 Amazon Elastic Compute Cloud User Guide for Linux Instances Get Statistics for Metrics 5 .
In the search ﬁeld , enter CPUUtilization and press Enter .
Choose the row for the speciﬁc instance , which displays a graph for the CPUUtilization metric for the instance .
To change the time range , select one of the predeﬁned values or choose custom .
To change the statistic or the period for the metric , choose the Graphed metrics tab .
Choose the column heading or an individual value , and then choose a diﬀerent value .
Instances that use basic monitoring are not included in the aggregates .
In addition , Amazon CloudWatch does not aggregate data across regions .
Before you can get statistics aggregated across instances , you must enable detailed monitoring ( at an additional charge ) , which provides data in 1-minute periods .
This example shows you how to use detailed monitoring to get the average CPU usage for your EC2 instances .
Important This technique for retrieving all dimensions across an AWS namespace does not work for custom namespaces that you publish to Amazon CloudWatch .
With custom namespaces , you must specify the complete set of dimensions that are associated with any given data point to retrieve statistics that include the data point .
Choose the EC2 namespace and then choose Across All Instances .
660 Amazon Elastic Compute Cloud User Guide for Linux Instances Get Statistics for Metrics 4 .
Choose the row that contains CPUUtilization , which displays a graph for the metric for all your EC2 instances .
To change the time range , select one of the predeﬁned values or choose custom .
To change the statistic or the period for the metric , choose the Graphed metrics tab .
Choose the column heading or an individual value , and then choose a diﬀerent value .
To get average CPU utilization across your instances ( AWS CLI ) Use the get-metric-statistics command as follows to get the average of the CPUUtilization metric across your instances .
Note that Amazon CloudWatch can not aggregate data across regions .
Metrics are completely separate between regions .
This example shows you how to retrieve the total bytes written to disk for one Auto Scaling group .
Choose the EC2 namespace and then choose By Auto Scaling Group .
Choose the row for the DiskWriteBytes metric and the speciﬁc Auto Scaling group , which displays a graph for the metric for the instances in the Auto Scaling group .
To change the time range , select one of the predeﬁned values or choose custom .
To change the statistic or the period for the metric , choose the Graphed metrics tab .
Choose the column heading or an individual value , and then choose a diﬀerent value .
To display DiskWriteBytes for the instances in an Auto Scaling group ( AWS CLI ) Use the get-metric-statistics command as follows .
Instances that use basic monitoring are not included .
Note that Amazon CloudWatch can not aggregate data across regions .
Metrics are completely separate between regions .
Before you can get statistics aggregated across instances , you must enable detailed monitoring ( at an additional charge ) , which provides data in 1-minute periods .
This example shows you how to determine average CPU utilization for all instances that use a speciﬁc Amazon Machine Image ( AMI ) .
Choose the row for the CPUUtilization metric and the speciﬁc AMI , which displays a graph for the metric for the speciﬁed AMI .
To change the time range , select one of the predeﬁned values or choose custom .
To change the statistic or the period for the metric , choose the Graphed metrics tab .
Choose the column heading or an individual value , and then choose a diﬀerent value .
To get the average CPU utilization for an image ID ( AWS CLI ) Use the get-metric-statistics command as follows .
Each value represents an average CPU utilization percentage for the EC2 instances running the speciﬁed AMI .
] , 663 Amazon Elastic Compute Cloud User Guide for Linux Instances Graph Metrics } '' Label '' : `` CPUUtilization '' Graph Metrics for Your Instances After you launch an instance , you can open the Amazon EC2 console and view the monitoring graphs for an instance on the Monitoring tab .
Each graph is based on one of the available Amazon EC2 metrics .
Graph Metrics Using the CloudWatch Console You can also use the CloudWatch console to graph metric data generated by Amazon EC2 and other AWS services .
For more information , see Graph Metrics in the Amazon CloudWatch User Guide .
Create a CloudWatch Alarm for an Instance You can create a CloudWatch alarm that monitors CloudWatch metrics for one of your instances .
CloudWatch will automatically send you a notiﬁcation when the metric reaches a threshold you specify .
You can create a CloudWatch alarm using the Amazon EC2 console , or using the more advanced options provided by the CloudWatch console .
To create an alarm using the CloudWatch console For examples , see Creating Amazon CloudWatch Alarms in the Amazon CloudWatch User Guide .
For With these recipients , enter one or more email addresses to receive notiﬁcation .
Specify the metric and the criteria for the policy .
c. 664 Amazon Elastic Compute Cloud User Guide for Linux Instances Create Alarms That Stop , Terminate , Reboot , or Recover an Instance Create Alarms That Stop , Terminate , Reboot , or Recover an Instance Using Amazon CloudWatch alarm actions , you can create alarms that automatically stop , terminate , reboot , or recover your instances .
You can use the stop or terminate actions to help you save money when you no longer need an instance to be running .
You can use the reboot and recover actions to automatically reboot those instances or recover them onto new hardware if a system impairment occurs .
The AWSServiceRoleForCloudWatchEvents service-linked role enables AWS to perform alarm actions on your behalf .
The ﬁrst time you create an alarm in the AWS Management Console , the IAM CLI , or the IAM API , CloudWatch creates the service-linked role for you .
There are a number of scenarios in which you might want to automatically stop or terminate your instance .
For example , you might have instances dedicated to batch payroll processing jobs or scientiﬁc computing tasks that run for a period of time and then complete their work .
Rather than letting those instances sit idle ( and accrue charges ) , you can stop or terminate them , which can help you to save money .
The main diﬀerence between using the stop and the terminate alarm actions is that you can easily restart a stopped instance if you need to run it again later , and you can keep the same instance ID and root volume .
You can add the stop , terminate , reboot , or recover actions to any alarm that is set on an Amazon EC2 per-instance metric , including basic and detailed monitoring metrics provided by Amazon CloudWatch 665 Amazon Elastic Compute Cloud User Guide for Linux Instances Create Alarms That Stop , Terminate , Reboot , or Recover an Instance ( in the AWS/EC2 namespace ) , as well as any custom metrics that include the InstanceId dimension , as long as its value refers to a valid running Amazon EC2 instance .
Console Support You can create alarms using the Amazon EC2 console or the CloudWatch console .
The procedures in this documentation use the Amazon EC2 console .
For procedures that use the CloudWatch console , see Create Alarms That Stop , Terminate , Reboot , or Recover an Instance in the Amazon CloudWatch User Guide .
If you have read/write permissions for Amazon CloudWatch but not for Amazon EC2 , you can still create an alarm but the stop or terminate actions wo n't be performed on the Amazon EC2 instance .
However , if you are later granted permission to use the associated Amazon EC2 APIs , the alarm actions you created earlier are performed .
For more information about IAM permissions , see Permissions and Policies in the IAM User Guide .
For example , you may run development or test instances and occasionally forget to shut them oﬀ .
You can create an alarm that is triggered when the average CPU utilization percentage has been lower than 10 percent for 24 hours , signaling that it is idle and no longer in use .
You can adjust the threshold , duration , and period to suit your needs , plus you can add an Amazon Simple Notiﬁcation Service ( Amazon SNS ) notiﬁcation so that you receive an email when the alarm is triggered .
Instances that use an Amazon EBS volume as the root device can be stopped or terminated , whereas instances that use the instance store as the root device can only be terminated .
Amazon Elastic Compute Cloud User Guide for Linux Instances Create Alarms That Stop , Terminate , Reboot , or Recover an Instance In the Create Alarm dialog box , do the following : a .
To receive an email when the alarm is triggered , for Send a notiﬁcation to , choose an existing Amazon SNS topic , or choose create topic to create a new one .
After you create the alarm , you will receive a subscription conﬁrmation email that you must accept before you can get notiﬁcations for this topic .
c. For Whenever , choose the statistic you want to use and then choose the metric .
Alarm names must contain only ASCII characters .
If you do n't enter a name for the alarm , Amazon CloudWatch automatically creates one for you .
Note You can adjust the alarm conﬁguration based on your own requirements before creating the alarm , or you can edit them later .
However , after you create an alarm , you can not edit its name later .
Adding Terminate Actions to Amazon CloudWatch Alarms You can create an alarm that terminates an EC2 instance automatically when a certain threshold has been met ( as long as termination protection is not enabled for the instance ) .
For example , you might want to terminate an instance when it has completed its work , and you don ’ t need the instance again .
If you might want to use the instance later , you should stop the instance instead of terminating it .
For information on enabling and disabling termination protection for an instance , see Enabling Termination Protection for an Instance in the Amazon EC2 User Guide for Linux Instances .
To receive an email when the alarm is triggered , for Send a notiﬁcation to , choose an existing Amazon SNS topic , or choose create topic to create a new one .
After you create the alarm , you will receive a subscription conﬁrmation email that you must accept before you can get notiﬁcations for this topic .
667 e. f. Amazon Elastic Compute Cloud User Guide for Linux Instances Create Alarms That Stop , Terminate , Reboot , or Recover an Instance For For at least , specify the evaluation period for the alarm .
Alarm names must contain only ASCII characters .
If you do n't enter a name for the alarm , Amazon CloudWatch automatically creates one for you .
Note g. You can adjust the alarm conﬁguration based on your own requirements before creating the alarm , or you can edit them later .
However , after you create an alarm , you can not edit its name later .
Adding Reboot Actions to Amazon CloudWatch Alarms You can create an Amazon CloudWatch alarm that monitors an Amazon EC2 instance and automatically reboots the instance .
The reboot alarm action is recommended for Instance Health Check failures ( as opposed to the recover alarm action , which is suited for System Health Check failures ) .
An instance reboot is equivalent to an operating system reboot .
In most cases , it takes only a few minutes to reboot your instance .
When you reboot an instance , it remains on the same physical host , so your instance keeps its public DNS name , private IP address , and any data on its instance store volumes .
For more information , see Reboot Your Instance in the Amazon EC2 User Guide for Linux Instances .
Important To avoid a race condition between the reboot and recover actions , avoid setting the same number of evaluation periods for a reboot alarm and a recover alarm .
We recommend that you set reboot alarms to three evaluation periods of one minute each .
For more information , see Evaluating an Alarm in the Amazon CloudWatch User Guide .
After you create the alarm , you will receive a subscription conﬁrmation email that you must accept before you can get notiﬁcations for this topic .
For For at least , specify the evaluation period for the alarm .
Alarm names must contain only ASCII characters .
If you do n't enter a name for the alarm , Amazon CloudWatch automatically creates one for you .
668 Amazon Elastic Compute Cloud User Guide for Linux Instances Create Alarms That Stop , Terminate , Reboot , or Recover an Instance Adding Recover Actions to Amazon CloudWatch Alarms You can create an Amazon CloudWatch alarm that monitors an Amazon EC2 instance .
If the instance becomes impaired due to an underlying hardware failure or a problem that requires AWS involvement to repair , you can automatically recover the instance .
Terminated instances can not be recovered .
A recovered instance is identical to the original instance , including the instance ID , private IP addresses , Elastic IP addresses , and all instance metadata .
CloudWatch prevents you from adding a recovery action to an alarm that is on an instance which does not support recovery actions .
When the StatusCheckFailed_System alarm is triggered , and the recover action is initiated , you are notiﬁed by the Amazon SNS topic that you chose when you created the alarm and associated the recover action .
During instance recovery , the instance is migrated during an instance reboot , and any data that is in-memory is lost .
When the process is complete , information is published to the SNS topic you've conﬁgured for the alarm .
Anyone who is subscribed to this SNS topic receives an email notiﬁcation that includes the status of the recovery attempt and any further instructions .
You notice an instance reboot on the recovered instance .
If your instance has a public IP address , it retains the public IP address after recovery .
Important To avoid a race condition between the reboot and recover actions , avoid setting the same number of evaluation periods for a reboot alarm and a recover alarm .
We recommend that you set recover alarms to two evaluation periods of one minute each .
For more information , see Evaluating an Alarm in the Amazon CloudWatch User Guide .
To receive an email when the alarm is triggered , for Send a notiﬁcation to , choose an existing Amazon SNS topic , or choose create topic to create a new one .
669 Amazon Elastic Compute Cloud User Guide for Linux Instances Create Alarms That Stop , Terminate , Reboot , or Recover an Instance To create a new topic , for Send a notiﬁcation to , enter a name for the topic , and for With these recipients , enter the email addresses of the recipients ( separated by commas ) .
After you create the alarm , you will receive a subscription conﬁrmation email that you must accept before you can get email for this topic .
Note • Users must subscribe to the speciﬁed SNS topic to receive email notiﬁcations when the alarm is triggered .
• The AWS account root user always receives email notiﬁcations when automatic instance recovery actions occur , even if an SNS topic is not speciﬁed .
• The AWS account root user always receives email notiﬁcations when automatic instance recovery actions occur , even if it is not subscribed to the speciﬁed SNS topic .
Alarm names must contain only ASCII characters .
If you do n't enter a name for the alarm , Amazon CloudWatch automatically creates one for you .
Using the Amazon CloudWatch Console to View Alarm and Action History You can view alarm and action history in the Amazon CloudWatch console .
Amazon CloudWatch keeps the last two weeks ' worth of alarm and action history .
The Details tab shows the most recent state transition along with the time and metric values .
Choose the History tab to view the most recent history entries .
Amazon CloudWatch Alarm Action Scenarios You can use the Amazon EC2 console to create alarm actions that stop or terminate an Amazon EC2 instance when certain conditions are met .
In the following screen capture of the console page where you set the alarm actions , we 've numbered the settings .
We 've also numbered the settings in the scenarios that follow , to help you create the appropriate actions .
670 Amazon Elastic Compute Cloud User Guide for Linux Instances Create Alarms That Stop , Terminate , Reboot , or Recover an Instance Scenario 1 : Stop Idle Development and Test Instances Create an alarm that stops an instance used for software development or testing when it has been idle for at least an hour .
In order to use the MemoryUtilization metric , you must install the Perl scripts for Linux instances .
For more information , see Monitoring Memory and Disk Metrics for Amazon EC2 Linux Instances .
Events from AWS services are delivered to CloudWatch Events in near real time .
You can write simple rules to indicate which events are of interest to you , and the automated actions to take when an event matches a rule .
The actions that can be automatically triggered include the following : • Invoking an AWS Lambda function • Invoking Amazon EC2 Run Command • Relaying the event to Amazon Kinesis Data Streams • Activating an AWS Step Functions state machine • Notifying an Amazon SNS topic or an Amazon SQS queue Some examples of using CloudWatch Events with Amazon EC2 include : • Activating a Lambda function whenever a new Amazon EC2 instance starts .
• Notifying an Amazon SNS topic when an Amazon EBS volume is created or modiﬁed .
For more information , see the Amazon CloudWatch Events User Guide .
Monitoring Memory and Disk Metrics for Amazon EC2 Linux Instances You can use Amazon CloudWatch to collect metrics and logs from the operating systems for your EC2 instances .
CloudWatch Agent You can use the CloudWatch agent to collect both system metrics and log ﬁles from Amazon EC2 instances and on-premises servers .
The agent supports both Windows Server and Linux , and enables 674 Amazon Elastic Compute Cloud User Guide for Linux Instances CloudWatch Monitoring Scripts you to select the metrics to be collected , including sub-resource metrics such as per-CPU core .
We recommend that you use the agent to collect metrics and logs instead of using the monitoring scripts .
For more information , see Collect Metrics from Amazon EC2 Instances and On-Premises Servers with the CloudWatch Agent in the Amazon CloudWatch User Guide .
CloudWatch Monitoring Scripts Important We recommend that you use the CloudWatch agent to collect metrics and logs .
The information about the monitoring scripts is provided for customers who are still using the old monitoring scripts to gather information from their Linux instances .
The monitoring scripts demonstrate how to produce and consume custom metrics for Amazon CloudWatch .
These sample Perl scripts comprise a fully functional example that reports memory , swap , and disk space utilization metrics for a Linux instance .
Standard Amazon CloudWatch usage charges for custom metrics apply to your use of these scripts .
For more information , see the Amazon CloudWatch pricing page .
675 Amazon Elastic Compute Cloud User Guide for Linux Instances CloudWatch Monitoring Scripts Install Required Packages With some versions of Linux , you must install additional Perl modules before you can use the monitoring scripts .
To install the required packages on Amazon Linux 2 and Amazon Linux AMI 1 .
At the CPAN prompt , run each of the below commands : run one command and it installs , and when you return to the CPAN prompt , run the next command .
On servers running SUSE Linux Enterprise Server 12 , you might need to download the perlSwitch package .
• mon-get-instance-stats.pl – Queries Amazon CloudWatch and displays the most recent utilization statistics for the EC2 instance on which this script is executed .
• awscreds.template – File template for AWS credentials that stores your access key ID and secret access key .
677 Amazon Elastic Compute Cloud User Guide for Linux Instances CloudWatch Monitoring Scripts mon-put-instance-data.pl This script collects memory , swap , and disk space utilization data on the current system .
It then makes a remote call to Amazon CloudWatch to report the collected data as custom metrics .
This metric counts memory allocated by applications and the operating system as used , and also includes cache and buﬀer memory as used if you specify the -- mem-used-incl-cachebuff option .
This metric counts memory allocated by applications and the operating system as used , and also includes cache and buﬀer memory as used if you specify the -- mem-used-inclcache-buff option .
This metric counts memory allocated by applications and the operating system as used , and also includes cache and buﬀer memory as used if you specify the -- mem-used-inclcache-buff option .
PATH can specify a mount point or any ﬁle located on a mount point for the ﬁlesystem that needs to be reported .
The metric is reported in percentages .
Note that the disk utilization metrics calculated by this script diﬀer from the values calculated by the df -k -l command .
If you ﬁnd the values from df -k -l more useful , you can change the calculations in the script .
The metric is reported by default in gigabytes .
678 Amazon Elastic Compute Cloud User Guide for Linux Instances CloudWatch Monitoring Scripts Name Description Due to reserved disk space in Linux operating systems , disk space used and disk space available might not accurately add up to the amount of total disk space .
The metric is reported in gigabytes .
Due to reserved disk space in the Linux operating systems , disk space used and disk space available might not accurately add up to the amount of total disk space .
If not speciﬁed , disk space is reported in gigabytes .
-- aws-access-keyid=VALUE Speciﬁes the AWS access key ID to use to identify the caller .
-- aws-secret-key=VALUE Speciﬁes the AWS secret access key to use to sign the request to CloudWatch .
If no credentials are speciﬁed , the default IAM role associated with the EC2 instance is applied .
Only one IAM role can be used .
If no IAM roles are found , or if more than one IAM role is found , the script will return an error .
The IAM policy associated with the IAM account or role using the scripts need to have permissions to call the EC2 action DescribeTags .
-- verify Performs a test run of the script that collects the metrics , prepares a complete HTTP request , but does not actually call CloudWatch to report the data .
This option also checks that credentials are provided .
When run in verbose mode , this option outputs the metrics that will be sent to CloudWatch .
679 Amazon Elastic Compute Cloud User Guide for Linux Instances CloudWatch Monitoring Scripts Name Description -- from-cron Use this option when calling the script from cron .
When this option is used , all diagnostic output is suppressed , but error messages are sent to the local system log of the user account .
-- verbose Displays detailed information about what the script is doing .
Examples The following examples assume that you provided an IAM role or awscreds.conf ﬁle .
The following example performs a simple test run without posting data to CloudWatch .
mon-get-instance-stats.pl This script queries CloudWatch for statistics on memory , swap , and disk space metrics within the time interval provided using the number of most recent hours .
This data is provided for the Amazon EC2 instance on which this script is executed .
680 Amazon Elastic Compute Cloud User Guide for Linux Instances CloudWatch Monitoring Scripts Options Name Description -- recent-hours=N Speciﬁes the number of recent hours to report on , as represented by N where N is an integer .
-- aws-access-keyid=VALUE Speciﬁes the AWS access key ID to use to identify the caller .
-- aws-secret-key=VALUE Speciﬁes the AWS secret access key to use to sign the request to CloudWatch .
If no credentials are speciﬁed , the default IAM role associated with the EC2 instance is applied .
Only one IAM role can be used .
If no IAM roles are found , or if more than one IAM role is found , the script will return an error .
This option also checks that credentials are provided .
-- verbose Displays detailed information about what the script is doing .
For Viewing , your custom metrics posted by the script are displayed with the preﬁx System/Linux .
If you create an AMI from an instance where you have run the monitoring scripts , any instances launched from the AMI within the cache TTL ( default : six hours , 24 hours for Auto Scaling groups ) emit metrics using the instance ID of the original instance .
After the cache TTL time period passes , the script retrieves fresh data and the monitoring scripts use the instance ID of the current instance .
To immediately correct this , remove the cached data using the following command : rm /var/tmp/aws-mon/instance-id Logging Amazon EC2 and Amazon EBS API Calls with AWS CloudTrail Amazon EC2 and Amazon EBS are integrated with AWS CloudTrail , a service that provides a record of actions taken by a user , role , or an AWS service in Amazon EC2 and Amazon EBS .
CloudTrail captures all API calls for Amazon EC2 and Amazon EBS as events , including calls from the console and from code calls to the APIs .
If you create a trail , you can enable continuous delivery of CloudTrail events to an Amazon S3 bucket , including events for Amazon EC2 and Amazon EBS .
If you do n't conﬁgure a trail , you can still view the most recent events in the CloudTrail console in Event history .
Using the information collected by CloudTrail , you can determine the request that was made to Amazon EC2 and Amazon EBS , the IP address from which the request was made , who made the request , when it was made , and additional details .
To learn more about CloudTrail , see the AWS CloudTrail User Guide .
Amazon EC2 and Amazon EBS Information in CloudTrail CloudTrail is enabled on your AWS account when you create the account .
When activity occurs in Amazon EC2 and Amazon EBS , that activity is recorded in a CloudTrail event along with other AWS service events in Event history .
You can view , search , and download recent events in your AWS account .
For more information , see Viewing Events with CloudTrail Event History .
For an ongoing record of events in your AWS account , including events for Amazon EC2 and Amazon EBS , create a trail .
By default , when you create a trail in the console , the trail applies to all Regions .
The trail logs events from all Regions in the AWS partition and delivers the log ﬁles to the Amazon S3 bucket that you specify .
Additionally , you 682 Amazon Elastic Compute Cloud User Guide for Linux Instances Understanding Amazon EC2 and Amazon EBS Log File Entries can conﬁgure other AWS services to further analyze and act upon the event data collected in CloudTrail logs .
For more information , see : • Overview for Creating a Trail • CloudTrail Supported Services and Integrations • Conﬁguring Amazon SNS Notiﬁcations for CloudTrail • Receiving CloudTrail Log Files from Multiple Regions and Receiving CloudTrail Log Files from Multiple Accounts All Amazon EC2 and Amazon EBS actions are logged by CloudTrail and are documented in the Amazon EC2 API Reference .
For example , calls to the RunInstances , DescribeInstances , or CreateImage actions generate entries in the CloudTrail log ﬁles .
Every event or log entry contains information about who generated the request .
The identity information helps you determine the following : • Whether the request was made with root or IAM user credentials .
• Whether the request was made with temporary security credentials for a role or federated user .
• Whether the request was made by another AWS service .
Understanding Amazon EC2 and Amazon EBS Log File Entries A trail is a conﬁguration that enables delivery of events as log ﬁles to an Amazon S3 bucket that you specify .
CloudTrail log ﬁles contain one or more log entries .
An event represents a single request from any source and includes information about the requested action , the date and time of the action , request parameters , and so on .
CloudTrail log ﬁles are not an ordered stack trace of the public API calls , so they do not appear in any speciﬁc order .
The following log ﬁle record shows that a user terminated an instance .
To audit SSH activity via EC2 Instance Connect using the AWS CloudTrail console 1 .
Verify that you are in the correct Region .
The page displays the events that correspond to the SendSSHPublicKey API calls .
Expand an event using the arrow to view additional details , such as the user name and AWS access key that was used to make the SSH connection , and the source IP address .
To display the full event information in JSON format , choose View event .
The requestParameters ﬁeld contains the destination instance ID , OS user name , and public key that were used to make the SSH connection .
For more information , see Getting and Viewing Your CloudTrail Log Files in the AWS CloudTrail User Guide .
685 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance IP Addressing Networking in Amazon EC2 Amazon EC2 provides the following networking features .
You can optionally assign an IPv6 CIDR block to your VPC and subnets , and assign IPv6 addresses from that block to instances in your subnet .
For more information about IPv6 , see IP Addressing in Your VPC in the Amazon VPC User Guide .
You can use private IPv4 addresses for communication between instances in the same VPC .
Note You can create a VPC with a publicly routable CIDR block that falls outside of the private IPv4 address ranges speciﬁed in RFC 1918 .
However , for the purposes of this documentation , we refer 686 Amazon Elastic Compute Cloud User Guide for Linux Instances Public IPv4 Addresses and External DNS Hostnames to private IPv4 addresses ( or 'private IP addresses ' ) as the IP addresses that are within the IPv4 CIDR range of your VPC .
Each instance is also given an internal DNS hostname that resolves to the primary private IPv4 address ; for example , ip-10-251-50-12.ec2.internal .
You can use the internal DNS hostname for communication between instances in the same VPC , but we ca n't resolve the internal DNS hostname outside of the VPC .
An instance receives a primary private IP address from the IPv4 address range of the subnet .
For more information , see VPC and Subnet Sizing in the Amazon VPC User Guide .
If you do n't specify a primary private IP address when you launch the instance , we select an available IP address in the subnet 's IPv4 range for you .
Unlike primary private IP addresses , secondary private IP addresses can be reassigned from one instance to another .
A private IPv4 address , regardless of whether it is a primary or secondary address , remains associated with the network interface when the instance is stopped and restarted , and is released when the instance is terminated .
You can use public addresses for communication between your instances and the Internet .
We resolve an external DNS hostname to the public IP address of the instance from outside its VPC , and to the private IPv4 address of the instance from inside its VPC .
The public IP address is mapped to the primary private IP address through network address translation ( NAT ) .
When you launch an instance in a default VPC , we assign it a public IP address by default .
When you launch an instance into a nondefault VPC , the subnet has an attribute that determines whether instances launched into that subnet receive a public IP address from the public IPv4 address pool .
You can control whether your instance receives a public IP address as follows : • Modifying the public IP addressing attribute of your subnet .
For more information , see Modifying the Public IPv4 Addressing Attribute for Your Subnet in the Amazon VPC User Guide .
• Enabling or disabling the public IP addressing feature during launch , which overrides the subnet's public IP addressing attribute .
A public IP address is assigned to your instance from Amazon 's pool of public IPv4 addresses , and is not associated with your AWS account .
When a public IP address is disassociated from your instance , it is released back into the public IPv4 address pool , and you can not reuse it .
You can not manually associate or disassociate a public IP address from your instance .
Instead , in certain cases , we release the public IP address from your instance , or assign it a new one : • We release your instance 's public IP address when it is stopped or terminated .
Your stopped instance receives a new public IP address when it is restarted .
• We release your instance 's public IP address when you associate an Elastic IP address with it .
When you disassociate the Elastic IP address from your instance , it receives a new public IP address .
• If the public IP address of your instance in a VPC has been released , it will not receive a new one if there is more than one network interface attached to your instance .
687 Amazon Elastic Compute Cloud User Guide for Linux Instances Elastic IP Addresses ( IPv4 ) • If your instance 's public IP address is released while it has a secondary private IP address that is associated with an Elastic IP address , the instance does not receive a new public IP address .
If you require a persistent public IP address that can be associated to and from instances as you require , use an Elastic IP address instead .
If you use dynamic DNS to map an existing DNS name to a new instance 's public IP address , it might take up to 24 hours for the IP address to propagate through the Internet .
As a result , new instances might not receive traﬃc while terminated instances continue to receive requests .
To solve this problem , use an Elastic IP address .
You can allocate your own Elastic IP address , and associate it with your instance .
If you assign an Elastic IP address to an instance , it receives an IPv4 DNS hostname if DNS hostnames are enabled .
For more information , see Using DNS with Your VPC in the Amazon VPC User Guide .
Note Instances that access other instances through their public NAT IP address are charged for regional or Internet data transfer , depending on whether the instances are in the same Region .
You can associate it to and from instances as you require , and it 's allocated to your account until you choose to release it .
The Amazon DNS server is located at the base of your VPC network range plus two .
For more information , see Amazon DNS Server in the Amazon VPC User Guide .
IPv6 Addresses You can optionally associate an IPv6 CIDR block with your VPC , and associate IPv6 CIDR blocks with your subnets .
The IPv6 CIDR block for your VPC is automatically assigned from Amazon 's pool of IPv6 addresses ; you can not choose the range yourself .
For more information , see the following topics in the Amazon VPC User Guide : • VPC and Subnet Sizing for IPv6 • Associating an IPv6 CIDR Block with Your VPC • Associating an IPv6 CIDR Block with Your Subnet IPv6 addresses are globally unique , and therefore reachable over the Internet .
Your instance receives an IPv6 address if an IPv6 CIDR block is associated with your VPC and subnet , and if one of the following is true : • Your subnet is conﬁgured to automatically assign an IPv6 address to an instance during launch .
• You assign an IPv6 address to the primary network interface of your instance after launch .
• You assign an IPv6 address to a network interface in the same subnet , and attach the network interface to your instance after launch .
688 Amazon Elastic Compute Cloud User Guide for Linux Instances Working with IP Addresses for Your Instance When your instance receives an IPv6 address during launch , the address is associated with the primary network interface ( eth0 ) of the instance .
You can disassociate the IPv6 address from the network interface .
We do not support IPv6 DNS hostnames for your instance .
An IPv6 address persists when you stop and start your instance , and is released when you terminate your instance .
You can not reassign an IPv6 address while it 's assigned to another network interface—you must ﬁrst unassign it .
You can assign additional IPv6 addresses to your instance by assigning them to a network interface attached to your instance .
The number of IPv6 addresses you can assign to a network interface and the number of network interfaces you can attach to an instance varies per instance type .
Working with IP Addresses for Your Instance You can view the IP addresses assigned to your instance , assign a public IPv4 address to your instance during launch , or assign an IPv6 address to your instance during launch .
You can also determine the public IPv4 and private IPv4 addresses of your instance from within your instance by using instance metadata .
In the details pane , get the private IPv4 address from the Private IPs ﬁeld , and get the internal DNS hostname from the Private DNS ﬁeld .
If you have one or more secondary private IPv4 addresses assigned to network interfaces that are attached to your instance , get those IP addresses from the Secondary private IPs ﬁeld .
Alternatively , in the navigation pane , choose Network Interfaces , and then select the network interface that 's associated with your instance .
Get the primary private IP address from the Primary private IPv4 IP ﬁeld , and the internal DNS hostname from the Private DNS ( IPv4 ) ﬁeld .
If you 've assigned secondary private IP addresses to the network interface , get those IP addresses from the Secondary private IPv4 IPs ﬁeld .
In the details pane , get the public IP address from the IPv4 Public IP ﬁeld , and get the external DNS hostname from the Public DNS ( IPv4 ) ﬁeld .
689 Amazon Elastic Compute Cloud User Guide for Linux Instances Working with IP Addresses for Your Instance 4 .
If one or more Elastic IP addresses have been associated with the instance , get the Elastic IP addresses from the Elastic IPs ﬁeld .
Note If your instance does not have a public IPv4 address , but you 've associated an Elastic IP address with a network interface for the instance , the IPv4 Public IP ﬁeld displays the Elastic IP address .
Get the public IP address from the IPv4 Public IP ﬁeld .
Note The public IPv4 address is displayed as a property of the network interface in the console , but it 's mapped to the primary private IPv4 address through NAT .
To determine your instance 's public IPv4 address from within the instance , you can use instance metadata .
Determining Your IPv6 Addresses You can use the Amazon EC2 console to determine the IPv6 addresses of your instances .
690 Amazon Elastic Compute Cloud User Guide for Linux Instances Working with IP Addresses for Your Instance To determine your instance 's IPv6 addresses using the console 1 .
By default , nondefault subnets have this attribute set to false , and default subnets have this attribute set to true .
When you launch an instance , a public IPv4 addressing feature is also available for you to control whether your instance is assigned a public IPv4 address ; you can override the default behavior of the subnet 's IP addressing attribute .
The public IPv4 address is assigned from Amazon 's pool of public IPv4 addresses , and is assigned to the network interface with the device index of eth0 .
This feature depends on certain conditions at the time you launch your instance .
Important You ca n't manually disassociate the public IP address from your instance after launch .
If you require a persistent public IP address that you can associate or disassociate at will , assign an Elastic IP address to the instance after launch instead .
To access the public IP addressing feature when launching an instance 1 .
Select an AMI and an instance type , and then choose Next : Conﬁgure Instance Details .
Choose Enable or Disable to override the default setting for the subnet .
Important You can not auto-assign a public IP address if you specify more than one network interface .
Additionally , you can not override the subnet setting using the auto-assign public IP feature if you specify an existing network interface for eth0 .
691 Amazon Elastic Compute Cloud User Guide for Linux Instances Working with IP Addresses for Your Instance 5 .
Follow the steps on the next pages of the wizard to complete your instance 's setup .
On the ﬁnal Review Instance Launch page , review your settings , and then choose Launch to choose a key pair and launch your instance .
On the Instances page , select your new instance and view its public IP address in IPv4 Public IP ﬁeld in the details pane .
The public IP addressing feature is only available during launch .
However , whether you assign a public IP address to your instance during launch or not , you can associate an Elastic IP address with your instance after it 's launched .
For more information , see Modifying the Public IPv4 Addressing Attribute for Your Subnet .
To enable or disable the public IP addressing feature using the command line You can use one of the following commands .
The IPv6 address is assigned from the IPv6 address range of the subnet , and is assigned to the network interface with the device index of eth0 .
Select an AMI and an instance type that supports IPv6 , and choose Next : Conﬁgure Instance Details .
Follow the remaining steps in the wizard to launch your instance .
You can specify an IPv6 address from the range of the subnet , or leave the Auto-assign value to let Amazon choose an IPv6 address for you .
692 Amazon Elastic Compute Cloud User Guide for Linux Instances Multiple IP Addresses Note If you launched your instance using Amazon Linux 2016.09.0 or later , or Windows Server 2008 R2 or later , your instance is conﬁgured for IPv6 , and no additional steps are needed to ensure that the IPv6 address is recognized on the instance .
If you launched your instance from an older AMI , you may have to conﬁgure your instance manually .
For more information , see Conﬁgure IPv6 on Your Instances in the Amazon VPC User Guide .
To assign an IPv6 address using the command line You can use one of the following commands .
To unassign an IPv6 address using the command line You can use one of the following commands .
Multiple IP Addresses You can specify multiple private IPv4 and IPv6 addresses for your instances .
The number of network interfaces and private IPv4 and IPv6 addresses that you can specify for an instance depends on the instance type .
It can be useful to assign multiple IP addresses to an instance in your VPC to do the following : • Host multiple websites on a single server by using multiple SSL certiﬁcates on a single server and associating each certiﬁcate with a speciﬁc IP address .
• Operate network appliances , such as ﬁrewalls or load balancers , that have multiple IP addresses for each network interface .
• Redirect internal traﬃc to a standby instance in case your instance fails , by reassigning the secondary IP address to the standby instance .
The network interface need not be attached to the instance .
• You must choose IPv6 addresses from the IPv6 CIDR block range of the subnet for the network interface .
Therefore , each IP address you specify in a network interface is subject to the security group of its network interface .
• Multiple IP addresses can be assigned and unassigned to network interfaces attached to running or stopped instances .
• Secondary private IPv4 addresses that are assigned to a network interface can be reassigned to another one if you explicitly allow it .
• An IPv6 address can not be reassigned to another network interface ; you must ﬁrst unassign the IPv6 address from the existing network interface .
• When assigning multiple IP addresses to a network interface using the command line tools or API , the entire operation fails if one of the IP addresses ca n't be assigned .
• Although you ca n't detach the primary network interface from an instance , you can reassign the secondary private IPv4 address of the primary network interface to another network interface .
• When a secondary private IPv4 address is reassigned to another interface , the secondary private IPv4 address retains its association with an Elastic IP address .
• When a secondary private IPv4 address is unassigned from an interface , an associated Elastic IP address is automatically disassociated from the secondary private IPv4 address .
This section includes the following procedures .
Select an AMI , then choose an instance type and choose Next : Conﬁgure Instance Details .
The console enables you to specify up to two network interfaces when you launch an instance .
After you launch the instance , choose Network Interfaces in the navigation pane to add additional network interfaces .
The total number of network interfaces that you can attach varies by instance type .
You will not be able to connect to the instance over IPv4 unless you assign an Elastic IP address to the primary network interface ( eth0 ) .
You can assign the Elastic IP address after you complete the Launch wizard .
• For each network interface , under Secondary IP addresses , choose Add IP , and then enter a private IP address from the subnet range , or accept the default Auto-assign value to let Amazon select an address .
On the next Add Storage page , you can specify volumes to attach to the instance besides the volumes speciﬁed by the AMI ( such as the root device volume ) , and then choose Next : Add Tags .
On the Conﬁgure Security Group page , select an existing security group or create a new one .
On the Review Instance Launch page , review your settings , and then choose Launch to choose a key pair and launch your instance .
If you 're new to Amazon EC2 and have n't created any key pairs , the wizard prompts you to create one .
Important After you have added a secondary private IP address to a network interface , you must connect to the instance and conﬁgure the secondary private IP address on the instance itself .
For 695 Amazon Elastic Compute Cloud User Guide for Linux Instances Multiple IP Addresses more information , see Conﬁguring the Operating System on Your Instance to Recognize the Secondary Private IPv4 Address ( p. 696 ) .
To assign a secondary IPv4 address during launch using the command line • You can use one of the following commands .
In the navigation pane , choose Network Interfaces , and then select the network interface attached to the instance .
Enter a speciﬁc IPv4 address that 's within the subnet range for the instance , or leave the ﬁeld blank to let Amazon select an IP address for you .
( Optional ) Choose Allow reassignment to allow the secondary private IP address to be reassigned if it is already assigned to another network interface .
You can conﬁgure the same information as you did in the steps above .
To assign a secondary private IPv4 to an existing instance using the command line • You can use one of the following commands .
• assign-private-ip-addresses ( AWS CLI ) • Register-EC2PrivateIpAddress ( AWS Tools for Windows PowerShell ) Conﬁguring the Operating System on Your Instance to Recognize the Secondary Private IPv4 Address After you assign a secondary private IPv4 address to your instance , you need to conﬁgure the operating system on your instance to recognize the secondary private IP address .
• If you are using Amazon Linux , the ec2-net-utils package can take care of this step for you .
It conﬁgures additional network interfaces that you attach while the instance is running , refreshes secondary IPv4 addresses during DHCP lease renewal , and updates the related routing rules .
You can immediately refresh the list of interfaces by using the command sudo service network restart and then view the up-to-date list using ip addr li .
If you require manual control over your network conﬁguration , you can remove the ec2-net-utils package .
• If you are using another Linux distribution , see the documentation for your Linux distribution .
Search for information about conﬁguring additional network interfaces and secondary IPv4 addresses .
If the 696 Amazon Elastic Compute Cloud User Guide for Linux Instances Multiple IP Addresses instance has two or more interfaces on the same subnet , search for information about using routing rules to work around asymmetric routing .
For information about conﬁguring a Windows instance , see Conﬁguring a secondary private IP address for your Windows instance in a VPC in the Amazon EC2 User Guide for Windows Instances .
Associating an Elastic IP Address with the Secondary Private IPv4 Address To associate an Elastic IP address with a secondary private IPv4 address 1 .
For Network interface , select the network interface , and then select the secondary IP address from the Private IP list .
To associate an Elastic IP address with a secondary private IPv4 address using the command line • You can use one of the following commands .
Select the network interface with private IP addresses to view .
On the Details tab in the details pane , check the Primary private IPv4 IP and Secondary private IPv4 IPs ﬁelds for the primary private IPv4 address and any secondary private IPv4 addresses assigned to the network interface .
On the Description tab in the details pane , check the Private IPs and Secondary private IPs ﬁelds for the primary private IPv4 address and any secondary private IPv4 addresses assigned to the instance through its network interface .
Unassigning a Secondary Private IPv4 Address If you no longer require a secondary private IPv4 address , you can unassign it from the instance or the network interface .
697 Amazon Elastic Compute Cloud User Guide for Linux Instances Multiple IP Addresses To unassign a secondary private IPv4 address from an instance 1 .
To unassign a secondary private IPv4 address using the command line • You can use one of the following commands .
To assign an IPv6 address to an instance , the VPC and subnet in which you launch the instance must have an associated IPv6 CIDR block .
For more information , see VPCs and Subnets in the Amazon VPC User Guide .
Ensure that you choose an instance type that support IPv6 .
On the Conﬁgure Instance Details page , select a VPC from the Network list , and a subnet from the Subnet list .
You can enter an IPv6 address from the range of the subnet , or leave the default Auto-assign value to let Amazon choose an IPv6 address from the subnet for you .
• Choose Add Device to add another network interface and repeat the steps above to add one or more IPv6 addresses to the network interface .
The console enables you to specify up to two network interfaces when you launch an instance .
After you launch the instance , choose Network Interfaces in the navigation pane to add additional network interfaces .
The total number of network interfaces that you can attach varies by instance type .
Follow the next steps in the wizard to attach volumes and tag your instance .
On the Conﬁgure Security Group page , select an existing security group or create a new one .
If you want your instance to be reachable over IPv6 , ensure that your security group has rules that allow access from IPv6 addresses .
On the Review Instance Launch page , review your settings , and then choose Launch to choose a key pair and launch your instance .
If you 're new to Amazon EC2 and have n't created any key pairs , the wizard prompts you to create one .
You can use the Instances screen Amazon EC2 console to assign multiple IPv6 addresses to an existing instance .
To assign a speciﬁc IPv6 address to the instance , ensure that the IPv6 address is not already assigned to another instance or network interface .
You can specify an IPv6 address from the range of the subnet , or leave the Auto-assign value to let Amazon choose an IPv6 address for you .
The network interface must have been created in a subnet that has an associated IPv6 CIDR block .
To assign a speciﬁc IPv6 address to the network interface , ensure that the IPv6 address is not already assigned to another network interface .
You can specify an IPv6 address from the range of the subnet , or leave the Auto-assign value to let Amazon choose an IPv6 address for you .
699 Amazon Elastic Compute Cloud User Guide for Linux Instances Multiple IP Addresses CLI Overview You can use one of the following commands .
CLI Overview You can use one of the following commands .
700 Amazon Elastic Compute Cloud User Guide for Linux Instances Bring Your Own IP Addresses 3 .
CLI Overview You can use one of the following commands .
Bring Your Own IP Addresses ( BYOIP ) You can bring part or all of your public IPv4 address range from your on-premises network to your AWS account .
You continue to own the address range , but AWS advertises it on the internet .
After you bring the address range to AWS , it appears in your account as an address pool .
You can create an Elastic IP address from your address pool and use it with your AWS resources , such as EC2 instances , NAT gateways , and Network Load Balancers .
Important BYOIP is not available in all Regions .
For a list of supported Regions , see the FAQ for Bring Your Own IP .
It must be registered to a business or institutional entity and can not be registered to an individual person .
• You can bring ﬁve address ranges per Region to your AWS account .
We might investigate the reputation of the IP address range and reserve the right to reject an IP address range if it contains an IP address that has poor reputation or is associated with malicious behavior .
• You must own the IP address that you use .
This means that only the following are supported : • ARIN - `` Direct Allocation '' and `` Direct Assignment '' network types • RIPE - `` ALLOCATED PA '' , `` LEGACY '' , and `` ASSIGNED PI '' allocation statuses • APNIC – `` ALLOCATED PORTABLE '' and `` ASSIGNED PORTABLE '' allocation statuses 701 Amazon Elastic Compute Cloud User Guide for Linux Instances Prepare to Bring Your Address Range to Your AWS Account Prepare to Bring Your Address Range to Your AWS Account To ensure that only you can bring your address range to your AWS account , you must authorize Amazon to advertise the address range .
You must also provide proof that you own the address range through a signed authorization message .
A Route Origin Authorization ( ROA ) is a cryptographic statement about your route announcements that you can create through your RIR .
It contains the address range , the Autonomous System numbers ( ASN ) that are allowed to advertise the address range , and an expiration date .
An ROA authorizes Amazon to advertise an address range under a speciﬁc AS number .
However , it does not authorize your AWS account to bring the address range to AWS .
To authorize your AWS account to bring an address range to AWS , you must publish a self-signed X509 certiﬁcate in the Registry Data Access Protocol ( RDAP ) remarks for the address range .
The certiﬁcate contains a public key , which AWS uses to verify the authorizationcontext signature that you provide .
You should keep your private key secure and use it to sign the authorization-context message .
The commands in these tasks are supported on Linux .
On Windows , you can use the Windows Subsystem for Linux to run Linux commands .
You must set the maximum length to the size of the smallest preﬁx that you want to bring ( for example , /24 ) .
It might take up to 24 hours for the ROA to become available to Amazon .
Generate an RSA 2048-bit key pair as shown in the following .
In this example , the certiﬁcate expires in 365 days , after which time it can not be trusted .
When prompted for information , you can accept the default values .
Update the RDAP record for your RIR with the X509 certiﬁcate .
Send the email using the APNIC authorized contact for the IP addresses .
Create a Signed Authorization Message The format of the signed authorization message is as follows , where the date is the expiry date of the message .
Replace the example account number , address range , and expiry date with your own values .
We also verify that you own the address range through a signed authorization message .
This message is signed with the self-signed X509 key pair that you used when updating the RDAP record with the X509 certiﬁcate .
Replace the example address range with your own address range .
It can take up to three weeks to complete the provisioning process .
To monitor the status of the address ranges that you 've provisioned , use the following describe-byoip-cidrs command .
You can use the -- public-ipv4-pool option to specify the ID of the address pool returned by describe-byoipcidrs .
Or you can use the -- address option to specify an address from the address range that you provisioned .
Advertise the Address Range through AWS After the address range is provisioned , it is ready to be advertised .
You must advertise the exact address range that you provisioned .
We recommend that you stop advertising the address range from other locations before you advertise it through AWS .
If you keep advertising your IP address range from other locations , we ca n't reliably support it or troubleshoot issues .
Speciﬁcally , we ca n't guarantee that traﬃc to the address range will enter our network .
To minimize down time , you can conﬁgure your AWS resources to use an address from your address pool before it is advertised , and then simultaneously stop advertising it from the current location and start advertising it through AWS .
Deprovision the Address Range To stop using your address range with AWS , you release any Elastic IP addresses still allocated from the address pool , stop advertising the address range , and then deprovision the address range .
aws ec2 deprovision-byoip-cidr -- cidr address-range 704 Amazon Elastic Compute Cloud User Guide for Linux Instances Elastic IP addresses Elastic IP addresses An Elastic IP address is a static IPv4 address designed for dynamic cloud computing .
An Elastic IP address is associated with your AWS account .
With an Elastic IP address , you can mask the failure of an instance or software by rapidly remapping the address to another instance in your account .
If your instance does not have a public IPv4 address , you can associate an Elastic IP address with your instance to enable communication with the internet .
For example , this allows you to connect to your instance from your local computer .
We currently do not support Elastic IP addresses for IPv6 .
• When you associate an Elastic IP address with an instance , it is also associated with the instance's primary network interface .
When you associate an Elastic IP address with a network interface that is attached to an instance , it is also associated with the instance .
• When you associate an Elastic IP address with an instance or its primary network interface , the instance 's public IPv4 address ( if it had one ) is released back into Amazon 's pool of public IPv4 addresses .
Any open connections to an instance continue to work for a time even after you disassociate its Elastic IP address and reassociate it with another instance .
We recommend that you reopen these connections using the reassociated Elastic IP address .
• A disassociated Elastic IP address remains allocated to your account until you explicitly release it .
• To ensure eﬃcient use of Elastic IP addresses , we impose a small hourly charge if an Elastic IP address is not associated with a running instance , or if it is associated with a stopped instance or an unattached network interface .
While your instance is running , you are not charged for one Elastic IP address associated with the instance , but you are charged for any additional Elastic IP addresses associated with the instance .
• An Elastic IP address is for use in a speciﬁc network border group only .
• When you associate an Elastic IP address with an instance that previously had a public IPv4 address , the public DNS host name of the instance changes to match the Elastic IP address .
• We resolve a public DNS host name to the public IPv4 address or the Elastic IP address of the instance outside the network of the instance , and to the private IPv4 address of the instance from within the network of the instance .
• When you allocate an Elastic IP address from an IP address pool that you have brought to your AWS account , it does not count toward your Elastic IP address limits .
705 Amazon Elastic Compute Cloud User Guide for Linux Instances Working with Elastic IP addresses • When you allocate the Elastic IP addresses , you can associate the Elastic IP addresses with a network border group .
This is the location from which we advertise the CIDR block .
Setting the network border group limits the CIDR block to this group .
If you do not specify the network border group , we set the border group containing all of the Availability Zones in the Region ( for example , us-west-2 ) .
Working with Elastic IP addresses The following sections describe how you can work with Elastic IP addresses .
You can allocate an Elastic IP address using one of the following methods .
For Scope , choose either VPC or EC2-Classic depending on the scope in which it will be used .
• My pool of public IPv4 addresses—If you want to allocate an IPv4 address from an IP address pool that you have brought to your AWS account .
This option is disabled if you do not have any IP address pools .
This option is disabled if you do not have an AWS Outpost .
706 Amazon Elastic Compute Cloud User Guide for Linux Instances Working with Elastic IP addresses 2 .
AWS CLI To allocate an Elastic IP address Use the allocate-address AWS CLI command .
PowerShell To allocate an Elastic IP address Use the New-EC2Address AWS Tools for Windows PowerShell command .
Describing your Elastic IP addresses You can describe an Elastic IP address using one of the following methods .
Select the Elastic IP address to view and choose Actions , View details .
Select a ﬁlter from the Resource Attribute list to begin searching .
AWS CLI To describe your Elastic IP addresses Use the describe-addresses AWS CLI command .
PowerShell To describe your Elastic IP addresses Use the Get-EC2Address AWS Tools for Windows PowerShell command .
Tagging an Elastic IP address You can assign custom tags to your Elastic IP addresses to categorize them in diﬀerent ways , for example , by purpose , owner , or environment .
This helps you to quickly ﬁnd a speciﬁc Elastic IP address based on the custom tags that you assigned to it .
707 Amazon Elastic Compute Cloud User Guide for Linux Instances Working with Elastic IP addresses You can only tag Elastic IP addresses that are in the VPC scope .
Note Cost allocation tracking using Elastic IP address tags is not supported .
You can tag an Elastic IP address using one of the following methods .
Select the Elastic IP address to tag and choose Actions , View details .
Select the Elastic IP address to tag and choose Tags .
In the Add/Edit Tags dialog box , choose Create Tag , and then specify the key and value for the tag .
( Optional ) Choose Create Tag to add additional tags to the Elastic IP address .
AWS CLI To tag an Elastic IP address Use the create-tags AWS CLI command .
The New-EC2Tag command needs a Tag parameter , which speciﬁes the key and value pair to be used for the Elastic IP address tag .
The following commands create the Tag parameter .
For more information , see Internet Gateways in the Amazon VPC User Guide .
You can associate an Elastic IP address with an instance or network interface using one of the following methods .
New console To associate an Elastic IP address with an instance 1 .
Select the Elastic IP address to associate and choose Actions , Associate Elastic IP address .
For instance , choose the instance with which to associate the Elastic IP address .
You can also enter text to search for a speciﬁc instance .
Select the Elastic IP address to associate and choose Actions , Associate Elastic IP address .
For Network interface , choose the network interface with which to associate the Elastic IP address .
You can also enter text to search for a speciﬁc network interface .
Old console To associate an Elastic IP address with an instance 1 .
Select an Elastic IP address and choose Actions , Associate address .
Select the instance from Instance and then choose Associate .
AWS CLI To associate an Elastic IP address Use the associate-address AWS CLI command .
709 Amazon Elastic Compute Cloud User Guide for Linux Instances Working with Elastic IP addresses PowerShell To associate an Elastic IP address Use the Register-EC2Address AWS Tools for Windows PowerShell command .
Disassociating an Elastic IP address You can disassociate an Elastic IP address from an instance or network interface at any time .
After you disassociate the Elastic IP address , you can reassociate it with another resource .
You can disassociate an Elastic IP address using one of the following methods .
New console To disassociate and reassociate an Elastic IP address 1 .
Select the Elastic IP address to disassociate , choose Actions , Disassociate Elastic IP address .
Old console To disassociate and reassociate an Elastic IP address 1 .
Select the Elastic IP address , choose Actions , and then select Disassociate address .
AWS CLI To disassociate an Elastic IP address Use the disassociate-address AWS CLI command .
PowerShell To disassociate an Elastic IP address Use the Unregister-EC2Address AWS Tools for Windows PowerShell command .
Releasing an Elastic IP address If you no longer need an Elastic IP address , we recommend that you release it using one of the following methods .
The address that you release must not be associated with an instance .
Select the Elastic IP address to release and choose Actions , Release Elastic IP addresses .
710 Amazon Elastic Compute Cloud User Guide for Linux Instances Using reverse DNS for email applications Old console To release an Elastic IP address 1 .
Select the Elastic IP address , choose Actions , and then select Release addresses .
AWS CLI To release an Elastic IP address Use the release-address AWS CLI command .
PowerShell To release an Elastic IP address Use the Remove-EC2Address AWS Tools for Windows PowerShell command .
Recovering an Elastic IP address If you have released your Elastic IP address , you might be able to recover it .
The following rules apply : • You can not recover an Elastic IP address if it has been allocated to another AWS account , or if it will result in your exceeding your Elastic IP address limit .
• You can not recover tags associated with an Elastic IP address .
• You can recover an Elastic IP address using the Amazon EC2 API or a command line tool only .
AWS CLI To recover an Elastic IP address Use the allocate-address AWS CLI command and specify the IP address using the -- address parameter as follows .
aws ec2 allocate-address -- domain vpc -- address 203.0.113.3 PowerShell To recover an Elastic IP address Use the New-EC2Address AWS Tools for Windows PowerShell command and specify the IP address using the -Address parameter as follows .
AWS works with ISPs and internet anti-spam organizations to reduce the chance that your email sent from these addresses will be ﬂagged as spam .
In addition , assigning a static reverse DNS record to your Elastic IP address that is used to send email can help avoid having email ﬂagged as spam by some anti-spam organizations .
Note that a corresponding 711 Amazon Elastic Compute Cloud User Guide for Linux Instances Elastic IP address limit forward DNS record ( record type A ) pointing to your Elastic IP address must exist before we can create your reverse DNS record .
If a reverse DNS record is associated with an Elastic IP address , the Elastic IP address is locked to your account and can not be released from your account until the record is removed .
To remove email sending limits , or to provide us with your Elastic IP addresses and reverse DNS records , go to the Request to Remove Email Sending Limitations page .
We strongly encourage you to use an Elastic IP address primarily for the ability to remap the address to another instance in the case of instance failure , and to use DNS hostnames for all other inter-node communication .
To verify how many Elastic IP addresses are in use , open the Amazon EC2 console at https : // console.aws.amazon.com/ec2/ and choose Elastic IPs from the navigation pane .
To verify your current account limit for Elastic IP addresses , do one of the following : • Open the Amazon EC2 console at https : //console.aws.amazon.com/ec2/ , choose Limits from the navigation pane , and enter IP in the search ﬁeld .
Enter IP in the search ﬁeld .
If you feel your architecture warrants additional Elastic IP addresses , you can request a quota increase directly from the Service Quotas console .
Elastic Network Interfaces An elastic network interface ( referred to as a network interface in this documentation ) is a logical networking component in a VPC that represents a virtual network card .
Your account might also have requester-managed network interfaces , which are created and managed by AWS services to enable you to use other resources and services .
You can not manage these network interfaces yourself .
712 Amazon Elastic Compute Cloud User Guide for Linux Instances Network Interface Basics Important The term 'elastic network interface ' is sometimes shortened to 'ENI ' .
This is not the same as the Elastic Network Adapter ( ENA ) , which is a custom interface that optimizes network performance on some instance types .
The attributes of a network interface follow it as it 's attached or detached from an instance and reattached to another instance .
When you move a network interface from one instance to another , network traﬃc is redirected to the new instance .
You can also modify the attributes of your network interface , including changing its security groups and managing its IP addresses .
You can not detach a primary network interface from an instance .
You can create and attach additional network interfaces .
The maximum number of network interfaces that you can use varies by instance type .
Public IPv4 addresses for network interfaces In a VPC , all subnets have a modiﬁable attribute that determines whether network interfaces created in that subnet ( and therefore instances launched into that subnet ) are assigned a public IPv4 address .
For more information , see IP Addressing Behavior for Your Subnet in the Amazon VPC User Guide .
If you later modify the public IPv4 addressing attribute of the subnet , the network interface keeps the setting that was in eﬀect when it was created .
If you launch an instance and specify an existing network interface for eth0 , the public IPv4 addressing attribute is determined by the network interface .
IPv6 addresses for network interfaces You can associate an IPv6 CIDR block with your VPC and subnet , and assign one or more IPv6 addresses from the subnet range to a network interface .
All subnets have a modiﬁable attribute that determines whether network interfaces created in that subnet ( and therefore instances launched into that subnet ) are automatically assigned an IPv6 address from the range of the subnet .
For more information , see IP Addressing Behavior for Your Subnet in the Amazon VPC User Guide .
Monitoring IP Traﬃc 713 Amazon Elastic Compute Cloud User Guide for Linux Instances IP Addresses Per Network Interface Per Instance Type You can enable a VPC ﬂow log on your network interface to capture information about the IP traﬃc going to and from a network interface .
After you 've created a ﬂow log , you can view and retrieve its data in Amazon CloudWatch Logs .
For more information , see VPC Flow Logs in the Amazon VPC User Guide .
IP Addresses Per Network Interface Per Instance Type The following table lists the maximum number of network interfaces per instance type , and the maximum number of private IPv4 addresses and IPv6 addresses per network interface .
The limit for IPv6 addresses is separate from the limit for private IPv4 addresses per network interface .
For more information about IPv6 in VPC , see IP Addressing in Your VPC in the Amazon VPC User Guide .
In this scenario , the primary network interface ( eth0 ) on the instance handles public traﬃc and the secondary network interface ( eth1 ) handles backend management traﬃc and is connected to a separate subnet in your VPC that has more restrictive access controls .
The public interface , which may or may not be behind a load balancer , has an associated security group that allows access to the server from the internet ( for example , allow TCP port 80 and 443 from 0.0.0.0/0 , or from the load balancer ) while the private facing interface has an associated security group allowing SSH access only from an allowed range of IP addresses either within the VPC or from the internet , a private subnet within the VPC or a virtual private gateway .
In the event of an instance failure , you can move the interface and/or secondary private IPv4 address to a standby instance .
723 Amazon Elastic Compute Cloud User Guide for Linux Instances Scenarios for Network Interfaces Use Network and Security Appliances in Your VPC Some network and security appliances , such as load balancers , network address translation ( NAT ) servers , and proxy servers prefer to be conﬁgured with multiple network interfaces .
You can create and attach secondary network interfaces to instances in a VPC that are running these types of applications and conﬁgure the additional interfaces with their own public and private IP addresses , security groups , and source/destination checking .
Creating Dual-homed Instances with Workloads/Roles on Distinct Subnets You can place a network interface on each of your web servers that connects to a mid-tier network where an application server resides .
Instead of routing network packets through the dualhomed instances , each dual-homed instance receives and processes requests on the front end , initiates a connection to the backend , and then sends requests to the servers on the backend network .
Create a Low Budget High Availability Solution If one of your instances serving a particular function fails , its network interface can be attached to a replacement or hot standby instance pre-conﬁgured for the same role in order to rapidly recover the service .
For example , you can use a network interface as your primary or secondary network interface to 724 Amazon Elastic Compute Cloud User Guide for Linux Instances Best Practices for Conﬁguring Network Interfaces a critical service such as a database instance or a NAT instance .
If the instance fails , you ( or more likely , the code running on your behalf ) can attach the network interface to a hot standby instance .
Because the interface maintains its private IP addresses , Elastic IP addresses , and MAC address , network traﬃc begins ﬂowing to the standby instance as soon as you attach the network interface to the replacement instance .
Users experience a brief loss of connectivity between the time the instance fails and the time that the network interface is attached to the standby instance , but no changes to the VPC route table or your DNS server are required .
• You can detach secondary network interfaces when the instance is running or stopped .
• You can move a network interface from one instance to another , if the instances are in the same Availability Zone and VPC but in diﬀerent subnets .
• Launching an Amazon Linux or Windows Server instance with multiple network interfaces automatically conﬁgures interfaces , private IPv4 addresses , and route tables on the operating system of the instance .
• A warm or hot attach of an additional network interface may require you to manually bring up the second interface , conﬁgure the private IPv4 address , and modify the route table accordingly .
Instances running Amazon Linux or Windows Server automatically recognize the warm or hot attach and conﬁgure themselves .
• Attaching another network interface to an instance ( for example , a NIC teaming conﬁguration ) can not be used as a method to increase or double the network bandwidth to or from the dual-homed instance .
• If you attach two or more network interfaces from the same subnet to an instance , you may encounter networking issues such as asymmetric routing .
Conﬁguring Your Network Interface Using ec2-net-utils Amazon Linux AMIs may contain additional scripts installed by AWS , known as ec2-net-utils .
These scripts optionally automate the conﬁguration of your network interfaces .
These scripts are available for Amazon Linux only .
725 Amazon Elastic Compute Cloud User Guide for Linux Instances Working with Network Interfaces hotplug script Generates an interface conﬁguration ﬁle suitable for use with DHCP ( /etc/sysconfig/networkscripts/ifcfg-ethN ) .
DHCP script Whenever the network interface receives a new DHCP lease , this script queries the instance metadata for Elastic IP addresses .
For each Elastic IP address , it adds a rule to the routing policy database to ensure that outbound traﬃc from that address uses the correct network interface .
It also adds each private IP address to the network interface as a secondary address .
After this script removes any rules for the network interface from the routing policy database , it runs ifdown .
ec2ifscan Checks for network interfaces that have not been conﬁgured and conﬁgures them .
For example , use the following command to disable the automation for the eth1 interface : $ sed -i -e 's/^EC2SYNC=yes/EC2SYNC=no/ ' /etc/sysconfig/network-scripts/ifcfg-eth1 To disable the automation completely , you can remove the package using the following command : $ yum remove ec2-net-utils Working with Network Interfaces You can work with network interfaces using the Amazon EC2 console or the command line .
You ca n't move the network interface to another subnet after it 's created , and you can only attach the network interface to instances in the same Availability Zone .
For Security groups , select one or more security groups .
To create a network interface using the command line You can use one of the following commands .
Deleting a network interface releases all attributes associated with the interface and releases any private IP addresses or Elastic IP addresses to be used by another instance .
727 Amazon Elastic Compute Cloud User Guide for Linux Instances Working with Network Interfaces 4 .
To delete a network interface using the command line You can use one of the following commands .
To describe a network interface using the command line You can use one of the following commands .
Note If an error occurs when attaching a network interface to your instance , this causes the instance launch to fail .
Select an AMI and instance type and choose Next : Conﬁgure Instance Details .
728 Amazon Elastic Compute Cloud User Guide for Linux Instances Working with Network Interfaces 5 .
In the Network Interfaces section , the console enables you to specify up to two network interfaces ( new , existing , or a combination ) when you launch an instance .
You can also enter a primary IPv4 address and one or more secondary IPv4 addresses for any new interface .
You can add additional network interfaces to the instance after you launch it .
The total number of network interfaces that you can attach varies by instance type .
You can enter an IPv6 address from the range of the subnet , or leave the default Auto-assign value to let Amazon choose an IPv6 address from the subnet for you .
On the Add Storage page , you can specify volumes to attach to the instance besides the volumes speciﬁed by the AMI ( such as the root device volume ) , and then choose Next : Add Tags .
On the Conﬁgure Security Group page , you can select a security group or create a new one .
Note If you speciﬁed an existing network interface in step 5 , the instance is associated with the security group for that network interface , regardless of any option that you select in this step .
On the Review Instance Launch page , details about the primary and additional network interface are displayed .
Review the settings , and then choose Launch to choose a key pair and launch your instance .
If you 're new to Amazon EC2 and have n't created any key pairs , the wizard prompts you to create one .
To attach a network interface when launching an instance using the command line You can use one of the following commands .
Note If the public IPv4 address on your instance is released , it does not receive a new one if there is more than one network interface attached to the instance .
729 Amazon Elastic Compute Cloud User Guide for Linux Instances Working with Network Interfaces 2 .
In the Attach Network Interface dialog box , select the network interface and choose Attach .
To attach a network interface to an instance using the Network Interfaces page 1 .
Select the network interface and choose Attach .
In the Attach Network Interface dialog box , select the instance and choose Attach .
To attach a network interface to an instance using the command line You can use one of the following commands .
In the Detach Network Interface dialog box , select the network interface and choose Detach .
The network interfaces for those resources will be deleted when the resource is deleted .
To detach a network interface from an instance using the Network Interfaces page 1 .
Select the network interface and check the description to verify that the network interface is attached to an instance , not another type of resource .
If the network interface is the primary network interface for the instance , the Detach button is disabled .
If the network interface fails to detach from the instance , choose Force detachment and then try again .
We recommend that you choose this option only as a last resort .
Forcing a detachment can prevent you from attaching a diﬀerent network interface on the same index until you restart the 730 Amazon Elastic Compute Cloud User Guide for Linux Instances Working with Network Interfaces instance .
It can also prevent the instance metadata from reﬂecting that the network interface was detached until you restart the instance .
To detach a network interface using the command line You can use one of the following commands .
When you create the security group , be sure to specify the same VPC as the subnet for the network interface .
Note To change security group membership for interfaces owned by other services , such as Elastic Load Balancing , use the console or command line interface for that service .
Select the network interface and choose Actions , Change Security Groups .
In the Change Security Groups dialog box , select the security groups to use , and choose Save .
To change the security group of a network interface using the command line You can use one of the following commands .
Disabling this attribute enables an instance to handle network traﬃc that is n't speciﬁcally destined for the instance .
For example , instances running services such as network address translation , routing , or a ﬁrewall should set this value to disabled .
To change source/destination checking for a network interface using the command line You can use one of the following commands .
You can associate one Elastic IP address with each private IPv4 address .
You can associate an Elastic IP address using the Amazon EC2 console or the command line .
To associate an Elastic IP address using the console 1 .
Select the network interface and choose Actions , Associate Address .
In the Associate Elastic IP Address dialog box , select the Elastic IP address from the Address list .
For Associate to private IP address , select the private IPv4 address to associate with the Elastic IP address .
Choose Allow reassociation to allow the Elastic IP address to be associated with the speciﬁed network interface if it 's currently associated with another instance or network interface , and then choose Associate Address .
To associate an Elastic IP address using the command line You can use one of the following commands .
This is the only way to associate an Elastic IP address with an instance in a diﬀerent subnet or VPC using a network interface , as network interfaces are speciﬁc to a particular subnet .
You can disassociate an Elastic IP address using the Amazon EC2 console or the command line .
To disassociate an Elastic IP address using the console 1 .
Select the network interface and choose Actions , Disassociate Address .
To disassociate an Elastic IP address using the command line You can use one of the following commands .
The network interface must be in a subnet that has an associated IPv6 CIDR block .
To assign a speciﬁc IPv6 address to the network interface , ensure that the IPv6 address is not already assigned to another network interface .
In the navigation pane , choose Network Interfaces and select the network interface .
Specify an IPv6 address from the range of the subnet .
To assign an IPv6 address to a network interface using the command line • You can use one of the following commands .
In the navigation pane , choose Network Interfaces and select the network interface .
To unassign an IPv6 address from a network interface using the command line • You can use one of the following commands .
You can specify whether the network interface should be automatically deleted when you terminate the instance to which it 's attached .
You can change the terminating behavior for a network interface using the Amazon EC2 console or the command line .
733 Amazon Elastic Compute Cloud User Guide for Linux Instances Working with Network Interfaces To change the termination behavior for a network interface using the console 1 .
Select the network interface and choose Actions , Change Termination Behavior .
In the Change Termination Behavior dialog box , select the Delete on termination check box if you want the network interface to be deleted when you terminate an instance .
To change the termination behavior for a network interface using the command line You can use one of the following commands .
Select the network interface and choose Actions , Change Description .
In the Change Description dialog box , enter a description for the network interface , and then choose Save .
To change the description for a network interface using the command line You can use one of the following commands .
Tags are private and are only visible to your account .
Each tag consists of a key and an optional value .
In the Add/Edit Tags dialog box , choose Create Tag for each tag to create , and enter a key and optional value .
734 Amazon Elastic Compute Cloud User Guide for Linux Instances Requester-Managed Network Interfaces To add or edit tags for a network interface using the command line You can use one of the following commands .
This network interface can represent an instance for another service , such as an Amazon RDS instance , or it can enable you to access another service or resource , such as an AWS PrivateLink service , or an Amazon ECS task .
If you delete the resource that the network interface represents , the AWS service detaches and deletes the network interface for you .
To change the security groups for a requester-managed network interface , you might have to use the console or command line tools for that service .
You can view the requester-managed network interfaces that are in your account .
Select the network interface and view the following information on the details pane : • Attachment owner : If you created the network interface , this ﬁeld displays your AWS account ID .
Otherwise , it displays an alias or ID for the principal or service that created the network interface .
Use the describe-network-interfaces AWS CLI command to describe the network interfaces in your account .
In the output , the RequesterManaged ﬁeld displays true if the network interface is managed by another AWS service .
SR-IOV is a method of device virtualization that provides higher I/O performance and lower CPU utilization when compared to traditional virtualized network interfaces .
There is no additional charge for using enhanced networking .
Intel 82599 Virtual Function ( VF ) interface The Intel 82599 Virtual Function interface supports network speeds of up to 10 Gbps for supported instance types .
For information about the supported network speed for each instance type , see Amazon EC2 Instance Types .
736 Amazon Elastic Compute Cloud User Guide for Linux Instances Enabling enhanced networking on your instance Enabling enhanced networking on your instance If your instance type supports the Elastic Network Adapter for enhanced networking , follow the procedures in Enabling enhanced networking with the Elastic Network Adapter ( ENA ) on Linux instances ( p. 737 ) .
If your instance type supports the Intel 82599 VF interface for enhanced networking , follow the procedures in Enabling enhanced networking with the Intel 82599 VF interface on Linux instances ( p. 749 ) .
Enabling enhanced networking with the Elastic Network Adapter ( ENA ) on Linux instances Amazon EC2 provides enhanced networking capabilities through the Elastic Network Adapter ( ENA ) .
To use enhanced networking , you must install the required ENA module and enable ENA support .
• Launch the instance using a supported version of the Linux kernel and a supported distribution , so that ENA enhanced networking is enabled for your instance automatically .
For more information , see ENA Linux Kernel Driver Release Notes .
• Install and conﬁgure the AWS CLI or the AWS Tools for Windows PowerShell on any computer you choose , preferably your local desktop or laptop .
Enhanced networking can not be managed from the Amazon EC2 console .
• If you have important data on the instance that you want to preserve , you should back that data up now by creating an AMI from your instance .
Updating kernels and kernel modules , as well as enabling the enaSupport attribute , might render incompatible instances or operating systems unreachable .
If you have a recent backup , your data will still be retained if this happens .
If your instance satisﬁes these two conditions , then the ethtool -i ethn command should show that the module is in use on the network interface .
Kernel module ( ena ) To verify that the ena module is installed , use the modinfo command as shown in the following example .
In the above Amazon Linux case , the ena module is installed .
738 Amazon Elastic Compute Cloud User Guide for Linux Instances Enhanced networking : ENA Instance attribute ( enaSupport ) To check whether an instance has the enhanced networking enaSupport attribute set , use one of the following commands .
If the attribute is set , the response is true .
If the attribute is set , the response is true .
In the following example , the ena module is not loaded , because the listed driver is vif .
This instance has enhanced networking properly conﬁgured .
Therefore , if you launch an instance with an HVM version of Amazon Linux on a supported instance type , enhanced networking is already enabled for your instance .
If you launched your instance using an older Amazon Linux AMI and it does not have enhanced networking enabled already , use the following procedure to enable enhanced networking .
Connect to your instance again and verify that the ena module is installed and at the minimum recommended version using the modinfo ena command from Testing whether enhanced networking is enabled ( p. 738 ) .
If your instance is managed by AWS OpsWorks , you should stop the instance in the AWS OpsWorks console so that the instance state remains in sync .
The AMI inherits the enhanced networking enaSupport attribute from the instance .
Therefore , you can use this AMI to launch another instance with enhanced networking enabled by default .
If your instance is managed by AWS OpsWorks , you should start the instance in the AWS OpsWorks console so that the instance state remains in sync .
Connect to your instance and verify that the ena module is installed and loaded on your network interface using the ethtool -i ethn command from Testing whether enhanced networking is enabled ( p. 738 ) .
To enable enhanced networking on Amazon Linux AMI ( instance store-backed instances ) Follow the previous procedure until the step where you stop the instance .
Enabling enhanced networking on Ubuntu The latest Ubuntu HVM AMIs include the module required for enhanced networking with ENA installed and have ENA support enabled .
Therefore , if you launch an instance with the latest Ubuntu HVM AMI on a supported instance type , enhanced networking is already enabled for your instance .
If you launched your instance using an older AMI and it does not have enhanced networking enabled already , you can install the linux-aws kernel package to get the latest enhanced networking drivers and update the required attribute .
Update the package cache and packages .
If during the update process you are prompted to install grub , use /dev/xvda to install grub onto , and then choose to keep the current version of /boot/grub/menu.lst .
If your instance is managed by AWS OpsWorks , you should stop the instance in the AWS OpsWorks console so that the instance state remains in sync .
The AMI inherits the enhanced networking enaSupport attribute from the instance .
Therefore , you can use this AMI to launch another instance with enhanced networking enabled by default .
If your instance is managed by AWS OpsWorks , you should start the instance in the AWS OpsWorks console so that the instance state remains in sync .
To enable enhanced networking on Ubuntu ( instance store-backed instances ) Follow the previous procedure until the step where you stop the instance .
Enabling enhanced networking on Linux The latest AMIs for Red Hat Enterprise Linux , SUSE Linux Enterprise Server , and CentOS include the module required for enhanced networking with ENA and have ENA support enabled .
Therefore , if you launch an instance with the latest AMI on a supported instance type , enhanced networking is already enabled for your instance .
The following procedure provides the general steps for enabling enhanced networking on a Linux distribution other than Amazon Linux AMI or Ubuntu .
For more information , such as detailed syntax for commands , ﬁle locations , or package and tool support , see the documentation for your Linux distribution .
Clone the source code for the ena module on your instance from GitHub at https : //github.com/ amzn/amzn-drivers .
Compile and install the ena module on your instance .
These steps depend on the Linux distribution .
For more information about compiling the module on Red Hat Enterprise Linux , see the AWS Knowledge Center article .
Run the sudo depmod command to update module dependencies .
Update initramfs on your instance to ensure that the new module loads at boot time .
For example , if your distribution supports dracut , you can use the following command .
Determine if your system uses predictable network interface names by default .
Systems that use systemd or udev versions 197 or greater can rename Ethernet devices and they do not guarantee that a single network interface will be named eth0 .
This behavior can cause problems connecting to your instance .
For more information and to see other conﬁguration options , see Predictable Network Interface Names on the freedesktop.org website .
You can check the systemd or udev versions on RPM-based systems with the following command .
If your instance is managed by AWS OpsWorks , you should stop the instance in the AWS OpsWorks console so that the instance state remains in sync .
The AMI inherits the enhanced networking enaSupport attribute from the instance .
743 Amazon Elastic Compute Cloud User Guide for Linux Instances Enhanced networking : ENA Therefore , you can use this AMI to launch another instance with enhanced networking enabled by default .
Important If your instance operating system contains an /etc/udev/rules.d/70-persistentnet.rules ﬁle , you must delete it before creating the AMI .
This ﬁle contains the MAC address for the Ethernet adapter of the original instance .
If another instance boots with this ﬁle , the operating system will be unable to ﬁnd the device and eth0 might fail , causing boot issues .
This ﬁle is regenerated at the next boot cycle , and any instances launched from the AMI create their own version of the ﬁle .
If your instance is managed by AWS OpsWorks , you should start the instance in the AWS OpsWorks console so that the instance state remains in sync .
( Optional ) Connect to your instance and verify that the module is installed .
To enable enhanced networking on Linux ( instance store–backed instances ) Follow the previous procedure until the step where you stop the instance .
Enabling enhanced networking on Ubuntu with DKMS This method is for testing and feedback purposes only .
It is not intended for use with production deployments .
Important Using DKMS voids the support agreement for your subscription .
Using kmod conﬁgurations is an acceptable alternative for running the latest available kernel modules .
Install the build-essential packages to compile the kernel module and the dkms package so that your ena module is rebuilt every time your kernel is updated .
Move the amzn-drivers package to the /usr/src/ directory so DKMS can ﬁnd it and build it for each kernel update .
Append the version number ( you can ﬁnd the current version number in the release notes ) of the source code to the directory name .
Create the DKMS conﬁguration ﬁle with the following values , substituting your version of ena .
Add , build , and install the ena module on your instance using DKMS .
Rebuild initramfs so the correct module is loaded at boot time .
Verify that the ena module is installed using the modinfo ena command from Testing whether enhanced networking is enabled ( p. 738 ) .
Operating System Optimizations To achieve the maximum network performance on instances with enhanced networking , you may need to modify the default operating system conﬁguration .
We recommend the following conﬁguration changes for applications that require high network performance .
In addition to these operating system optimizations , you should also consider the maximum transmission unit ( MTU ) of your network traﬃc , and adjust according to your workload and network architecture .
AWS regularly measures average round trip latencies between instances launched in a cluster placement group of 50us and tail latencies of 200us at the 99.9 percentile .
If your applications require consistently low latencies , we recommend using the latest version of the ENA drivers on ﬁxed performance Nitrobased instances .
These procedures were written for Amazon Linux 2 and Amazon Linux AMI .
However , they may also work for other Linux distributions with kernel version 3.9 or newer .
To optimize your Amazon Linux instance for enhanced networking 1 .
If the clock source is xen , complete the following substeps .
Ensure that your reserved kernel memory is suﬃcient to sustain a high rate of packet buﬀer allocations ( the default value may be too small ) .
Add the vm.min_free_kbytes line to the ﬁle with the reserved kernel memory value ( in kilobytes ) for your instance type .
As a rule of thumb , you should set this value to between 1-3 % of available system memory , and adjust this value up or down to meet the needs of your application .
Reboot your instance to load the new conﬁguration : 747 Amazon Elastic Compute Cloud User Guide for Linux Instances Enhanced networking : ENA sudo reboot 6 .
( Optional ) Manually distribute packet receive interrupts so that they are associated with diﬀerent CPUs that all belong to the same NUMA node .
Note The conﬁguration change in this step does not survive a reboot .
( Optional ) If the vCPUs that handle receive IRQs are overloaded , or if your application network processing is demanding on CPU , you can oﬄoad part of the network processing to other cores with receive packet steering ( RPS ) .
Ensure that cores used for RPS belong to the same NUMA node to avoid inter-NUMA node locks .
Note The conﬁguration change in this step does not survive a reboot .
When you run your network processing program , bind it to a single NUMA node .
Use multiple elastic network interfaces for diﬀerent classes of traﬃc .
For example , if you are running a web server that uses a backend database , use one elastic network interfaces for the web server front end , and another for the database connection .
Enabling enhanced networking with the Intel 82599 VF interface on Linux instances Amazon EC2 provides enhanced networking capabilities through the Intel 82599 VF interface , which uses the Intel ixgbevf driver .
• Launch the instance from an HVM AMI using Linux kernel version of 2.6.32 or later .
The latest Amazon Linux HVM AMIs have the modules required for enhanced networking installed and have the required attributes set .
749 Amazon Elastic Compute Cloud User Guide for Linux Instances Enhanced networking : Intel 82599 VF Warning Enhanced networking is supported only for HVM instances .
Enabling enhanced networking with a PV instance can make it unreachable .
Setting this attribute without the proper module or module version can also make your instance unreachable .
• Install and conﬁgure the AWS CLI or the AWS Tools for Windows PowerShell on any computer you choose , preferably your local desktop or laptop .
Enhanced networking can not be managed from the Amazon EC2 console .
• If you have important data on the instance that you want to preserve , you should back that data up now by creating an AMI from your instance .
Updating kernels and kernel modules , as well as enabling the sriovNetSupport attribute , might render incompatible instances or operating systems unreachable .
If you have a recent backup , your data will still be retained if this happens .
Testing whether enhanced networking is enabled Enhanced networking with the Intel 82599 VF interface is enabled if the ixgbevf module is installed on your instance and the sriovNetSupport attribute is set .
If the attribute is set , the value is simple , as shown in the following example output .
If the attribute is set , the value is simple .
750 Amazon Elastic Compute Cloud User Guide for Linux Instances Enhanced networking : Intel 82599 VF Network interface driver Use the following command to verify that the module is being used on a particular interface , substituting the interface name that you want to check .
In the following example , the ixgbevf module is not loaded , because the listed driver is vif .
This instance has enhanced networking properly conﬁgured .
Therefore , if you launch an instance type using a current Amazon Linux HVM AMI , enhanced networking is already enabled for your instance .
If you launched your instance using an older Amazon Linux AMI and it does not have enhanced networking enabled already , use the following procedure to enable enhanced networking .
Warning There is no way to disable the enhanced networking attribute after you 've enabled it .
Connect to your instance again and verify that the ixgbevf module is installed and at the minimum recommended version using the modinfo ixgbevf command from Testing whether enhanced networking is enabled ( p. 750 ) .
If your instance is managed by AWS OpsWorks , you should stop the instance in the AWS OpsWorks console so that the instance state remains in sync .
The AMI inherits the enhanced networking attribute from the instance .
Therefore , you can use this AMI to launch another instance with enhanced networking enabled by default .
If your instance is managed by AWS OpsWorks , you should start the instance in the AWS OpsWorks console so that the instance state remains in sync .
Connect to your instance and verify that the ixgbevf module is installed and loaded on your network interface using the ethtool -i ethn command from Testing whether enhanced networking is enabled ( p. 750 ) .
To enable enhanced networking ( instance store-backed instances ) Follow the previous procedure until the step where you stop the instance .
The Quick Start Ubuntu HVM AMIs include the necessary drivers for enhanced networking .
If you have a version of ixgbevf earlier than 2.16.4 , you can install the linux-aws kernel package to get the latest enhanced networking drivers .
752 Amazon Elastic Compute Cloud User Guide for Linux Instances Enhanced networking : Intel 82599 VF The following procedure provides the general steps for compiling the ixgbevf module on an Ubuntu instance .
Update the package cache and packages .
The latest Quick Start HVM AMIs include the necessary drivers for enhanced networking , therefore you do not need to perform additional steps .
The following procedure provides the general steps if you need to enable enhanced networking with the Intel 82599 VF interface on a Linux distribution other than Amazon Linux or Ubuntu .
For more information , such as detailed syntax for commands , ﬁle locations , or package and tool support , see the speciﬁc documentation for your Linux distribution .
Compile and install the ixgbevf module on your instance .
Warning If you compile the ixgbevf module for your current kernel and then upgrade your kernel without rebuilding the driver for the new kernel , your system might revert to the distribution-speciﬁc ixgbevf module at the next reboot .
This could make your system unreachable if the distribution-speciﬁc version is incompatible with enhanced networking .
Run the sudo depmod command to update module dependencies .
Update initramfs on your instance to ensure that the new module loads at boot time .
Determine if your system uses predictable network interface names by default .
Systems that use systemd or udev versions 197 or greater can rename Ethernet devices and they do not guarantee that a single network interface will be named eth0 .
This behavior can cause problems connecting to your instance .
For more information and to see other conﬁguration options , see Predictable Network Interface Names on the freedesktop.org website .
If your instance is managed by AWS OpsWorks , you should stop the instance in the AWS OpsWorks console so that the instance state remains in sync .
The AMI inherits the enhanced networking attribute from the instance .
Therefore , you can use this AMI to launch another instance with enhanced networking enabled by default .
Important If your instance operating system contains an /etc/udev/rules.d/70-persistentnet.rules ﬁle , you must delete it before creating the AMI .
This ﬁle contains the MAC address for the Ethernet adapter of the original instance .
If another instance boots with this ﬁle , the operating system will be unable to ﬁnd the device and eth0 might fail , causing boot issues .
This ﬁle is regenerated at the next boot cycle , and any instances launched from the AMI create their own version of the ﬁle .
If your instance is managed by AWS OpsWorks , you should start the instance in the AWS OpsWorks console so that the instance state remains in sync .
( Optional ) Connect to your instance and verify that the module is installed .
To enable enhanced networking ( instance store–backed instances ) Follow the previous procedure until the step where you stop the instance .
Troubleshooting connectivity issues If you lose connectivity while enabling enhanced networking , the ixgbevf module might be incompatible with the kernel .
Try installing the version of the ixgbevf module included with the distribution of Linux for your instance .
If you enable enhanced networking for a PV instance or AMI , this can make your instance unreachable .
Troubleshooting the Elastic Network Adapter ( ENA ) The Elastic Network Adapter ( ENA ) is designed to improve operating system health and reduce the chances of long-term disruption because of unexpected hardware behavior and or failures .
The ENA architecture keeps device or driver failures as transparent to the system as possible .
This topic provides troubleshooting information for ENA .
If you are able to connect to your instance , you can gather diagnostic information by using the failure detection and recovery mechanisms that are covered in the later sections of this topic .
This can happen if you install the module for a speciﬁc kernel version ( without dkms , or with an improperly conﬁgured dkms.conf ﬁle ) and then your instance kernel is updated .
If the instance kernel that is loaded at boot time does not have the ena module properly installed , your instance will not recognize the network adapter and your instance becomes unreachable .
If you enable enhanced networking for a PV instance or AMI , this can also make your instance unreachable .
If your instance becomes unreachable after enabling enhanced networking with ENA , you can disable the enaSupport attribute for your instance and it will fall back to the stock network adapter .
If your 755 Amazon Elastic Compute Cloud User Guide for Linux Instances Troubleshooting ENA instance is managed by AWS OpsWorks , you should stop the instance in the AWS OpsWorks console so that the instance state remains in sync .
From your local computer , disable the enhanced networking attribute using the following command .
If your instance is managed by AWS OpsWorks , you should start the instance in the AWS OpsWorks console so that the instance state remains in sync .
( Optional ) Connect to your instance and try reinstalling the ena module with your current kernel version by following the steps in Enabling enhanced networking with the Elastic Network Adapter ( ENA ) on Linux instances ( p. 737 ) .
Be sure to disable the enhanced networking enaSupport attribute when you register the AMI .
If a message or messages are present , the watchdog is rearmed , otherwise the driver concludes that the device experienced a failure and then does the following : • Dumps its current statistics to syslog • Resets the ENA device • Resets the ENA driver state The above reset procedure may result in some traﬃc loss for a short period of time ( TCP connections should be able to recover ) , but should not otherwise aﬀect the user .
The ENA device may also indirectly request a device reset procedure , by not sending a keep-alive notiﬁcation , for example , if the ENA device reaches an unknown state after loading an irrecoverable conﬁguration .
MMIO registers are accessed by the ENA device driver only during its initialization procedure .
If the driver logs ( available in dmesg output ) indicate failures of read operations , this may be caused by an incompatible or incorrectly compiled driver , a busy hardware device , or hardware failure .
Intermittent log entries that indicate failures on read operations should not be considered an issue ; the driver will retry them in this case .
The following command output parameters are described below : tx_timeout : N The number of times that the Netdev watchdog was activated .
This value should always be zero .
This value should always be zero .
This value should always be zero .
queue_N_tx_missing_tx_comp : codeN The number of packets that were left uncompleted for queue N. This value should always be zero .
queue_N_rx_page_alloc_fail : N The number of time that page allocation failed for queue N. If this value is not zero , it indicates low memory resources .
queue_N_rx_skb_alloc_fail : N The number of time that SKB allocation failed for queue N. If this value is not zero , it indicates low system resources .
If this value is not 0 , it indicates usage of very small buﬀers .
759 Amazon Elastic Compute Cloud User Guide for Linux Instances Troubleshooting ENA queue_N_rx_small_copy_len_pkt : N Optimization : For packets smaller that this threshold , which is set by sysfs , the packet is copied directly to the stack to avoid allocation of a new page .
ena_admin_q_out_of_space : N The number of times that the driver tried to submit new admin command , but the queue was full .
Driver error logs in syslog The ENA driver writes log messages to syslog during system boot .
You can examine these logs to look for errors if you are experiencing issues .
Below is an example of information logged by the ENA driver in syslog during system boot , along with some annotations for select messages .
The following warnings that may appear in your system 's error logs can be ignored for the Elastic Network Adapter : 760 Amazon Elastic Compute Cloud User Guide for Linux Instances Elastic Fabric Adapter Set host attribute is n't supported Host attributes are not supported for this device .
failed to alloc buﬀer for rx queue This is a recoverable error , and it indicates that there may have been a memory pressure issue when the error was thrown .
Feature X is n't supported The referenced feature is not supported by the Elastic Network Adapter .
Failed to conﬁg AENQ The Elastic Network Adapter does not support AENQ conﬁguration .
Trying to set unsupported AENQ events This error indicates an attempt to set an AENQ events group that is not supported by the Elastic Network Adapter .
Elastic Fabric Adapter An Elastic Fabric Adapter ( EFA ) is a network device that you can attach to your Amazon EC2 instance to accelerate High Performance Computing ( HPC ) and machine learning applications .
EFA enables you to achieve the application performance of an on-premises HPC cluster , with the scalability , ﬂexibility , and elasticity provided by the AWS Cloud .
EFA provides lower and more consistent latency and higher throughput than the TCP transport traditionally used in cloud-based HPC systems .
It enhances the performance of inter-instance communication that is critical for scaling HPC and machine learning applications .
It is optimized to work on the existing AWS network infrastructure and it can scale depending on application requirements .
Note The OS-bypass capabilities of EFAs are not supported on Windows instances .
If you attach an EFA to a Windows instance , the instance functions as an Elastic Network Adapter , without the added EFA capabilities .
It provides all of the functionality of an ENA , with an additional OS-bypass functionality .
OS-bypass is an access model that allows HPC and machine learning applications to communicate directly with the network interface hardware to provide low-latency , reliable transport functionality .
In the AWS Cloud , this has meant that applications interface with MPI , which then uses the operating system 's TCP/IP stack and the ENA device driver to enable network communication between instances .
With an EFA , HPC applications use MPI or NCCL to interface with the Libfabric API .
The Libfabric API bypasses the operating system kernel and communicates directly with the EFA device to put packets on the network .
This reduces overhead and enables the HPC application to run more eﬃciently .
762 Amazon Elastic Compute Cloud User Guide for Linux Instances Supported Interfaces and Libraries Note Libfabric is a core component of the OpenFabrics Interfaces ( OFI ) framework , which deﬁnes and exports the user-space API of OFI .
Diﬀerences between EFAs and ENAs Elastic Network Adapters ( ENAs ) provide traditional IP networking features that are required to support VPC networking .
EFAs provide all of the same traditional IP networking features as ENAs , and they also support OS-bypass capabilities .
OS-bypass enables HPC and machine learning applications to bypass the operating system kernel and to communicate directly with the EFA device .
EFA Limitations EFA has the following limitations : • You can attach only one EFA per instance .
In other words , EFA traﬃc can not be sent from one subnet to another .
Normal IP traﬃc from the EFA can be sent from one subnet to another .
Normal IP traﬃc from the EFA remains routable .
• The EFA must be a member of a security group that allows all inbound and outbound traﬃc to and from the security group itself .
Getting Started with EFA and MPI This tutorial helps you to launch an EFA and MPI-enabled instance cluster for HPC workloads .
In the navigation pane , choose Security Groups and then choose Create Security Group .
For Security group name , enter a descriptive name for the security group , such as EFAenabled security group .
For VPC , select the VPC into which you intend to launch your EFA-enabled instances .
Select the security group that you created , and on the Description tab , copy the Group ID .
Step 2 : Launch a Temporary Instance Launch a temporary instance that you can use to install and conﬁgure the EFA software components .
You use this instance to create an EFA-enabled AMI from which you can launch your EFA-enabled instances .
764 Amazon Elastic Compute Cloud User Guide for Linux Instances Getting Started with EFA and MPI c. Choose Next : Add Storage .
On the Add Storage page , specify the volumes to attach to the instances in addition to the volumes that are speciﬁed by the AMI ( such as the root device volume ) .
On the Add Tags page , specify a tag that you can use to identify the temporary instance , and then choose Next : Conﬁgure Security Group .
On the Conﬁgure Security Group page , for Assign a security group , select Select an existing security group , and then select the security group that you created in Step 1 .
On the Review Instance Launch page , review the settings , and then choose Launch to choose a key pair and to launch your instance .
Step 3 : Install the EFA Software Install the EFA-enabled kernel , EFA drivers , Libfabric , and Open MPI stack that is required to support EFA on your temporary instance .
The steps diﬀer depending on whether you intend to use EFA with Open MPI or with Intel MPI .
To ensure that all of your software packages are up to date , perform a quick software update on your instance .
Download the EFA software installation ﬁles .
To download the latest stable version , use the following command .
$ curl -O https : //s3.us-west-2.amazonaws.com/aws-efa-installer/aws-efainstaller-1.8.4.tar.gz You can also get the latest version by replacing the version number with latest in the preceding command .
Extract the ﬁles from the compressed .tar.gz ﬁle and navigate into the extracted directory .
• If you intend to use EFA with Open MPI , you must install the EFA software with Libfabric and Open MPI , and you must skip Step 4 : Install Intel MPI .
765 Amazon Elastic Compute Cloud User Guide for Linux Instances Getting Started with EFA and MPI To install the EFA software with Libfabric and Open MPI , run the following command .
• If you intend to use EFA with Intel MPI only , you can install the EFA software without Libfabric and Open MPI .
In this case , Intel MPI uses its embedded Libfabric .
To install the EFA software without Libfabric and Open MPI , run the following command .
Log out of the instance and then log back in .
Conﬁrm that the EFA software components were successfully installed .
The following example shows the command output .
The shared memory feature uses Cross Memory Attach ( CMA ) , which is not supported with ptrace protection .
If you are using a Linux distribution that has ptrace protection enabled by default , such as Ubuntu , you must disable it .
If your Linux distribution does not have ptrace protection enabled by default , skip this step .
To disable ptrace protection Do one of the following : • To temporarily disable ptrace protection for testing purposes , run the following command .
Perform this step only if you intend to use Intel MPI .
Intel MPI requires an additional installation and environment variable conﬁguration .
Prerequisites Ensure that the user performing the following steps has sudo permissions .
To download the Intel MPI installation ﬁles , see the Intel Developer Zone website .
You must register before you can download the installation ﬁles .
Extract the ﬁles from the compressed .tar.gz ﬁle and navigate into the extracted directory .
Save the changes and close the ﬁle .
Add the Intel MPI environment variables to the corresponding shell startup scripts to ensure that they are set each time that the instance starts .
Do one of the following depending on your shell .
Log out of the instance and then log back in .
767 Amazon Elastic Compute Cloud User Guide for Linux Instances Getting Started with EFA and MPI 7 .
Run the following command to conﬁrm that Intel MPI was successfully installed .
Note If you no longer want to use Intel MPI , remove the environment variables from the shell startup scripts .
Step 6 : Install Your HPC Application Install the HPC application on the temporary instance .
The installation procedure varies depending on the speciﬁc HPC application .
For more information about installing software on your Linux instance , see Managing Software on Your Linux Instance .
Note You might need to refer to your HPC application ’ s documentation for installation instructions .
Step 7 : Create an EFA-Enabled AMI After you have installed the required software components , you create an AMI that you can reuse to launch your EFA-enabled instances .
Locate the AMI you created in the list .
Wait for the Status to transition from pending to available before continuing to the next step .
Note It is not an absolute requirement to launch your EFA-enabled instances into a cluster placement group .
768 Amazon Elastic Compute Cloud User Guide for Linux Instances Getting Started with EFA and MPI 2 .
On the Choose an AMI page , choose My AMIs , ﬁnd the AMI that you created in Step 6 , and then choose Select .
For Number of instances , enter the number of EFA-enabled instances that you want to launch .
For Network and Subnet , select the VPC and subnet into which to launch the instances .
On the Add Storage page , specify the volumes to attach to the instances in addition to the volumes speciﬁed by the AMI ( such as the root device volume ) , and then choose Next : Add Tags .
On the Conﬁgure Security Group page , for Assign a security group , select Select an existing security group , and then select the security group that you created in Step 1 .
On the Review Instance Launch page , review the settings , and then choose Launch to choose a key pair and to launch your instances .
Step 9 : Terminate the Temporary Instance At this point , you no longer need the temporary instance that you launched in Step 1 .
You can terminate the instance to stop incurring charges for it .
Step 10 : Enable Passwordless SSH To enable your applications to run across all of the instances in your cluster , you must enable passwordless SSH access from the leader node to the member nodes .
The leader node is the instance from which you run your applications .
The remaining instances in the cluster are the member nodes .
To enable passwordless SSH between the instances in the cluster 1 .
Select one instance in the cluster as the leader node , and connect to it .
769 Amazon Elastic Compute Cloud User Guide for Linux Instances Getting Started with EFA and NCCL 2 .
Disable strictHostKeyChecking and enable ForwardAgent on the leader node .
Open ~/.ssh/ config using your preferred text editor and add the following .
Change the permissions of the private key on the leader node .
Open ~/.ssh/id_rsa.pub using your preferred text editor and copy the key .
Open ~/.ssh/authorized_keys using your preferred text editor and add the public key that you copied earlier .
To test that the passwordless SSH is functioning as expected , connect to your leader node and run the following command .
$ ssh member_node_private_ip You should connect to the member node without being prompted for a key or password .
Getting Started with EFA and NCCL The Nvidia Collective Communications Library ( NCCL ) is a library of standard collective communication routines for multiple GPUs across a single node or multiple nodes .
NCCL can be used together with EFA , Libfabric , and MPI to support various machine learning workloads .
The following tutorials help you to launch an EFA and NCCL-enabled instance cluster for machine learning workloads .
In the navigation pane , choose Security Groups and then choose Create Security Group .
For Security group name , enter a descriptive name for the security group , such as EFAenabled security group .
Select the security group that you created , and on the Description tab , copy the Group ID .
d. Paste the security group ID that you copied into the ﬁeld .
Step 2 : Launch a Temporary Instance Launch a temporary instance that you can use to install and conﬁgure the EFA software components .
You use this instance to create an EFA-enabled AMI from which you can launch your EFA-enabled instances .
771 Amazon Elastic Compute Cloud User Guide for Linux Instances Getting Started with EFA and NCCL 3 .
On the Choose an Instance Type page , select p3dn.24xlarge and then choose Next : Conﬁgure Instance Details .
On the Add Storage page , specify the volumes to attach to the instances , in addition to the volumes speciﬁed by the AMI ( such as the root device volume ) .
On the Add Tags page , specify a tag that you can use to identify the temporary instance , and then choose Next : Conﬁgure Security Group .
On the Conﬁgure Security Group page , for Assign a security group , select Select an existing security group .
Then select the security group that you created in Step 1 .
On the Review Instance Launch page , review the settings , and then choose Launch to choose a key pair and to launch your instance .
Step 3 : Install the EFA Software Install the EFA-enabled kernel , EFA drivers , Libfabric , and Open MPI stack that is required to support EFA on your temporary instance .
To ensure that all of your software packages are up to date , perform a quick software update on your instance .
Download the EFA software installation ﬁles .
To download the latest stable version , use the following command .
$ curl -O https : //s3.us-west-2.amazonaws.com/aws-efa-installer/aws-efainstaller-1.8.4.tar.gz You can also get the latest version by replacing the version number with latest in the preceding command .
Extract the ﬁles from the compressed .tar.gz ﬁle and navigate into the extracted directory .
Run the EFA software installation script .
Log out of the instance and then log back in .
Conﬁrm that the EFA software components were successfully installed .
The following example shows the command output .
Install the utilities that are needed to install the Nvidia GPU drivers and the Nvidia CUDA toolkit .
To use the Nvidia GPU driver , you must ﬁrst disable the nouveau open source drivers .
Install the gcc compiler and the kernel headers package for the version of the kernel that you are currently running .
Reboot the instance and reconnect to it .
Download the Nvidia CUDA Toolkit installer .
Run the Nvidia CUDA Toolkit installer .
At the CUDA Installer menu , ensure that all of the items are selected , highlight Install , and then press Enter .
Add the following statements to the shell startup scripts to ensure that the CUDA paths are set each time that the instance starts .
To conﬁrm that the Nvidia GPU drivers are functional , run the following command .
774 Amazon Elastic Compute Cloud User Guide for Linux Instances Getting Started with EFA and NCCL $ nvidia-smi -q | head The command should return information about the Nvidia GPUs , Nvidia GPU drivers , and Nvidia CUDA toolkit .
For more information about NCCL , see the NCCL repository .
For more information about installing the latest version , see CUDA Toolkit 10.1 Update 2 Download on the Nvidia website .
Clone the oﬃcial NCCL repository to the instance and navigate into the local cloned repository .
Build and install NCCL and specify the CUDA installation directory .
The following command assumes that CUDA is installed in the default directory .
This enables you to use Libfabric as a network provider while running NCCL-based applications .
Install the utilities that are required to install the aws-oﬁ-nccl plugin .
To install the required utilities , run the following command .
Clone the aws branch of the oﬃcial AWS aws-oﬁ-nccl repository to the instance and navigate into the local cloned repository .
To generate the make ﬁles , run the configure script and specify the MPI , Libfabric , NCCL , and CUDA installation directories .
The NCCL tests enable you to conﬁrm that NCCL is properly installed and that it is operating as expected .
Clone the oﬃcial nccl-tests repository to the instance and navigate into the local cloned repository .
To update the path in the make ﬁle , run the following command .
Install the NCCL tests and specify the MPI , NCCL , and CUDA installation directories .
Create a host ﬁle that speciﬁes the hosts on which to run the tests .
The following command runs the all_reduce_perf test on 8 GPUs on the instance itself , and speciﬁes the following environment variables .
• FI_EFA_TX_MIN_CREDITS=64—speciﬁes the minimum number of send credits that the sender requests from the receiver .
64 is the recommended value for NCCL jobs using EFA .
The value should only be increased for message transfers that are larger than 256 MB .
You can also specify VERSION to print only the NCCL version at the start of the test , or WARN to receive only error messages .
For more information about the NCCL test arguments , see the NCCL Tests README in the oﬃcial nccl-tests repository .
The installation procedure varies depending on the speciﬁc machine learning application .
For more information about installing software on your Linux instance , see Managing Software on Your Linux Instance .
Note You might need to refer to your machine learning application ’ s documentation for installation instructions .
Step 10 : Create an EFA and NCCL-Enabled AMI After you have installed the required software components , you create an AMI that you can reuse to launch your EFA-enabled instances .
Locate the AMI you created in the list .
Wait for the Status to transition from pending to available before continuing to the next step .
Step 11 : Terminate the Temporary Instance At this point , you no longer need the temporary instance that you launched in Step 1 .
You can terminate the instance to stop incurring charges for it .
778 Amazon Elastic Compute Cloud User Guide for Linux Instances Getting Started with EFA and NCCL 2 .
On the Choose an AMI page , choose My AMIs , ﬁnd the AMI that you created earlier , and then choose Select .
On the Choose an Instance Type page , select p3dn.24xlarge and then choose Next : Conﬁgure Instance Details .
For Number of instances , enter the number of EFA and NCCL-enabled instances that you want to launch .
For Network and Subnet , select the VPC and subnet into which to launch the instances .
If you are launching the instance into a subnet that has an associated IPv6 CIDR block , you can optionally specify a primary IPv6 address and one or more secondary IPv6 addresses .
On the Add Storage page , specify the volumes to attach to the instances in addition to the volumes speciﬁed by the AMI ( such as the root device volume ) .
On the Conﬁgure Security Group page , for Assign a security group , select Select an existing security group , and then select the security group that you created earlier .
On the Review Instance Launch page , review the settings , and then choose Launch to choose a key pair and to launch your instances .
Step 13 : Enable Passwordless SSH To enable your applications to run across all of the instances in your cluster , you must enable passwordless SSH access from the leader node to the member nodes .
The leader node is the instance from which you run your applications .
The remaining instances in the cluster are the member nodes .
To enable passwordless SSH between the instances in the cluster 1 .
Select one instance in the cluster as the leader node , and connect to it .
779 Amazon Elastic Compute Cloud User Guide for Linux Instances Getting Started with EFA and NCCL 2 .
Disable strictHostKeyChecking and enable ForwardAgent on the leader node .
Open ~/.ssh/ config using your preferred text editor and add the following .
Change the permissions of the private key on the leader node .
Open ~/.ssh/id_rsa.pub using your preferred text editor and copy the key .
Open ~/.ssh/authorized_keys using your preferred text editor and add the public key that you copied earlier .
To test that the passwordless SSH is functioning as expected , connect to your leader node and run the following command .
$ ssh member_node_private_ip You should connect to the member node without being prompted for a key or password .
In the navigation pane , choose Security Groups and then choose Create Security Group .
For Security group name , enter a descriptive name for the security group , such as EFAenabled security group .
Select the security group that you created , and on the Description tab , copy the Group ID .
d. Paste the security group ID that you copied into the ﬁeld .
Step 2 : Launch a Temporary Instance Launch a temporary instance that you can use to install and conﬁgure the EFA software components .
You use this instance to create an EFA-enabled AMI from which you can launch your EFA-enabled instances .
On the Choose an AMI page , choose a supported AWS Deep Learning AMI Version 25.0 or later .
On the Choose an Instance Type page , select p3dn.24xlarge and then choose Next : Conﬁgure Instance Details .
On the Add Storage page , specify the volumes to attach to the instances , in addition to the volumes speciﬁed by the AMI ( such as the root device volume ) .
On the Add Tags page , specify a tag that you can use to identify the temporary instance , and then choose Next : Conﬁgure Security Group .
On the Conﬁgure Security Group page , for Assign a security group , select Select an existing security group .
Then select the security group that you created in Step 1 .
On the Review Instance Launch page , review the settings , and then choose Launch to choose a key pair and to launch your instance .
781 Amazon Elastic Compute Cloud User Guide for Linux Instances Getting Started with EFA and NCCL Step 3 : Test Your EFA and NCCL Conﬁguration Run a test to ensure that your temporary instance is properly conﬁgured for EFA and NCCL .
Create a host ﬁle that speciﬁes the hosts on which to run the tests .
The following command runs the all_reduce_perf test on 8 GPUs on the instance itself , and speciﬁes the following environment variables .
• FI_EFA_TX_MIN_CREDITS=64—speciﬁes the minimum number of send credits that the sender requests from the receiver .
64 is the recommended value for NCCL jobs using EFA .
The value should only be increased for message transfers that are larger than 256 MB .
You can also specify VERSION to print only the NCCL version at the start of the test , or WARN to receive only error messages .
For more information about the NCCL test arguments , see the NCCL Tests README in the oﬃcial nccl-tests repository .
The installation procedure varies depending on the speciﬁc machine learning application .
For more information about installing software on your Linux instance , see Managing Software on Your Linux Instance .
Note You might need to refer to your machine learning application ’ s documentation for installation instructions .
782 Amazon Elastic Compute Cloud User Guide for Linux Instances Getting Started with EFA and NCCL Step 5 : Create an EFA and NCCL-Enabled AMI After you have installed the required software components , you create an AMI that you can reuse to launch your EFA-enabled instances .
Choose Create Image and then choose Close .
Locate the AMI you created in the list .
Wait for the Status to transition from pending to available before continuing to the next step .
Step 6 : Terminate the Temporary Instance At this point , you no longer need the temporary instance that you launched in Step 1 .
You can terminate the instance to stop incurring charges for it .
On the Choose an AMI page , choose My AMIs , ﬁnd the AMI that you created earlier , and then choose Select .
On the Choose an Instance Type page , select p3dn.24xlarge and then choose Next : Conﬁgure Instance Details .
For Network and Subnet , select the VPC and subnet into which to launch the instances .
For Placement group , select Add instance to placement group .
For Placement group name , select Add to a new placement group , and then enter a descriptive name for the placement group .
783 Amazon Elastic Compute Cloud User Guide for Linux Instances Getting Started with EFA and NCCL f. In the Network Interfaces section , for device eth0 , choose New network interface .
If you are launching the instance into a subnet that has an associated IPv6 CIDR block , you can optionally specify a primary IPv6 address and one or more secondary IPv6 addresses .
On the Add Storage page , specify the volumes to attach to the instances in addition to the volumes speciﬁed by the AMI ( such as the root device volume ) .
On the Conﬁgure Security Group page , for Assign a security group , select Select an existing security group , and then select the security group that you created earlier .
On the Review Instance Launch page , review the settings , and then choose Launch to choose a key pair and to launch your instances .
Step 8 : Enable Passwordless SSH To enable your applications to run across all of the instances in your cluster , you must enable passwordless SSH access from the leader node to the member nodes .
The leader node is the instance from which you run your applications .
The remaining instances in the cluster are the member nodes .
To enable passwordless SSH between the instances in the cluster 1 .
Select one instance in the cluster as the leader node , and connect to it .
Disable strictHostKeyChecking and enable ForwardAgent on the leader node .
Open ~/.ssh/ config using your preferred text editor and add the following .
Change the permissions of the private key on the leader node .
Open ~/.ssh/id_rsa.pub using your preferred text editor and copy the key .
Open ~/.ssh/authorized_keys using your preferred text editor and add the public key that you copied earlier .
To test that the passwordless SSH is functioning as expected , connect to your leader node and run the following command .
$ ssh member_node_private_ip You should connect to the member node without being prompted for a key or password .
784 Amazon Elastic Compute Cloud User Guide for Linux Instances Working with EFA Working with EFA You can create , use , and manage an EFA much like any other elastic network interface in Amazon EC2 .
However , unlike elastic network interfaces , EFAs can not be attached to or detached from an instance in a running state .
• Use a security group that allows all inbound and outbound traﬃc to and from the security group itself .
You ca n't move the EFA to another subnet after it 's created , and you can only attach it to stopped instances in the same Availability Zone .
For Subnet , select the subnet in which to create the EFA .
For Security groups , select one or more security groups .
785 Amazon Elastic Compute Cloud User Guide for Linux Instances Working with EFA 9 .
To create a new EFA using the AWS CLI Use the create-network-interface command and for interface-type , specify efa , as shown in the following example .
You can not attach an EFA to an instance that is in the running state .
You attach an EFA to an instance in the same way that you attach an elastic network interface to an instance .
Attaching an EFA When Launching an Instance To attach an existing EFA when launching an instance ( AWS CLI ) Use the run-instances command and for NetworkInterfaceId , specify the ID of the EFA , as shown in the following example .
You can leverage launch templates to launch EFA-enabled instances with other AWS services , such as AWS Batch .
Assigning an IP Address to an EFA If you have an Elastic IP ( IPv4 ) address , you can associate it with an EFA .
If your EFA is provisioned in a subnet that has an associated IPv6 CIDR block , you can assign one or more IPv6 addresses to the EFA .
786 Amazon Elastic Compute Cloud User Guide for Linux Instances Monitoring an EFA You assign an Elastic IP ( IPv4 ) and IPv6 address to an EFA in the same way that you assign an IP address to an elastic network interface .
To enable OS-bypass functionality , the EFA must be a member of a security group that allows all inbound and outbound traﬃc to and from the security group itself .
You change the security group that is associated with an EFA in the same way that you change the security group that is associated with an elastic network interface .
Detaching an EFA To detach an EFA from an instance , you must ﬁrst stop the instance .
You can not detach an EFA from an instance that is in the running state .
You detach an EFA from an instance in the same way that you detach an elastic network interface from an instance .
Viewing EFAs You can view all of the EFAs in your account .
You view EFAs in the same way that you view elastic network interfaces .
Deleting an EFA To delete an EFA , you must ﬁrst detach it from the instance .
You can not delete an EFA while it is attached to an instance .
You delete EFAs in the same way that you delete elastic network interfaces .
Monitoring an EFA You can use the following features to monitor the performance of your Elastic Fabric Adapters .
Amazon VPC Flow Logs You can create an Amazon VPC Flow Log to capture information about the traﬃc going to and from an EFA .
Flow log data can be published to Amazon CloudWatch Logs and Amazon S3 .
After you create a 787 Amazon Elastic Compute Cloud User Guide for Linux Instances Placement Groups ﬂow log , you can retrieve and view its data in the chosen destination .
For more information , see VPC Flow Logs in the Amazon VPC User Guide .
You create a ﬂow log for an EFA in the same way that you create a ﬂow log for an elastic network interface .
For more information , see Creating a Flow Log in the Amazon VPC User Guide .
In the ﬂow log entries , EFA traﬃc is identiﬁed by the srcAddress and destAddress , which are both formatted as MAC addresses , as shown in the following example .
You can collect and track metrics , create customized dashboards , and set alarms that notify you or take actions when a speciﬁed metric reaches a threshold that you specify .
Placement Groups When you launch a new EC2 instance , the EC2 service attempts to place the instance in such a way that all of your instances are spread out across underlying hardware to minimize correlated failures .
You can use placement groups to inﬂuence the placement of a group of interdependent instances to meet the needs of your workload .
Depending on the type of workload , you can create a placement group using one of the following placement strategies : • Cluster – packs instances close together inside an Availability Zone .
This strategy enables workloads to achieve the low-latency network performance necessary for tightly-coupled node-to-node communication that is typical of HPC applications .
• Partition – spreads your instances across logical partitions such that groups of instances in one partition do not share the underlying hardware with groups of instances in diﬀerent partitions .
This strategy is typically used by large distributed and replicated workloads , such as Hadoop , Cassandra , and Kafka .
• Spread – strictly places a small group of instances across distinct underlying hardware to reduce correlated failures .
A cluster placement group can span peered VPCs in the same Region .
Instances in the same cluster placement group enjoy a higher per-ﬂow throughput limit of up to 10 Gbps for TCP/IP traﬃc and are placed in the same high-bisection bandwidth segment of the network .
The following image shows instances that are placed into a cluster placement group .
Cluster placement groups are recommended for applications that beneﬁt from low network latency , high network throughput , or both .
They are also recommended when the majority of the network traﬃc is between the instances in the group .
To provide the lowest latency and the highest packet-persecond network performance for your placement group , choose an instance type that supports enhanced networking .
We recommend that you launch your instances in the following way : • Use a single launch request to launch the number of instances that you need in the placement group .
• Use the same instance type for all instances in the placement group .
If you try to add more instances to the placement group later , or if you try to launch more than one instance type in the placement group , you increase your chances of getting an insuﬃcient capacity error .
If you stop an instance in a placement group and then start it again , it still runs in the placement group .
However , the start fails if there is n't enough capacity for the instance .
If you receive a capacity error when launching an instance in a placement group that already has running instances , stop and start all of the instances in the placement group , and try the launch again .
Starting the instances may migrate them to hardware that has capacity for all of the requested instances .
Partition Placement Groups Partition placement groups help reduce the likelihood of correlated hardware failures for your application .
When using partition placement groups , Amazon EC2 divides each group into logical segments called partitions .
Amazon EC2 ensures that each partition within a placement group has 789 Amazon Elastic Compute Cloud User Guide for Linux Instances Spread Placement Groups its own set of racks .
Each rack has its own network and power source .
No two partitions within a placement group share the same racks , allowing you to isolate the impact of hardware failure within your application .
The following image is a simple visual representation of a partition placement group in a single Availability Zone .
The instances in a partition do not share racks with the instances in the other partitions , allowing you to contain the impact of a single hardware failure to only the associated partition .
Partition placement groups can be used to deploy large distributed and replicated workloads , such as HDFS , HBase , and Cassandra , across distinct racks .
When you launch instances into a partition placement group , Amazon EC2 tries to distribute the instances evenly across the number of partitions that you specify .
You can also launch instances into a speciﬁc partition to have more control over where the instances are placed .
A partition placement group can have partitions in multiple Availability Zones in the same Region .
A partition placement group can have a maximum of seven partitions per Availability Zone .
The number of instances that can be launched into a partition placement group is limited only by the limits of your account .
In addition , partition placement groups oﬀer visibility into the partitions — you can see which instances are in which partitions .
These applications use this information to make intelligent data replication decisions for increasing data availability and durability .
If you start or launch an instance in a partition placement group and there is insuﬃcient unique hardware to fulﬁll the request , the request fails .
Amazon EC2 makes more distinct hardware available over time , so you can try your request again later .
Spread Placement Groups A spread placement group is a group of instances that are each placed on distinct racks , with each rack having its own network and power source .
The following image shows seven instances in a single Availability Zone that are placed into a spread placement group .
The seven instances are placed on seven diﬀerent racks .
Spread placement groups are recommended for applications that have a small number of critical instances that should be kept separate from each other .
Launching instances in a spread placement 790 Amazon Elastic Compute Cloud User Guide for Linux Instances Placement Group Rules and Limitations group reduces the risk of simultaneous failures that might occur when instances share the same racks .
Spread placement groups provide access to distinct racks , and are therefore suitable for mixing instance types or launching instances over time .
A spread placement group can span multiple Availability Zones in the same Region .
You can have a maximum of seven running instances per Availability Zone per group .
If you start or launch an instance in a spread placement group and there is insuﬃcient unique hardware to fulﬁll the request , the request fails .
Amazon EC2 makes more distinct hardware available over time , so you can try your request again later .
Placement Group Rules and Limitations General Rules and Limitations Before you use placement groups , be aware of the following rules : • The name that you specify for a placement group must be unique within your AWS account for the Region .
• An instance can be launched in one placement group at a time ; it can not span multiple placement groups .
The capacity reservation can be used by instances in a placement group .
However , it is not possible to explicitly reserve capacity for a placement group .
• Instances with a tenancy of host can not be launched in placement groups .
• The maximum network throughput speed of traﬃc between two instances in a cluster placement group is limited by the slower of the two instances .
For applications with high-throughput requirements , choose an instance type with network connectivity that meets your requirements .
Instances that are not within a cluster placement group can use up to 5 Gbps for single-ﬂow traﬃc .
• Traﬃc to and from Amazon S3 buckets within the same Region over the public IP address space or through a VPC endpoint can use all available instance aggregate bandwidth .
However , this reduces the likelihood that the required capacity will be available for your launch to succeed .
We recommend using the same instance type for all instances in a cluster placement group .
791 Amazon Elastic Compute Cloud User Guide for Linux Instances Creating a Placement Group • Network traﬃc to the internet and over an AWS Direct Connect connection to on-premises resources is limited to 5 Gbps .
Partition Placement Group Rules and Limitations The following rules apply to partition placement groups : • A partition placement group supports a maximum of seven partitions per Availability Zone .
The number of instances that you can launch in a partition placement group is limited only by your account limits .
• When instances are launched into a partition placement group , Amazon EC2 tries to evenly distribute the instances across all partitions .
• Partition placement groups are not supported for Dedicated Hosts .
Spread Placement Group Rules and Limitations The following rules apply to spread placement groups : • A spread placement group supports a maximum of seven running instances per Availability Zone .
If you try to start an eighth instance in the same Availability Zone and in the same spread placement group , the instance will not launch .
If you need to have more than seven instances in an Availability Zone , then the recommendation is to use multiple spread placement groups .
Using multiple spread placement groups does not provide guarantees about the spread of instances between groups , but it does ensure the spread for each group , thus limiting impact from certain classes of failures .
• Spread placement groups are not supported for Dedicated Instances or Dedicated Hosts .
Creating a Placement Group You can create a placement group using one of the following methods .
Note You can tag a placement group on creation using the command line tools only .
Choose the placement strategy for the group .
If you choose Partition , choose the number of partitions within the group .
Choose the placement strategy for the group .
If you choose Partition , specify the number of partitions within the group .
AWS CLI To create a placement group using the AWS CLI Use the create-placement-group command .
The following example creates a placement group named my-cluster that uses the cluster placement strategy , and it applies a tag with a key of purpose and a value of production .
Specify the -- strategy parameter with the value partition , and specify the -- partition-count parameter with the desired number of partitions .
In this example , the partition placement group is named HDFS-Group-A and is created with ﬁve partitions .
Tagging a Placement Group To help categorize and manage your existing placement groups , you can tag them with custom metadata .
When you tag a placement group , the instances that are launched into the placement group are not automatically tagged .
You need to explicitly tag the instances that are launched into the placement group .
You can view , add , and delete tags using the new console and the command line tools .
The Manage tags section displays any tags that are assigned to the placement group .
Do the following to add or remove tags : 793 Amazon Elastic Compute Cloud User Guide for Linux Instances Tagging a Placement Group 5 .
You can add up to 50 tags per placement group .
AWS CLI To view placement group tags Use the describe-tags command to view the tags for the speciﬁed resource .
In the following example , you describe the tags for all of your placement groups .
Use the describe-placement-groups command to view the conﬁguration of the speciﬁed placement group , which includes any tags that were speciﬁed for the placement group .
For examples , see Examples in the AWS CLI Command Reference .
PowerShell To view placement group tags Use the Get-EC2Tag command .
To tag an existing placement group Use the New-EC2Tag command .
Launching Instances in a Placement Group You can launch an instance into a placement group if the placement group rules and limitations are met ( p. 791 ) using one of the following methods .
Complete the wizard as directed , taking care to do the following : • On the Choose an Instance Type page , select an instance type that can be launched into a placement group .
• On the Conﬁgure Instance Details page , the following ﬁelds are applicable to placement groups : • For Number of instances , enter the total number of instances that you need in this placement group , because you might not be able to add instances to the placement group later .
• For Placement group , select the Add instance to placement group check box .
If you do not see Placement group on this page , verify that you have selected an instance type that can be launched into a placement group .
• For Placement group name , you can choose to add the instances to an existing placement group or to a new placement group that you create .
If you choose partition , for Target partition , choose Auto distribution to have Amazon EC2 do a best eﬀort to distribute the instances evenly across all the partitions in the group .
Alternatively , specify the partition in which to launch the instances .
In this example , the placement group is named mycluster .
Describing Instances in a Placement Group You can view the placement information of your instances using one of the following methods .
You can also ﬁlter partition placement groups by the partition number using the AWS CLI .
Console To view the placement group and partition number of an instance using the console 1 .
If the instance is not in a placement group , the ﬁeld is empty .
If the placement group is a partition placement group , inspect Partition number for the partition number for the instance .
AWS CLI To view the partition number for an instance in a partition placement group using the AWS CLI Use the describe-instances command and specify the -- instance-id parameter .
The following is example output showing only the instance ID , instance type , and placement information for the returned instances .
You can move or remove an instance using the AWS CLI or an AWS SDK .
AWS CLI To move an instance to a placement group using the AWS CLI 1 .
Use the modify-instance-placement command and specify the name of the placement group to which to move the instance .
PowerShell To move an instance to a placement group using the AWS Tools for Windows PowerShell 1 .
Use the Edit-EC2InstancePlacement command and specify the name of the placement group to which to move the instance .
AWS CLI To remove an instance from a placement group using the AWS CLI 1 .
Use the modify-instance-placement command and specify an empty string for the placement group name .
798 Amazon Elastic Compute Cloud User Guide for Linux Instances Deleting a Placement Group PowerShell To remove an instance from a placement group using the AWS Tools for Windows PowerShell 1 .
Use the Edit-EC2InstancePlacement command and specify an empty string for the placement group name .
Deleting a Placement Group If you need to replace a placement group or no longer need one , you can delete it .
You can delete a placement group using one of the following methods .
Important Before you can delete a placement group , it must contain no instances .
You can verify that an instance is in a placement group before you terminate or move it by selecting the instance in the Instances screen and checking the value of Placement group in the details pane .
Select the placement group and choose Delete .
When prompted for conﬁrmation , enter Delete and then choose Delete .
Select the placement group and choose Delete Placement Group .
AWS CLI To delete a placement group using the AWS CLI Use the delete-placement-group command and specify the placement group name to delete the placement group .
aws ec2 delete-placement-group -- group-name my-cluster PowerShell To delete a placement group using the AWS Tools for Windows PowerShell 799 Amazon Elastic Compute Cloud User Guide for Linux Instances Network MTU Use the Remove-EC2PlacementGroup command to delete the placement group .
Network Maximum Transmission Unit ( MTU ) for Your EC2 Instance The maximum transmission unit ( MTU ) of a network connection is the size , in bytes , of the largest permissible packet that can be passed over the connection .
The larger the MTU of a connection , the more data that can be passed in a single packet .
Ethernet packets consist of the frame , or the actual data you are sending , and the network overhead information that surrounds it .
Ethernet frames can come in diﬀerent formats , and the most common format is the standard Ethernet v2 frame format .
It supports 1500 MTU , which is the largest Ethernet packet size supported over most of the Internet .
The maximum supported MTU for an instance depends on its instance type .
Fewer packets are needed to send the same amount of usable data .
VPN connections and traﬃc sent over an Internet gateway are limited to 1500 MTU .
If packets are over 1500 bytes , they are fragmented , or they are dropped if the Do n't Fragment ﬂag is set in the IP header .
Jumbo frames should be used with caution for Internet-bound traﬃc or any traﬃc that leaves a VPC .
Packets are fragmented by intermediate systems , which slows down this traﬃc .
To use jumbo frames inside a VPC and not slow traﬃc that 's bound for outside the VPC , you can conﬁgure the MTU size by route , or use multiple elastic network interfaces with diﬀerent MTU sizes and diﬀerent routes .
For instances that are collocated inside a cluster placement group , jumbo frames help to achieve the maximum network throughput possible , and they are recommended in this case .
You can use jumbo frames for traﬃc between your VPCs and your on-premises networks over AWS Direct Connect .
For more information , and for how to verify Jumbo Frame capability , see Setting Network MTU in the AWS Direct Connect User Guide .
Path MTU Discovery Path MTU Discovery is used to determine the path MTU between two devices .
The path MTU is the maximum packet size that 's supported on the path between the originating host and the receiving host .
If a host sends a packet that 's larger than the MTU of the receiving host or that 's larger than the MTU of a device along the path , the receiving host or device returns the following ICMP message : Destination 800 Amazon Elastic Compute Cloud User Guide for Linux Instances Check the Path MTU Between Two Hosts Unreachable : Fragmentation Needed and Do n't Fragment was Set ( Type 3 , Code 4 ) .
This instructs the original host to adjust the MTU until the packet can be transmitted .
By default , security groups do not allow any inbound ICMP traﬃc .
To ensure that your instance can receive this message and the packet does not get dropped , you must add a Custom ICMP Rule with the Destination Unreachable protocol to the inbound security group rules for your instance .
Important Modifying your instance 's security group to allow path MTU discovery does not guarantee that jumbo frames will not be dropped by some routers .
An Internet gateway in your VPC will forward packets up to 1500 bytes only .
Check the Path MTU Between Two Hosts You can check the path MTU between two hosts using the tracepath command , which is part of the iputils package that is available by default on many Linux distributions , including Amazon Linux .
To check path MTU using tracepath Use the following command to check the path MTU between your EC2 instance and another host .
You can use a DNS name or an IP address as the destination .
If the destination is another EC2 instance , verify that the security group allows inbound UDP traﬃc .
Check and Set the MTU on Your Linux Instance Some instances are conﬁgured to use jumbo frames , and others are conﬁgured to use standard frame sizes .
You may want to use jumbo frames for network traﬃc within your VPC or you may want to use standard frames for Internet traﬃc .
Whatever your use case , we recommend verifying that your instance will behave the way you expect it to .
You can use the procedures in this section to check your network interface 's MTU setting and modify it if needed .
To check the MTU setting on a Linux instance You can check the current MTU value using the following ip command .
Note that in the example output , mtu 9001 indicates that this instance uses jumbo frames .
You can set the MTU value using the ip command .
( Optional ) Reboot your instance and verify that the MTU setting is correct .
Troubleshooting If you experience connectivity issues between your EC2 instance and an Amazon Redshift cluster when using jumbo frames , see Queries Appear to Hang in the Amazon Redshift Cluster Management Guide Virtual Private Clouds Amazon Virtual Private Cloud ( Amazon VPC ) enables you to deﬁne a virtual network in your own logically isolated area within the AWS cloud , known as a virtual private cloud ( VPC ) .
You can launch your Amazon EC2 resources , such as instances , into the subnets of your VPC .
Your VPC closely resembles a traditional network that you might operate in your own data center , with the beneﬁts of using scalable infrastructure from AWS .
You can conﬁgure your VPC ; you can select its IP address range , create subnets , and conﬁgure route tables , network gateways , and security settings .
You can connect instances in your VPC to the internet or to your own data center .
When you create your AWS account , we create a default VPC for you in each Region .
A default VPC is a VPC that is already conﬁgured and ready for you to use .
You can launch instances into your default VPC immediately .
Alternatively , you can create your own nondefault VPC and conﬁgure it as you need .
If you created your AWS account before 2013-12-04 , you might have support for the EC2-Classic platform in some regions .
802 Amazon Elastic Compute Cloud User Guide for Linux Instances Amazon VPC Documentation Amazon VPC Documentation For more information about Amazon VPC , see the following documentation .
Guide Description Amazon VPC User Guide Describes key concepts and provides instructions for using the features of Amazon VPC .
Amazon VPC Peering Guide Describes VPC peering connections and provides instructions for using them .
Amazon VPC Transit Gateways Describes transit gateways and provides instructions for conﬁguring and using them .
AWS Site-to-Site VPN User Guide Describes Site-to-Site VPN connections and provides instructions for conﬁguring and using them .
By default , when you launch an instance , we launch it into your default VPC .
Alternatively , you can create a nondefault VPC and specify it when you launch an instance .
Detecting Supported Platforms The Amazon EC2 console indicates which platforms you can launch instances into for the selected region , and whether you have a default VPC in that Region .
Verify that the Region you 'll use is selected in the navigation bar .
On the Amazon EC2 console dashboard , look for Supported Platforms under Account Attributes .
Accounts that Support EC2-Classic The dashboard displays the following under Account Attributes to indicate that the account supports both the EC2-Classic platform and VPCs in this region , but the Region does not have a default VPC .
The output of the describe-account-attributes command includes only the VPC value for the supported-platforms attribute .
Note that you must create a nondefault VPC if you do not have a default VPC and you are using the AWS CLI , Amazon EC2 API , or AWS SDK to launch a VPC-only instance .
The Amazon EC2 console creates a nondefault VPC in your account and launches the instance into the subnet in the ﬁrst Availability Zone .
The console creates the VPC with the following attributes : • One subnet in each Availability Zone , with the public IPv4 addressing attribute set to true so that instances receive a public IPv4 address .
For more information , see IP Addressing in Your VPC in the Amazon VPC User Guide .
• An Internet gateway , and a main route table that routes traﬃc in the VPC to the Internet gateway .
This enables the instances you launch in the VPC to communicate over the Internet .
For more information , see Internet Gateways in the Amazon VPC User Guide .
• A default security group for the VPC and a default network ACL that is associated with each subnet .
For more information , see Security Groups for Your VPC in the Amazon VPC User Guide .
If you have other resources in EC2-Classic , you can take steps to migrate them to a VPC .
Diﬀerences Between Instances in EC2-Classic and a VPC The following table summarizes the diﬀerences between instances launched in EC2-Classic , instances launched in a default VPC , and instances launched in a nondefault VPC .
Your instance receives a static private IPv4 address from the address range of your default VPC .
Your instance receives a static private IPv4 address from the address range of your VPC .
Multiple private IPv4 addresses We select a single private IP address for your instance ; multiple IP addresses are not supported .
You can assign multiple private IPv4 addresses to your instance .
You can assign multiple private IPv4 addresses to your instance .
805 Amazon Elastic Compute Cloud User Guide for Linux Instances Diﬀerences Between Instances in EC2-Classic and a VPC Characteristic EC2-Classic Default VPC Nondefault VPC Elastic IP address ( IPv4 ) An Elastic IP is disassociated from your instance when you stop it .
An Elastic IP remains associated with your instance when you stop it .
An Elastic IP remains associated with your instance when you stop it .
Associating an Elastic IP address You associate an Elastic IP address with an instance .
You associate an Elastic IP address with an instance by updating the network interface attached to the instance .
You associate an Elastic IP address with an instance by updating the network interface attached to the instance .
Reassociating an Elastic IP address If the Elastic IP address is already associated with another instance , the address is automatically associated with the new instance .
If the Elastic IP address is already associated with another instance , the address is automatically associated with the new instance .
If the Elastic IP address is already associated with another instance , it succeeds only if you allowed reassociation .
Tagging Elastic IP addresses You can not apply tags to an Elastic IP address .
You can apply tags to an Elastic IP address .
You can apply tags to an Elastic IP address .
DNS hostnames DNS hostnames are enabled by default .
DNS hostnames are enabled by default .
DNS hostnames are disabled by default .
Security group A security group can reference security groups that belong to other AWS accounts .
A security group can reference security groups for your VPC only .
Security group association You ca n't change the security groups of your running instance .
You can either modify the rules of the assigned security groups , or replace the instance with a new one ( create an AMI from the instance , launch a new instance from this AMI with the security groups that you need , disassociate any Elastic IP address from the original instance and associate it with the new instance , and then terminate the original instance ) .
You can assign up to 5 security groups to an instance .
You can assign up to 5 security groups to an instance .
You can assign security groups to your instance when you launch it and while it 's running .
You can assign security groups to your instance when you launch it and while it 's running .
You can add rules for inbound traﬃc only .
You can add rules for inbound and outbound traﬃc .
You can add rules for inbound and outbound traﬃc .
Security group rules 806 Amazon Elastic Compute Cloud User Guide for Linux Instances Diﬀerences Between Instances in EC2-Classic and a VPC Characteristic EC2-Classic Default VPC Nondefault VPC Tenancy Your instance runs on shared hardware .
You can run your instance on shared hardware or single-tenant hardware .
You can run your instance on shared hardware or single-tenant hardware .
Accessing the Internet Your instance can access the Internet .
Your instance automatically receives a public IP address , and can access the Internet directly through the AWS network edge .
An Internet gateway is attached to your default VPC , and your default subnet has a route to the Internet gateway .
By default , your instance can not access the Internet .
Your VPC may have an Internet gateway , depending on how it was created .
You can optionally associate an IPv6 CIDR block with your VPC , and assign IPv6 addresses to instances in your VPC .
You can optionally associate an IPv6 CIDR block with your VPC , and assign IPv6 addresses to instances in your VPC .
When you launch an instance in EC2-Classic , you must specify a security group in the same Region as the instance .
However , you can add rules to or remove rules from a security group , and those changes are automatically applied to all instances that are associated with the security group after a short period .
You can create custom security groups .
The security group name must be unique within your account for the Region .
You can add inbound rules to your default and custom security groups .
When you create a security group rule , you can use a diﬀerent security group for EC2-Classic in the same Region as the source or destination .
You can have up to 800 security group rules per instance .
This is calculated as the multiple of rules per security group and security groups per instance .
If you reference other security groups in your security group rules , we recommend that you use security group names that are 22 characters or less in length .
If you create a custom ﬁrewall conﬁguration in EC2-Classic , you must create a rule in your ﬁrewall that allows inbound traﬃc from port 53 ( DNS ) —with a destination port from the ephemeral range—from 807 Amazon Elastic Compute Cloud User Guide for Linux Instances Diﬀerences Between Instances in EC2-Classic and a VPC the address of the Amazon DNS server ; otherwise , internal DNS resolution from your instances fails .
If your ﬁrewall does n't automatically allow DNS query responses , then you need to allow traﬃc from the IP address of the Amazon DNS server .
To get the IP address of the Amazon DNS server , use the following command from within your instance : grep nameserver /etc/resolv.conf Elastic IP Addresses If your account supports EC2-Classic , there 's one pool of Elastic IP addresses for use with the EC2-Classic platform and another for use with your VPCs .
However , you can migrate an Elastic IP address you 've allocated for use in the EC2-Classic platform for use with a VPC .
You can not migrate an Elastic IP address to another Region .
To allocate an Elastic IP address for use in EC2-Classic using the console 1 .
Migrating an Elastic IP Address from EC2-Classic If your account supports EC2-Classic , you can migrate Elastic IP addresses that you 've allocated for use with EC2-Classic platform to be used with a VPC , within the same Region .
This can assist you to migrate your resources from EC2-Classic to a VPC ; for example , you can launch new web servers in your VPC , and then use the same Elastic IP addresses that you used for your web servers in EC2-Classic for your new VPC web servers .
You can not migrate an Elastic IP address that was originally allocated for use with a VPC to EC2-Classic .
To migrate an Elastic IP address , it must not be associated with an instance .
You can migrate as many EC2-Classic Elastic IP addresses as you can have in your account .
However , when you migrate an Elastic IP address , it counts against your Elastic IP address limit for VPCs .
You can not migrate an Elastic IP address if it will result in your exceeding your limit .
Similarly , when you restore an Elastic IP address to EC2-Classic , it counts against your Elastic IP address limit for EC2-Classic .
You can not migrate an Elastic IP address that has been allocated to your account for less than 24 hours .
You can migrate an Elastic IP address from EC2-Classic using the Amazon EC2 console or the Amazon VPC console .
This option is only available if your account supports EC2-Classic .
Select the Elastic IP address , and choose Actions , Move to VPC scope .
Amazon Elastic Compute Cloud User Guide for Linux Instances Sharing and Accessing Resources Between EC2-Classic and a VPC In the conﬁrmation dialog box , choose Move Elastic IP .
You can restore an Elastic IP address to EC2-Classic using the Amazon EC2 console or the Amazon VPC console .
After you 've performed the command to move or restore your Elastic IP address , the process of migrating the Elastic IP address can take a few minutes .
Use the describe-moving-addresses command to check whether your Elastic IP address is still moving , or has completed moving .
After you 've moved your Elastic IP address , you can view its allocation ID on the Elastic IPs page in the Allocation ID ﬁeld .
If the Elastic IP address is in a moving state for longer than 5 minutes , contact Premium Support .
To move an Elastic IP address using the command line You can use one of the following commands .
809 Amazon Elastic Compute Cloud User Guide for Linux Instances Sharing and Accessing Resources Between EC2-Classic and a VPC If your account supports EC2-Classic , you might have set up resources for use in EC2-Classic .
If you want to migrate from EC2-Classic to a VPC , you must recreate those resources in your VPC .
You ca n't migrate an Elastic IP address that was originally allocated for use in a VPC to EC2-Classic .
Instance An EC2-Classic instance can communicate with instances in a VPC using public IPv4 addresses , or you can use ClassicLink to enable communication over private IPv4 addresses .
However , you can migrate your application from an instance in EC2-Classic to an instance in a VPC .
Key pair Load balancer If you 're using ClassicLink , you can register a linked EC2-Classic instance with a load balancer in a VPC , provided that the VPC has a subnet in the same Availability Zone as the instance .
Placement group Reserved Instance You can change the network platform for your Reserved Instances from EC2-Classic to a VPC .
Security group A linked EC2-Classic instance can use a VPC security groups through ClassicLink to control traﬃc to and from the VPC .
You can copy rules from a security group for EC2-Classic to a security group 810 Amazon Elastic Compute Cloud User Guide for Linux Instances ClassicLink Resource Notes for a VPC .
Snapshot The following resources ca n't be shared or moved between EC2-Classic and a VPC : • Spot Instances ClassicLink ClassicLink allows you to link EC2-Classic instances to a VPC in your account , within the same Region .
If you associate the VPC security groups with a EC2-Classic instance , this enables communication between your EC2-Classic instance and instances in your VPC using private IPv4 addresses .
ClassicLink removes the need to make use of public IPv4 addresses or Elastic IP addresses to enable communication between instances in these platforms .
ClassicLink is available to all users with accounts that support the EC2-Classic platform , and can be used with any EC2-Classic instance .
There is no additional charge for using ClassicLink .
Standard charges for data transfer and instance usage apply .
By default , all VPCs in your account are not enabled for ClassicLink , to maintain their isolation .
After you 've enabled the VPC for ClassicLink , you can then link any running EC2-Classic instance in the same Region in your account to that VPC .
Linking your instance includes selecting security groups from the VPC to associate with your EC2-Classic instance .
After you 've linked the instance , it can communicate with instances in your VPC using their private IP addresses , provided the VPC security groups allow it .
Your EC2-Classic instance does not lose its private IP address when linked to the VPC .
Note Linking your instance to a VPC is sometimes referred to as attaching your instance .
If you list your instances and ﬁlter by VPC , for example , through the DescribeInstances API request , or by using the Instances screen in the Amazon EC2 console , the results do not return any EC2Classic instances that are linked to the VPC .
The same occurs if you use a public 811 Amazon Elastic Compute Cloud User Guide for Linux Instances ClassicLink DNS hostname to address a linked EC2-Classic instance from an instance in the VPC .
If you want the public DNS hostname to resolve to the private IP address , you can enable ClassicLink DNS support for the VPC .
If you no longer require a ClassicLink connection between your instance and the VPC , you can unlink the EC2-Classic instance from the VPC .
This disassociates the VPC security groups from the EC2-Classic instance .
After you 've unlinked all linked EC2-Classic instances from the VPC , you can disable ClassicLink for the VPC .
Using other AWS services in your VPC with ClassicLink Linked EC2-Classic instances can access the following AWS services in the VPC : Amazon Redshift , Amazon ElastiCache , Elastic Load Balancing , and Amazon RDS .
However , instances in the VPC can not access the AWS services provisioned by the EC2-Classic platform using ClassicLink .
If you use Elastic Load Balancing , you can register your linked EC2-Classic instances with the load balancer .
You must create your load balancer in the ClassicLink-enabled VPC and enable the Availability Zone in which the instance runs .
If you terminate the linked EC2-Classic instance , the load balancer deregisters the instance .
If you use Amazon EC2 Auto Scaling , you can create an Amazon EC2 Auto Scaling group with instances that are automatically linked to a speciﬁed ClassicLink-enabled VPC at launch .
If you use Amazon RDS instances or Amazon Redshift clusters in your VPC , and they are publicly accessible ( accessible from the Internet ) , the endpoint you use to address those resources from a linked EC2-Classic instance by default resolves to a public IP address .
If those resources are not publicly accessible , the endpoint resolves to a private IP address .
To address a publicly accessible RDS instance or Redshift cluster over private IP using ClassicLink , you must use their private IP address or private DNS hostname , or you must enable ClassicLink DNS support for the VPC .
If you use a private DNS hostname or a private IP address to address an RDS instance , the linked EC2Classic instance can not use the failover support available for Multi-AZ deployments .
You can use the Amazon EC2 console to ﬁnd the private IP addresses of your Amazon Redshift , Amazon ElastiCache , or Amazon RDS resources .
To locate the private IP addresses of AWS resources in your VPC 1 .
Check the descriptions of the network interfaces in the Description column .
A network interface that 's used by Amazon Redshift , Amazon ElastiCache , or Amazon RDS will have the name of the service in the description .
In the details pane , get the private IP address from the Primary private IPv4 IP ﬁeld .
Controlling the use of ClassicLink By default , IAM users do not have permission to work with ClassicLink .
You can create an IAM policy that grants users permissions to enable or disable a VPC for ClassicLink , link or unlink an instance to a ClassicLink-enabled VPC , and to view ClassicLink-enabled VPCs and linked EC2-Classic instances .
812 Amazon Elastic Compute Cloud User Guide for Linux Instances ClassicLink Security groups in ClassicLink Linking your EC2-Classic instance to a VPC does not aﬀect your EC2-Classic security groups .
They continue to control all traﬃc to and from the instance .
This excludes traﬃc to and from instances in the VPC , which is controlled by the VPC security groups that you associated with the EC2-Classic instance .
EC2-Classic instances that are linked to the same VPC can not communicate with each other through the VPC ; regardless of whether they are associated with the same VPC security group .
Communication between EC2-Classic instances is controlled by the EC2-Classic security groups associated with those instances .
After you 've linked your instance to a VPC , you can not change which VPC security groups are associated with the instance .
To associate diﬀerent security groups with your instance , you must ﬁrst unlink the instance , and then link it to the VPC again , choosing the required security groups .
Routing for ClassicLink When you enable a VPC for ClassicLink , a static route is added to all of the VPC route tables with a destination of 10.0.0.0/8 and a target of local .
This allows communication between instances in the VPC and any EC2-Classic instances that are then linked to the VPC .
When you disable ClassicLink for a VPC , this route is automatically deleted in all of the VPC route tables .
VPCs that are in the 10.0.0.0/16 and 10.1.0.0/16 IP address ranges can be enabled for ClassicLink only if they do not have any existing static routes in route tables in the 10.0.0.0/8 IP address range , excluding the local routes that were automatically added when the VPC was created .
Similarly , if you've enabled a VPC for ClassicLink , you may not be able to add any more speciﬁc routes to your route tables within the 10.0.0.0/8 IP address range .
Important If your VPC CIDR block is a publicly routable IP address range , consider the security implications before you link an EC2-Classic instance to your VPC .
For example , if your linked EC2-Classic instance receives an incoming Denial of Service ( DoS ) request ﬂood attack from a source IP address that falls within the VPC ’ s IP address range , the response traﬃc is sent into your VPC .
We strongly recommend that you create your VPC using a private IP address range as speciﬁed in RFC 1918 .
For more information about route tables and routing in your VPC , see Route Tables in the Amazon VPC User Guide .
Enabling a VPC peering connection for ClassicLink If you have a VPC peering connection between two VPCs , and there are one or more EC2-Classic instances that are linked to one or both of the VPCs via ClassicLink , you can extend the VPC peering connection to enable communication between the EC2-Classic instances and the instances in the VPC on the other side of the VPC peering connection .
This enables the EC2-Classic instances and the instances in the VPC to communicate using private IP addresses .
For more information and examples , see Conﬁgurations With ClassicLink in the Amazon VPC Peering Guide .
ClassicLink limitations To use the ClassicLink feature , you need to be aware of the following limitations : 813 Amazon Elastic Compute Cloud User Guide for Linux Instances ClassicLink • You can link an EC2-Classic instance to only one VPC at a time .
• If you stop your linked EC2-Classic instance , it 's automatically unlinked from the VPC and the VPC security groups are no longer associated with the instance .
You can link your instance to the VPC again after you 've restarted it .
For more information , see the Amazon VPC Peering Guide .
You can associate an IPv6 CIDR block with your VPC and assign IPv6 address to resources in your VPC , however , communication between a ClassicLinked instance and resources in the VPC is over IPv4 only .
• VPCs with routes that conﬂict with the EC2-Classic private IP address range of 10/8 can not be enabled for ClassicLink .
This does not include VPCs with 10.0.0.0/16 and 10.1.0.0/16 IP address ranges that already have local routes in their route tables .
• VPCs conﬁgured for dedicated hardware tenancy can not be enabled for ClassicLink .
Contact AWS support to request that your dedicated tenancy VPC be allowed to be enabled for ClassicLink .
If you 've set the tenancy of your VPC to dedicated because of regulatory or security requirements , then linking an EC2-Classic instance to your VPC might not conform to those requirements , as this allows a shared tenancy resource to address your isolated resources directly using private IP addresses .
If you need to enable your dedicated VPC for ClassicLink , provide a detailed reason in your request to AWS support .
To work around this issue , run your DNS server on a diﬀerent IP address within the VPC .
Your linked EC2-Classic instance does n't have access to any VPN connection , VPC gateway endpoint , NAT gateway , or Internet gateway associated with the VPC .
Working with ClassicLink You can use the Amazon EC2 and Amazon VPC consoles to work with the ClassicLink feature .
Note The ClassicLink features are only visible in the consoles for accounts and regions that support EC2-Classic .
You can not enable a VPC for ClassicLink if the VPC has routing that conﬂicts with the EC2-Classic private IP address range .
( Optional ) If you want the public DNS hostname to resolve to the private IP address , enable ClassicLink DNS support for the VPC before you link any instances .
Creating a VPC with ClassicLink enabled You can create a new VPC and immediately enable it for ClassicLink by using the VPC wizard in the Amazon VPC console .
From the Amazon VPC dashboard , choose Start VPC Wizard .
Select one of the VPC conﬁguration options and choose Select .
On the next page of the wizard , choose Yes for Enable ClassicLink .
Complete the rest of the steps in the wizard to create your VPC .
For more information about using the VPC wizard , see Scenarios for Amazon VPC in the Amazon VPC User Guide .
( Optional ) If you want the public DNS hostname to resolve to the private IP address , enable ClassicLink DNS support for the VPC before you link any instances .
You can not link an instance that 's in the stopped state .
If you want the public DNS hostname to resolve to the private IP address , enable ClassicLink DNS support for the VPC before you link the instance .
You can select more than one instance to link to the same VPC .
Only VPCs that have been enabled for ClassicLink are displayed .
Select one or more of the VPC security groups to associate with your instance .
Linking an instance to a VPC at launch You can use the launch wizard in the Amazon EC2 console to launch an EC2-Classic instance and immediately link it to a ClassicLink-enabled VPC .
Select an AMI , and then choose an instance type .
On the Conﬁgure Instance Details page , ensure that you select Launch into EC2-Classic from the Network list .
Ensure that you select an instance type that can be launched into EC2-Classic .
Select the security groups from the VPC to associate with the instance .
Complete the other conﬁguration options on the page , and then complete the rest of the steps in the wizard to launch your instance .
Viewing your ClassicLink-enabled VPCs and linked instances You can view all of your ClassicLink-enabled VPCs in the Amazon VPC console , and your linked EC2Classic instances in the Amazon EC2 console .
A value of Enabled indicates that the VPC is enabled for ClassicLink .
If the instance is linked to a VPC , the ﬁeld displays the ID of the VPC to which the instance is linked .
If the instance is not linked to any VPC , the ﬁeld displays Unlinked .
Alternatively , you can ﬁlter your instances to display only linked EC2-Classic instances for a speciﬁc VPC or security group .
In the search bar , start typing ClassicLink , select the relevant ClassicLink resource attribute , and then select the security group ID or the VPC ID .
Enabling ClassicLink DNS support You can enable ClassicLink DNS support for your VPC so that DNS hostnames that are addressed between linked EC2-Classic instances and instances in the VPC resolve to private IP addresses and not public IP addresses .
For this feature to work , your VPC must be enabled for DNS hostnames and DNS resolution .
Note If you enable ClassicLink DNS support for your VPC , your linked EC2-Classic instance can access any private hosted zone associated with the VPC .
For more information , see Working with Private Hosted Zones in the Amazon Route 53 Developer Guide .
Disabling ClassicLink DNS support You can disable ClassicLink DNS support for your VPC so that DNS hostnames that are addressed between linked EC2-Classic instances and instances in the VPC resolve to public IP addresses and not private IP addresses .
For ClassicLink DNS Support , clear the Enable check box , and then choose Save .
Unlinking an instance from a VPC If you no longer require a ClassicLink connection between your EC2-Classic instance and your VPC , you can unlink the instance from the VPC .
Unlinking the instance disassociates the VPC security groups from the instance .
You can select more than one instance to unlink from the same VPC .
Choose Yes in the conﬁrmation dialog box .
817 Amazon Elastic Compute Cloud User Guide for Linux Instances ClassicLink Disabling ClassicLink for a VPC If you no longer require a connection between EC2-Classic instances and your VPC , you can disable ClassicLink on the VPC .
You must ﬁrst unlink all linked EC2-Classic instances that are linked to the VPC .
Example IAM policies for ClassicLink You can enable a VPC for ClassicLink and then link an EC2-Classic instance to the VPC .
Users can not enable or disable any other VPCs for ClassicLink .
The second statement allows users to use the VPC and security group resources , which are required to link an instance to a VPC .
Users can not link an instance to any other VPC , and they can not specify any other of the VPC security groups to associate with the instance in the request .
The second statement grants users permissions to use the VPC resource , which is required to unlink an instance from a VPC .
Your web server accepts HTTPS traﬃc from the Internet , and then communicates with your application server over TCP port 6001 .
Your application server then communicates with your database server over TCP port 6004 .
You 're in the process of migrating your entire application to a VPC in your account .
You 've already migrated your application server and your database server to your VPC .
Your web server is still in EC2-Classic and linked to your VPC via ClassicLink .
You want a security group conﬁguration that allows traﬃc to ﬂow only between these instances .
The following diagram displays the architecture of your instances , and their security group conﬁguration .
820 Amazon Elastic Compute Cloud User Guide for Linux Instances ClassicLink Security groups for your web server ( sg-1a1a1a1a and sg-2b2b2b2b ) You have one security group in EC2-Classic , and the other in your VPC .
You associated the VPC security group with your web server instance when you linked the instance to your VPC via ClassicLink .
The VPC security group enables you to control the outbound traﬃc from your web server to your application server .
Inbound Source Type Port Range Comments 0.0.0.0/0 HTTPS 443 Allows Internet traﬃc to reach your web server .
Outbound 821 Amazon Elastic Compute Cloud User Guide for Linux Instances Migrating from EC2-Classic to a VPC Destination Type Port Range Comments sg-3c3c3c3c TCP 6001 Allows outbound traﬃc from your web server to your application server in your VPC ( or to any other instance associated with sg-3c3c3c3c ) .
Security group for your application server ( sg-3c3c3c3c ) The following are the security group rules for the VPC security group that 's associated with your application server .
Inbound Source Type Port Range Comments sg-2b2b2b2b TCP 6001 Allows the speciﬁed type of traﬃc from your web server ( or any other instance associated with sg-2b2b2b2b ) to reach your application server .
Destination Type Port Range Comments sg-4d4d4d4d TCP 6004 Allows outbound traﬃc from the application server to the database server ( or to any other instance associated with sg-4d4d4d4d ) .
Outbound Security group for your database server ( sg-4d4d4d4d ) The following are the security group rules for the VPC security group that 's associated with your database server .
Inbound Source Type Port Range Comments sg-3c3c3c3c TCP 6004 Allows the speciﬁed type of traﬃc from your application server ( or any other instance associated with sg-3c3c3c3c ) to reach your database server .
822 Amazon Elastic Compute Cloud User Guide for Linux Instances Migrating from EC2-Classic to a VPC If your account supports EC2-Classic , you might have set up resources for use in EC2-Classic .
If you want to migrate from EC2-Classic to a VPC , you must recreate those resources in your VPC .
You can do a full migration , or you can do an incremental migration over time .
The method you choose depends on the size and complexity of your application in EC2-Classic .
For example , if your application consists of one or two instances running a static website , and you can aﬀord a short period of downtime , you can do a full migration .
If you have a multi-tier application with processes that can not be interrupted , you can do an incremental migration using ClassicLink .
This allows you to transfer functionality one component at a time until your application is running fully in your VPC .
You can create one using one of these methods : • Your AWS account comes with a default VPC in each region , which is ready for you to use .
Instances that you launch are by default launched into this VPC , unless you specify otherwise .
For more information about your default VPC , see Default VPC and Default Subnets .
Use this option if you 'd prefer not to set up a VPC yourself , or if you do not need speciﬁc requirements for your VPC conﬁguration .
• In your existing AWS account , open the Amazon VPC console and use the VPC wizard to create a new VPC .
For more information , see Amazon VPC Console Wizard Conﬁgurations .
Use this option if you want to set up a VPC quickly in your existing EC2-Classic account , using one of the available conﬁguration sets in the wizard .
You 'll specify this VPC each time you launch an instance .
• In your existing AWS account , open the Amazon VPC console and set up the components of a VPC according to your requirements .
Use this option if you have speciﬁc requirements for your VPC , such as a particular number of subnets .
You 'll specify this VPC each time you launch an instance .
However , if you want your instances in your VPC to have the same security group rules as your EC2-Classic instances , you can use 823 Amazon Elastic Compute Cloud User Guide for Linux Instances Migrating from EC2-Classic to a VPC the Amazon EC2 console to copy your existing EC2-Classic security group rules to a new VPC security group .
Important You can only copy security group rules to a new security group in the same AWS account in the same Region .
If you 've created a new AWS account , you can not use this method to copy your existing security group rules to your new account .
Select the security group that 's associated with your EC2-Classic instance , then choose Actions and select Copy to new .
In the Create Security Group dialog box , specify a name and description for your new security group .
Select your VPC from the VPC list .
The Inbound tab is populated with the rules from your EC2-Classic security group .
You can modify the rules as required .
In the Outbound tab , a rule that allows all outbound traﬃc has automatically been created for you .
If you 've deﬁned a rule in your EC2-Classic security group that references another security group , you will not be able to use the same rule in your VPC security group .
Modify the rule to reference a security group in the same VPC .
You can create your own AMI based on an existing EC2Classic instance , then use that AMI to launch instances into your VPC .
The method you use to create your AMI depends on the root device type of your instance , and the operating system platform on which your instance runs .
To ﬁnd out the root device type of your instance , go to the Instances page , select your instance , and look at the information in the Root device type ﬁeld in the Description tab .
You can also use the describe-instances AWS CLI command to ﬁnd out the root device type .
The following table provides options for you to create your AMI based on the root device type of your instance , and the software platform .
Important Some instance types support both PV and HVM virtualization , while others support only one or the other .
If you plan to use your AMI to launch a diﬀerent instance type than your current instance type , check that the instance type supports the type of virtualization that your AMI oﬀers .
If your AMI supports PV virtualization , and you want to use an instance type that supports HVM virtualization , you may have to reinstall your software on a base HVM AMI .
Instance Root Device Type Action EBS Create an EBS-backed AMI from your instance .
824 Amazon Elastic Compute Cloud User Guide for Linux Instances Migrating from EC2-Classic to a VPC Instance Root Device Type Action Instance store Create an instance store-backed AMI from your instance using the AMI tools .
( Optional ) Store Your Data on Amazon EBS Volumes You can create an Amazon EBS volume and use it to back up and store the data on your instance— like you would use a physical hard drive .
Amazon EBS volumes can be attached and detached from any instance in the same Availability Zone .
You can detach a volume from your instance in EC2-Classic , and attach it to a new instance that you launch into your VPC in the same Availability Zone .
If you need to , you can restore an Amazon EBS volume from your snapshot .
The instance will have the same data and conﬁgurations as your existing EC2-Classic instance .
Using Your Existing EC2-Classic Account You can use the Amazon EC2 launch wizard to launch an instance into your VPC .
On the Choose an Amazon Machine Image page , select the My AMIs category , and select the AMI you created .
On the Choose an Instance Type page , select the type of instance , and choose Next : Conﬁgure Instance Details .
On the Conﬁgure Instance Details page , select your VPC from the Network list .
Select the required subnet from the Subnet list .
Conﬁgure any other details you require , then go through the next pages of the wizard until you reach the Conﬁgure Security Group page .
Select Select an existing group , and select the security group you created earlier .
7. Review your instance details , then choose Launch to specify a key pair and launch your instance .
For more information about the parameters you can conﬁgure in each step of the wizard , see Launching an instance using the Launch Instance Wizard ( p. 446 ) .
Using Your New , VPC-Only Account To launch an instance in your new AWS account , you 'll ﬁrst have to share the AMI you created with your new account .
You can then use the Amazon EC2 launch wizard to launch an instance into your default VPC .
To share an AMI with your new AWS account 1 .
Switch to the account in which you created your AMI .
In the Filter list , ensure Owned by me is selected , then select your AMI .
Enter the account number of your new AWS account , choose Add Permission , and then choose Save .
Switch to your new AWS account .
Select the AMI that you shared from your EC2-Classic account , then choose Launch .
On the Choose an Instance Type page , select the type of instance , and choose Next : Conﬁgure Instance Details .
On the Conﬁgure Instance Details page , your default VPC should be selected in the Network list .
Conﬁgure any other details you require , then go through the next pages of the wizard until you reach the Conﬁgure Security Group page .
Select Select an existing group , and select the security group you created earlier .
8. Review your instance details , then choose Launch to specify a key pair and launch your instance .
For more information about the parameters you can conﬁgure in each step of the wizard , see Launching an instance using the Launch Instance Wizard ( p. 446 ) .
Example : Migrating a Simple Web Application In this example , you use AWS to host your gardening website .
Instances A and B host your public-facing web application , and you use Elastic Load Balancing to load balance the traﬃc between these instances .
You 've assigned Elastic IP addresses to instances A and B so that you have static IP addresses for conﬁguration and administration tasks on those instances .
You 've registered the domain name www.garden.example.com , and you 've used Route 53 to create a hosted zone with an alias record set that 's associated with the DNS name of your load balancer .
826 Amazon Elastic Compute Cloud User Guide for Linux Instances Migrating from EC2-Classic to a VPC The ﬁrst part of migrating to a VPC is deciding what kind of VPC architecture will suit your needs .
In this case , you 've decided on the following : one public subnet for your web servers , and one private subnet for your database server .
As your website grows , you can add more web servers and database servers to your subnets .
By default , instances in the private subnet can not access the Internet ; however , you can enable Internet access through a Network Address Translation ( NAT ) device in the public subnet .
You may want to set up a NAT device to support periodic updates and patches from the Internet for your database server .
You 'll migrate your Elastic IP addresses to a VPC , and create a load balancer in your public subnet to load balance the traﬃc between your web servers .
827 Amazon Elastic Compute Cloud User Guide for Linux Instances Migrating from EC2-Classic to a VPC To migrate your web application to a VPC , you can follow these steps : • Create a VPC : In this case , you can use the VPC wizard in the Amazon VPC console to create your VPC and subnets .
The second wizard conﬁguration creates a VPC with one private and one public subnet , and launches and conﬁgures a NAT device in your public subnet for you .
For more information , see VPC with Public and Private Subnets ( NAT ) in the Amazon VPC User Guide .
• Create AMIs from your instances : Create an AMI from one of your web servers , and a second AMI from your database server .
• Conﬁgure your security groups : In your EC2-Classic environment , you have one security group for your web servers , and another security group for your database server .
You can use the Amazon EC2 console to copy the rules from each security group into new security groups for your VPC .
Tip Create the security groups that are referenced by other security groups ﬁrst .
• Launch an instance into your new VPC : Launch replacement web servers into your public subnet , and launch your replacement database server into your private subnet .
• Conﬁgure your NAT device : If you are using a NAT instance , you must create security group for it that allows HTTP and HTTPS traﬃc from your private subnet .
If you are using a NAT gateway , traﬃc from your private subnet is automatically allowed .
828 Amazon Elastic Compute Cloud User Guide for Linux Instances Migrating from EC2-Classic to a VPC • Conﬁgure your database : When you created an AMI from your database server in EC2-Classic , all the conﬁguration information that was stored in that instance was copied to the AMI .
You may have to connect to your new database server and update the conﬁguration details ; for example , if you conﬁgured your database to grant full read , write , and modiﬁcation permissions to your web servers in EC2-Classic , you 'll have to update the conﬁguration ﬁles to grant the same permissions to your new VPC web servers instead .
• Conﬁgure your web servers : Your web servers will have the same conﬁguration settings as your instances in EC2-Classic .
For example , if you conﬁgured your web servers to use the database in EC2Classic , update your web servers ' conﬁguration settings to point to your new database instance .
Note By default , instances launched into a nondefault subnet are not assigned a public IP address , unless you specify otherwise at launch .
Your new database server may not have a public IP address .
In this case , you can update your web servers ' conﬁguration ﬁle to use your new database server 's private DNS name .
Instances in the same VPC can communicate with each other via private IP address .
• Migrate your Elastic IP addresses : Disassociate your Elastic IP addresses from your web servers in EC2Classic , and then migrate them to a VPC .
After you 've migrated them , you can associate them with your new web servers in your VPC .
• Create a new load balancer : To continue using Elastic Load Balancing to load balance the traﬃc to your instances , make sure you understand the various ways you can conﬁgure your load balancer in VPC .
For more information , see Elastic Load Balancing in Amazon VPC .
• Update your DNS records : After you 've set up your load balancer in your public subnet , ensure that your www.garden.example.com domain points to your new load balancer .
To do this , you 'll need to update your DNS records and update your alias record set in Route 53 .
• Shut down your EC2-Classic resources : After you 've veriﬁed that your web application is working from within the VPC architecture , you can shut down your EC2-Classic resources to stop incurring charges for them .
Incremental Migration to a VPC Using ClassicLink The ClassicLink feature makes it easier to manage an incremental migration to a VPC .
ClassicLink allows you to link an EC2-Classic instance to a VPC in your account in the same region , allowing your new VPC resources to communicate with the EC2-Classic instance using private IPv4 addresses .
You can then migrate functionality to the VPC one step at a time .
This topic provides some basic steps for managing an incremental migration from EC2-Classic to a VPC .
You may decide to start the migration process with the authentication logic , then the database server , and ﬁnally , the web server .
You can create one using one of these methods : • In your existing AWS account , open the Amazon VPC console and use the VPC wizard to create a new VPC .
For more information , see Amazon VPC Console Wizard Conﬁgurations .
Use this option if you want to set up a VPC quickly in your existing EC2-Classic account , using one of the available conﬁguration sets in the wizard .
You 'll specify this VPC each time you launch an instance .
• In your existing AWS account , open the Amazon VPC console and set up the components of a VPC according to your requirements .
Use this option if you have speciﬁc requirements for your VPC , such as a particular number of subnets .
You 'll specify this VPC each time you launch an instance .
Select your VPC , and then select Enable ClassicLink from the Actions list .
You can create your own AMI based on an existing EC2Classic instance , then use that AMI to launch instances into your VPC .
The method you use to create your AMI depends on the root device type of your instance , and the operating system platform on which your instance runs .
To ﬁnd out the root device type of your instance , go to the Instances page , select your instance , and look at the information in the Root device type ﬁeld in the Description tab .
You can also use the describe-instances AWS CLI command to ﬁnd out the root device type .
The following table provides options for you to create your AMI based on the root device type of your instance , and the software platform .
Important Some instance types support both PV and HVM virtualization , while others support only one or the other .
If you plan to use your AMI to launch a diﬀerent instance type than your current instance type , check that the instance type supports the type of virtualization that your AMI oﬀers .
If your AMI supports PV virtualization , and you want to use an instance type that 830 Amazon Elastic Compute Cloud User Guide for Linux Instances Migrating from EC2-Classic to a VPC supports HVM virtualization , you may have to reinstall your software on a base HVM AMI .
Instance Root Device Type Action EBS Create an EBS-backed AMI from your instance .
Instance store Create an instance store-backed AMI from your instance using the AMI tools .
( Optional ) Store Your Data on Amazon EBS Volumes You can create an Amazon EBS volume and use it to back up and store the data on your instance— like you would use a physical hard drive .
Amazon EBS volumes can be attached and detached from any instance in the same Availability Zone .
You can detach a volume from your instance in EC2-Classic , and attach it to a new instance that you launch into your VPC in the same Availability Zone .
If you need to , you can restore an Amazon EBS volume from your snapshot .
You can use the AMIs that you created in the previous step to launch instances into your VPC .
The instances will have the same data and conﬁgurations as your existing EC2Classic instances .
To launch an instance into your VPC using your custom AMI 1 .
On the Choose an Amazon Machine Image page , select the My AMIs category , and select the AMI you created .
On the Choose an Instance Type page , select the type of instance , and choose Next : Conﬁgure Instance Details .
On the Conﬁgure Instance Details page , select your VPC from the Network list .
Select the required subnet from the Subnet list .
Conﬁgure any other details you require , then go through the next pages of the wizard until you reach the Conﬁgure Security Group page .
Select Select an existing group , and select the security group you created earlier .
7. Review your instance details , then choose Launch to specify a key pair and launch your instance .
For more information about the parameters you can conﬁgure in each step of the wizard , see Launching an instance using the Launch Instance Wizard ( p. 446 ) .
After you 've launched your instance and it 's in the running state , you can connect to it and conﬁgure it as required .
Step 6 : Link Your EC2-Classic Instances to Your VPC After you 've conﬁgured your instances and made the functionality of your application available in the VPC , you can use ClassicLink to enable private IP communication between your new VPC instances and your EC2-Classic instances .
Ensure that your instance is in the running state .
Select one or more of the VPC security groups to associate with your instance .
Step 7 : Complete the VPC Migration Depending on the size of your application and the functionality that must be migrated , repeat steps 4 to 6 until you 've moved all the components of your application from EC2-Classic into your VPC .
After you 've enabled internal communication between the EC2-Classic and VPC instances , you must update your application to point to your migrated service in your VPC , instead of your service in the EC2Classic platform .
Generally , this includes updating your destination IP addresses to point to the IP addresses of your VPC instances instead of your EC2-Classic instances .
You can migrate your Elastic IP addresses that you are currently using in the EC2-Classic platform to a VPC .
After you 've completed this step and you 've tested that the application is functioning from your VPC , you can terminate your EC2-Classic instances , and disable ClassicLink for your VPC .
You can also clean up any EC2-Classic resources that you may no longer need to avoid incurring charges for them ; for example , you can release Elastic IP addresses , and delete the volumes that were associated with your EC2-Classic instances .
832 Amazon Elastic Compute Cloud User Guide for Linux Instances Infrastructure security Security in Amazon EC2 Cloud security at AWS is the highest priority .
As an AWS customer , you beneﬁt from a data center and network architecture that are built to meet the requirements of the most security-sensitive organizations .
The shared responsibility model describes this as security of the cloud and security in the cloud : • Security of the cloud – AWS is responsible for protecting the infrastructure that runs AWS services in the AWS Cloud .
AWS also provides you with services that you can use securely .
Third-party auditors regularly test and verify the eﬀectiveness of our security as part of the AWS Compliance Programs .
To learn about the compliance programs that apply to Amazon EC2 , see AWS Services in Scope by Compliance Program .
• Security in the cloud – Your responsibility is determined by the AWS service that you use .
You are also responsible for other factors including the sensitivity of your data , your company ’ s requirements , and applicable laws and regulations .
This documentation helps you understand how to apply the shared responsibility model when using Amazon EC2 .
It shows you how to conﬁgure Amazon EC2 to meet your security and compliance objectives .
You also learn how to use other AWS services that help you to monitor and secure your Amazon EC2 resources .
You use AWS published API calls to access Amazon EC2 through the network .
Most modern systems such as Java 7 and later support these modes .
Additionally , requests must be signed using an access key ID and a secret access key that is associated with an IAM principal .
Or you can use the AWS Security Token Service ( AWS STS ) to generate temporary security credentials to sign requests .
833 Amazon Elastic Compute Cloud User Guide for Linux Instances Network isolation Network isolation A virtual private cloud ( VPC ) is a virtual network in your own logically isolated area in the AWS Cloud .
Use separate VPCs to isolate infrastructure by workload or organizational entity .
When you launch an instance , you launch it into a subnet in your VPC .
Use private subnets for your instances if they should not be accessed directly from the internet .
To call the Amazon EC2 API from your VPC without sending traﬃc over the public internet , use AWS PrivateLink .
Isolation on physical hosts Diﬀerent EC2 instances on the same physical host are isolated from each other as though they are on separate physical hosts .
The hypervisor isolates CPU and memory , and the instances are provided virtualized disks instead of access to the raw disk devices .
When you stop or terminate an instance , the memory allocated to it is scrubbed ( set to zero ) by the hypervisor before it is allocated to a new instance , and every block of storage is reset .
This ensures that your data is not unintentionally exposed to another instance .
Network MAC addresses are dynamically assigned to instances by the AWS network infrastructure .
IP addresses are either dynamically assigned to instances by the AWS network infrastructure , or assigned by an EC2 administrator through authenticated API requests .
The AWS network allows instances to send traﬃc only from the MAC and IP addresses assigned to them .
By default , an instance can not receive traﬃc that is not speciﬁcally addressed to it .
If you need to run network address translation ( NAT ) , routing , or ﬁrewall services on your instance , you can disable source/ destination checking for the network interface .
For example , you can allow traﬃc only from the address ranges for your corporate network .
• Use private subnets for your instances if they should not be accessed directly from the internet .
Use a bastion host or NAT gateway for internet access from an instance in a private subnet .
• Use AWS Virtual Private Network or AWS Direct Connect to establish private connections from your remote networks to your VPCs .
• Use VPC Flow Logs to monitor the traﬃc that reaches your instances .
• Use AWS Security Hub to check for unintended network accessibility from your instances .
• Use AWS Systems Manager Session Manager to access your instances remotely instead of opening inbound SSH ports and managing SSH keys .
• Use AWS Systems Manager Run Command to automate common administrative tasks instead of opening inbound SSH ports and managing SSH keys .
In addition to restricting network access to each Amazon EC2 instance , Amazon VPC supports implementing additional network security controls like in-line gateways , proxy servers , and various network monitoring options .
834 Amazon Elastic Compute Cloud User Guide for Linux Instances Interface VPC endpoints For more information , see the AWS Security Best Practices whitepaper .
Amazon EC2 and interface VPC endpoints You can improve the security posture of your VPC by conﬁguring Amazon EC2 to use an interface VPC endpoint .
Interface endpoints are powered by AWS PrivateLink , a technology that enables you to privately access Amazon EC2 APIs by restricting all network traﬃc between your VPC and Amazon EC2 to the Amazon network .
For more information about AWS PrivateLink and VPC endpoints , see Interface VPC Endpoints ( AWS PrivateLink ) .
For more information , see Creating an Interface Endpoint in the Amazon VPC User Guide .
Create an interface VPC endpoint policy You can attach a policy to your VPC endpoint to control access to the Amazon EC2 API .
• The resource on which the actions can be performed .
Important When a non-default policy is applied to an interface VPC endpoint for Amazon EC2 , certain failed API requests , such as those failing from RequestLimitExceeded , might not be logged to AWS CloudTrail or Amazon CloudWatch .
For more information , see Controlling Access to Services with VPC Endpoints in the Amazon VPC User Guide .
The following example shows a VPC endpoint policy that denies permission to create unencrypted volumes or to launch instances with unencrypted volumes .
The example policy also grants permission to perform all other Amazon EC2 actions .
With Availability Zones , you can design and operate applications and databases that automatically fail over between zones without interruption .
Availability Zones are more highly available , fault tolerant , and scalable than traditional single or multiple data center infrastructures .
For more information about AWS Regions and Availability Zones , see AWS Global Infrastructure .
In addition to the AWS global infrastructure , Amazon EC2 oﬀers the following features to support your data resiliency : • Copying AMIs across Regions • Copying EBS snapshots across Regions • Automating EBS snapshots using Amazon Data Lifecycle Manager • Maintaining the health and availability of your ﬂeet using Amazon EC2 Auto Scaling • Distributing incoming traﬃc across multiple instances in a single Availability Zone or multiple Availability Zones using Elastic Load Balancing Data protection in Amazon EC2 Amazon Elastic Compute Cloud ( Amazon EC2 ) conforms to the AWS shared responsibility model , which includes regulations and guidelines for data protection .
AWS is responsible for protecting the global infrastructure that runs all AWS services .
AWS maintains control over data hosted on this infrastructure , including the security conﬁguration controls for handling customer content and personal data .
AWS customers and APN Partners , acting either as data controllers or data processors , are responsible for any personal data that they put in the AWS Cloud .
836 Amazon Elastic Compute Cloud User Guide for Linux Instances Encryption at rest For data protection purposes , we recommend that you protect AWS account credentials and set up individual user accounts with AWS Identity and Access Management ( IAM ) , so that each user is given only the permissions necessary to fulﬁll their job duties .
• Set up API and user activity logging with AWS CloudTrail .
• Use AWS encryption solutions , along with all default security controls within AWS services .
• Use advanced managed security services such as Amazon Macie , which assists in discovering and securing personal data that is stored in Amazon S3 .
We strongly recommend that you never put sensitive identifying information , such as your customers' account numbers , into free-form ﬁelds or metadata , such as function names and tags .
Any data that you enter into metadata might get picked up for inclusion in diagnostic logs .
When you provide a URL to an external server , do n't include credential information in the URL to validate your request to that server .
For more information about data protection , see the AWS Shared Responsibility Model and GDPR blog post on the AWS Security Blog .
Encryption at rest Amazon EBS encryption is an encryption solution for your EBS volumes and snapshots .
The data on NVMe instance store volumes is encrypted using an XTS-AES-256 cipher implemented on a hardware module on the instance .
The encryption keys are generated using the hardware module and are unique to each NVMe instance storage device .
All encryption keys are destroyed when the instance is stopped or terminated and can not be recovered .
You can not disable this encryption and you can not provide your own encryption key .
Encryption in transit AWS provides secure and private connectivity between EC2 instances of all types .
In addition , we automatically encrypt in-transit traﬃc between supported instances in the same VPC or in peered VPCs , using AEAD algorithms with 256-bit encryption .
This encryption feature uses the oﬄoad capabilities of the underlying hardware , and there is no impact on network performance .
SSH provides a secure communications channel for remote access to your Linux instances .
Remote access to your instances using AWS Systems Manager Session Manager and Run Command is encrypted using TLS 1.2 , and requests to create a connection are signed using SigV4 .
Use an encryption protocol such as Transport Layer Security ( TLS ) to encrypt sensitive data in transit between clients and your instances .
Identity and access management for Amazon EC2 Your security credentials identify you to services in AWS and grant you unlimited use of your AWS resources , such as your Amazon EC2 resources .
You can use features of Amazon EC2 and AWS Identity and Access Management ( IAM ) to allow other users , services , and applications to use your Amazon EC2 resources without sharing your security credentials .
You can use IAM to control how other users use resources in your AWS account , and you can use security groups to control access to your Amazon EC2 instances .
You can choose to allow full use or limited use of your Amazon EC2 resources .
When you launch an instance , you assign it one or more security groups .
You add rules to each security group that control traﬃc for the instance .
You can modify the rules for a security group at any time ; the new rules are automatically applied to all instances to which the security group is assigned .
Amazon EC2 permission attributes Your organization might have multiple AWS accounts .
Amazon EC2 enables you to specify additional AWS accounts that can use your Amazon Machine Images ( AMIs ) and Amazon EBS snapshots .
These permissions work at the AWS account level only ; you ca n't restrict permissions for speciﬁc users within the speciﬁed AWS account .
All users in the AWS account that you 've speciﬁed can use the AMI or snapshot .
Each AMI has a LaunchPermission attribute that controls which AWS accounts can access the AMI .
Each Amazon EBS snapshot has a createVolumePermission attribute that controls which AWS accounts can use the snapshot .
IAM and Amazon EC2 IAM enables you to do the following : • Create users and groups under your AWS account • Assign unique security credentials to each user under your AWS account • Control each user 's permissions to perform tasks using AWS resources • Allow the users in another AWS account to share your AWS resources • Create roles for your AWS account and deﬁne the users or services that can assume them • Use existing identities for your enterprise to grant permissions to perform tasks using AWS resources By using IAM with Amazon EC2 , you can control whether users in your organization can perform a task using speciﬁc Amazon EC2 API actions and whether they can use speciﬁc AWS resources .
This topic helps you answer the following questions : • How do I create groups and users in IAM ?
How do I grant permissions to perform actions on speciﬁc resources in Amazon EC2 ?
838 Amazon Elastic Compute Cloud User Guide for Linux Instances IAM and Amazon EC2 Creating an IAM group and users To create an IAM group 1 .
In the navigation pane , choose Groups and then choose Create New Group .
On the Attach Policy page , select an AWS managed policy and then choose Next Step .
Your new group is listed under Group Name .
For Access type , select both Programmatic access and AWS Management Console access .
Each user gets a randomly generated password that meets the current password policy in eﬀect ( if any ) .
You can view or download the passwords when you get to the Final page .
Each user is assigned the password that you enter in the box .
On the Set permissions page , choose Add user to group .
Select the check box next to the group that you created earlier and choose Next : Review .
To view the users ' access keys ( access key IDs and secret access keys ) , choose Show next to each password and secret access key to see .
To save the access keys , choose Download .csv and then save the ﬁle to a safe location .
Important You can not retrieve the secret access key after you complete this step ; if you misplace it you must create a new one .
Give each user his or her credentials ( access keys and password ) ; this enables them to use services based on the permissions you speciﬁed for the IAM group .
To allow IAM users to create or modify resources and perform tasks , you must create IAM policies that grant IAM users permission to use the speciﬁc resources and API actions they 'll need , and then attach those policies to the IAM users or groups that require those permissions .
When you attach a policy to a user or group of users , it allows or denies the users permission to perform the speciﬁed tasks on the speciﬁed resources .
For more general information about IAM policies , see Permissions and Policies in the IAM User Guide .
For more information about managing and creating custom IAM policies , see Managing IAM Policies .
Getting Started An IAM policy must grant or deny permissions to use one or more Amazon EC2 actions .
It must also specify the resources that can be used with the action , which can be all resources , or in some cases , speciﬁc resources .
The policy can also include conditions that you apply to the resource .
This means that for some EC2 API actions , you can not specify which resource a user is allowed to work with for that action .
Instead , you have to allow users to work with all resources for that action .
Each statement is structured as follows .
By default , IAM users do n't have permission to use resources and API actions , so all requests are denied .
An explicit allow overrides the default .
An explicit deny overrides any allows .
• Action : The action is the speciﬁc API action for which you are granting or denying permission .
Some Amazon EC2 API actions allow you to include speciﬁc resources in your policy that can be created or modiﬁed by the action .
They can be used to control when your policy is in eﬀect .
Actions for Amazon EC2 In an IAM policy statement , you can specify any API action from any service that supports IAM .
Supported resource-level permissions for Amazon EC2 API actions Resource-level permissions refers to the ability to specify which resources users are allowed to perform actions on .
This means that for certain Amazon EC2 actions , you can control when users are allowed to use those actions based on conditions that have to be fulﬁlled , or speciﬁc resources that users are allowed to use .
If an API action does not support individual ARNs , you must use a wildcard ( * ) to specify that all resources can be aﬀected by the action .
To see tables that identify which Amazon EC2 API actions support resource-level permissions , and the ARNs and condition keys that you can use in a policy , see Actions , Resources , and Condition Keys for Amazon EC2 in the IAM User Guide .
Keep in mind that you can apply tag-based resource-level permissions in the IAM policies you use for Amazon EC2 API actions .
Amazon Resource Names ( ARNs ) for Amazon EC2 Each IAM policy statement applies to the resources that you specify using their ARNs .
For example , AttachVolume attaches an Amazon EBS volume to an instance , so an IAM user must have permissions to use the volume and the instance .
Condition keys for Amazon EC2 In a policy statement , you can optionally specify conditions that control when it is in eﬀect .
For more information , see Information Available in All Requests in the IAM User Guide .
To use a condition key in your IAM policy , use the Condition statement .
For example , the following policy grants users permission to add and remove inbound and outbound rules for any security group .
It uses the ec2 : Vpc condition key to specify that these actions can only be performed on security groups in a speciﬁc VPC .
If you specify a single condition with multiple values for one key , we evaluate the condition using a logical OR operation .
For permissions to be granted , all conditions must be met .
You can also use placeholders when you specify conditions .
For example , you can grant an IAM user permission to use resources with a tag that speciﬁes his or her IAM user name .
For more information , see Policy Variables in the IAM User Guide .
Important Many condition keys are speciﬁc to a resource , and some API actions use multiple resources .
If you write a policy with a condition key , use the Resource element of the statement to specify the resource to which the condition key applies .
If not , the policy may prevent users from performing the action at all , because the condition check fails for the resources to which the condition key does not apply .
If you do not want to specify a resource , or if you 've written the Action element of your policy to include multiple API actions , then you must use the .IfExists condition type to ensure that the condition key is ignored for resources that do not use it .
The ec2 : SourceInstanceARN key can be used for conditions that specify the ARN of the instance from which a request is made .
The ec2 : SourceInstanceARN key can not be used as a variable to populate the ARN for the Resource element in a statement .
Checking that users have the required permissions After you 've created an IAM policy , we recommend that you check whether it grants users the permissions to use the particular API actions and resources they need before you put the policy into production .
First , create an IAM user for testing purposes , and then attach the IAM policy that you created to the test user .
If the Amazon EC2 action that you are testing creates or modiﬁes a resource , you should make the request using the DryRun parameter ( or run the AWS CLI command with the -- dry-run option ) .
In this case , the call completes the authorization check , but does not complete the operation .
For example , you can check whether the user can terminate a particular instance without actually terminating it .
If the test user has the required permissions , the request returns DryRunOperation ; otherwise , it returns UnauthorizedOperation .
If the policy does n't grant the user the permissions that you expected , or is overly permissive , you can adjust the policy as needed and retest until you get the desired results .
Important It can take several minutes for policy changes to propagate before they take eﬀect .
Therefore , we recommend that you allow ﬁve minutes to pass before you test your policy updates .
If an authorization check fails , the request returns an encoded message with diagnostic information .
You can decode the message using the DecodeAuthorizationMessage action .
For more information , see DecodeAuthorizationMessage in the AWS Security Token Service API Reference , and decode-authorizationmessage in the AWS CLI Command Reference .
844 Amazon Elastic Compute Cloud User Guide for Linux Instances IAM policies Granting permission to tag resources during creation Some resource-creating Amazon EC2 API actions enable you to specify tags when you create the resource .
To enable users to tag resources on creation , they must have permissions to use the action that creates the resource , such as ec2 : RunInstances or ec2 : CreateVolume .
If tags are speciﬁed in the resourcecreating action , Amazon performs additional authorization on the ec2 : CreateTags action to verify if users have permissions to create tags .
In the IAM policy deﬁnition for the ec2 : CreateTags action , use the Condition element with the ec2 : CreateAction condition key to give tagging permissions to the action that creates the resource .
The following example demonstrates a policy that allows users to launch instances and apply any tags to instances and volumes during launch .
Therefore , a user that has permissions to create a resource ( assuming there are no tagging conditions ) does not require permissions to use the ec2 : CreateTags action if no tags are speciﬁed in the request .
However , if the user attempts to create a resource with tags , the request fails if the user does not have permissions to use the ec2 : CreateTags action .
Controlling access to speciﬁc tags You can use additional conditions in the Condition element of your IAM policies to control the tag keys and values that can be applied to resources .
The following condition keys can be used with the examples in the preceding section : • aws : RequestTag : To indicate that a particular tag key or tag key and value must be present in a request .
Other tags can also be speciﬁed in the request .
• Use with the ForAllValues modiﬁer to enforce speciﬁc tag keys if they are provided in the request ( if tags are speciﬁed in the request , only speciﬁc tag keys are allowed ; no other tags are allowed ) .
To learn whether an Amazon EC2 API action supports tagging , see Actions , Resources , and Condition Keys for Amazon EC2 in the IAM User Guide .
To force users to specify tags when they create a resource , you must use the aws : RequestTag condition key or the aws : TagKeys condition key with the ForAnyValue modiﬁer on the resource-creating action .
846 Amazon Elastic Compute Cloud User Guide for Linux Instances IAM policies For conditions , the condition key is not case-sensitive and the condition value is case-sensitive .
For more information about multi-value conditions , see Creating a Condition That Tests Multiple Key Values in the IAM User Guide .
Controlling access using EC2 resource tags You can also provide tag information in the Condition element of a policy to control access based on tags .
For example , you can create a policy that allows users to terminate an instance but denies the action if the instance has the tag environment=production .
To do this , you use the ec2 : ResourceTag condition key to allow or deny access to the resource based on the tags that are attached to the resource .
Note that the Describe actions do not support resource-level permissions , and therefore you must specify them in a separate statement without conditions .
Note If you allow or deny users access to resources based on tags , you must consider explicitly denying users the ability to add those tags to or remove them from the same resources .
Otherwise , it 's possible for a user to circumvent your restrictions and gain access to a resource by modifying its tags .
Example policies for working with the AWS CLI or an AWS SDK The following examples show policy statements that you could use to control the permissions that IAM users have to Amazon EC2 .
These policies are designed for requests that are made with the AWS CLI or an AWS SDK .
For examples of IAM policies speciﬁc to Amazon VPC , see Identity and Access Management for Amazon VPC .
The Resource element uses a wildcard to indicate that users can specify all resources with these API actions .
The * wildcard is also necessary in cases where the API action does not support resource-level permissions .
For more information about which ARNs you can use with which Amazon EC2 API actions , see Actions , Resources , and Condition Keys for Amazon EC2 in the IAM User Guide .
Users do n't have permission to perform any actions on the resources ( unless another statement grants them permission to do so ) because they 're denied permission to use API actions by default .
It uses the global condition key aws : RequestedRegion , which is supported by all Amazon EC2 API actions .
The Resource element uses a * wildcard to indicate that users can specify all resources with these API actions .
The * wildcard is also necessary in cases where the API action does not support resource-level permissions .
For more information about which ARNs you can use with which Amazon EC2 API actions , see Actions , Resources , and Condition Keys for Amazon EC2 in the IAM User Guide .
The users do n't have permission to use any other API actions ( unless another statement grants them permission to do so ) because users are denied permission to use API actions by default .
The ﬁrst statement uses a * wildcard for the Resource element to indicate that users can specify all resources with the action ; in this case , they can list all instances .
For more information about which ARNs you can use with which Amazon EC2 API actions , see Actions , Resources , and Condition Keys for Amazon EC2 in the IAM User Guide .
The second statement uses resource-level permissions for the StopInstances and StartInstances actions .
The speciﬁc instances are indicated by their ARNs in the Resource element .
The Condition element qualiﬁes when the policy statement is in eﬀect .
If you need to use a Condition element with one or more of these resources , you must create multiple statements as shown in this example .
If you attach this policy to an IAM group , the aws : username policy variable gives each IAM user in the group permission to attach or detach volumes from the instances with a tag named volume_user that has his or her IAM user name as a value .
The user is allowed to create a volume only if the volume is encrypted and only if the volume size is less than 20 GiB .
The aws : TagKeys condition key uses the ForAllValues modiﬁer to indicate that only the keys costcenter and stack are allowed in the request ( no other tags can be speciﬁed ) .
If users do n't pass these speciﬁc tags , or if they do n't specify tags at all , the request fails .
For resource-creating actions that apply tags , users must also have permissions to use the CreateTags action .
The second statement uses the ec2 : CreateAction condition key to allow users to create tags only in the context of CreateVolume .
Users can not tag existing volumes or any other resources .
The CreateTags action is only evaluated if tags are speciﬁed in the CreateVolume request .
No other tags are allowed in the request .
The customer can create snapshots only if the volume is encrypted and only if the volume size is less than 20 GiB .
The customer can create snapshots only if all of the volumes on the instance are type GP2 .
The aws : TagKeys condition key uses the ForAllValues modiﬁer to indicate that only the keys costcenter and stack can be speciﬁed in the request .
The request fails if either of these conditions is not met .
For resource-creating actions that apply tags , customers must also have permissions to use the CreateTags action .
The third statement uses the ec2 : CreateAction condition key to allow customers to create tags only in the context of CreateSnapshot .
Customers can not tag existing volumes or any other resources .
The aws : TagKeys condition 854 Amazon Elastic Compute Cloud User Guide for Linux Instances IAM policies key uses the ForAllValues modiﬁer to indicate that only the keys costcenter and stack can be speciﬁed in the request .
The request fails if either of these conditions is not met .
The CreateTags action is evaluated only if tags are speciﬁed in the CreateSnapshot or CreateSnapshots request .
No other tags are allowed in the request .
The customer can add additional tags to the snapshot .
You can only create snapshots ( in the context of CreateSnapshots ) when the snapshots are being created in the Region us-east-1 and when the instance type is t2* .
The request fails if this condition is not met .
RunInstances requires an AMI and creates an instance ; and users can specify a key pair and security group in the request .
You can create a policy statement that requires users to specify an optional parameter on RunInstances , or restricts users to particular values for a parameter .
859 Amazon Elastic Compute Cloud User Guide for Linux Instances IAM policies For more information about the resource-level permissions that are required to launch an instance , see Actions , Resources , and Condition Keys for Amazon EC2 in the IAM User Guide .
One way to grant the users permission to manage the resulting instances is to create a speciﬁc tag for each instance , and then create a statement that enables them to manage instances with that tag .
The users ca n't launch an instance using other AMIs ( unless another statement grants the users permission to do so ) .
The Condition element of the ﬁrst statement tests whether ec2 : Owner is amazon .
The users ca n't launch an instance using other AMIs ( unless another statement grants the users permission to do so ) .
The group ca n't launch instances into any another subnet ( unless another statement grants the users permission to do so ) .
The statement does this by denying permission to create a network interface , except where subnet subnet-12345678 is speciﬁed .
This denial overrides any other policies that are created to allow launching instances into other subnets .
The user must launch an instance from an AMI that was created with encrypted snapshots , to ensure that the root volume is encrypted .
Any additional volume that the user attaches to the instance during launch must also be encrypted .
For resourcecreating actions that apply tags , users must have permissions to use the CreateTags action .
The second statement uses the ec2 : CreateAction condition key to allow users to create tags only in the context 863 Amazon Elastic Compute Cloud User Guide for Linux Instances IAM policies of RunInstances , and only for instances .
Users can not tag existing resources , and users can not tag volumes using the RunInstances request .
The aws : TagKeys condition key uses the ForAllValues modiﬁer to indicate that only the keys environment and purpose are allowed in the request ( no other tags can be speciﬁed ) .
If no tags are speciﬁed in the request , the request fails .
The tag must be applied to both instances and volumes .
Any tag values can be speciﬁed in the request .
Users can apply the tags to any taggable resource in the RunInstances request .
The ec2 : IsLaunchTemplateResource condition key prevents users from overriding any of the resources speciﬁed in the launch template .
The second part of the statement allows users to tag instances on creation—this part of the statement is necessary if tags are speciﬁed for the instance in the launch template .
Users can launch instances in any Region , but they can only attach an elastic GPU during a launch in the us-east-2 Region .
The ec2 : ElasticGpuType condition key uses the ForAnyValue modiﬁer to indicate that only the elastic GPU types eg1.medium and eg1.large are allowed in the request .
Users can override any parameters in the launch template by specifying the parameters in the RunInstances action .
The policy uses the ec2 : IsLaunchTemplateResource condition key to prevent users from overriding any pre-existing ARNs in the launch template .
Users can not override the subnet and network interface parameters in the request ; these parameters can only be speciﬁed in the launch template .
The ﬁrst part of the statement uses the NotResource element to allow all other resources except subnets and network interfaces .
The second part of the statement allows the subnet and network interface resources , but only if they are sourced from the launch template .
Users can not override any of the launch template parameters in the RunInstances action .
869 Amazon Elastic Compute Cloud User Guide for Linux Instances IAM policies It is not possible to set resource-level permissions for individual Reserved Instances .
This policy means that users have access to all the Reserved Instances in the account .
The Resource element uses a * wildcard to indicate that users can specify all resources with the action ; in this case , they can list and modify all Reserved Instances in the account .
They can also purchase Reserved Instances using the account credentials .
The * wildcard is also necessary in cases where the API action does not support resource-level permissions .
The ForAllValues modiﬁer is used with the aws : TagKeys condition key to indicate that only the key environment is allowed in the request ( no other tags are allowed ) .
The user can not tag any other resource types .
Users can specify additional tags in the request .
For example , the following policy allows users to delete tags for a volume if the tag keys speciﬁed in the request are environment or cost-center .
Any value can be speciﬁed for the tag but the tag key must match either of the speciﬁed keys .
Note If you delete a resource , all tags associated with the resource are also deleted .
Users do not need permissions to use the ec2 : DeleteTags action to delete a resource that has tags ; they only need permissions to perform the deleting action .
Users can not delete any other tags for a resource .
Replacing or detaching an IAM role requires an association ID , therefore the policy also grants users permission to use the ec2 : DescribeIamInstanceProfileAssociations action .
IAM users must have permission to use the iam : PassRole action in order to pass the role to the instance .
Users can only attach or replace IAM roles with names that begin with TestRole- .
For the iam : PassRole action , ensure that you specify the name of the IAM role and not the instance proﬁle ( if the names are diﬀerent ) .
The policy allows an instance to view resources in various AWS services .
It uses the ec2 : SourceInstanceARN condition key to specify that the instance from which the request is made must be instance i-093452212644b0dd6 .
If the same IAM role is associated with another instance , the other instance can not perform any of these actions .
Users can not work with other launch templates .
You can combine the following four policies into one policy with four statements .
It can work equally well as a deny policy that you apply to an existing IAM policy ( taking away and limiting existing permission ) , or as an SCP that is applied globally across an account , an organizational unit ( OU ) , or an entire organization .
Note The following RunInstances metadata options policies must be used in conjunction with a policy that gives the principal permissions to launch an instance with RunInstances .
If the principal does not also have RunInstances permissions , it will not be able to launch an instance .
Important If you use Auto Scaling groups and you need to require the use of IMDSv2 on all new instances , your Auto Scaling groups must use launch templates .
When an Auto Scaling group uses a launch template , the ec2 : RunInstances permissions of the IAM principal are checked when a new Auto Scaling group is created .
They are also checked when an existing Auto Scaling group is updated to use a new launch template or a new version of a launch template .
Restrictions on the use of IMDSv1 on IAM principals for RunInstances are only checked when an Auto Scaling group that is using a launch template , is created or updated .
For an Auto Scaling group that is conﬁgured to use the Latest or Default launch template , the permissions are not checked when a new version of the launch template is created .
For permissions to be checked , you must conﬁgure the Auto Scaling group to use a speciﬁc version of the launch template .
To enforce the use of IMDSv2 on instances launched by Auto Scaling groups , the following additional steps are required : 1 .
Disable the use of launch conﬁgurations for all accounts in your organization by using either service control policies ( SCPs ) or IAM permissions boundaries for new principals that are created .
For existing IAM principals with Auto Scaling group permissions , update their associated policies with this condition key .
To disable the use of launch conﬁgurations , create or modify the relevant SCP , permissions boundary , or IAM policy with the `` autoscaling : LaunchConfigurationName '' condition key with the value speciﬁed as null .
For new launch templates , conﬁgure the instance metadata options in the launch template .
For existing launch templates , create a new version of the launch template and conﬁgure the instance metadata options in the new version .
By restricting the use to a speciﬁc version of a launch template , you can ensure that new instances will be launched using the version in which the instance metadata options are conﬁgured .
For more information , see LaunchTemplateSpeciﬁcation in the Amazon EC2 Auto Scaling API Reference , speciﬁcally the Version parameter .
For an Auto Scaling group that uses a launch conﬁguration , replace the launch conﬁguration with a launch template .
For an Auto Scaling group that uses a launch template , make sure that it uses a new launch template with the instance metadata options conﬁgured , or uses a new version of the current launch template with the instance metadata options conﬁgured .
If you do not specify that the instance requires IMDSv2 , you get an UnauthorizedOperation error when you call the RunInstances API .
If you fail to do that , you get an UnauthorizedOperation error when you call the RunInstances API .
Note When the following policy and the preceding one are applied to an account via an SCP , you can ’ t use the EC2 console to launch instances because the console doesn ’ t yet support the MetadataHttpTokens and MetadataHttpPutResponseHopLimit parameters .
If any principal other than the ec2-imds-admins role tries to call the ModifyInstanceMetadataOptions API , it will get an UnauthorizedOperation error .
This statement could be used to control the use of the ModifyInstanceMetadataOptions API ; there are currently no ﬁne-grained access controls ( conditions ) for the ModifyInstanceMetadataOptions API .
Otherwise , all of its API calls will get an UnauthorizedOperation error .
This statement/policy can be applied generally because , if the request is not signed by EC2 role credentials , it has no eﬀect .
You can use the example policies in the previous section ; however , they are designed for requests that are made with the AWS CLI or an AWS SDK .
The console uses additional API actions for its features , so these policies may not work as expected .
For example , a user that has permission to use only the DescribeVolumes API action will encounter errors when trying to view volumes in the console .
This section demonstrates policies that enable users to work with speciﬁc parts of the console .
Tip To help you work out which API actions are required to perform tasks in the console , you can use a service such as AWS CloudTrail .
For more information , see the AWS CloudTrail User Guide .
If your policy does not grant permission to create or modify a speciﬁc resource , the console displays an encoded message with diagnostic information .
You can decode the message using the DecodeAuthorizationMessage API action for AWS STS , or the decode-authorization-message command in the AWS CLI .
Users can not perform any actions on those resources or create new resources , unless another statement grants them permission to do so .
The following policy allows users to view all instances , AMIs , and snapshots in the Amazon EC2 console .
The console requires the tagging information to display public AMIs ; however , you can remove this action to allow users to view only private AMIs .
Therefore , the * wildcard is necessary in the Resource element of the above statement .
For more information about which ARNs you can use with which Amazon EC2 API actions , see Actions , Resources , and Condition Keys for Amazon EC2 in the IAM User Guide .
View instances and CloudWatch metrics The following policy allows users to view instances in the Amazon EC2 console , as well as CloudWatch alarms and metrics in the Monitoring tab of the Instances page .
The Amazon EC2 console uses the CloudWatch API to display the alarms and metrics , so you must grant users permission to use the cloudwatch : DescribeAlarms and cloudwatch : GetMetricStatistics actions .
Your policy must include permission to use the API actions that allow users to work with the wizard's options .
If your policy does not include permission to use those actions , some items in the wizard can not load properly , and users can not complete a launch .
• To add outbound rules to VPC security groups , users must be granted permission to use the ec2 : AuthorizeSecurityGroupEgress API action .
If users do not have permission to use this action and they attempt to apply tags on the tagging page of the launch wizard , the launch fails .
Important Be careful about granting users permission to use the ec2 : CreateTags action .
This limits your ability to use the ec2 : ResourceTag condition key to restrict the use of other resources ; users can change a resource 's tag in order to bypass those restrictions .
Currently , the Amazon EC2 Describe* API actions do not support resource-level permissions , so you can not restrict which individual resources users can view in the launch wizard .
However , you can apply resource-level permissions on the ec2 : RunInstances API action to restrict which resources users can use to launch an instance .
The launch fails if users select options that they are not authorized to use .
The ﬁrst statement grants users permission to view the options in the launch wizard or to create new ones , as explained in the example above .
The second statement grants users permission to use the network interface , volume , key pair , security group , and subnet resources for the ec2 : RunInstances action , which are required to launch an instance into a VPC .
The third and fourth statements grant users permission to use the instance and AMI resources respectively , but only if the instance is a t2.micro instance , and only if the AMI is owned by Amazon .
Users can attach any volume to instances that have the tag `` purpose=test '' , and also detach volumes from those instances .
To attach a volume using the Amazon EC2 console , it is helpful for users to have permission to use the ec2 : DescribeInstances action , as this allows them to select an instance from a 881 Amazon Elastic Compute Cloud User Guide for Linux Instances IAM policies pre-populated list in the Attach Volume dialog box .
However , this also allows users to view all instances on the Instances page in the console , so you can omit this action .
In the ﬁrst statement , the ec2 : DescribeAvailabilityZones action is necessary to ensure that a user can select an Availability Zone when creating a volume .
Users can not tag the volumes that they create ( either during or after volume creation ) .
In the ﬁrst statement , the ec2 : DescribeTags action allows users to view tags in the console , which makes it easier for users to identify the security groups that they are allowed to modify .
With these permissions , users can create a new security group successfully , but they can not add any rules to it .
To work with rules in the Create Security Group dialog box , you can add the following API actions to your policy : • ec2 : AuthorizeSecurityGroupIngress : To add inbound rules .
This is useful to allow users to use the Copy to new feature in the console .
This feature opens the Create Security Group dialog box and populates it with the same rules as the security group that was selected .
This is useful to allow users to modify or delete the default outbound rule that allows all outbound traﬃc .
The console ﬁrst creates the security group , and then adds the speciﬁed rules .
If the rules are invalid , the action fails , and the console attempts to delete the security group .
The user remains in the Create Security Group dialog box so that they can correct the invalid rule and try to create the security group again .
This API action is not required , but if a user is not granted permission to use it and attempts to create a security group with invalid rules , the security group is created without any rules , and the user must add them afterward .
The following policy grants users permission to use the Create Security Group dialog box , and to create inbound and outbound rules for security groups that are associated with a speciﬁc VPC ( vpc-1a2b3c4d ) .
Users can create security groups for EC2-Classic or another VPC , but they can not add any rules to them .
Similarly , users can not add any rules to any existing security group that 's not associated with VPC vpc-1a2b3c4d .
Users are also granted permission to view all security groups in the console .
This makes it easier for users to identify the security groups to which they can add inbound rules .
This policy also grants users permission to delete security groups that are associated with VPC vpc-1a2b3c4d .
To allow users to work with Elastic IP addresses , you can add the following actions to your policy .
The screen displays the available instances or network interfaces to which you can associate an Elastic IP address .
The following policy allows users to view , allocate , and associate Elastic IP addresses with instances .
Users can not associate Elastic IP addresses with network interfaces , disassociate Elastic IP addresses , or release them .
It gives the user access to view and modify Reserved Instances in your account , as well as purchase new Reserved Instances in the AWS Management Console .
This policy allows users to view all the Reserved Instances , as well as On-Demand Instances , in the account .
The ec2 : DescribeInstances action is not required , but ensures that the user can view the instances in the account and purchase reservations to match the correct speciﬁcations .
IAM roles for Amazon EC2 Applications must sign their API requests with AWS credentials .
Therefore , if you are an application developer , you need a strategy for managing credentials for your applications that run on EC2 instances .
For example , you can securely distribute your AWS credentials to the instances , enabling the applications on those instances to use your credentials to sign requests , while protecting your credentials from other users .
However , it 's challenging to securely distribute credentials to each instance , especially those that AWS creates on your behalf , such as Spot Instances or instances in Auto Scaling groups .
You must also be able to update the credentials on each instance when you rotate your AWS credentials .
885 Amazon Elastic Compute Cloud User Guide for Linux Instances IAM roles We designed IAM roles so that your applications can securely make API requests from your instances , without requiring you to manage the security credentials that the applications use .
Instead of creating and distributing your AWS credentials , you can delegate permission to make API requests using IAM roles as follows : 1 .
Deﬁne which accounts or AWS services can assume the role .
Deﬁne which API actions and resources the application can use after assuming the role .
Specify the role when you launch your instance , or attach the role to an existing instance .
Have the application retrieve a set of temporary credentials and use them .
For example , you can use IAM roles to grant permissions to applications running on your instances that need to use a bucket in Amazon S3 .
You can specify permissions for IAM roles by creating a policy in JSON format .
These are similar to the policies that you create for IAM users .
When creating IAM roles , associate least privilege IAM policies that restrict access to the speciﬁc API calls the application requires .
You can not attach multiple IAM roles to a single instance , but you can attach a single IAM role to multiple instances .
For more information about creating and using IAM roles , see Roles in the IAM User Guide .
You can apply resource-level permissions to your IAM policies to control the users ' ability to attach , replace , or detach IAM roles for an instance .
When you create an IAM role using the IAM console , the console creates an instance proﬁle automatically and gives it the same name as the role to which it corresponds .
If you use the Amazon EC2 console to launch an instance with an IAM role or to attach an IAM role to an instance , you choose the role based on a list of instance proﬁle names .
If you use the AWS CLI , API , or an AWS SDK to create a role , you create the role and instance proﬁle as separate actions , with potentially diﬀerent names .
If you then use the AWS CLI , API , or an AWS SDK to launch an instance with an IAM role or to attach an IAM role to an instance , specify the instance proﬁle name .
An instance proﬁle can contain only one IAM role .
This limit can not be increased .
For more information , see Instance Proﬁles in the IAM User Guide .
Retrieving security credentials from instance metadata An application on the instance retrieves the security credentials provided by the role from the instance metadata item iam/security-credentials/role-name .
The application is granted the permissions 886 Amazon Elastic Compute Cloud User Guide for Linux Instances IAM roles for the actions and resources that you 've deﬁned for the role through the security credentials associated with the role .
These security credentials are temporary and we rotate them automatically .
We make new credentials available at least ﬁve minutes before the expiration of the old credentials .
Warning If you use services that use instance metadata with IAM roles , ensure that you do n't expose your credentials when the services make HTTP calls on your behalf .
The types of services that could expose your credentials include HTTP proxies , HTML/CSS validator services , and XML processors that support XML inclusion .
The following command retrieves the security credentials for an IAM role named s3access .
To make a call outside of the instance using temporary security credentials ( for example , to test IAM policies ) , you must provide the access key , secret key , and the session token .
For more information , see Using Temporary Security Credentials to Request Access to AWS Resources in the IAM User Guide .
Granting an IAM user permission to pass an IAM role to an instance To enable an IAM user to launch an instance with an IAM role or to attach or replace an IAM role for an existing instance , you must grant the user permission to pass the role to the instance .
However , consider whether users who launch instances with your roles ( ones that exist or that you create later on ) might be granted permissions that they do n't need or should n't have .
Working with IAM roles You can create an IAM role and attach it to an instance during or after launch .
You can also replace or detach an IAM role for an instance .
To create an IAM role using the IAM console 1 .
On the Attach permissions policy page , select an AWS managed policy that grants your instances access to the resources that they need .
On the Review page , enter a name for the role and choose Create role .
Alternatively , you can use the AWS CLI to create an IAM role .
The following example creates an IAM role with a policy that allows the role to use an Amazon S3 bucket .
Create the following trust policy and save it in a text ﬁle named ec2-role-trust-policy.json .
For example , this policy grants administrative permissions for Amazon S3 to applications running on the instance .
Important After you create an IAM role , it may take several seconds for the permissions to propagate .
If your ﬁrst attempt to launch an instance with a role fails , wait a few seconds before trying again .
For more information , see Troubleshooting Working with Roles in the IAM User Guide .
Select an AMI and instance type and then choose Next : Conﬁgure Instance Details .
On the Conﬁgure Instance Details page , for IAM role , select the IAM role that you created .
Note The IAM role list displays the name of the instance proﬁle that you created when you created your IAM role .
If you created your IAM role using the console , the instance proﬁle was created for you and given the same name as the role .
If you created your IAM role using the AWS CLI , API , or an AWS SDK , you may have named your instance proﬁle diﬀerently .
Conﬁgure any other details , then follow the instructions through the rest of the wizard , or choose Review and Launch to accept default settings and go directly to the Review Instance Launch page .
If you are using the Amazon EC2 API actions in your application , retrieve the AWS security credentials made available on the instance and use them to sign the requests .
The AWS SDK does this for you .
You must specify the instance proﬁle in the command .
Use the run-instances command to launch an instance using the instance proﬁle .
The following example shows how to launch an instance with the instance proﬁle .
If you are using the Amazon EC2 API actions in your application , retrieve the AWS security credentials made available on the instance and use them to sign the requests .
The AWS SDK does this for you .
curl http : //169.254.169.254/latest/meta-data/iam/security-credentials/role_name Attaching an IAM role to an instance To attach an IAM role to an instance that has no role , the instance can be in the stopped or running state .
Select the IAM role to attach to your instance , and choose Apply .
If required , describe your instances to get the ID of the instance to which to attach the role .
Use the associate-iam-instance-proﬁle command to attach the IAM role to the instance by specifying the instance proﬁle .
You can use the Amazon Resource Name ( ARN ) of the instance proﬁle , or you can use its name .
You can do this if you want to change the IAM role for an instance without detaching the existing one ﬁrst .
For example , you can do this to ensure that API actions performed by applications running on the instance are not interrupted .
Select the IAM role to attach to your instance , and choose Apply .
If required , describe your IAM instance proﬁle associations to get the association ID for the IAM instance proﬁle to replace .
Use the replace-iam-instance-proﬁle-association command to replace the IAM instance proﬁle by specifying the association ID for the existing instance proﬁle and the ARN or name of the instance proﬁle that should replace it .
If required , use describe-iam-instance-proﬁle-associations to describe your IAM instance proﬁle associations and get the association ID for the IAM instance proﬁle to detach .
For example , you can allow computers from only your home network to access your instance using SSH .
If your instance is a web server , you can allow all IP addresses to access your instance using HTTP or HTTPS , so that external users can browse the content on your web server .
Your default security groups and newly created security groups include default rules that do not enable you to access your instance from the internet .
To enable network access to your instance , you must allow inbound traﬃc to your instance .
To open a port for inbound traﬃc , add a rule to a security group that you associated with your instance when you launched it .
To connect to your instance , you must set up a rule to authorize SSH traﬃc from your computer 's public IPv4 address .
To allow SSH traﬃc from additional IP address ranges , add another rule for each range you need to authorize .
Your local computer must have an IPv6 address and must be conﬁgured to use IPv6 .
If you need to enable network access to a Windows instance , see Authorizing Inbound Traﬃc for Your Windows Instances in the Amazon EC2 User Guide for Windows Instances .
Before you start Decide who requires access to your instance ; for example , a single host or a speciﬁc network that you trust such as your local computer 's public IPv4 address .
The security group editor in the Amazon EC2 console can automatically detect the public IPv4 address of your local computer for you .
Alternatively , you can use the search phrase `` what is my IP address '' in an internet browser , or use the following service : Check IP .
If you are connecting through an ISP or from behind your ﬁrewall without a static IP address , you need to ﬁnd out the range of IP addresses used by client computers .
In production , you authorize only a speciﬁc IP address or range of addresses to access your instance .
Decide whether you 'll support SSH access to your instances using EC2 Instance Connect .
Adding a rule for inbound SSH traﬃc to a Linux instance Security groups act as a ﬁrewall for associated instances , controlling both inbound and outbound traﬃc at the instance level .
You must add rules to a security group that enable you to connect to your Linux instance from your IP address using SSH .
Select your instance and look at the Description tab ; Security groups lists the security groups that are associated with the instance .
Choose view inbound rules to display a list of the rules that are in eﬀect for the instance .
Select one of the security groups associated with your instance .
In the dialog , choose Add Rule , and then choose SSH from the Type list .
In the Source ﬁeld , choose My IP to automatically populate the ﬁeld with the public IPv4 address of your local computer .
Alternatively , choose Custom and specify the public IPv4 address of your computer or network in CIDR notation .
If you launched an instance with an IPv6 address and want to connect to your instance using its IPv6 address , you must add rules that allow inbound IPv6 traﬃc over SSH .
Select the security group for your instance .
In the Source ﬁeld , specify the IPv6 address of your computer in CIDR notation .
Note Be sure to run the following commands on your local system , not on the instance itself .
When you add or remove rules , those changes are automatically applied to all instances to which you 've assigned the security group .
After you launch an instance , you can change its security groups .
For more information , see Changing an Instance 's Security Groups in the Amazon VPC User Guide .
Amazon EC2 key pairs and Linux instances Amazon EC2 uses public key cryptography to encrypt and decrypt login information .
Public key cryptography uses a public key to encrypt a piece of data , and then the recipient uses the private key to decrypt the data .
The public and private keys are known as a key pair .
Public key cryptography enables you to securely access your instances using a private key instead of a password .
You can have up to 5,000 key pairs per Region .
Amazon EC2 stores the public key only , and you store the private key .
Anyone who possesses your private key can decrypt your login information , so it 's important that you store your private keys in a secure place .
Because Amazon EC2 does n't keep a copy of your private key , there is no way to recover a private key if you lose it .
However , there can still be a way to connect to instances that use a lost key pair .
When you launch an instance , you are prompted for the name of a key pair .
If you plan to connect to the instance using SSH , you must specify a key pair .
At boot time , the public key content is placed on your Linux instance in an entry within ~/.ssh/authorized_keys .
When you connect to your Linux instance using SSH , you must specify the private key that corresponds to the public key content to log in .
Amazon EC2 associates the public key with the name that you specify as the key name .
For File format , choose the format in which to save the private key .
To save the private key in a format that can be used with OpenSSH , choose pem .
To save the private key in a format that can be used with PuTTY , choose ppk .
The navigation pane is on the left side of the Amazon EC2 console .
If you do not see the pane , it might be minimized ; choose the arrow to expand the pane .
For Key pair name , enter a name for the new key pair , and then choose Create .
The private key ﬁle is automatically downloaded by your browser .
The base ﬁle name is the name you speciﬁed as the name of your key pair , and the ﬁle name extension is .pem .
This is the only chance for you to save the private key ﬁle .
You 'll need to provide the name of your key pair when you launch an instance and the corresponding private key each time you connect to the instance .
If you will use an SSH client on a macOS or Linux computer to connect to your Linux instance , use the following command to set the permissions of your private key ﬁle so that only you can read it .
chmod 400 my-key-pair.pem 897 Amazon Elastic Compute Cloud User Guide for Linux Instances Preparing a key pair If you do not set these permissions , then you can not connect to your instance using this key pair .
AWS CLI To create your key pair Use the create-key-pair AWS CLI command .
PowerShell To create your key pair Use the New-EC2KeyPair AWS Tools for Windows PowerShell command .
Option 2 : Import your own public key to Amazon EC2 Instead of using Amazon EC2 to create your key pair , you can create an RSA key pair using a thirdparty tool and then import the public key to Amazon EC2 .
Alternatively , Java , Ruby , Python , and many other programming languages provide standard libraries that you can use to create an RSA key pair .
If you connect using SSH while using the EC2 Instance Connect API , the SSH2 format is also supported .
The ﬁle name extension for this ﬁle is not important .
Save the private key to a diﬀerent local ﬁle that has the .pem extension .
You 'll need to provide the name of your key pair when you launch an instance and the corresponding private key each time you connect to the instance .
After you have created the key pair , use one of the following methods to import your key pair to Amazon EC2 .
Either choose Browse to navigate to and select your public key , or paste the contents of your public key into the Public key contents ﬁeld .
Verify that the key pair you imported appears in the list of key pairs .
In the Import Key Pair dialog box , choose Browse , and select the public key ﬁle that you saved previously .
Enter a name for the key pair in the Key pair name ﬁeld , and choose Import .
Verify that the key pair you imported appears in the list of key pairs .
AWS CLI To import the public key Use the import-key-pair AWS CLI command .
To verify that the key pair was imported successfully Use the describe-key-pairs AWS CLI command .
PowerShell To import the public key Use the Import-EC2KeyPair AWS Tools for Windows PowerShell command .
To verify that the key pair was imported successfully Use the Get-EC2KeyPair AWS Tools for Windows PowerShell command .
Tagging a key pair To help categorize and manage your existing key pairs , you can tag them with custom metadata .
You can view , add , and delete tags using the new console and the command line tools .
The Manage tags section displays any tags that are assigned to the key pair .
You can add up to 50 tags per key pair .
AWS CLI To view key pair tags Use the describe-tags AWS CLI command .
In the following example , you describe the tags for all of your key pairs .
For examples , see Examples in the AWS CLI Command Reference .
PowerShell To view key pair tags Use the Get-EC2Tag command .
To tag an existing key pair Use the New-EC2Tag command .
Retrieving the public key for your key pair On your local Linux or macOS computer , you can use the ssh-keygen command to retrieve the public key for your key pair .
chmod 400 my-key-pair.pem Retrieving the public key for your key pair through instance metadata The public key that you speciﬁed when you launched an instance is also available to you through its instance metadata .
Instead , the instance metadata continues to show the public key for the key pair that you speciﬁed when you launched the instance .
You can open this ﬁle in an editor .
The following is an example entry for the key pair named my-key-pair .
It consists of the public key followed by the name of the key pair .
AWS calculates the ﬁngerprint diﬀerently depending on whether the key pair was generated by AWS or a third-party tool .
If you created the key pair using AWS , the ﬁngerprint is calculated using an SHA-1 hash function .
If you created the key pair with a third-party tool and uploaded the public key to AWS , or if you generated a new public key from an existing AWS-created private key and uploaded it to AWS , the ﬁngerprint is calculated using an MD5 hash function .
You can use the SSH2 ﬁngerprint that 's displayed on the Key Pairs page to verify that the private key you have on your local machine matches the public key stored in AWS .
From the computer where you downloaded the private key ﬁle , generate an SSH2 ﬁngerprint from the private key ﬁle .
The output should match the ﬁngerprint that 's displayed in the console .
If you created your key pair using AWS , you can use the OpenSSL tools to generate a ﬁngerprint as shown in the following example .
For example , if a user in your organization requires access to the system user account using a separate key pair , you can add that key pair to your instance .
Or , if someone has a copy of the .pem ﬁle and you want to prevent them from connecting to your instance ( for example , if they 've left your organization ) , you can replace the key pair with a new one .
Note These procedures are for modifying the key pair for the default user account , such as ec2-user .
Retrieve the public key from your new key pair .
Connect to your instance using your existing private key ﬁle .
Paste the public key information from your new key pair underneath the existing public key information .
Disconnect from your instance , and test that you can connect to your instance using the new private key ﬁle .
( Optional ) If you 're replacing an existing key pair , connect to your instance and delete the public key information for the original key pair from the .ssh/authorized_keys ﬁle .
Note If you 're using an Auto Scaling group ( for example , in an Elastic Beanstalk environment ) , ensure that the key pair you 're replacing is not speciﬁed in your launch conﬁguration .
Amazon EC2 Auto Scaling launches a replacement instance if it detects an unhealthy instance ; however , the instance launch fails if the key pair can not be found .
Connecting to your Linux instance if you lose your private key If you lose the private key for an EBS-backed instance , you can regain access to your instance .
You must stop the instance , detach its root volume and attach it to another instance as a data volume , modify the 903 Amazon Elastic Compute Cloud User Guide for Linux Instances Connecting to your Linux instance if you lose your private key authorized_keys ﬁle with a new public key , move the volume back to the original instance , and restart the instance .
This procedure is not supported for instances with instance-store backed root volumes .
To determine the root device type of your instance , open the Amazon EC2 console , choose Instances , select the instance , and check the value of Root device type in the details pane .
The value is either ebs or instance store .
If the root device is an instance store volume , you can not use this procedure to regain access to your instance ; you must have the private key to connect to the instance .
If you want to name your new key pair exactly the same as the lost private key , you must ﬁrst delete the existing key pair .
Choose Instances in the navigation pane , and then select the instance that you 'd like to connect to .
From the Description tab , save the following information that you need to complete this procedure .
If Stop is disabled , either the instance is already stopped or its root device is an instance store volume .
Warning When you stop an instance , the data on any instance store volumes is erased .
To keep data from instance store volumes , be sure to back it up to persistent storage .
904 Amazon Elastic Compute Cloud User Guide for Linux Instances Connecting to your Linux instance if you lose your private key Step 4 : Launch a temporary instance Choose Launch Instance , and then use the launch wizard to launch a temporary instance with the following options : • On the Choose an AMI page , select the same AMI that you used to launch the original instance .
If this AMI is unavailable , you can create an AMI that you can use from the stopped instance .
• On the Choose an Instance Type page , leave the default instance type that the wizard selects for you .
• On the Conﬁgure Instance Details page , specify the same Availability Zone as the original instance .
• On the Add Tags page , add the tag Name=Temporary to the instance to indicate that this is a temporary instance .
Step 5 : Detach the root volume from the original instance and attach it to the temporary instance 1 .
In the navigation pane , choose Volumes and select the root device volume for the original instance ( you wrote down its volume ID in a previous step ) .
Wait for the state of the volume to become available .
With the volume still selected , choose Actions , and then select Attach Volume .
Note If you launched your original instance from an AWS Marketplace AMI and your volume contains AWS Marketplace codes , you must ﬁrst stop the temporary instance before you can attach the volume .
From the temporary instance , mount the volume that you attached to the instance so that you can access its ﬁle system .
Note The device name might appear diﬀerently on your instance .
Use the lsblk command to determine if the volume is partitioned .
The required command depends on your operating system 's ﬁle system .
From the temporary instance , use the following command to update authorized_keys on the mounted volume with the new public key from the authorized_keys for the temporary instance .
Important The following examples use the Amazon Linux user name ec2-user .
You might need to substitute a diﬀerent user name , such as ubuntu for Ubuntu instances .
( Optional ) Otherwise , if you do n't have permission to edit ﬁles in /mnt/tempvol , you must update the ﬁle using sudo and then check the permissions on the ﬁle to verify that you are able to log into the original instance .
Use the following command to check the permissions on the ﬁle .
From the temporary instance , unmount the volume that you attached so that you can reattach it to the original instance .
For example , use the following command to unmount the volume at /mnt/ tempvol .
Detach the volume from the temporary instance ( you unmounted it in the previous step ) : From the Amazon EC2 console , select the root device volume for the original instance ( you wrote down volume ID in a previous step ) , choose Actions , Detach Volume , and then select Yes , Detach .
Wait for the state of the volume to become available .
Reattach the volume to the original instance : With the volume still selected , choose Actions , Attach Volume .
Select the instance ID of the original instance , specify the device name that you noted earlier for the original root device attachment ( /dev/sda1 or /dev/xvda ) , and then choose Attach .
Important If you do n't specify the same device name as the original attachment , you can not start the original instance .
Step 8 : Connect to the original instance using the new key pair Select the original instance , choose Actions , select Instance State , and then choose Start .
After the instance enters the running state , you can connect to it using the private key ﬁle for your new key pair .
Note If the name of your new key pair and corresponding private key ﬁle is diﬀerent from the name of the original key pair , ensure that you specify the name of the new private key ﬁle when you connect to your instance .
Step 9 : Clean up ( Optional ) You can terminate the temporary instance if you have no further use for it .
Deleting your key pair When you delete a key pair , you are only deleting the Amazon EC2 copy of the public key .
Deleting a key pair does n't aﬀect the private key on your computer or the public key on any instances that already launched using that key pair .
You ca n't launch a new instance using a deleted key pair , but you can continue to connect to any instances that you launched using a deleted key pair , as long as you still have the private key ( .pem ) ﬁle .
If you 're using an Auto Scaling group ( for example , in an Elastic Beanstalk environment ) , ensure that the key pair you 're deleting is not speciﬁed in your launch conﬁguration .
Amazon EC2 Auto Scaling launches 907 Amazon Elastic Compute Cloud User Guide for Linux Instances Security Groups a replacement instance if it detects an unhealthy instance ; however , the instance launch fails if the key pair can not be found .
You can delete a key pair using one of the following methods .
Select the key pair to delete and choose Delete .
In the conﬁrmation ﬁeld , enter Delete and then choose Delete .
Select the key pair and choose Delete .
AWS CLI To delete your key pair Use the delete-key-pair AWS CLI command .
PowerShell To delete your key pair Use the Remove-EC2KeyPair AWS Tools for Windows PowerShell command .
If you create a Linux AMI from an instance , and then use the AMI to launch a new instance in a diﬀerent Region or account , the new instance includes the public key from the original instance .
This enables you to connect to the new instance using the same private key ﬁle as your original instance .
You can remove this public key from your instance by removing its entry from the .ssh/authorized_keys ﬁle using a text editor of your choice .
For more information about managing users on your instance and providing remote access using a speciﬁc key pair , see Managing User Accounts on Your Linux Instance ( p. 560 ) .
Amazon EC2 Security Groups for Linux Instances A security group acts as a virtual ﬁrewall that controls the traﬃc for one or more instances .
When you launch an instance , you can specify one or more security groups ; otherwise , we use the default security group .
You can add rules to each security group that allow traﬃc to or from its associated instances .
You can modify the rules for a security group at any time ; the new rules are automatically applied to all instances that are associated with the security group .
When we decide whether to allow traﬃc to reach an instance , we evaluate all the rules from all the security groups that are associated with the instance .
After you launch an instance , you can change its security groups .
Security groups are associated with 908 Amazon Elastic Compute Cloud User Guide for Linux Instances Security Group Rules network interfaces .
For more information , see Changing an Instance 's Security Groups in the Amazon VPC User Guide .
You can also change the security groups associated with any other network interface .
If you have requirements that are n't met by security groups , you can maintain your own ﬁrewall on any of your instances in addition to using security groups .
If you need to allow traﬃc to a Windows instance , see Amazon EC2 Security Groups for Windows Instances in the Amazon EC2 User Guide for Windows Instances .
The following are the characteristics of security group rules : • By default , security groups allow all outbound traﬃc .
• Security groups are stateful — if you send a request from your instance , the response traﬃc for that request is allowed to ﬂow in regardless of inbound security group rules .
For VPC security groups , this also means that responses to allowed inbound traﬃc are allowed to ﬂow out , regardless of outbound rules .
• You can add and remove rules at any time .
Your changes are automatically applied to the instances associated with the security group .
909 Amazon Elastic Compute Cloud User Guide for Linux Instances Security Group Rules Note The eﬀect of some rule changes may depend on how the traﬃc is tracked .
• When you associate multiple security groups with an instance , the rules from each security group are eﬀectively aggregated to create one set of rules .
We use this set of rules to determine whether to allow access .
Note You can assign multiple security groups to an instance , therefore an instance can have hundreds of rules that apply .
This might cause problems when you access the instance .
We recommend that you condense your rules as much as possible .
For more information , see Gateway VPC Endpoints in the Amazon VPC User Guide .
This allows instances associated with the speciﬁed security group to access instances associated with this security group .
This does not add rules from the source security group to this security group .
When you specify a security group as the source or destination for a rule , the rule aﬀects all instances associated with the security group .
Incoming traﬃc is allowed based on the private IP addresses of the instances that are associated with the source security group ( and not the public IP or Elastic IP addresses ) .
If your security group rule references a security group in a peer VPC , and the referenced security group or VPC peering connection is deleted , the rule is marked as stale .
For more information , see Working with Stale Security Group Rules in the Amazon VPC Peering Guide .
If there is more than one rule for a speciﬁc port , we apply the most permissive rule .
For example , if you have a rule that allows access to TCP port 22 ( SSH ) from IP address 203.0.113.1 and another rule that allows access to TCP port 22 from everyone , everyone has access to TCP port 22 .
Connection Tracking Your security groups use connection tracking to track information about traﬃc to and from the instance .
Rules are applied based on the connection state of the traﬃc to determine if the traﬃc is allowed or 910 Amazon Elastic Compute Cloud User Guide for Linux Instances Security Group Rules denied .
This allows security groups to be stateful — responses to inbound traﬃc are allowed to ﬂow out of the instance regardless of outbound security group rules , and vice versa .
For example , if you initiate an ICMP ping command to your instance from your home computer , and your inbound security group rules allow ICMP traﬃc , information about the connection ( including the port information ) is tracked .
Response traﬃc from the instance for the ping command is not tracked as a new request , but rather as an established connection and is allowed to ﬂow out of the instance , even if your outbound security group rules restrict outbound ICMP traﬃc .
Not all ﬂows of traﬃc are tracked .
The response traﬃc is therefore allowed to ﬂow based on the inbound or outbound rule that permits the response traﬃc , and not on tracking information .
In the following example , the security group has speciﬁc inbound rules for TCP and ICMP traﬃc , and an outbound rule that allows all outbound traﬃc .
If you remove the outbound rule from the security group , then all traﬃc to and from the instance is tracked , including traﬃc on port 80 ( HTTP ) .
An existing ﬂow of traﬃc that is tracked may not be interrupted when you remove the security group rule that enables that ﬂow .
Instead , the ﬂow is interrupted when it 's stopped by you or the other host for at least a few minutes ( or up to 5 days for established TCP connections ) .
For UDP , this may require terminating actions on the remote side of the ﬂow .
An untracked ﬂow of traﬃc is immediately interrupted if the rule that enables the ﬂow is removed or modiﬁed .
For example , if you remove a rule that allows all inbound SSH traﬃc to the instance , then your existing SSH connections to the instance are immediately dropped .
For protocols other than TCP , UDP , or ICMP , only the IP address and protocol number is tracked .
If your instance sends traﬃc to another host ( host B ) , and host B initiates the same type of traﬃc to your instance in a separate request within 600 seconds of the original request or response , your instance accepts it regardless of inbound security group rules , because it ’ s regarded as response traﬃc .
To ensure that traﬃc is immediately interrupted when you remove a security group rule , or to ensure that all inbound traﬃc is subject to ﬁrewall rules , you can use a network ACL for your subnet — network ACLs are stateless and therefore do not automatically allow response traﬃc .
For more information , see Network ACLs in the Amazon VPC User Guide .
911 Amazon Elastic Compute Cloud User Guide for Linux Instances Default Security Groups Default Security Groups Your AWS account automatically has a default security group for the default VPC in each Region .
If you do n't specify a security group when you launch an instance , the instance is automatically associated with the default security group for the VPC .
A default security group is named default , and it has an ID assigned by AWS .
The following are the default rules for each default security group : • Allows all inbound traﬃc from other instances associated with the default security group ( the security group speciﬁes itself as a source security group in its inbound rules ) • Allows all outbound traﬃc from the instance .
You can add or remove inbound and outbound rules for any default security group .
Custom Security Groups If you do n't want your instances to use the default security group , you can create your own security groups and specify them when you launch your instances .
You can create multiple security groups to reﬂect the diﬀerent roles that your instances play ; for example , a web server or a database server .
A security group name must be unique for the VPC .
The following are the default rules for a security group that you create : • Allows no inbound traﬃc • Allows all outbound traﬃc After you 've created a security group , you can change its inbound rules to reﬂect the type of inbound traﬃc that you want to reach the associated instances .
You can also change its outbound rules .
Working with Security Groups You can create , view , update , and delete security groups and security group rules using the Amazon EC2 console .
You must specify the VPC for which you 're creating the security group .
You can start adding rules , or you can choose Create to create the security group now ( you can always add rules later ) .
Select the security group you want to copy , choose Actions , Copy to new .
The Create Security Group dialog opens , and is populated with the rules from the existing security group .
Specify a name and description for your new security group .
You can assign a security group to an instance when you launch the instance .
When you add or remove rules , those changes are automatically applied to all instances to which you 've assigned the security group .
After you launch an instance , you can change its security groups .
For more information , see Changing an Instance 's Security Groups in the Amazon VPC User Guide .
Describing Your Security Groups You can view information about your security groups using the Amazon EC2 console or the command line .
( Optional ) Select VPC ID from the ﬁlter list , then choose the ID of the VPC .
913 Amazon Elastic Compute Cloud User Guide for Linux Instances Working with Security Groups 4 .
We display general information in the Description tab , inbound rules on the Inbound tab , outbound rules on the Outbound tab , and tags on the Tags tab .
To describe one or more security groups using the command line • describe-security-groups ( AWS CLI ) • Get-EC2SecurityGroup ( AWS Tools for Windows PowerShell ) Adding Rules to a Security Group When you add a rule to a security group , the new rule is automatically applied to any instances associated with the security group after a short period .
In the navigation pane , choose Security Groups and select the security group .
• If you select a custom TCP or UDP protocol , specify the port range in Port Range .
• If you select Custom Protocol , then for Protocol , enter either the protocol name or the protocol number .
This option enables all traﬃc of the speciﬁed type to reach your instance .
In production , authorize only a speciﬁc IP address or range of addresses to access your instance .
You can also specify outbound rules .
• If you select a custom TCP or UDP protocol , specify the port range in Port Range .
914 Amazon Elastic Compute Cloud User Guide for Linux Instances Working with Security Groups • If you select a custom ICMP protocol , choose the ICMP type name from Protocol , and , if applicable , the code name from Port Range .
This option enables outbound traﬃc to all IP addresses .
To add one or more ingress rules to a security group using the command line • authorize-security-group-ingress ( AWS CLI ) • Grant-EC2SecurityGroupIngress ( AWS Tools for Windows PowerShell ) To add one or more egress rules to a security group using the command line • authorize-security-group-egress ( AWS CLI ) • Grant-EC2SecurityGroupEgress ( AWS Tools for Windows PowerShell ) Updating Security Group Rules When you modify the protocol , port range , or source or destination of an existing security group rule using the console , the console deletes the existing rule and adds a new one for you .
Select the security group to update , and choose Inbound Rules to update a rule for inbound traﬃc or Outbound Rules to update a rule for outbound traﬃc .
Modify the rule entry as required and choose Save .
To update the protocol , port range , or source or destination of an existing rule using the Amazon EC2 API or a command line tool , you can not modify the rule .
To update the description for an ingress security group rule using the command line • update-security-group-rule-descriptions-ingress ( AWS CLI ) • Update-EC2SecurityGroupRuleIngressDescription ( AWS Tools for Windows PowerShell ) To update the description for an egress security group rule using the command line • update-security-group-rule-descriptions-egress ( AWS CLI ) 915 Amazon Elastic Compute Cloud User Guide for Linux Instances Security Group Rules Reference • Update-EC2SecurityGroupRuleEgressDescription ( AWS Tools for Windows PowerShell ) Deleting Rules from a Security Group When you delete a rule from a security group , the change is automatically applied to any instances associated with the security group .
You ca n't delete a security group that is referenced by a rule in another security group in the same VPC .
If your security group is referenced by one of its own rules , you must delete the rule before you can delete the security group .
To delete a security group using the command line • delete-security-group ( AWS CLI ) • Remove-EC2SecurityGroup ( AWS Tools for Windows PowerShell ) Security Group Rules Reference You can create a security group and add rules that reﬂect the role of the instance that 's associated with the security group .
For example , an instance that 's conﬁgured as a web server needs security group rules 916 Amazon Elastic Compute Cloud User Guide for Linux Instances Security Group Rules Reference that allow inbound HTTP and HTTPS access , and a database instance needs rules that allow access for the type of database , such as access over port 3306 for MySQL .
The following are examples of the kinds of rules that you can add to security groups for speciﬁc kinds of access .
If your VPC is enabled for IPv6 , you can add rules to control inbound HTTP and HTTPS traﬃc from IPv6 addresses .
For more information about Amazon RDS instances , see the Amazon RDS User Guide .
For the source IP , specify one of the following : • A speciﬁc IP address or range of IP addresses ( in CIDR block notation ) in your local network • A security group ID for a group of instances that access the database 917 Amazon Elastic Compute Cloud User Guide for Linux Instances Security Group Rules Reference Protocol type Protocol number Port Notes TCP 6 1433 ( MS SQL ) The default port to access a Microsoft SQL Server database , for example , on an Amazon RDS instance TCP 6 3306 ( MYSQL/Aurora ) The default port to access a MySQL or Aurora database , for example , on an Amazon RDS instance TCP 6 5439 ( Redshift ) The default port to access an Amazon Redshift cluster database .
TCP 6 5432 ( PostgreSQL ) The default port to access a PostgreSQL database , for example , on an Amazon RDS instance TCP 6 1521 ( Oracle ) The default port to access an Oracle database , for example , on an Amazon RDS instance You can optionally restrict outbound traﬃc from your database servers , for example , if you want allow access to the internet for software updates , but restrict all other kinds of traﬃc .
You must ﬁrst remove the default outbound rule that allows all outbound traﬃc .
If your VPC is enabled for IPv6 and your instance has an IPv6 address , you can enter an IPv6 address or range .
If your VPC is enabled for IPv6 and your instance has an IPv6 address , you can enter an IPv6 address or range .
Rules to Connect to Instances from an Instance with the Same Security Group To allow instances that are associated with the same security group to communicate with each other , you must explicitly add rules for this .
The following table describes the inbound rule for a security group that enables associated instances to communicate with each other .
The rule allows all types of traﬃc .
Protocol type Protocol number Ports Source IP -1 ( All ) -1 ( All ) -1 ( All ) The ID of the security group Rules for Path MTU Discovery The path MTU is the maximum packet size that 's supported on the path between the originating host and the receiving host .
If a host sends a packet that 's larger than the MTU of the receiving host or that's larger than the MTU of a device along the path , the receiving host returns the following ICMP message : Destination Unreachable : Fragmentation Needed and Do n't Fragment was Set To ensure that your instance can receive this message and the packet does not get dropped , you must add an ICMP rule to your inbound security group rules .
919 Amazon Elastic Compute Cloud User Guide for Linux Instances Security Group Rules Reference Protocol type Protocol number ICMP type ICMP code Source IP ICMP 1 3 ( Destination Unreachable ) 4 ( Fragmentation Needed and Don't Fragment was Set ) The IP addresses of the hosts that communicate with your instance Rules for Ping/ICMP The ping command is a type of ICMP traﬃc .
To ping your instance , you must add the following inbound ICMP rule .
For the source IP , specify one of the following : • An IP address or range of IP addresses ( in CIDR block notation ) in a network • The ID of a security group for the set of instances in your network that require access to the DNS server Protocol type Protocol number Port TCP 6 53 UDP 17 53 920 Amazon Elastic Compute Cloud User Guide for Linux Instances Security Group Rules Reference Amazon EFS Rules If you 're using an Amazon EFS ﬁle system with your Amazon EC2 instances , the security group that you associate with your Amazon EFS mount targets must allow traﬃc over the NFS protocol .
Allows inbound NFS access from resources ( including the mount target ) associated with this security group .
To mount an Amazon EFS ﬁle system on your Amazon EC2 instance , you must connect to your instance .
Therefore , the security group associated with your instance must have rules that allow inbound SSH from your local computer or local network .
Protocol type Protocol number Ports Source IP Notes TCP 6 22 ( SSH ) The IP address range of your local computer , or the range of IP addresses ( in CIDR block notation ) for your network .
Allows inbound SSH access from your local computer .
Elastic Load Balancing Rules If you 're using a load balancer , the security group associated with your load balancer must have rules that allow communication with your instances or targets .
Inbound Protocol type Protocol number Port Source IP Notes TCP 6 The listener port For an Internetfacing loadbalancer : 0.0.0.0/0 ( all IPv4 addresses ) Allow inbound traﬃc on the load balancer listener port .
For an internal load-balancer : the IPv4 CIDR block of the VPC Outbound Protocol type Protocol number Port 921 Destination IP Notes Amazon Elastic Compute Cloud User Guide for Linux Instances Update management TCP 6 The instance listener port The ID of the instance security group Allow outbound traﬃc to instances on the instance listener port .
TCP 6 The health check port The ID of the instance security group Allow outbound traﬃc to instances on the health check port .
The security group rules for your instances must allow the load balancer to communicate with your instances on both the listener port and the health check port .
Inbound Protocol type Protocol number Port Source IP Notes TCP 6 The instance listener port The ID of the load balancer security group Allow traﬃc from the load balancer on the instance listener port .
TCP 6 The health check port The ID of the load balancer security group Allow traﬃc from the load balancer on the health check port .
For more information , see Conﬁgure Security Groups for Your Classic Load Balancer in the User Guide for Classic Load Balancers , and Security Groups for Your Application Load Balancer in the User Guide for Application Load Balancers .
VPC Peering Rules You can update the inbound or outbound rules for your VPC security groups to reference security groups in the peered VPC .
Doing so allows traﬃc to ﬂow to and from instances that are associated with the referenced security group in the peered VPC .
For more information about how to conﬁgure security groups for VPC peering , see Updating Your Security Groups to Reference Peer VPC Groups .
Update management in Amazon EC2 We recommend that you regularly patch , update , and secure the operating system and applications on your EC2 instances .
You can use AWS Systems Manager Patch Manager to automate the process of installing security-related updates for both the operating system and applications .
Alternatively , you can use any automatic update services or recommended processes for installing updates that are provided by the application vendor .
Compliance validation for Amazon EC2 Third-party auditors assess the security and compliance of Amazon EC2 as part of multiple AWS compliance programs .
922 Amazon Elastic Compute Cloud User Guide for Linux Instances Compliance validation For a list of AWS services in scope of speciﬁc compliance programs , see AWS Services in Scope by Compliance Program .
For more information , see Downloading Reports in AWS Artifact .
Your compliance responsibility when using Amazon EC2 is determined by the sensitivity of your data , your company 's compliance objectives , and applicable laws and regulations .
AWS provides the following resources to help with compliance : • Security and Compliance Quick Start Guides – These deployment guides discuss architectural considerations and provide steps for deploying security- and compliance-focused baseline environments on AWS .
• Architecting for HIPAA Security and Compliance Whitepaper – This whitepaper describes how companies can use AWS to create HIPAA-compliant applications .
• AWS Compliance Resources – This collection of workbooks and guides might apply to your industry and location .
• Evaluating Resources with Rules in the AWS Conﬁg Developer Guide – AWS Conﬁg ; assesses how well your resource conﬁgurations comply with internal practices , industry guidelines , and regulations .
• AWS Security Hub – This AWS service provides a comprehensive view of your security state within AWS that helps you check your compliance with security industry standards and best practices .
923 Amazon Elastic Compute Cloud User Guide for Linux Instances Storage Amazon EC2 provides you with ﬂexible , cost eﬀective , and easy-to-use data storage options for your instances .
Each option has a unique combination of performance and durability .
These storage options can be used independently or in combination to suit your requirements .
After reading this section , you should have a good understanding about how you can use the data storage options supported by Amazon EC2 to meet your speciﬁc requirements .
Amazon EBS Amazon EBS provides durable , block-level storage volumes that you can attach to a running instance .
You can use Amazon EBS as a primary storage device for data that requires frequent and granular updates .
For example , Amazon EBS is the recommended storage option when you run a database on an instance .
The volume persists independently from the running life of an instance .
After an EBS volume 924 Amazon Elastic Compute Cloud User Guide for Linux Instances Amazon EBS is attached to an instance , you can use it like any other physical hard drive .
As illustrated in the previous ﬁgure , multiple volumes can be attached to an instance .
You can also detach an EBS volume from one instance and attach it to another instance .
You can dynamically change the conﬁguration of a volume attached to an instance .
EBS volumes can also be created as encrypted volumes using the Amazon EBS encryption feature .
You can create an EBS volume from a snapshot , and attach it to another instance .
Amazon EC2 instance store Many instances can access storage from disks that are physically attached to the host computer .
This disk storage is referred to as instance store .
The data on an instance store volume persists only during the life of the associated instance ; if you stop or terminate an instance , any data on instance store volumes is lost .
Amazon EFS ﬁle system Amazon EFS provides scalable ﬁle storage for use with Amazon EC2 .
You can create an EFS ﬁle system and conﬁgure your instances to mount the ﬁle system .
You can use an EFS ﬁle system as a common data source for workloads and applications running on multiple instances .
It is designed to make web-scale computing easier by enabling you to store and retrieve any amount of data , at any time , from within Amazon EC2 or anywhere on the web .
For example , you can use Amazon S3 to store backup copies of your data and applications .
Adding storage Every time you launch an instance from an AMI , a root storage device is created for that instance .
The root storage device contains all the information necessary to boot the instance .
You can specify storage volumes in addition to the root device volume when you create an AMI or launch an instance using block device mapping .
You can also attach EBS volumes to a running instance .
Storage pricing For information about storage pricing , open AWS Pricing , scroll down to Services Pricing , choose Storage , and then choose the storage option to open that storage option 's pricing page .
For information about estimating the cost of storage , see the AWS Pricing Calculator .
Amazon Elastic Block Store ( Amazon EBS ) Amazon Elastic Block Store ( Amazon EBS ) provides block level storage volumes for use with EC2 instances .
You can mount these volumes as devices on your instances .
You can mount multiple volumes on the same instance , and you can mount a volume to multiple instances at a time .
You can create a ﬁle system on top of these volumes , or use 925 Amazon Elastic Compute Cloud User Guide for Linux Instances Features of Amazon EBS them in any way you would use a block device ( like a hard drive ) .
You can dynamically change the conﬁguration of a volume attached to an instance .
EBS volumes are highly available and reliable storage volumes that can be attached to any running instance that is in the same Availability Zone .
EBS volumes that are attached to an EC2 instance are exposed as storage volumes that persist independently from the life of the instance .
With Amazon EBS , you pay only for what you use .
For more information about Amazon EBS pricing , see the Projecting Costs section of the Amazon Elastic Block Store page .
You can attach multiple volumes to the same instance within the limits speciﬁed by your AWS account .
Your account has a limit on the number of EBS volumes that you can use , and the total storage available to you .
For more information about these limits , and how to request an increase in your limits , see Request to Increase the Amazon EBS Volume Limit .
Amazon EBS is recommended when data must be quickly accessible and requires long-term persistence .
EBS volumes are particularly well-suited for use as the primary storage for ﬁle systems , databases , or for any applications that require ﬁne granular updates and access to raw , unformatted , block-level storage .
Amazon EBS is well suited to both database-style applications that rely on random reads and writes , and to throughput-intensive applications that perform long , continuous reads and writes .
To make a volume available outside of the Availability Zone , you can create a snapshot and restore that snapshot to a new volume anywhere in that Region .
You can copy snapshots to other Regions and then restore them to new volumes there , making it easier to leverage multiple AWS Regions for geographical expansion , data center migration , and disaster recovery .
The following is a summary of performance and use cases for each volume type .
These volumes are ideal for a broad range of use cases such as boot volumes , small and medium-size databases , and development and test environments .
This allows you to predictably scale to tens of thousands of IOPS per EC2 instance .
• Throughput Optimized HDD volumes provide low-cost magnetic storage that deﬁnes performance in terms of throughput rather than IOPS .
These volumes are ideal for large , sequential workloads such as Amazon EMR , ETL , data warehouses , and log processing .
926 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Volumes • Cold HDD volumes provide low-cost magnetic storage that deﬁnes performance in terms of throughput rather than IOPS .
If you require infrequent access to your data and are looking to save costs , these volumes provides inexpensive block storage .
• You can create your EBS volumes as encrypted volumes , in order to meet a wide range of data-at-rest encryption requirements for regulated/audited data and applications .
When you create an encrypted EBS volume and attach it to a supported instance type , data stored at rest on the volume , disk I/O , and snapshots created from the volume are all encrypted .
Snapshots protect data for long-term durability , and they can be used as the starting point for new EBS volumes .
The same snapshot can be used to instantiate as many volumes as you wish .
These snapshots can be copied across AWS Regions .
These metrics , provided by Amazon CloudWatch , allow you to monitor the performance of your volumes to make sure that you are providing enough performance for your applications without paying for resources you do n't need .
Amazon EBS Volumes An Amazon EBS volume is a durable , block-level storage device that you can attach to one instance or to multiple instances at the same time .
You can use EBS volumes as primary storage for data that requires frequent updates , such as the system drive for an instance or storage for a database application .
You can also use them for throughput-intensive applications that perform continuous disk scans .
EBS volumes persist independently from the running life of an EC2 instance .
You can attach multiple EBS volumes to a single instance .
The volume and instance must be in the same Availability Zone .
After you attach a volume to an instance , you can use it like any other physical hard drive .
For current-generation volumes attached to current-generation instance types , you can dynamically increase size , modify the provisioned IOPS capacity , and change volume type on live production volumes .
They diﬀer in performance characteristics and price , allowing you to tailor your storage performance and cost to the needs of your applications .
Data availability When you create an EBS volume , it is automatically replicated within its Availability Zone to prevent data loss due to failure of any single hardware component .
You can attach an EBS volume to any EC2 instance in the same Availability Zone .
After you attach a volume , it appears as a native block device similar to a hard drive or other physical device .
At that point , the instance can interact with the volume just as it would with a local drive .
You can connect to the instance and format the EBS volume with a ﬁle system , such as ext3 , and then install applications .
If you attach multiple volumes to a device that you have named , you can stripe data across the volumes for increased I/O and throughput performance .
You can get monitoring data for your EBS volumes , including root device volumes for EBS-backed instances , at no additional charge .
Data persistence An EBS volume is oﬀ-instance storage that can persist independently from the life of an instance .
You continue to pay for the volume usage as long as the data persists .
EBS volumes that are attached to a running instance can automatically detach from the instance with their data intact when the instance is terminated if you uncheck the Delete on Termination checkbox when you conﬁgure EBS volumes for your instance on the EC2 console .
The volume can then be reattached to a new instance , enabling quick recovery .
If you are using an EBSbacked instance , you can stop and restart that instance without aﬀecting the data stored in the attached volume .
This enables you to process and store the data on your volume indeﬁnitely , only using the processing and storage resources when required .
The data persists on the volume until the volume is deleted explicitly .
The physical block storage used by deleted EBS volumes is overwritten with zeroes before it is allocated to another account .
If you are dealing with sensitive data , you should consider encrypting your data manually or storing the data on a volume protected by Amazon EBS encryption .
By default , the root EBS volume that is created and attached to an instance at launch is deleted when that instance is terminated .
You can modify this behavior by changing the value of the ﬂag DeleteOnTermination to false when you launch the instance .
This modiﬁed value causes the volume to persist even after the instance is terminated , and enables you to attach the volume to another instance .
By default , additional EBS volumes that are created and attached to an instance at launch are not deleted when that instance is terminated .
You can modify this behavior by changing the value of the ﬂag DeleteOnTermination to true when you launch the instance .
This modiﬁed value causes the volumes to be deleted when the instance is terminated .
928 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Volumes Data encryption For simpliﬁed data encryption , you can create encrypted EBS volumes with the Amazon EBS encryption feature .
All EBS volume types support encryption .
You can use encrypted EBS volumes to meet a wide range of data-at-rest encryption requirements for regulated/audited data and applications .
The encryption occurs on the server that hosts the EC2 instance , providing encryption of data-in-transit from the EC2 instance to Amazon EBS storage .
Amazon EBS encryption uses AWS Key Management Service ( AWS KMS ) master keys when creating encrypted volumes and any snapshots created from your encrypted volumes .
The ﬁrst time you create an encrypted EBS volume in a region , a default master key is created for you automatically .
This key is used for Amazon EBS encryption unless you select a customer master key ( CMK ) that you created separately using AWS KMS .
Creating your own CMK gives you more ﬂexibility , including the ability to create , rotate , disable , deﬁne access controls , and audit the encryption keys used to protect your data .
For more information , see the AWS Key Management Service Developer Guide .
Snapshots Amazon EBS provides the ability to create snapshots ( backups ) of any EBS volume and write a copy of the data in the volume to Amazon S3 , where it is stored redundantly in multiple Availability Zones .
The volume does not need to be attached to a running instance in order to take a snapshot .
As you continue to write data to a volume , you can periodically create a snapshot of the volume to use as a baseline for new volumes .
These snapshots can be used to create multiple new EBS volumes or move volumes across Availability Zones .
Snapshots of encrypted EBS volumes are automatically encrypted .
When you create a new volume from a snapshot , it 's an exact copy of the original volume at the time the snapshot was taken .
EBS volumes that are restored from encrypted snapshots are automatically encrypted .
By optionally specifying a diﬀerent Availability Zone , you can use this functionality to create a duplicate volume in that zone .
The snapshots can be shared with speciﬁc AWS accounts or made public .
When you create snapshots , you incur charges in Amazon S3 based on the volume 's total size .
For a successive snapshot of the volume , you are only charged for any additional data beyond the volume's original size .
Snapshots are incremental backups , meaning that only the blocks on the volume that have changed after your most recent snapshot are saved .
If you have a volume with 100 GiB of data , but only 5 GiB of data have changed since your last snapshot , only the 5 GiB of modiﬁed data is written to Amazon S3 .
Even though snapshots are saved incrementally , the snapshot deletion process is designed so that you need to retain only the most recent snapshot in order to restore the volume .
To help categorize and manage your volumes and snapshots , you can tag them with metadata of your choice .
Flexibility EBS volumes support live conﬁguration changes while in production .
You can modify volume type , volume size , and IOPS capacity without service interruptions .
Amazon EBS Volume Types Amazon EBS provides the following volume types , which diﬀer in performance characteristics and price , so that you can tailor your storage performance and cost to the needs of your applications .
The volumes types fall into two categories : 929 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Volumes • SSD-backed volumes optimized for transactional workloads involving frequent read/write operations with small I/O size , where the dominant performance attribute is IOPS • HDD-backed volumes optimized for large streaming workloads where throughput ( measured in MiB/s ) is a better performance measure than IOPS There are several factors that can aﬀect the performance of EBS volumes , such as instance conﬁguration , I/O characteristics , and workload demand .
For more information about pricing , see Amazon EBS Pricing .
Volume Characteristics The following table describes the use cases and performance characteristics for each volume type .
Older gp2 volumes might not reach full performance unless you modify the volume .
Previous Generation Volume Types The following table describes previous-generation EBS volume types .
If you need higher performance or performance consistency than previous-generation volumes can provide , we recommend that you consider using General Purpose SSD ( gp2 ) or other current volume types .
These volumes deliver single-digit millisecond latencies and the ability to burst to 3,000 931 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Volumes IOPS for extended periods of time .
I/O Credits and Burst Performance The performance of gp2 volumes is tied to volume size , which determines the baseline performance level of the volume and how quickly it accumulates I/O credits ; larger volumes have higher baseline performance levels and accumulate I/O credits faster .
I/O credits represent the available bandwidth that your gp2 volume can use to burst large amounts of I/O when more than the baseline performance is needed .
The more credits your volume has for I/O , the more time it can burst beyond its baseline performance level and the better it performs when more performance is needed .
This initial credit balance is designed to provide a fast initial boot cycle for boot volumes and to provide a good bootstrapping experience for other applications .
Volumes earn I/O credits at the baseline performance rate of 3 IOPS per GiB of volume size .
932 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Volumes When your volume requires more than the baseline performance I/O level , it draws on I/O credits in the credit balance to burst to the required performance level , up to a maximum of 3,000 IOPS .
When the baseline performance of a volume is higher than maximum burst performance , I/O credits are never spent .
The burst duration of a volume is dependent on the size of the volume , the burst IOPS required , and the credit balance when the burst begins .
If your gp2 volume uses all of its I/O credit balance , the maximum IOPS performance of the volume remains at the baseline IOPS performance level ( the rate at which your volume earns credits ) and the volume 's maximum throughput is reduced to the baseline IOPS multiplied by the maximum I/O size .
When I/O demand drops below the baseline level and unused credits are added to the I/O credit balance , the maximum IOPS performance of the volume again exceeds the baseline .
The larger a volume is , the greater the baseline performance is and the faster it replenishes the credit balance .
If you notice that your volume performance is frequently limited to the baseline level ( due to an empty I/O credit balance ) , you should consider using a larger gp2 volume ( with a higher baseline performance level ) or switching to an io1 volume for workloads that require sustained IOPS performance greater than 16,000 IOPS .
Unlike gp2 , which uses a bucket and credit model to calculate performance , an io1 volume allows you to specify a consistent IOPS rate when you create the volume , and Amazon EBS delivers the provisioned performance 99.9 percent of the time .
The following graph illustrates these performance characteristics : 935 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Volumes Your per-I/O latency experience depends on the IOPS provisioned and your workload proﬁle .
For the best I/O latency experience , ensure that you provision IOPS to meet the I/O proﬁle of your workload .
If you are unable to create an io1 volume ( or launch an instance with an io1 volume in its block device mapping ) in one of these Regions , try a diﬀerent Availability Zone in the Region .
Volume size determines the baseline throughput of your volume , which is the rate at which the volume accumulates throughput credits .
Volume size also determines the burst throughput of your volume , which is the rate at which you can 936 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Volumes spend credits when they are available .
Larger volumes have higher baseline and burst throughput .
The more credits your volume has , the longer it can drive I/O at the burst level .
After the bucket is depleted , throughput is limited to the baseline rate of 40 MiB/s per TiB .
938 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Volumes Cold HDD ( sc1 ) Volumes Cold HDD ( sc1 ) volumes provide low-cost magnetic storage that deﬁnes performance in terms of throughput rather than IOPS .
If you require infrequent access to your data and are looking to save costs , sc1 provides inexpensive block storage .
Volume size determines the baseline throughput of your volume , which is the rate at which the volume accumulates throughput credits .
Volume size also determines the burst throughput of your volume , which is the rate at which you can spend credits when they are available .
Larger volumes have higher baseline and burst throughput .
The more credits your volume has , the longer it can drive I/O at the burst level .
After the bucket is depleted , throughput is limited to the baseline rate of 12 MiB/s per TiB .
Magnetic ( standard ) Magnetic volumes are backed by magnetic drives and are suited for workloads where data is accessed infrequently , and scenarios where low-cost storage for small volume sizes is important .
These volumes deliver approximately 100 IOPS on average , with burst capability of up to hundreds of IOPS , and they can range in size from 1 GiB to 1 TiB .
For new applications , we recommend using one of the newer volume types .
Performance Considerations When Using HDD Volumes For optimal throughput results using HDD volumes , plan your workloads with the following considerations in mind .
Cold HDD The st1 and sc1 bucket sizes vary according to volume size , and a full bucket contains enough tokens for a full volume scan .
Volumes attached to smaller instances are limited to the per-instance throughput rather than the st1 or sc1 throughput limits .
941 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Volumes The following table shows ideal scan times for volumes of various size , assuming full buckets and suﬃcient instance throughput .
Ineﬃciency of Small Read/Writes on HDD The performance model for st1 and sc1 volumes is optimized for sequential I/Os , favoring highthroughput workloads , oﬀering acceptable performance on workloads with mixed IOPS and throughput , and discouraging workloads with small , random I/O .
Limitations on per-Instance Throughput Throughput for st1 and sc1 volumes is always determined by the smaller of the following : • Throughput limits of the volume • Throughput limits of the instance As for all Amazon EBS volumes , we recommend that you select an appropriate EBS-optimized EC2 instance in order to avoid network bottlenecks .
CloudWatch also allows you to set an alarm that notiﬁes you when the BurstBalance value falls to a certain level .
Constraints on the Size and Conﬁguration of an EBS Volume The size of an Amazon EBS volume is constrained by the physics and arithmetic of block data storage , as well as by the implementation decisions of operating system ( OS ) and ﬁle system designers .
AWS imposes additional limits on volume size to safeguard the reliability of its services .
The following sections describe the most important factors that limit the usable size of an EBS volume and oﬀer recommendations for conﬁguring your EBS volumes .
To an operating system installed on an EC2 instance , an attached EBS volume appears to be a physical hard disk drive containing 512-byte disk sectors .
The OS manages the allocation of data blocks ( or clusters ) onto those virtual sectors through its storage management utilities .
EBS is not aware of the data contained in its virtual disk sectors ; it only ensures the integrity of the sectors .
This means that AWS actions and OS actions are independent of each other .
When you are selecting a volume size , be aware of the capabilities and limits of both , as in the following cases : • EBS currently supports a maximum volume size of 16 TiB .
This means that you can create an EBS volume as large as 16 TiB , but whether the OS recognizes all of that capacity depends on its own design characteristics and on how the volume is partitioned .
• Linux boot volumes may use either the MBR or GPT partitioning scheme .
If your Linux AMI uses MBR , your boot volume is limited to 2047 GiB , but your non-boot volumes do not have this limit .
Partitioning Schemes Among other impacts , the partitioning scheme determines how many logical data blocks can be uniquely addressed in a single volume .
The common 944 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Volumes partitioning schemes in use are master boot record ( MBR ) and GUID partition table ( GPT ) .
The important diﬀerences between these schemes can be summarized as follows .
This means that each data block is mapped 32 with one of 2 possible integers .
Consequently , Linux and Windows never detect an MBR volume as being larger than 2 TiB even if AWS shows its size to be larger .
This means that each data block is mapped 64 with one of 2 possible integers .
Data Block Sizes Data storage on a modern hard drive is managed through logical block addressing , an abstraction layer that allows the operating system to read and write data in logical blocks without knowing much about the underlying hardware .
The OS relies on the storage device to map the blocks to its physical sectors .
EBS advertises 512-byte sectors to the operating system , which reads and writes data to disk using data blocks that are a multiple of the sector size .
Because certain workloads beneﬁt from a smaller or larger block size , ﬁle systems support non-default block sizes that can be speciﬁed during formatting .
Scenarios in which non-default block sizes should be used are outside the scope of this topic , but the choice of block size has consequences for the storage capacity of the volume .
Creating an Amazon EBS Volume You can create an Amazon EBS volume that you can then attach to any EC2 instance within the same Availability Zone .
You can choose to create an encrypted EBS volume , but encrypted volumes can only be attached to supported instance types .
If you are creating a volume for a high-performance storage scenario , you should make sure to use a Provisioned IOPS SSD ( io1 ) volume and attach it to an instance with enough bandwidth to support your application , such as an EBS-optimized instance or an instance with 10-Gigabit network connectivity .
New EBS volumes receive their maximum performance the moment that they are available and do not require initialization ( formerly known as pre-warming ) .
However , storage blocks on volumes that were restored from snapshots must be initialized ( pulled down from Amazon S3 and written to the volume ) before you can access the block .
This preliminary action takes time and can cause a signiﬁcant increase in the latency of an I/O operation the ﬁrst time each block is accessed .
For most applications , amortizing this cost over the lifetime of the volume is acceptable .
Performance is restored after the data is accessed once .
Methods of Creating a Volume • You can create an EBS volume and attach it to a running instance .
• You can create and attach EBS volumes when you launch instances by specifying a block device mapping .
From the navigation bar , select the Region in which you would like to create your volume .
This choice is important because some Amazon EC2 resources can be shared between Regions , while others ca n't .
For Availability Zone , choose the Availability Zone in which to create the volume .
EBS volumes can only be attached to EC2 instances within the same Availability Zone .
( Optional ) If the instance type supports EBS encryption and you want to encrypt the volume , select Encrypt this volume and choose a CMK .
If encryption by default is enabled in this Region , EBS encryption is enabled and the default CMK for EBS encryption is chosen .
You can choose a diﬀerent CMK from Master Key or paste the full ARN of any key that you can access .
After the volume status is Available , you can attach the volume to an instance .
To create a new ( empty ) EBS volume using the command line You can use one of the following commands .
You must know the ID of the snapshot and you must have access permissions for the snapshot .
EBS snapshots are the preferred backup tool on Amazon EC2 due to their speed , convenience , and cost .
When restoring a volume from a snapshot , you recreate its state at a speciﬁc point in the past with all data intact .
By attaching a restored volume to an instance , you can duplicate data across regions , create test environments , replace a damaged or corrupted production volume in its entirety , or retrieve speciﬁc ﬁles and directories and transfer them to another attached volume .
New volumes created from existing EBS snapshots load lazily in the background .
This means that after a volume is created from a snapshot , there is no need to wait for all of the data to transfer from Amazon S3 to your EBS volume before your attached instance can start accessing the volume and all its data .
If your instance accesses data that has n't yet been loaded , the volume immediately downloads the requested data from Amazon S3 , and then continues loading the rest of the volume data in the background .
EBS Performance New EBS volumes receive their maximum performance the moment that they are available and do not require initialization ( formerly known as pre-warming ) .
For volumes that were restored from snapshots , the storage blocks must be pulled down from Amazon S3 and written to the volume before you can access them .
This preliminary action takes time and can cause a signiﬁcant increase in the latency of I/O operations the ﬁrst time each block is accessed .
Volume performance is achieved after all blocks have been downloaded and written to the volume .
For most applications , amortizing the initialization cost over the lifetime of the volume is acceptable .
To avoid this initial performance hit in a production environment , you can use one of the following options : 947 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Volumes • Force the immediate initialization of the entire volume .
• Enable fast snapshot restore on a snapshot to ensure that the EBS volumes created from it are fullyinitialized at creation and instantly deliver all of their provisioned performance .
EBS Encryption New EBS volumes that are restored from encrypted snapshots are automatically encrypted .
You can also encrypt a volume on-the-ﬂy while restoring it from an unencrypted snapshot .
Encrypted volumes can only be attached to instance types that support EBS encryption .
From the navigation bar , select the Region that your snapshot is located in .
To restore the snapshot to a volume in a diﬀerent region , you can copy your snapshot to the new Region and then restore it to a volume in that Region .
For Snapshot ID , start typing the ID or description of the snapshot from which you are restoring the volume , and choose it from the list of suggested options .
( Optional ) Select Encrypt this volume to change the encryption state of your volume .
Select a CMK from Master Key to specify a CMK other than the default CMK for EBS encryption .
For Size ( GiB ) , type the size of the volume , or verify that the default size of the snapshot is adequate .
If you specify both a volume size and a snapshot , the size must be equal to or greater than the snapshot size .
When you select a volume type and a snapshot , the minimum and maximum sizes for the volume are shown next to Size .
For Availability Zone , choose the Availability Zone in which to create the volume .
EBS volumes can only be attached to EC2 instances in the same Availability Zone .
If you restored a snapshot to a larger volume than the default for that snapshot , you must extend the ﬁle system on the volume to take advantage of the extra space .
948 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Volumes To create an EBS volume from a snapshot using the command line You can use one of the following commands .
• create-volume ( AWS CLI ) • New-EC2Volume ( AWS Tools for Windows PowerShell ) Attaching an Amazon EBS Volume to an Instance You can attach an available EBS volume to one or more of your instances that is in the same Availability Zone as the volume .
Prerequisites • Determine how many volumes you can attach to your instance .
• If a volume is encrypted , it can only be attached to an instance that supports Amazon EBS encryption .
• You must be subscribed to the AWS Marketplace code that is on the volume .
• AWS Marketplace product codes are copied from the volume to the instance .
To attach an EBS volume to an instance using the console 1 .
Select an available volume and choose Actions , Attach Volume .
For Instance , start typing the name or ID of the instance .
Select the instance from the list of options ( only instances that are in the same Availability Zone as the volume are displayed ) .
For Device , you can keep the suggested device name , or type a diﬀerent supported device name .
Connect to your instance and mount the volume .
To attach an EBS volume to an instance using the command line You can use one of the following commands .
You can attach multiple Multi-Attach enabled volumes to an instance or set of instances .
Each instance to which the volume is attached has full read and write permission to the shared volume .
Multi-Attach makes it easier for you to achieve higher application availability in clustered Linux applications that manage concurrent write operations .
I/O fencing protocols control write access in a shared storage environment to maintain data consistency .
Your applications must provide write ordering for the attached instances to maintain data consistency .
• Multi-Attach enabled volumes can be attached to one block device mapping per instance .
• Multi-Attach enabled volumes that have an issue at the Amazon EBS infrastructure layer are unavailable to all attached instances .
Issues at the Amazon EC2 or networking layer might only impact some attached instances .
Performance Each attached instance is able to drive its maximum IOPS performance up to the volume 's maximum provisioned performance .
However , the aggregate performance of all of the attached instances can't 950 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Volumes exceed the volume 's maximum provisioned performance .
If the attached instances ' demand for IOPS is higher than the volume 's Provisioned IOPS , the volume will not exceed its provisioned performance .
Each instance can drive its maximum IOPS as it is less than the volume 's Provisioned IOPS of 50,000 .
To achieve consistent performance , it is best practice to balance I/O driven from attached instances across the sectors of a Multi-Attach enabled volume .
Working with Multi-Attach Multi-Attach enabled volumes can be managed in much the same way that you would manage any other Amazon EBS volume .
Use one of the following methods to enable Multi-Attach for an Amazon EBS volume during creation .
For Size and IOPS , choose the required volume size and the number of IOPS to provision .
For Availability Zone , choose the same Availability Zone that the instances are in .
Deleting on Termination Multi-Attach enabled volumes are deleted on instance termination if the last attached instance is terminated and if that instance is conﬁgured to delete the volume on termination .
If the volume is attached to multiple instances that have diﬀerent delete on termination settings in their volume block device mappings , the last attached instance 's block device mapping setting determines the delete on termination behavior .
To ensure predictable delete on termination behavior , enable or disable delete on termination for all of the instances to which the volume is attached .
By default , when a volume is attached to an instance the delete on termination setting for the block device mapping is set to false .
If you want to turn on delete on termination for a Multi-Attach enabled volume , modify the block device mapping .
If you want the volume to be deleted when the attached instances are terminated , enable delete on termination in the block device mapping for all of the attached instances .
If you want to retain the volume after the attached instances have been terminated , disable delete on termination in the block device mapping for all of the attached instances .
You can modify an instance 's delete on termination setting at launch or after it has launched .
If you enable or disable delete on termination during instance launch , the settings apply only to volumes that are attached at launch .
If you attach a volume to an instance after launch , you must explicitly set the delete on termination behavior for that volume .
You can modify an instance 's delete on termination setting using the command line tools only .
To modify the delete on termination setting for an existing instance Use the modify-instance-attribute command and specify the DeleteOnTermination attribute in the -- block-device-mappings option .
Data is aggregated across all of the attached instances .
952 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Volumes Pricing and billing There are no additional charges for using Amazon EBS Multi-Attach .
Making an Amazon EBS Volume Available for Use on Linux After you attach an Amazon EBS volume to your instance , it is exposed as a block device .
You can format the volume with any ﬁle system and then mount it .
After you make the EBS volume available for use , you can access it in the same ways that you access any other volume .
Any data written to this ﬁle system is written to the EBS volume and is transparent to applications using the device .
You can take snapshots of your EBS volume for backup purposes or to use as a baseline when you create another volume .
You can get directions for volumes on a Windows instance from Making a Volume Available for Use on Windows in the Amazon EC2 User Guide for Windows Instances .
Format and Mount an Attached Volume Suppose that you have an EC2 instance with an EBS volume for the root device , /dev/xvda , and that you have just attached an empty EBS volume to the instance using /dev/sdf .
Use the following procedure to make the newly attached volume available for use .
To format and mount an EBS volume on Linux 1 .
Connect to your instance using SSH .
The device could be attached to the instance with a diﬀerent device name than you speciﬁed in the block device mapping .
Use the lsblk command to view your available disk devices and their mount points ( if applicable ) to help you determine the correct device name to use .
The output of lsblk removes the /dev/ preﬁx from full device paths .
The following is example output for an instance built on the Nitro System ( p. 188 ) , which exposes EBS volumes as NVMe block devices .
Determine whether there is a ﬁle system on the volume .
New volumes are raw block devices , and you must create a ﬁle system on them before you can mount and use them .
Volumes that have been restored from snapshots likely have a ﬁle system on them already ; if you create a new ﬁle system on top of an existing ﬁle system , the operation overwrites your data .
953 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Volumes Use the ﬁle -s command to get information about a device , such as its ﬁle system type .
If the output shows simply data , as in the following example output , there is no ﬁle system on the device and you must create one .
For example , the following output shows a root device with the XFS ﬁle system .
( Conditional ) If you discovered that there is a ﬁle system on the device in the previous step , skip this step .
If you have an empty volume , use the mkfs -t command to create a ﬁle system on the volume .
Use the mkdir command to create a mount point directory for the volume .
The mount point is where the volume is located in the ﬁle system tree and where you read and write ﬁles to after you mount the volume .
Use the following command to mount the volume at the directory you created in the previous step .
For more information about ﬁle permissions , see File security at The Linux Documentation Project .
The mount point is not automatically preserved after rebooting your instance .
Automatically Mount an Attached Volume After Reboot To mount an attached EBS volume on every system reboot , add an entry for the device to the /etc/ fstab ﬁle .
Device names can change , but the UUID persists throughout the life of the partition .
By using the UUID , you reduce the chances that the system becomes unbootable after a hardware reconﬁguration .
954 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Volumes To mount an attached volume automatically after reboot 1 .
( Optional ) Create a backup of your /etc/fstab ﬁle that you can use if you accidentally destroy or delete this ﬁle while editing it .
Use the blkid command to ﬁnd the UUID of the device .
Open the /etc/fstab ﬁle using any text editor , such as nano or vim .
Add the following entry to /etc/fstab to mount the device at the speciﬁed mount point .
The ﬁelds are the UUID value returned by blkid ( or lsblk for Ubuntu 18.04 ) , the mount point , the ﬁle system , and the recommended ﬁle system mount options .
UUID=aebf131c-6957-451e-8d34-ec978d9581ae /data xfs defaults , nofail 0 2 Note If you ever boot your instance without this volume attached ( for example , after moving the volume to another instance ) , the nofail mount option enables the instance to boot even if there are errors mounting the volume .
To verify that your entry works , run the following commands to unmount the device and then mount all ﬁle systems in /etc/fstab .
If there are no errors , the /etc/fstab ﬁle is OK and your ﬁle system will mount automatically after it is rebooted .
If you are unsure how to correct errors in /etc/fstab and you created a backup ﬁle in the ﬁrst step of this procedure , you can restore from your backup ﬁle using the following command .
For example , you can view information about all volumes in a speciﬁc Region or view detailed information about a single volume , including its size , volume type , whether the volume is encrypted , which master key was used to encrypt the volume , and the speciﬁc instance to which the volume is attached .
You can get additional information about your EBS volumes , such as how much disk space is available , from the operating system on the instance .
Viewing Descriptive information To view information about an EBS volume using the console 1 .
In the details pane , you can inspect the information provided about the volume .
In the details pane , you can inspect the information provided about the volume .
To view the EBS volumes that are attached to an instance 1 .
To view more information about an instance , select it .
In the details pane , you can inspect the information provided about root and block devices .
To view information about an EBS volume using the command line You can use one of the following commands to view volume attributes .
• describe-volumes ( AWS CLI ) • Get-EC2Volume ( AWS Tools for Windows PowerShell ) Viewing Free Disk Space You can get additional information about your EBS volumes , such as how much disk space is available , from the Linux operating system on the instance .
EBS Volume Status Checks Volume status checks enable you to better understand , track , and manage potential inconsistencies in the data on an Amazon EBS volume .
They are designed to provide you with the information that you need to determine whether your Amazon EBS volumes are impaired , and to help you control how a potentially inconsistent volume is handled .
Volume status checks are automated tests that run every 5 minutes and return a pass or fail status .
If all checks pass , the status of the volume is ok .
If the status is insufficient-data , the checks may still be in progress on the volume .
You can view the results of volume status checks to identify any impaired volumes and take any necessary actions .
When Amazon EBS determines that a volume 's data is potentially inconsistent , the default is that it disables I/O to the volume from any attached EC2 instances , which helps to prevent data corruption .
After I/O is disabled , the next volume status check fails , and the volume status is impaired .
In addition , you 'll see an event that lets you know that I/O is disabled , and that you can resolve the impaired status of the volume by enabling I/O to the volume .
We wait until you enable I/O to give you the opportunity to decide whether to continue to let your instances use the volume , or to run a consistency check using a command , such as fsck , before doing so .
Note Volume status is based on the volume status checks , and does not reﬂect the volume state .
If the consistency of a particular volume is not a concern , and you 'd prefer that the volume be made available immediately if it 's impaired , you can override the default behavior by conﬁguring the volume to automatically enable I/O .
If you enable the Auto-Enable IO volume attribute ( autoEnableIO in the API ) , the volume status check continues to pass .
In addition , you 'll see an event that lets you know that the volume was determined to be potentially inconsistent , but that its I/O was automatically enabled .
This enables you to check the volume 's consistency or replace it at a later time .
The I/O performance status check compares actual volume performance to the expected performance of a volume and alerts you if the volume is performing below expectations .
The I/O performance status check is performed once every minute and CloudWatch collects this data every 5 minutes , so it may take up to 5 minutes from the moment you attach a io1 volume to an instance for this check to report the I/O performance status .
Important While initializing io1 volumes that were restored from snapshots , the performance of the volume may drop below 50 percent of its expected level , which causes the volume to display a warning state in the I/O Performance status check .
This is expected , and you can ignore the warning state on io1 volumes while you are initializing them .
The following table lists statuses for Amazon EBS volumes .
The Volume Status column displays the operational status of each volume .
To view the status details of a volume , select the volume and choose Status Checks .
Alternatively , you can choose Events in the navigator to view all the events for your instances and volumes .
To view volume status information with the command line You can use one of the following commands to view the status of your Amazon EBS volumes .
This causes the volume status check to fail , and creates a volume status event that indicates the cause of the failure .
Each event includes a start time that indicates the time at which the event occurred , and a duration that indicates how long I/O for the volume was disabled .
The end time is added to the event when I/O for the volume is enabled .
Volume status events include one of the following descriptions : Awaiting Action : Enable IO Volume data is potentially inconsistent .
I/O is disabled for the volume until you explicitly enable it .
The event description changes to IO Enabled after you explicitly enable I/O .
IO Enabled I/O operations were explicitly enabled for this volume .
IO Auto-Enabled I/O operations were automatically enabled on this volume after an event occurred .
We recommend that you check for data inconsistencies before continuing to use the data .
Volume performance is well below expectations .
You can view events for your volumes using the Amazon EC2 console , the API , or the command line interface .
To view events for your volumes in the console 1 .
All instances and volumes that have events are listed .
You can ﬁlter by volume to view only volume status .
You can also ﬁlter on speciﬁc status types .
If you have a volume where I/O performance is below normal , this might be a temporary condition due to an action you have taken ( for example , creating a snapshot of a volume during peak usage , running the volume on an instance that can not support the I/O bandwidth required , accessing data on the volume for the ﬁrst time , etc . ) .
To view events for your volumes with the command line You can use one of the following commands to view event information for your Amazon EBS volumes .
Stop any applications from using the volume .
Check the data on the volume .
( Optional ) Review any available application or system logs for relevant error messages .
c. If the volume has been impaired for more than 20 minutes , you can contact the AWS Support Center .
Choose Troubleshoot , and then in the Troubleshoot Status Checks dialog box , choose Contact Support to submit a support case .
To enable I/O for a volume with the command line You can use one of the following commands to view event information for your Amazon EBS volumes .
Important This procedure may cause the loss of write I/Os that were suspended when volume I/O was disabled .
Stop any applications from using the volume .
Detach the volume from the instance .
Select the volume that you detached in the previous step .
Attach the volume to another instance .
Check the data on the volume .
( Optional ) Review any available application or system logs for relevant error messages .
c. If the volume has been impaired for more than 20 minutes , you can contact the AWS Support Center .
Choose Troubleshoot , and then in the troubleshooting dialog box , choose Contact Support to submit a support case .
To enable I/O for a volume with the command line You can use one of the following commands to view event information for your Amazon EBS volumes .
If you have a recent snapshot that backs up the data on the volume , you can create a new volume from the snapshot .
Working with the Auto-Enabled IO Volume Attribute When Amazon EBS determines that a volume 's data is potentially inconsistent , it disables I/O to the volume from any attached EC2 instances by default .
This causes the volume status check to fail , and creates a volume status event that indicates the cause of the failure .
If the consistency of a particular volume is not a concern , and you prefer that the volume be made available immediately if it 's impaired , you can override the default behavior by conﬁguring the volume to automatically enable I/O .
In addition , you 'll see an event that lets you know that the volume was in a potentially inconsistent state , but that its I/O was automatically enabled .
When this event occurs , you should check the volume 's consistency and replace it if necessary .
This procedure explains how to view and modify the Auto-Enabled IO attribute of a volume .
Select the volume and choose Status Checks .
962 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Volumes To modify the Auto-Enabled IO attribute of a volume in the console 1 .
Select the Auto-Enable Volume IO check box to automatically enable I/O for an impaired volume .
To view or modify the autoEnableIO attribute of a volume with the command line You can use one of the following commands to view the autoEnableIO attribute of your Amazon EBS volumes .
However , if the instance is running , you must ﬁrst unmount the volume from the instance .
If an EBS volume is the root device of an instance , you must stop the instance before you can detach the volume .
When a volume with an AWS Marketplace product code is detached from an instance , the product code is no longer associated with the instance .
Important After you detach a volume , you are still charged for volume storage as long as the storage amount exceeds the limit of the AWS Free Tier .
You must delete a volume to avoid incurring further charges .
This example unmounts the volume and then explicitly detaches it from the instance .
This is useful when you want to terminate an instance or attach a volume to a diﬀerent instance .
You can reattach a volume that you detached ( without unmounting it ) , but it might not get the same mount point .
If there were writes to the volume in progress when it was detached , the data on the volume might be out of sync .
You can get directions for volumes on a Windows instance from Detaching a volume from a Windows instance in the Amazon EC2 User Guide for Windows Instances .
From your Linux instance , use the following command to unmount the /dev/sdh device .
To detach an EBS volume from an instance using the command line After unmounting the volume , you can use one of the following commands to detach it .
964 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Volumes Note To guard against the possibility of data loss , take a snapshot of your volume before attempting to unmount it .
Forced detachment of a stuck volume can cause damage to the ﬁle system or the data it contains or an inability to attach a new volume using the same device name , unless you reboot the instance .
• If you encounter problems while detaching a volume through the Amazon EC2 console , it may be helpful to use the describe-volumes CLI command to diagnose the issue .
• If your volume stays in the detaching state , you can force the detachment by choosing Force Detach .
Use this option only as a last resort to detach a volume from a failed instance , or if you are detaching a volume with the intention of deleting it .
The instance does n't get an opportunity to ﬂush ﬁle system caches or ﬁle system metadata .
If you use this option , you must perform the ﬁle system check and repair procedures .
• If you 've tried to force the volume to detach multiple times over several minutes and it stays in the detaching state , you can post a request for help to the Amazon EC2 forum .
To help expedite a resolution , include the volume ID and describe the steps that you 've already taken .
• When you attempt to detach a volume that is still mounted , the volume can become stuck in the busy state while it is trying to detach .
When you encounter this state , detachment can be delayed indeﬁnitely until you unmount the volume , force detachment , reboot the instance , or all three .
Deleting an Amazon EBS Volume After you no longer need an Amazon EBS volume , you can delete it .
After deletion , its data is gone and the volume ca n't be attached to any instance .
965 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Snapshots To delete an EBS volume using the command line You can use one of the following commands .
Snapshots are incremental backups , which means that only the blocks on the device that have changed after your most recent snapshot are saved .
This minimizes the time required to create the snapshot and saves on storage costs by not duplicating data .
When you delete a snapshot , only the data unique to that snapshot is removed .
Each snapshot contains all of the information that is needed to restore your data ( from the moment when the snapshot was taken ) to a new EBS volume .
When you create an EBS volume based on a snapshot , the new volume begins as an exact replica of the original volume that was used to create the snapshot .
The replicated volume loads data in the background so that you can begin using it immediately .
If you access data that has n't been loaded yet , the volume immediately downloads the requested data from Amazon S3 , and then continues loading the rest of the volume 's data in the background .
Snapshot Events You can track the status of your EBS snapshots through CloudWatch Events .
Multi-Volume Snapshots Snapshots can be used to create a backup of critical workloads , such as a large database or a ﬁle system that spans across multiple EBS volumes .
You are no longer required to stop your instance or to coordinate between volumes to ensure crash consistency , because snapshots are automatically taken across multiple EBS volumes .
Snapshot Pricing Charges for your snapshots are based on the amount of data stored .
Because snapshots are incremental , deleting a snapshot might not reduce your data storage costs .
Data referenced exclusively by a snapshot is removed when that snapshot is deleted , but data referenced by other snapshots is preserved .
For more information , see Amazon Elastic Block Store Volumes and Snapshots in the AWS Billing and Cost Management User Guide .
In the diagram below , Volume 1 is shown at three points in time .
A snapshot is taken of each of these three volume states .
Because Snap A is the ﬁrst snapshot taken of the volume , the entire 10 GiB of data must be copied .
Snap B needs to copy and store only the 4 GiB that changed after Snap A was taken .
This is indicated by the dashed arrow .
Relations among Multiple Snapshots of a Volume 967 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Snapshots Note If you copy a snapshot and encrypt it to a new CMK , a complete ( non-incremental ) copy is always created , resulting in additional delay and storage costs .
Copying and Sharing Snapshots You can share a snapshot across AWS accounts by modifying its access permissions .
You can make copies of your own snapshots as well as snapshots that have been shared with you .
A snapshot is constrained to the AWS Region where it was created .
After you create a snapshot of an EBS volume , you can use it to create new volumes in the same Region .
You can also copy snapshots across Regions , making it possible to use multiple Regions for geographical expansion , data center migration , and disaster 968 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Snapshots recovery .
You can copy any accessible snapshot that has a completed status .
Encryption Support for Snapshots EBS snapshots fully support EBS encryption .
• Volumes that you create from encrypted snapshots are automatically encrypted .
• Volumes that you create from an unencrypted snapshot that you own or have access to can be encrypted on-the-ﬂy .
• When you copy an unencrypted snapshot that you own , you can encrypt it during the copy process .
• When you copy an encrypted snapshot that you own or have access to , you can reencrypt it with a diﬀerent key during the copy process .
• The ﬁrst snapshot you take of an encrypted volume that has been created from an unencrypted snapshot is always a full snapshot .
Creating Amazon EBS Snapshots You can create a point-in-time snapshot of an EBS volume and use it as a baseline for new volumes or for data backup .
If you make periodic snapshots of a volume , the snapshots are incremental—the new snapshot saves only the blocks that have changed since your last snapshot .
Snapshots occur asynchronously ; the point-in-time snapshot is created immediately , but the status of the snapshot is pending until the snapshot is complete ( when all of the modiﬁed blocks have been transferred to Amazon S3 ) , which can take several hours for large initial snapshots or subsequent snapshots where many blocks have changed .
While it is completing , an in-progress snapshot is not aﬀected by ongoing reads and writes to the volume .
You can take a snapshot of an attached volume that is in use .
However , snapshots only capture data that has been written to your Amazon EBS volume at the time the snapshot command is issued .
This might exclude any data that has been cached by any applications or the operating system .
If you can pause any ﬁle writes to the volume long enough to take a snapshot , your snapshot should be complete .
However , if you ca n't pause all ﬁle writes to the volume , you should unmount the volume from within the instance , issue the snapshot command , and then remount the volume to ensure a consistent and complete snapshot .
You can remount and use your volume while the snapshot status is pending .
To make snapshot management easier , you can tag your snapshots during creation or add tags afterward .
For example , you can apply tags describing the original volume from which the snapshot was created , or the device name that was used to attach the original volume to an instance .
Snapshot Encryption Snapshots that are taken from encrypted volumes are automatically encrypted .
Volumes that are created from encrypted snapshots are also automatically encrypted .
The data in your encrypted volumes and 969 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Snapshots any associated snapshots is protected both at rest and in motion .
By default , only you can create volumes from snapshots that you own .
However , you can share your unencrypted snapshots with speciﬁc AWS accounts , or you can share them with the entire AWS community by making them public .
You can share an encrypted snapshot only with speciﬁc AWS accounts .
For others to use your shared , encrypted snapshot , you must also share the CMK key that was used to encrypt it .
Users with access to your encrypted snapshot must create their own personal copy of it and then use that copy to restore the volume .
You can also create lifecycle policies to automate the creation and retention of multivolume snapshots .
After the snapshots are created , each snapshot is treated as an individual snapshot .
You can also tag your multi-volume snapshots as you would a single volume snapshot .
We recommend you tag your multiple volume snapshots to manage them collectively during restore , copy , or retention .
It is helpful to identify the snapshots that are in a crash-consistent set by tagging your set with the instance ID , name , or other relevant details .
You can also choose to automatically copy tags from the source volume to the corresponding snapshots .
This helps you to set the snapshot metadata , such as access policies , attachment information , and cost allocation , to match the source volume .
You can perform all operations , such as restore , delete , and copy across Regions and accounts .
You can also tag your snapshots .
We recommend that you tag your multi-volume snapshots to collectively manage them during restore , copy , or retention .
The snapshots are collectively managed and , therefore , if any one snapshot for the volume set fails , all of the other snapshots display an error status .
Considerations The following considerations apply to creating snapshots : • When you create a snapshot for an EBS volume that serves as a root device , you should stop the instance before taking the snapshot .
• You can not create snapshots from instances for which hibernation is enabled .
• Although you can take a snapshot of a volume while a previous snapshot of that volume is in the pending status , having multiple pending snapshots of a volume can result in reduced volume performance until the snapshots complete .
If you receive a 970 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Snapshots ConcurrentSnapshotLimitExceeded error while trying to create multiple concurrent snapshots of the same volume , wait for one or more of the pending snapshots to complete before creating another snapshot of that volume .
• When a snapshot is created from a volume with an AWS Marketplace product code , the product code is propagated to the snapshot .
Creating a Snapshot Use the following procedure to create a snapshot from the speciﬁed volume .
Choose Snapshots under Elastic Block Store in the navigation pane .
To create a snapshot using the command line You can use one of the following commands .
Choose Snapshots under Elastic Block Store in the navigation pane .
Select the instance ID for which you want to create simultaneous backups for all of the attached EBS volumes .
( Optional ) Set Copy tags from volume ﬂag to automatically copy tags from the source volume to the corresponding snapshots .
If one of the snapshots in the volume set fails , the other snapshots are moved to error status for the volume set .
You can 971 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Snapshots monitor the progress of your snapshots using CloudWatch Events .
After the snapshot creation process completes , CloudWatch generates an event that contains the status and all of the relevant snapshots details for the aﬀected instance .
To create multi-volume snapshots using the command line You can use one of the following commands .
Unique data will not be deleted unless all of the snapshots that reference that data are deleted .
Deleting previous snapshots of a volume does not aﬀect your ability to restore volumes from later snapshots of that volume .
Deleting a volume has no eﬀect on the snapshots made from it .
This means that only the blocks on the device that have changed after your last snapshot are saved in the new snapshot .
Even though snapshots are saved incrementally , the snapshot deletion process is designed so that you need to retain only the most recent snapshot in order to restore the volume .
Data that was present on a volume , held in an earlier snapshot or series of snapshots , that is subsequently deleted from that volume at a later time , is still considered unique data of the earlier snapshots .
This unique data is not deleted from the sequence of snapshots unless all snapshots that reference the unique data are deleted .
Other snapshots might reference that snapshot 's data , and referenced data is always preserved .
If you delete a snapshot containing data being used by a later snapshot , costs associated with the referenced data are allocated to the later snapshot .
To delete multi-volume snapshots , retrieve all of the snapshots for your multi-volume group using the tag you applied to the group when you created the snapshots .
You will not be prevented from deleting individual snapshots in the multi-volume snapshots group .
In the following diagram , Volume 1 is shown at three points in time .
Because Snap A is the ﬁrst snapshot taken of the volume , the entire 10 GiB of data must be copied .
Snap B needs to copy and store only the 4 GiB that changed after Snap A was taken .
This is indicated by the dashed arrow .
The 6 GiB of data stored in Snapshot A that were referenced by Snapshot B have now been moved to Snapshot B , as shown by the heavy arrow .
Example 1 : Deleting a Snapshot with Some of its Data Referenced by Another Snapshot 972 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Snapshots Note that you ca n't delete a snapshot of the root device of an EBS volume used by a registered AMI .
You must ﬁrst deregister the AMI before you can delete the snapshot .
Choose Snapshots in the navigation pane .
Select a snapshot and then choose Delete from the Actions list .
To delete a snapshot using the command line You can use one of the following commands .
If you are also at your concurrent snapshot limit ( ﬁve snapshots in progress ) , and you attempt to take an additional snapshot , you may get the ConcurrentSnapshotLimitExceeded error .
973 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Snapshots Copying an Amazon EBS Snapshot With Amazon EBS , you can create point-in-time snapshots of volumes , which we store for you in Amazon S3 .
After you create a snapshot and it has ﬁnished copying to Amazon S3 ( when the snapshot status is completed ) , you can copy it from one AWS Region to another , or within the same Region .
The snapshot copy receives an ID that is diﬀerent from the ID of the original snapshot .
To copy multi-volume snapshots to another AWS Region , retrieve the snapshots using the tag you applied to the multi-volume snapshots group when you created it .
Then individually copy the snapshots to another Region .
For information about copying an Amazon RDS snapshot , see Copying a DB Snapshot in the Amazon RDS User Guide .
If you would like another account to be able to copy your snapshot , you must either modify the snapshot permissions to allow access to that account or make the snapshot public so that all AWS accounts can copy it .
For pricing information about copying snapshots across AWS Regions and accounts , see Amazon EBS Pricing .
Note that snapshot copy operations within a single account and Region do not copy any actual data and therefore are cost-free as long as the encryption status of the snapshot copy does not change .
• Disaster recovery : Back up your data and logs across diﬀerent geographical locations at regular intervals .
In case of disaster , you can restore your applications using point-in-time backups stored in the secondary Region .
This minimizes data loss and recovery time .
• Encryption : Encrypt a previously unencrypted snapshot , change the key with which the snapshot is encrypted , or , for encrypted snapshots that have been shared with you , create a copy that you own in order to restore a volume from it .
• Data retention and auditing requirements : Copy your encrypted EBS snapshots from one AWS account to another to preserve data logs or other ﬁles for auditing or data retention .
Using a diﬀerent account helps prevent accidental snapshot deletions , and protects you if your main AWS account is compromised .
Prerequisites • You can copy any accessible snapshots that have a completed status , including shared snapshots and snapshots that you have created .
• You can copy AWS Marketplace , VM Import/Export , and AWS Storage Gateway snapshots , but you must verify that the snapshot is supported in the destination Region .
Limits • Each account can have up to twenty concurrent snapshot copy requests to a single destination Region .
974 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Snapshots • User-deﬁned tags are not copied from the source snapshot to the new snapshot .
You can add userdeﬁned tags during or after the copy operation .
• Snapshots created by the CopySnapshot action have an arbitrary volume ID that should not be used for any purpose .
Incremental Snapshot Copying Whether a snapshot copy is incremental is determined by the most recently completed snapshot copy .
When you copy a snapshot across Regions or accounts , the copy is an incremental copy if the following conditions are met : • The snapshot was copied to the destination Region or account previously .
• The most recent snapshot copy still exists in the destination Region or account .
• All copies of the snapshot in the destination Region or account are either unencrypted or were encrypted using the same CMK .
If the most recent snapshot copy was deleted , the next copy is a full copy , not an incremental copy .
If a copy is still pending when you start a another copy , the second copy starts only after the ﬁrst copy ﬁnishes .
We recommend that you tag your snapshots with the volume ID and creation time so that you can keep track of the most recent snapshot copy of a volume in the destination Region or account .
Encryption and Snapshot Copying When you copy a snapshot , you can encrypt the copy or you can specify a CMK diﬀerent from the original one , and the resulting copied snapshot uses the new CMK .
To copy an encrypted snapshot shared from another AWS account , you must have permissions to use the snapshot and the customer master key ( CMK ) that was used to encrypt the snapshot .
When using an encrypted snapshot that was shared with you , we recommend that you re-encrypt the snapshot by copying it using a CMK that you own .
This protects you if the original CMK is compromised , or if the owner revokes it , which could cause you to lose access to any encrypted volumes that you created using the snapshot .
You apply encryption to EBS snapshot copies by setting the Encrypted parameter to true .
Optionally , you can use KmsKeyId to specify a custom key to use to encrypt the snapshot copy .
( The Encrypted parameter must also be set to true , even if encryption by default is enabled . ) .
If KmsKeyId is not speciﬁed , the key that is used for encryption depends on the encryption state of the source snapshot and its ownership .
The following table describes the encryption outcome for each possible combination of settings .
975 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Snapshots Encryption outcomes : Copying a snapshot Is Encrypted parameter set ?
Source snapshot Default ( no KmsKeyId speciﬁed ) Custom ( KmsKeyId speciﬁed ) No No Unencrypted snapshot that you own Unencrypted N/A No No Encrypted snapshot that you own Encrypted by same key No No Unencrypted snapshot that is shared with you Unencrypted No No Encrypted snapshot that is shared with you Encrypted by default CMK* Yes No Unencrypted snapshot that you own Encrypted by default CMK Yes No Encrypted snapshot that you own Encrypted by same key Yes No Unencrypted snapshot that is shared with you Encrypted by default CMK Yes No Encrypted snapshot that is shared with you Encrypted by default CMK No Yes Unencrypted snapshot that you own Encrypted by default CMK No Yes Encrypted snapshot that you own Encrypted by same key No Yes Unencrypted snapshot that is shared with you Encrypted by default CMK No Yes Encrypted snapshot that is shared with you Encrypted by default CMK Yes Yes Unencrypted snapshot that you own Encrypted by default CMK Yes Yes Encrypted snapshot that you own Encrypted by same key 976 Encrypted by a speciﬁed CMK** N/A Encrypted by a speciﬁed CMK Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Snapshots Is Encrypted parameter set ?
Source snapshot Default ( no KmsKeyId speciﬁed ) Yes Yes Unencrypted snapshot that is shared with you Encrypted by default CMK Yes Yes Encrypted snapshot that is shared with you Encrypted by default CMK Custom ( KmsKeyId speciﬁed ) * This is the default CMK used for EBS encryption for the AWS account and Region .
By default this is a unique AWS managed CMK for EBS , or you can specify a customer managed CMK .
This CMK is used instead of the default CMK for the AWS account and Region .
Select the snapshot to copy , and then choose Copy from the Actions list .
In the Copy Snapshot dialog box , update the following as necessary : • Destination region : Select the Region where you want to write the copy of the snapshot .
• Description : By default , the description includes information about the source snapshot so that you can identify a copy from the original .
You can change this description as necessary .
• Encryption : If the source snapshot is not encrypted , you can choose to encrypt the copy .
If you have enabled encryption by default ( p. 1012 ) , the Encryption option is set and can not be unset from the snapshot console .
If the Encryption option is set , you can choose to encrypt it to a customer managed CMK by selecting one in the ﬁeld , described below .
You can not strip encryption from an encrypted snapshot .
The default key for your account is displayed initially , but you can optionally select from the master keys in your account or type/paste the ARN of a key from a diﬀerent account .
You can create new master encryption keys in the IAM console https : //console.aws.amazon.com/iam/ .
In the Copy Snapshot conﬁrmation dialog box , choose Snapshots to go to the Snapshots page in the Region speciﬁed , or choose Close .
To view the progress of the copy process , switch to the destination Region , and then refresh the Snapshots page .
Copies in progress are listed at the top of the page .
To check for failure 977 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Snapshots If you attempt to copy an encrypted snapshot without having permissions to use the encryption key , the operation fails silently .
The error state is not displayed in the console until you refresh the page .
You can also check the state of the snapshot from the command line , as in the following example .
When copying an encrypted snapshot , you must have DescribeKey permissions on the default CMK .
Explicitly denying these permissions results in copy failure .
For information about managing CMK keys , see Controlling Access to Customer Master Keys .
To copy a snapshot using the command line You can use one of the following commands .
Choose Snapshots in the navigation pane .
To reduce the list , choose an option from the Filter list .
You can ﬁlter your snapshots further by using the advanced search options .
Choose the search bar to view the ﬁlters available .
To view snapshot information using the command line You can use one of the following commands .
Users that you have authorized can use the snapshots you share as the basis for creating their own EBS volumes , while your original snapshot remains unaﬀected .
If you choose , you can make your unencrypted snapshots available publicly to all AWS users .
When you share an encrypted snapshot , you must also share the customer managed CMK used to encrypt the snapshot .
You can apply cross-account permissions to a customer managed CMK either when it is created or at a later time .
978 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Snapshots Important When you share a snapshot , you are giving others access to all of the data on the snapshot .
Share snapshots only with people with whom you want to share all of your snapshot data .
Considerations The following considerations apply to sharing snapshots : • Snapshots are constrained to the Region in which they were created .
To share a snapshot with another Region , copy the snapshot to that Region .
• If your snapshot uses the longer resource ID format , you can only share it with another account that also supports longer IDs .
• AWS prevents you from sharing snapshots that were encrypted with your default CMK .
Snapshots that you intend to share must instead be encrypted with a customer managed CMK .
For more information , see Creating Keys in the AWS Key Management Service Developer Guide .
• Users of your shared CMK who are accessing encrypted snapshots must be granted permissions to perform the following actions on the key : kms : DescribeKey , kms : CreateGrant , GenerateDataKey , and kms : ReEncrypt .
For more information , see Controlling Access to Customer Master Keys in the AWS Key Management Service Developer Guide .
Sharing an Unencrypted Snapshot Using the Console To share a snapshot using the console 1 .
Choose Snapshots in the navigation pane .
Select the snapshot and then choose Actions , Modify Permissions .
Make the snapshot public or share it with speciﬁc AWS accounts as follows : • To make the snapshot public , choose Public .
This option is not valid for encrypted snapshots or snapshots with an AWS Marketplace product code .
To share the snapshot with one or more AWS accounts , choose Private , enter the AWS account ID ( without hyphens ) in AWS Account Number , and choose Add Permission .
Repeat for any additional AWS accounts .
To use an unencrypted snapshot that was privately shared with you 1 .
Choose Snapshots in the navigation pane .
Locate the snapshot by ID or description .
You can use this snapshot as you would any other ; for example , you can create a volume from the snapshot or copy the snapshot to a diﬀerent Region .
Sharing an Encrypted Snapshot Using the Console To share an encrypted snapshot using the console 1 .
To change the AWS Region , use the Region selector in the upper-right corner of the page .
Choose Customer managed keys in the navigation pane .
In the Alias column , choose the alias ( text link ) of the customer managed key that you used to encrypt the snapshot .
In the Key policy section , you see either the policy view or the default view .
The policy view displays the key policy document .
The default view displays sections for Key administrators , Key deletion , Key Use , and Other AWS accounts .
The default view displays if you created the policy in the console and have not customized it .
If the default view is not available , you 'll need to manually edit the policy in the policy view .
Use either the policy view or the default view , depending on which view you can access , to add one or more AWS account IDs to the policy , as follows : • ( Policy view ) Choose Edit .
Add one or more AWS account IDs to the following statements : '' Allow use of the key '' and `` Allow attachment of persistent resources '' .
In the following example , the AWS account ID 444455556666 is added to the policy .
Choose Add other AWS accounts and enter the AWS account ID as prompted .
To add another account , choose Add another AWS account and enter the AWS account ID .
When you have added all AWS accounts , choose Save changes .
Choose Snapshots in the navigation pane .
Select the snapshot and then choose Actions , Modify Permissions .
For each AWS account , enter the AWS account ID in AWS Account Number and choose Add Permission .
When you have added all AWS accounts , choose Save .
980 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Snapshots To use an encrypted snapshot that was shared with you 1 .
Choose Snapshots in the navigation pane .
Locate the snapshot by ID or description .
The copy of the snapshot is encrypted by the key displayed in Master Key .
To select a customer managed CMK , click inside the input box to see a list of available keys .
Sharing a Snapshot Using the Command Line The permissions for a snapshot are speciﬁed using the createVolumePermission attribute of the snapshot .
To share a snapshot with a speciﬁc AWS account , set the user to the ID of the AWS account .
Accessing the contents of an EBS snapshot You can use the Amazon Elastic Block Store ( EBS ) direct APIs to directly read the data on your EBS snapshots , and identify the diﬀerence between two snapshots .
You can view the details of blocks in an EBS snapshot , compare the block diﬀerence between two snapshots , and directly access the data in a snapshot .
If you ’ re an independent software vendor ( ISV ) who oﬀers backup services for EBS , the EBS direct APIs makes it easier and more cost-eﬀective to track incremental changes on your EBS volumes via EBS snapshots .
This can be done without having to create new volumes from EBS snapshots , and then use EC2 instances to compare the diﬀerences .
This user guide provides an overview of the elements that make up the EBS direct APIs , and examples of how to use them eﬀectively .
For more information about the actions , data types , parameters , and errors of the APIs , see the EBS direct APIs reference .
For more information about the supported AWS Regions , endpoints , and service quotas for the EBS direct APIs , see Amazon Elastic Block Store Endpoints and Quotas in the AWS General Reference .
Snapshots Snapshots are the primary means to back up data from your EBS volumes .
To save storage costs , successive snapshots are incremental , containing only the volume data that changed since the previous snapshot .
Note Public snapshots are not supported by the EBS direct APIs .
Each snapshot can contain thousands of blocks .
Block indexes A block index is the oﬀset position of a block within a snapshot , and it is used to identify the block .
Multiply the BlockIndex value with the BlockSize value ( BlockIndex * BlockSize ) to identify the logical oﬀset of the data in the logical block .
Block tokens A block token is the identifying hash of a block within a snapshot , and it is used to locate the block data .
Note Block tokens returned by EBS direct APIs are temporary .
Block tokens change if you run another ListSnapshotBlocks or ListChangedBlocks request for the same snapshot .
List snapshot blocks The ListSnapshotBlocks API operation returns the block indexes and block tokens for blocks in the speciﬁed snapshot .
For more information , see ListSnapshotBlocks in the EBS direct APIs reference .
List changed blocks The ListChangedBlocks API operation returns the block indexes and block tokens for blocks that are diﬀerent between two speciﬁed snapshots of the same volume/snapshot lineage .
For more information , see ListChangedBlocks in the EBS direct APIs reference .
Get snapshot blocks The GetSnapshotBlock API operation returns the data in a block for the speciﬁed snapshot ID , block index , and block token .
For more information , see GetSnapshotBlock in the EBS direct APIs reference .
Using the APIs Use the ListSnapshotBlocks or ListChangedBlocks API operations to identify the block indexes and block tokens of blocks for which you want to get data .
Then , use the GetSnapshotBlock API 982 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Snapshots operation to get the data from the blocks in a snapshot .
Examples for how to run these operations using the AWS CLI are provided later in this guide .
Permissions for IAM users An IAM user must have the following policies to use the EBS direct APIs .
Important Exercise caution when assigning the following policies to IAM users .
By assigning these policies , you might give access to a user who is denied access to the same resource via the EC2 APIs , such as the CopySnapshot or CreateVolume operations .
The following policy grants full access to the EBS direct APIs .
In the policy , be sure to replace the date and time range shown with the date and time range for your policy .
In the policy , replace < AccountId > with the ID of the AWS account for the AWS KMS key , and < KeyId > with the ID of the key used to encrypt the snapshot that you want to access with the EBS direct APIs .
Working with EBS direct APIs using the command line The following examples show how to use the EBS direct APIs using the AWS Command Line Interface ( AWS CLI ) .
For more information about installing and conﬁguring the AWS CLI , see Installing the AWS CLI version 1 and Quickly Conﬁguring the AWS CLI .
Example Example : Get the block indexes and block tokens for blocks that are in a snapshot The following list-snapshot-blocks command example returns the block indexes and block tokens for blocks that are in snapshot snap-0987654321 , in the us-east-1 AWS Region .
To get the data in a block , use the get-snapshot-block command and specify the block index and block token for the block .
The block tokens are valid until the expiry time listed .
Additionally , block indexes 6001 , 6002 , and 6003 exist only in the ﬁrst snapshot ID speciﬁed , and not in the second snapshot ID because there is no second block token listed in the response .
To get the data in a block , use the get-snapshot-block command and specify the block index and block token for the block .
The block tokens are valid until the expiry time listed .
If you run the command on a Linux or Unix computer , replace the output path with /tmp/output.txt to output the data to the output.txt ﬁle in the /tmp directory .
It shows the size of the data returned , the checksum to validate the data , and the checksum algorithm used to generate the checksum .
The binary data is automatically saved to the directory and ﬁle you speciﬁed in the request command .
You can also use one of the AWS SDKs to access an API that 's tailored to the programming language or platform that you 're using .
The EBS direct APIs require an AWS Signature Version 4 signature .
For more information about creating these signatures , see Signature Version 4 Signing Process in the AWS General Reference .
You need to learn how to sign HTTP requests only if you intend to manually create them .
When you use the AWS Command Line Interface ( AWS CLI ) or one of the AWS SDKs to make requests to AWS , these tools automatically sign the requests for you with the access key that you specify when you conﬁgure the tools .
When you use these tools , you do n't need to learn how to sign requests yourself .
Frequently asked questions for the EBS direct APIs Can a snapshot be accessed using the EBS direct APIs if it has a pending status ?
The snapshot can only be accessed if it has a completed status .
Are the block indexes returned by the EBS direct APIs in numerical order ?
The block indexes returned are unique , and in numerical order .
The minimum MaxResult parameter value you can use is 100 .
If you submit a request with a MaxResult parameter value of under 100 , and there are more than 100 blocks in the snapshot , then the API will return at least 100 results .
987 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Snapshots Can I run API requests concurrently ?
You can run API requests concurrently .
Be sure to account for other workloads that may be running in the account to avoid bottlenecks .
You should also build retry mechanisms into your EBS direct APIs workﬂows to handle throttling , timeouts , and service unavailability .
When running the ListChangedBlocks operation , is it possible to get an empty response even though there are blocks in the snapshot ?
If the changed blocks are few and far between in the snapshot , the response may be empty but the API will return a next page token value .
Use the next page token value to continue to the next page of results .
You can conﬁrm that you have reached the last page of results when the API returns a next page token value of null .
If the NextToken parameter is speciﬁed together with a StartingBlockIndex parameter , which of the two is used ?
The NextToken is used , and the StartingBlockIndex is ignored .
How long are the block tokens and next tokens valid ?
Block tokens are valid for seven days , and next tokens are valid for 60 minutes .
Encrypted snapshots can be accessed using the EBS direct APIs .
To access an encrypted snapshot , the user must have access to the key used to encrypt the snapshot , and the AWS KMS decrypt operation .
See the ( p. Use the ListSnapshotBlocks or ListChangedBlocks API operations to identify the block indexes and block tokens of blocks for which you want to get data .
Then , use the GetSnapshotBlock API operation to get the data from the blocks in a snapshot .
Examples for how to run these operations using the AWS CLI are provided later in this guide. ) .
section earlier in this guide for the AWS KMS policy to assign to a user .
Does list snapshot block return all block indexes and block tokens in a snapshot , or only those that have data written to them ?
It returns only block indexes and tokens that have data written to them .
Automating the Amazon EBS Snapshot Lifecycle You can use Amazon Data Lifecycle Manager to automate the creation , retention , and deletion of snapshots taken to back up your Amazon EBS volumes .
• Retain backups as required by auditors or internal compliance .
Combined with the monitoring features of Amazon CloudWatch Events and AWS CloudTrail , Amazon Data Lifecycle Manager provides a complete backup solution for EBS volumes at no additional cost .
To save storage costs , successive snapshots are incremental , containing only the volume data that changed since the previous snapshot .
When you delete one snapshot in a series of snapshots for a volume , only the data unique to that snapshot is removed .
The rest of the captured history of the volume is preserved .
Target Resource Tags Amazon Data Lifecycle Manager uses resource tags to identify the EBS volumes to back up .
Tags are customizable metadata that you can assign to your AWS resources ( including EBS volumes and snapshots ) .
Multiple tags can be assigned to a volume if you want to run multiple policies on it .
Snapshot Tags Amazon Data Lifecycle Manager applies the following tags to all snapshots created by a policy , to distinguish them from snapshots created by any other means : • aws : dlm : lifecycle-policy-id • aws : dlm : lifecycle-schedule-name You can also specify custom tags to be applied to snapshots on creation .
The target tags that Amazon Data Lifecycle Manager uses to associate volumes with a policy can optionally be applied to snapshots created by the policy .
989 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Snapshots Lifecycle Policies A lifecycle policy consists of these core settings : • Resource type—The type of AWS resource managed by the policy .
Use VOLUME to create snapshots of individual volumes or use INSTANCE to create multi-volume snapshots from the volumes for an instance .
• Target tags—The tags that must be associated with an EBS volume or an EC2 instance for it to be managed by the policy .
• Retention—You can retain snapshots based on either the total count of snapshots or the age of each snapshot .
Considerations for Amazon Data Lifecycle Manager Your AWS account has the following quotas related to Amazon Data Lifecycle Manager : • You can create up to 100 lifecycle policies per Region .
The following considerations apply to lifecycle policies : • A policy does not begin creating snapshots until you set its activation status to enabled .
You can conﬁgure a policy to be enabled upon creation .
• The ﬁrst snapshot is created by a policy within one hour after the speciﬁed start time .
• If you modify a policy by removing or changing its target tag , the EBS volumes with that tag are no longer aﬀected by the policy .
• If you modify the schedule name for a policy , the snapshots created under the old schedule name are no longer aﬀected by the policy .
• If you modify a retention schedule based on time to use a new time interval , the new interval is used only for new snapshots .
The new schedule does not aﬀect the retention schedule of existing snapshots created by this policy .
• You can not change the retention schedule of a policy from the count of snapshots to the age of each snapshot .
• If you disable a policy with a retention schedule based on the age of each snapshot , the snapshots whose retention periods expire while the policy is disabled are retained indeﬁnitely .
You must delete these snapshots manually .
When you enable the policy again , Amazon Data Lifecycle Manager resumes deleting snapshots as their retention periods expire .
• If you delete the resource to which a policy with count-based retention applies , the policy no longer manages the previously created snapshots .
You must manually delete the snapshots if they are no longer needed .
• If you delete the resource to which a policy with age-based retention applies , the policy continues to delete snapshots on the deﬁned schedule , up to the last snapshot .
You must manually delete the last snapshot if it is no longer needed .
• You can create multiple policies to back up an EBS volume or an EC2 instance .
For example , if an EBS volume has two tags , where tag A is the target for policy A to create a snapshot every 12 hours , and 990 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Snapshots tag B is the target for policy B to create a snapshot every 24 hours , Amazon Data Lifecycle Manager creates snapshots according to the schedules for both policies .
The following considerations apply to lifecycle policies and fast snapshot restore ( p. 1020 ) : • A snapshot that is enabled for fast snapshot restore remains enabled even if you delete or disable the lifecycle policy , disable fast snapshot restore for the lifecycle policy , or disable fast snapshot restore for the Availability Zone .
You can disable fast snapshot restore for these snapshots manually .
• If you enable fast snapshot restore and you exceed the maximum number of snapshots that can be enabled for fast snapshot restore , Amazon Data Lifecycle Manager creates snapshots as scheduled but does not enable them for fast snapshot restore .
After a snapshot that is enabled for fast snapshot restore is deleted , the next snapshot Amazon Data Lifecycle Manager creates is enabled for fast snapshot restore .
We recommend that you create a schedule that ensures that each snapshot is fully optimized before Amazon Data Lifecycle Manager creates the next snapshot .
Use the timestamp tag to identify the set of time-consistent snapshots created from the attached instances .
Prerequisites The following prerequisites are required by Amazon Data Lifecycle Manager .
Prerequisites • Permissions for Amazon Data Lifecycle Manager ( p. 991 ) • Permissions for IAM Users ( p. 992 ) Permissions for Amazon Data Lifecycle Manager Amazon Data Lifecycle Manager uses an IAM role to get the permissions that are required to manage snapshots on your behalf .
Amazon Data Lifecycle Manager creates the AWSDataLifecycleManagerDefaultRole role the ﬁrst time that you create a lifecycle policy using the AWS Management Console .
You can also create this role using the following create-default-role command .
aws dlm create-default-role Alternatively , you can create a custom IAM role with the required permissions and select it when you create a lifecycle policy .
Select the role you created and then choose Trust relationships .
992 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Snapshots Manage Backups Using the Console The following examples show how to use Amazon Data Lifecycle Manager to manage the backups of your EBS volumes using the AWS Management Console .
In the navigation pane , choose Elastic Block Store , Lifecycle Manager , then choose Create snapshot lifecycle policy .
Use VOLUME to create snapshots of individual volumes or use INSTANCE to create multi-volume snapshots from the volumes for an instance .
• Target with these tags–The resource tags that identify the volumes or instances to back up .
The ﬁrst policy run starts within an hour after the scheduled time .
• Retain–You can retain snapshots based on either the total count of snapshots or the age of each snapshot .
After the maximum count is reached , the oldest snapshot is deleted when a new one is created .
After the retention period of each snapshot expires , it is deleted .
The retention period should be greater than or equal to the creation interval .
• Cross Region copy–You can copy each snapshot to up at three additional Regions .
For each Region , you can choose diﬀerent retention policies and whether to copy all tags or no tags .
If the source snapshot is encrypted or if encryption by default is enabled , the snapshots copies are encrypted .
If the source snapshot is unencrypted , you can enable encryption .
If you do not specify a CMK , the snapshots are encrypted using the default key for EBS encryption in each destination Region .
You must ensure that you do not exceed the number of concurrent snapshot copies per Region .
You can also specify additional tags for the snapshots in addition to the tags applied by Amazon Data Lifecycle Manager .
If the resource type is INSTANCE , you can choose to automatically tag your snapshots with the following variable tags : instance-id and timestamp .
The values of the variable tags are determined when the tags are added .
• Fast snapshot restore–Choose whether to enable fast snapshot restore and in which Availability Zones .
You can also specify the maximum number of snapshots that can be enabled for fast snapshot store .
993 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Snapshots • IAM role–An IAM role that has permissions to create , delete , and describe snapshots , and to describe volumes .
• Policy status after creation–Choose Enable policy to start the policy runs at the next scheduled time or Disable policy to prevent the policy from running .
The Details tab displays information about the policy .
Modify the policy settings as needed .
For example , you can modify the schedule , add or remove tags , or enable or disable the policy .
When prompted for conﬁrmation , choose Delete Snapshot Lifecycle Policy .
Manage Backups Using the AWS CLI The following examples show how to use Amazon Data Lifecycle Manager to manage the backups of your EBS volumes using the AWS CLI .
This example uses a resource type of VOLUME to create snapshots of all volumes with the speciﬁed target tags .
To create snapshots of all volumes for all instances with the speciﬁed target tags , use a resource type of INSTANCE instead .
It includes the information that you speciﬁed , plus metadata inserted by AWS .
You can see that the state , the value of the tag , the snapshot interval , and the snapshot start time were changed .
Delete a Lifecycle Policy Use the delete-lifecycle-policy command to delete a lifecycle policy and free up the target tags speciﬁed in the policy for reuse .
aws dlm delete-lifecycle-policy -- policy-id policy-0123456789abcdef0 Manage Backups Using the API The Amazon Data Lifecycle Manager API Reference provides descriptions and syntax for each of the actions and data types for the Amazon Data Lifecycle Manager Query API .
Alternatively , you can use one of the AWS SDKs to access the API in a way that 's tailored to the programming language or platform that you 're using .
Monitor the Snapshot Lifecycle You can use the following features to monitor the lifecycle of your snapshots .
You can ﬁlter snapshots using tags to verify that your backups are being created as you intend .
CloudWatch Events Amazon EBS and Amazon Data Lifecycle Manager emit events related to lifecycle policy actions .
You can use AWS Lambda and Amazon CloudWatch Events to handle event notiﬁcations programmatically .
For more information , see the Amazon CloudWatch Events User Guide .
• DLM Policy State Change—A Amazon Data Lifecycle Manager event emitted when a lifecycle policy enters an error state .
The event contains a description of what caused the error .
For more information , see the AWS CloudTrail User Guide .
Amazon EBS data services Amazon EBS provides the following data services .
If your instance supports Elastic Volumes , you can do so without detaching the volume or restarting the instance .
This enables you to continue using your application while the changes take eﬀect .
There is no charge to modify the conﬁguration of a volume .
You are charged for the new volume conﬁguration after volume modiﬁcation starts .
For more information , see the Amazon EBS Pricing page .
To learn more about the general requirements for EBS volumes , see Constraints on the Size and Conﬁguration of an EBS Volume ( p. 943 ) .
999 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS data services Requirements for Linux volumes Linux AMIs require a GUID partition table ( GPT ) and GRUB 2 for boot volumes that are 2 TiB ( 2,048 GiB ) or larger .
Many Linux AMIs today still use the MBR partitioning scheme , which only supports boot volume sizes up to 2 TiB .
If your instance does not boot with a boot volume larger than 2 TiB , the AMI you are using may be limited to a boot volume size of less than 2 TiB .
Non-boot volumes do not have this limitation on Linux instances .
For requirements aﬀecting Windows volumes , see Requirements for Windows Volumes in the Amazon EC2 User Guide for Windows Instances .
• The new volume size can not exceed the supported volume capacity .
If detached and modiﬁed to st1 or sc1 , it can not be attached to an instance as the root volume .
• In some cases , you must detach the volume or stop the instance for modiﬁcation to proceed .
If you encounter an error message while attempting to modify an EBS volume , or if you are modifying an EBS volume attached to a previous-generation instance type , take one of the following steps : 1000 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS data services • For a non-root volume , detach the volume from the instance , apply the modiﬁcations , and then reattach the volume .
• After provisioning over 32,000 IOPS on an existing io1 volume , you may need to do one of the following to see the full performance improvements : • Detach and attach the volume .
• Decreasing the size of an EBS volume is not supported .
However , you can create a smaller volume and then migrate your data to it using an application-level tool such as rsync .
• Modiﬁcation time is increased if you modify a volume that has not been fully initialized .
• After modifying a volume , wait at least six hours and ensure that the volume is in the in-use or available state before making additional modiﬁcations to the same volume .
Requesting modiﬁcations to your EBS Volumes With Elastic Volumes , you can dynamically modify the size , performance , and volume type of your Amazon EBS volumes without detaching them .
( Optional ) Before modifying a volume that contains valuable data , it is a best practice to create a snapshot of the volume in case you need to roll back your changes .
Monitor the progress of the volume modiﬁcation .
If the size of the volume was modiﬁed , extend the volume 's ﬁle system to take advantage of the increased storage capacity .
The Modify Volume window displays the volume ID and the volume 's current conﬁguration , including type , size , and IOPS .
You can change any or all of these settings in a single action .
Set new conﬁguration values as follows : 1001 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS data services • To modify the type , choose a value for Volume Type .
After you have ﬁnished changing the volume settings , choose Modify .
Modifying volume size has no practical eﬀect until you also extend the volume 's ﬁle system to make use of the new storage capacity .
Modifying an EBS volume using Elastic Volumes ( AWS CLI ) Use the modify-volume command to modify one or more conﬁguration settings for a volume .
Initializing Elastic Volumes support ( if needed ) Before you can modify a volume that was attached to an instance before November 3 , 2016 23:40 UTC , you must initialize volume modiﬁcation support using one of the following actions : • Detach and attach the volume • Stop and start the instance Use one of the following procedures to determine whether your instances are ready for volume modiﬁcation .
To determine whether your instances are ready using the console 1 .
1002 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS data services 2 .
Select the Launch Time and Block Devices attributes and then choose Close .
Sort the list of instances by the Launch Time column .
For instances that were started before the cutoﬀ date , check when the devices were attached .
In the following example , you must initialize volume modiﬁcation for the ﬁrst instance because it was started before the cutoﬀ date and its root volume was attached before the cutoﬀ date .
The other instances are ready because they were started after the cutoﬀ date .
To determine whether your instances are ready using the CLI Use the following describe-instances command to determine whether the volume was attached before November 3 , 2016 23:40 UTC .
The ﬁrst line is followed by one or more lines that show whether each EBS volume was attached before the cutoﬀ date ( True or False ) .
In the following example output , you must initialize volume modiﬁcation for the ﬁrst instance because it was started before the cutoﬀ date and its root volume was attached before the cutoﬀ date .
The other instances are ready because they were started after the cutoﬀ date .
i-e905622e True i-719f99a8 True i-006b02c1b78381e57 False False i-e3d172ed True True False False False Modifying an EBS volume if Elastic Volumes is not supported If you are using a supported instance type , you can use Elastic Volumes to dynamically modify the size , performance , and volume type of your Amazon EBS volumes without detaching them .
If you can not use Elastic Volumes but you need to modify the root ( boot ) volume , you must stop the instance , modify the volume , and then restart the instance .
After the instance has started , you can check the ﬁle system size to see if your instance recognizes the larger volume space .
On Linux , use the df -h command to check the ﬁle system size .
Monitoring the progress of volume modiﬁcations When you modify an EBS volume , it goes through a sequence of states .
The volume enters the modifying state , the optimizing state , and ﬁnally the completed state .
At this point , the volume is ready to be further modiﬁed .
This is not an indication of volume health ; it merely indicates that the modiﬁcation to the volume failed .
While the volume is in the optimizing state , your volume performance is in between the source and target conﬁguration speciﬁcations .
Transitional volume performance will be no less than the source volume performance .
If you are downgrading IOPS , transitional volume performance is no less than the target volume performance .
Volume modiﬁcation changes take eﬀect as follows : • Size changes usually take a few seconds to complete and take eﬀect after a volume is in the Optimizing state .
• Performance ( IOPS ) changes can take from a few minutes to a few hours to complete and are dependent on the conﬁguration change being made .
• It may take up to 24 hours for a new conﬁguration to take eﬀect , and in some cases more , such as when the volume has not been fully initialized .
Use one of the following methods to monitor the progress of a volume modiﬁcation .
The volume modiﬁcation state is displayed in the State column and in the State ﬁeld in the details pane .
The next volume in the list has a state of modifying .
Choose the text in the State ﬁeld to display before and after information about the most recent modiﬁcation action , as shown in this screenshot .
1004 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS data services Monitoring the progress of a volume modiﬁcation ( AWS CLI ) Use the describe-volumes-modiﬁcations command to view the progress of one or more volume modiﬁcations .
The following example describes the volume modiﬁcations for two volumes .
You can use your rule to generate a notiﬁcation message using Amazon SNS or to invoke a Lambda function in response to matching events .
For Build event pattern to match events by service , choose Custom event pattern .
For Build custom event pattern , replace the contents with the following and choose Save .
You can resize the ﬁle system as soon as the volume enters the optimizing state .
Important Before extending a ﬁle system that contains valuable data , it is best practice to create a snapshot of the volume , in case you need to roll back your changes .
If your Linux AMI uses the MBR partitioning scheme , you are limited to a boot volume size of up to 2 TiB .
For information about extending a Windows ﬁle system , see Extending a Windows File System after Resizing a Volume in the Amazon EC2 User Guide for Windows Instances .
For the following tasks , suppose that you have resized the boot volume of an instance from 8 GB to 16 GB and an additional volume from 8 GB to 30 GB .
Example : File systems on an instance built on the Nitro System The following example shows an instance built on the Nitro System ( p. 188 ) that has a boot volume with an XFS ﬁle system and an additional volume with an XFS ﬁle system .
Example : File systems on a T2 instance The following example shows a T2 instance that has a boot volume with an ext4 ﬁle system and an additional volume with an XFS ﬁle system .
1007 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS data services /dev/xvdf : SGI XFS filesystem data .
Increasing the size of a volume does not increase the size of the partition .
Before you extend the ﬁle system on a resized volume , check whether the volume has a partition that must be extended to the new size of the volume .
Use the lsblk command to display information about the block devices attached to your instance .
If a resized volume has a partition and the partition does not reﬂect the new size of the volume , use the growpart command to extend the partition .
While the size of the root volume reﬂects the new size , 16 GB , the size of the partition reﬂects the original size , 8 GB , and must be extended before you can extend the ﬁle system .
To extend the partition on the root volume , use the following growpart command .
Notice that there is a space between the device name and the partition number .
While the size of the volume is 16 GB , the size of the partition is still 8 GB and must be extended .
While the size of the volume is 30G , the size of the partition is still 8 GB and must be extended .
1008 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS data services To extend the partition on each volume , use the following growpart commands .
Note that there is a space between the device name and the partition number .
For a ﬁle system other than the examples shown here , refer to the documentation for the ﬁle system for instructions .
1009 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS data services [ ec2-user ~ ] $ sudo yum install xfsprogs Use the xfs_growfs command to extend the ﬁle system on each volume .
It uses AWS Key Management Service ( AWS KMS ) customer master keys ( CMK ) when creating encrypted volumes and snapshots .
Encryption operations occur on the servers that host EC2 instances , ensuring the security of both dataat-rest and data-in-transit between an instance and its attached EBS storage .
When you create an encrypted EBS volume and attach it to a supported instance type , the following types of data are encrypted : • Data at rest inside the volume • All data moving between the volume and the instance • All snapshots created from the volume • All volumes created from those snapshots EBS encrypts your volume with a data key using the industry-standard AES-256 algorithm .
Your data key is stored on-disk with your encrypted data , but not before EBS encrypts it with your CMK .
Your data key never appears on disk in plaintext .
The same data key is shared by snapshots of the volume and any subsequent volumes created from those snapshots .
For more information , see Data Keys in the AWS Key Management Service Developer Guide .
Amazon EBS works with AWS KMS to encrypt and decrypt your EBS volumes as follows : 1010 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS data services 1 .
Amazon EBS sends a CreateGrant request to AWS KMS , so that it can decrypt the data key .
Amazon EBS sends a GenerateDataKeyWithoutPlaintext request to AWS KMS , specifying the CMK to use to encrypt the volume .
AWS KMS generates a new data key , encrypts it under the speciﬁed CMK , and sends the encrypted data key to Amazon EBS to be stored with the volume metadata .
When you attach an encrypted volume to an instance , Amazon EC2 sends a Decrypt request to AWS KMS , specifying the encrypted data key .
AWS KMS decrypts the encrypted data key and sends the decrypted data key to Amazon EC2 .
Amazon EC2 uses the plaintext data key in hypervisor memory to encrypt disk I/O to the volume .
The plaintext data key persists in memory as long as the volume is attached to the instance .
For more information , see How Amazon Elastic Block Store ( Amazon EBS ) Uses AWS KMS and AWS KMS Log File Entries in the AWS Key Management Service Developer Guide .
Requirements Before you begin , verify that the following requirements are met .
Supported volume types Encryption is supported by all EBS volume types .
You can expect the same IOPS performance on encrypted volumes as on unencrypted volumes , with a minimal eﬀect on latency .
You can access encrypted volumes the same way that you access unencrypted volumes .
Encryption and decryption are handled transparently , and they require no additional action from you or your applications .
Supported instance types Amazon EBS encryption is available on the instance types listed below .
You can attach both encrypted and unencrypted volumes to these instance types simultaneously .
Default key for EBS encryption Amazon EBS automatically creates a unique AWS managed CMK in each Region where you store AWS resources .
By default , Amazon EBS uses this key for encryption .
Alternatively , you can specify a symmetric customer managed CMK that you created as the default key for EBS encryption .
Using your own CMK gives you more ﬂexibility , including the ability to create , rotate , and disable keys .
Important Amazon EBS does not support asymmetric CMKs .
For more information , see Using Symmetric and Asymmetric Keys in the AWS Key Management Service Developer Guide .
Choose Change the default key and then choose an available key .
Encryption by default You can conﬁgure your AWS account to enforce the encryption of the new EBS volumes and snapshot copies that you create .
For example , Amazon EBS encrypts the EBS volumes created when you launch an instance and the snapshots that you copy from an unencrypted snapshot .
Encryption by default has no eﬀect on existing EBS volumes or snapshots .
If you enable it for a Region , you can not disable it for individual volumes or snapshots in that Region .
• When you enable encryption by default , you can launch an instance only if the instance type supports EBS encryption .
If encryption by default is already on and you are experiencing delta replication failures , turn oﬀ encryption by default .
Instead , enable AMI encryption when you create the replication job .
1012 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS data services To enable encryption by default for a Region 1 .
Under EBS Storage , select Always encrypt new EBS volumes .
You can not change the CMK that is associated with an existing snapshot or encrypted volume .
However , you can associate a diﬀerent CMK during a snapshot copy operation so that the resulting copied snapshot is encrypted by the new CMK .
Encrypting EBS resources You encrypt EBS volumes by enabling encryption , either using encryption by default ( p. 1012 ) or by enabling encryption when you create a volume that you want to encrypt .
When you encrypt a volume , you can specify the symmetric CMK to use to encrypt the volume .
If you do not specify a CMK , the key that is used for encryption depends on the encryption state of the source snapshot and its ownership .
You can not change the CMK that is associated with an existing snapshot or volume .
However , you can associate a diﬀerent CMK during a snapshot copy operation so that the resulting copied snapshot is encrypted by the new CMK .
Encrypting an empty volume on creation When you create a new , empty EBS volume , you can encrypt it by enabling encryption for the speciﬁc volume creation operation .
If you enabled EBS encryption by default , the volume is automatically encrypted .
By default , the volume is encrypted to your default key for EBS encryption .
Alternatively , you can specify a diﬀerent symmetric CMK for the speciﬁc volume creation operation .
The volume is encrypted by the time it is ﬁrst available , so your data is always secured .
By default , the CMK that you selected when creating a volume encrypts the snapshots that you make from the volume and the volumes that you restore from those encrypted snapshots .
You can not remove encryption from an encrypted volume or snapshot , which means that a volume restored from an encrypted snapshot , or a copy of an encrypted snapshot , is always encrypted .
Public snapshots of encrypted volumes are not supported , but you can share an encrypted snapshot with speciﬁc accounts .
Encrypting unencrypted resources Although there is no direct way to encrypt an existing unencrypted volume or snapshot , you can encrypt them by creating either a volume or a snapshot .
If you enabled encryption by default , Amazon EBS encrypts the resulting new volume or snapshot using your default key for EBS encryption .
Even if you have not enabled encryption by default , you can enable encryption when you create an individual volume or snapshot .
Whether you enable encryption by default or in individual creation operations , you can override the default key for EBS encryption and select a symmetric customer managed CMK .
1013 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS data services Important Amazon EBS does not support asymmetric CMKs .
For more information , see Using Symmetric and Asymmetric Kyes in the AWS Key Management Service Developer Guide .
You can also apply new encryption states when launching an instance from an EBS-backed AMI .
This is because EBS-backed AMIs include snapshots of EBS volumes that can be encrypted as described .
Encryption scenarios When you create an encrypted EBS resource , it is encrypted by your account 's default key for EBS encryption unless you specify a diﬀerent customer managed CMK in the volume creation parameters or the block device mapping for the AMI or instance .
The following examples illustrate how you can manage the encryption state of your volumes and snapshots .
However , you can encrypt the resulting volume by setting the Encrypted parameter and , optionally , the KmsKeyId parameter .
The following diagram illustrates the process .
1014 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS data services If you leave out the KmsKeyId parameter , the resulting volume is encrypted using your default key for EBS encryption .
You must specify a key ID to encrypt the volume to a diﬀerent CMK .
Restore an unencrypted volume ( encryption by default enabled ) When you have enabled encryption by default , encryption is mandatory for volumes restored from unencrypted snapshots , and no encryption parameters are required for your default CMK to be used .
The following diagram shows this simple default case : If you want to encrypt the restored volume to a symmetric customer managed CMK , you must supply both the Encrypted and KmsKeyId parameters as shown in Restore an unencrypted volume ( encryption by default not enabled ) ( p. 1014 ) .
Copy an unencrypted snapshot ( encryption by default not enabled ) Without encryption by default enabled , a copy of an unencrypted snapshot is unencrypted by default .
However , you can encrypt the resulting snapshot by setting the Encrypted parameter and , optionally , the KmsKeyId parameter .
If you omit KmsKeyId , the resulting snapshot is encrypted by your default CMK .
You must specify a key ID to encrypt the volume to a diﬀerent symmetric CMK .
The following diagram illustrates the process .
1015 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS data services Note If you copy a snapshot and encrypt it to a new CMK , a complete ( non-incremental ) copy is always created , resulting in additional delay and storage costs .
You can encrypt an EBS volume by copying an unencrypted snapshot to an encrypted snapshot and then creating a volume from the encrypted snapshot .
Copy an unencrypted snapshot ( encryption by default enabled ) When you have enabled encryption by default , encryption is mandatory for copies of unencrypted snapshots , and no encryption parameters are required if your default CMK is used .
1016 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS data services Re-encrypt an encrypted volume When the CreateVolume action operates on an encrypted snapshot , you have the option of reencrypting it with a diﬀerent CMK .
The following diagram illustrates the process .
Re-encrypt an encrypted snapshot The ability to encrypt a snapshot during copying allows you to apply a new symmetric CMK to an already-encrypted snapshot that you own .
Volumes restored from the resulting copy are only accessible using the new CMK .
The following diagram illustrates the process .
1017 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS data services Note If you copy a snapshot and encrypt it to a new CMK , a complete ( non-incremental ) copy is always created , resulting in additional delay and storage costs .
In a related scenario , you can choose to apply new encryption parameters to a copy of a snapshot that has been shared with you .
However , we recommend that you create a copy of the shared snapshot using a diﬀerent CMK that you control .
This protects your access to the volume if the original CMK is compromised , or if the owner revokes the CMK for any reason .
Migrate data between encrypted and unencrypted volumes When you have access to both an encrypted and unencrypted volume , you can freely transfer data between them .
For example , use the rsync command to copy the data .
In the following command , the source data is located in /mnt/source and the destination volume is mounted at /mnt/destination .
Source of volume Default ( no CMK speciﬁed ) Custom ( CMK speciﬁed ) No No New ( empty ) volume Unencrypted N/A No No Unencrypted snapshot that you own Unencrypted No No Encrypted snapshot that you own Encrypted by same key No No Unencrypted snapshot that is shared with you Unencrypted 1018 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS data services Is encryption enabled ?
Source of volume Default ( no CMK speciﬁed ) No No Encrypted snapshot that is Encrypted by shared with you default CMK* Yes No New volume Encrypted by default CMK Yes No Unencrypted snapshot that you own Encrypted by default CMK Yes No Encrypted snapshot that you own Encrypted by same key Yes No Unencrypted snapshot that is shared with you Encrypted by default CMK Yes No Encrypted snapshot that is Encrypted by shared with you default CMK No Yes New ( empty ) volume Encrypted by default CMK No Yes Unencrypted snapshot that you own Encrypted by default CMK No Yes Encrypted snapshot that you own Encrypted by same key No Yes Unencrypted snapshot that is shared with you Encrypted by default CMK No Yes Encrypted snapshot that is Encrypted by shared with you default CMK Yes Yes New volume Encrypted by default CMK Yes Yes Unencrypted snapshot that you own Encrypted by default CMK Yes Yes Encrypted snapshot that you own Encrypted by same key Yes Yes Unencrypted snapshot that is shared with you Encrypted by default CMK Yes Yes Encrypted snapshot that is Encrypted by shared with you default CMK Custom ( CMK speciﬁed ) Encrypted by a speciﬁed CMK** N/A Encrypted by a speciﬁed CMK * This is the default CMK used for EBS encryption for the AWS account and Region .
By default this is a unique AWS managed CMK for EBS , or you can specify a customer managed CMK .
** This is a customer managed CMK speciﬁed for the volume at launch time .
This CMK is used instead of the default CMK for the AWS account and Region .
1019 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS data services Setting encryption defaults using the API and CLI You can manage encryption by default and the default customer master key ( CMK ) using the following API actions and CLI commands .
API action CLI command Description DisableEbsEncryptionByDefault disable-ebs-encryption-by-default Disables encryption by default .
ModifyEbsDefaultKmsKeyId modify-ebs-default-kms-key-id Changes the default CMK used to encrypt EBS volumes .
ResetEbsDefaultKmsKeyId reset-ebs-default-kms-key-id Resets the AWS managed default CMK as the default CMK used to encrypt EBS volumes .
Amazon EBS fast snapshot restore Amazon EBS fast snapshot restore enables you to create a volume from a snapshot that is fullyinitialized at creation .
This eliminates the latency of I/O operations on a block when it is accessed for the ﬁrst time .
Volumes created using fast snapshot restore instantly deliver all of their provisioned performance .
To get started , enable fast snapshot restore for speciﬁc snapshots in speciﬁc Availability Zones .
Each snapshot and Availability Zone pair refers to one fast snapshot restore .
You can enable up to 50 fast snapshot restores per Region .
When you create a volume from one of these snapshots in one of its enabled Availability Zones , the volume is restored using fast snapshot restore .
1020 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS data services • optimizing — Fast snapshot restore is being enabled .
You can enable fast snapshot restore again as needed .
Volume creation credits The number of volumes that receive the full performance beneﬁt of fast snapshot restore is determined by the volume creation credits for the snapshot .
There is one credit bucket per snapshot per Availability Zone .
Each volume that you create from a snapshot with fast snapshot restore enabled consumes one credit from the credit bucket .
The size of a credit bucket depends on the size of the snapshot , not the size of the volumes created from the snapshot .
When the credit bucket is full , you can create 10 initialized volumes from this snapshot simultaneously .
You can use Cloudwatch metrics to monitor the size of your credit buckets and the number of credits available in each bucket .
After you create a volume from a snapshot with fast snapshot restore enabled , you can describe the volume using describe-volumes and check the fastRestored ﬁeld in the output to determine whether the volume was created as an initialized volume using fast snapshot restore .
Managing fast snapshot restore Use the following procedure to enable fast snapshot restore for a snapshot .
You can not enable fast snapshot restore on a snapshot that was shared with you .
Select or deselect Availability Zones , and then choose Save .
To track the state of fast snapshot restore as it is enabled , see Fast Snapshot Restore on the Description tab .
To manage fast snapshot restore using the AWS CLI • enable-fast-snapshot-restores 1021 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS data services • disable-fast-snapshot-restores • describe-fast-snapshot-restores View snapshots with fast snapshot restore enabled Use the following procedure to view the state of fast snapshot restore for a snapshot .
To view the state of fast snapshot restore using the console 1 .
On the Description tab , see Fast Snapshot Restore , which indicates the state of fast snapshot restore .
To view snapshots with fast snapshot restore enabled using the AWS CLI Use the describe-fast-snapshot-restores command to describe the snapshots that are enabled for fast snapshot restore .
Use the describe-volumes command to view volumes that were created from a snapshot that is enabled for fast snapshot restore .
The block device driver can assign NVMe device names in a diﬀerent order than you speciﬁed for the volumes in the block device mapping .
The EBS performance guarantees stated in Amazon EBS Product Details are valid regardless of the blockdevice interface .
Instances can support NVMe EBS volumes , NVMe instance store volumes , both types of NVMe volumes , or no NVMe volumes .
Conﬁrm that your instance has the NVMe driver You can conﬁrm that your instance has the NVMe driver and check the driver version using the following command .
$ modinfo nvme If the instance has the NVMe driver , the command returns information about the driver .
Update the NVMe driver If your instance has the NVMe driver , you can update the driver to the latest version using the following procedure .
Update your package cache to get necessary package updates as follows .
Reboot your instance to load the latest kernel version .
Reconnect to your instance after it has rebooted .
These devices rely on standard NVMe drivers on the operating system .
These drivers typically discover attached devices by scanning the PCI bus during instance boot , and create device nodes based on the order in which the devices respond , not on how the devices are speciﬁed in the block device mapping .
Occasionally , devices can 1024 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Volumes and NVMe respond to discovery in a diﬀerent order in subsequent instance starts , which causes the device name to change .
We recommend that you use stable identiﬁers for your EBS volumes within your instance , such as one of the following : • For Nitro-based instances , the block device mappings that are speciﬁed in the Amazon EC2 console when you are attaching an EBS volume or during AttachVolume or RunInstances API calls are captured in the vendor-speciﬁc data ﬁeld of the NVMe controller identiﬁcation .
With Amazon Linux AMIs later than version 2017.09.01 , we provide a udev rule that reads this data and creates a symbolic link to the block-device mapping .
• NVMe EBS volumes have the EBS volume ID set as the serial number in the device identiﬁcation .
A device label can be speciﬁed at the same time .
Other Linux AMIs With a kernel version of 4.2 or later , you can run the nvme id-ctrl command as follows to map an NVMe device to a volume ID .
For download and installation instructions for other distributions , refer to the documentation speciﬁc to your distribution .
The following example gets the volume ID and device name .
The lsblk command lists available devices and their mount points ( if applicable ) .
This helps you determine the correct device name to use .
In this example , /dev/nvme0n1p1 is mounted as the root device and /dev/nvme1n1 is attached but not mounted .
If you are using Linux kernel 4.2 or later , any change you make to the volume size of an NVMe EBS volume is automatically reﬂected in the instance .
For older Linux kernels , you might need to detach and attach the EBS volume or reboot the instance for the size change to be reﬂected .
With Linux kernel 3.19 or later , you can use the hdparm command as follows to force a rescan of the NVMe device : [ ec2-user ~ ] $ sudo hdparm -z /dev/nvme1n1 When you detach an NVMe EBS volume , the instance does not have an opportunity to ﬂush the ﬁle system caches or metadata before detaching the volume .
Therefore , before you detach an NVMe EBS volume , you should ﬁrst sync and unmount it .
I/O Operation Timeout EBS volumes attached to Nitro-based instances use the default NVMe driver provided by the operating system .
The default timeout is 30 seconds and can be changed using the nvme_core.io_timeout boot parameter .
If I/O latency exceeds the value of this timeout parameter , the Linux NVMe driver fails the I/O and returns an error to the ﬁlesystem or application .
Depending on the I/O operation , your ﬁlesystem or application can retry the error .
For an experience similar to EBS volumes attached to Xen instances , we recommend setting nvme_core.io_timeout to the highest value possible .
Depending on the version of Linux , the timeout might already be set to the supported maximum value .
For example , the timeout is set to 4294967295 by default for Amazon Linux AMI 2017.09.01 and later .
You can verify the maximum value for your Linux distribution by writing a value higher than the suggested maximum to /sys/module/nvme_core/parameters/io_timeout and checking for the Numerical result out of range error when attempting to save the ﬁle .
Amazon EBS–optimized instances An Amazon EBS–optimized instance uses an optimized conﬁguration stack and provides additional , dedicated capacity for Amazon EBS I/O .
This optimization provides the best performance for your EBS volumes by minimizing contention between Amazon EBS I/O and other traﬃc from your instance .
They include the dedicated bandwidth to Amazon EBS , the typical maximum aggregate throughput that can be achieved on that connection with a streaming read workload and 128 KiB I/O size , and the maximum IOPS the instance can support if you are using a 16 KiB I/O size .
Choose an EBS–optimized instance that provides more dedicated Amazon EBS throughput than your application needs ; otherwise , the connection between Amazon EBS and Amazon EC2 can become a performance bottleneck .
EBS optimized by default The following table lists the instance types that support EBS optimization and EBS optimization is enabled by default .
There is no need to enable EBS optimization and no eﬀect if you disable EBS optimization .
If you have a workload that requires sustained maximum performance for longer than 30 minutes , select an instance type according to baseline performance as shown in the following table .
You can enable EBS optimization when you launch these instances or after they are running .
Instances must have EBS optimization enabled to achieve the level of performance described .
When you enable EBS optimization for an instance that is not EBS-optimized by default , you pay an additional low , hourly fee for the dedicated capacity .
On these instances , network traﬃc and Amazon EBS traﬃc share the same 10-gigabit network interface .
You can use the EBSIOBalance % and EBSByteBalance % metrics to help you determine whether your instances are sized correctly .
You can view these metrics in the CloudWatch console and set an alarm that is triggered based on a threshold you specify .
Instances with a consistently low balance percentage are candidates for upsizing .
Instances where the balance percentage never drops below 100 % are candidates for downsizing .
Enabling EBS optimization at launch You can enable optimization for an instance by setting its attribute for EBS optimization .
To enable Amazon EBS optimization when launching an instance using the console 1 .
In Step 2 : Choose an Instance Type , select an instance type that is listed as supporting Amazon EBS optimization .
If the instance type that you selected in the previous step does n't support Amazon EBS optimization , this option is not present .
If the instance type that you selected is Amazon EBS–optimized by default , this option is selected and you ca n't deselect it .
Follow the directions to complete the wizard and launch your instance .
1038 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Performance To enable EBS optimization when launching an instance using the command line You can use one of the following commands with the corresponding option .
If the instance is running , you must stop it ﬁrst .
Warning When you stop an instance , the data on any instance store volumes is erased .
To keep data from instance store volumes , be sure to back it up to persistent storage .
To enable EBS optimization for an existing instance using the console 1 .
It can take a few minutes for the instance to stop .
In the Change Instance Type dialog box , do one of the following : • If the instance type of your instance is Amazon EBS–optimized by default , EBS-optimized is selected and you ca n't change it .
You can choose Cancel , because Amazon EBS optimization is already enabled for the instance .
You can select an instance type from Instance Type that supports Amazon EBS optimization , and then choose EBS-optimized , Apply .
To enable EBS optimization for an existing instance using the command line 1 .
Customers who follow the guidance on our Amazon EBS and Amazon EC2 product detail pages typically achieve good performance out of the box .
However , there are some cases where you may need to do some tuning in order to achieve peak performance on 1039 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Performance the platform .
This topic discusses general best practices as well as performance tuning that is speciﬁc to certain use cases .
We recommend that you tune performance with information from your actual workload , in addition to benchmarking , to determine your optimal conﬁguration .
After you learn the basics of working with EBS volumes , it 's a good idea to look at the I/O performance you require and at your options for increasing Amazon EBS performance to meet those requirements .
AWS updates to the performance of EBS volume types might not immediately take eﬀect on your existing volumes .
To see full performance on an older volume , you might ﬁrst need to perform a ModifyVolume action on it .
For more information , see Modifying the Size , IOPS , or Type of an EBS Volume on Linux .
Use EBS-Optimized Instances On instances without support for EBS-optimized throughput , network traﬃc can contend with traﬃc between your instance and your EBS volumes ; on EBS-optimized instances , the two types of traﬃc are kept separate .
Understand How Performance is Calculated When you measure the performance of your EBS volumes , it is important to understand the units of measure involved and how performance is calculated .
Understand Your Workload There is a relationship between the maximum performance of your EBS volumes , the size and number of I/O operations , and the time it takes for each action to complete .
Be Aware of the Performance Penalty When Initializing Volumes from Snapshots There is a signiﬁcant increase in latency when you ﬁrst access each block of data on a new EBS volume that was restored from a snapshot .
You can avoid this performance hit using one of the following options : • Access each block prior to putting the volume into production .
• Enable fast snapshot restore on a snapshot to ensure that the EBS volumes created from it are fullyinitialized at creation and instantly deliver all of their provisioned performance .
1040 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Performance Factors That Can Degrade HDD Performance When you create a snapshot of a Throughput Optimized HDD ( st1 ) or Cold HDD ( sc1 ) volume , performance may drop as far as the volume 's baseline value while the snapshot is in progress .
This behavior is speciﬁc to these volume types .
Other factors that can limit performance include driving more throughput than the instance can support , the performance penalty encountered while initializing volumes restored from a snapshot , and excessive amounts of small , random I/O on the volume .
The queue length is the number of pending I/O requests from your application to your volume .
This is a per-block-device setting that should only be applied to your HDD volumes .
Use a Modern Linux Kernel Use a modern Linux kernel with support for indirect descriptors .
If your average I/O size is at or near 44 KiB , you may be using an instance or kernel without support for indirect descriptors .
The appropriate parameter can be set in your OS boot command line .
Other Linux distributions , especially those that do not use the GRUB boot loader , may require a diﬀerent approach to adjusting the kernel parameters .
For more information about EBS I/O characteristics , see the Amazon EBS : Designing for Performance re : Invent presentation on this topic .
Use RAID 0 to Maximize Utilization of Instance Resources Some instance types can drive more I/O throughput than what you can provision for a single EBS volume .
Track Performance Using Amazon CloudWatch Amazon Web Services provides performance metrics for Amazon EBS that you can analyze and view with Amazon CloudWatch and status checks that you can use to monitor the health of your volumes .
To understand how SSD and HDD volumes will perform in your application , it is important to know the connection between demand on the volume , the quantity of IOPS available to it , the time it takes for an I/O operation to complete , and the volume 's throughput limits .
The operations are measured in KiB , and the underlying drive technology determines the maximum amount of data that a volume type counts as a single I/O .
I/O size is capped at 256 KiB for SSD volumes and 1,024 KiB for HDD volumes because SSD volumes handle small or random I/O much more eﬃciently than HDD volumes .
When small I/O operations are physically contiguous , Amazon EBS attempts to merge them into a single I/O operation up to the maximum size .
Volume Queue Length and Latency The volume queue length is the number of pending I/O requests for a device .
Latency is the true end-toend client time of an I/O operation , in other words , the time elapsed between sending an I/O to EBS and receiving an acknowledgement from EBS that the I/O read or write is complete .
Queue length must be correctly calibrated with I/O size and latency to avoid creating bottlenecks either on the guest operating system or on the network link to EBS .
Optimal queue length varies for each workload , depending on your particular application 's sensitivity to IOPS and latency .
If your workload is not delivering enough I/O requests to fully use the performance available to your EBS volume , then your volume might not deliver the IOPS or throughput that you have provisioned .
You can maintain high IOPS while keeping latency down by maintaining a low queue length and a high number of IOPS available to the volume .
Consistently driving more IOPS to a volume than it has available can cause increased I/O latency .
I/O size and volume throughput limits For SSD-backed volumes , if your I/O size is very large , you may experience a smaller number of IOPS than you provisioned because you are hitting the throughput limit of the volume .
This happens when the instance operating system merges small I/O operations into a larger operation before passing them to Amazon EBS .
If your workload uses small or random I/Os , you may experience a lower throughput than you expect .
This is because we count each random , non-sequential I/O toward the total IOPS count , which can cause you to hit the volume 's IOPS limit sooner than expected .
Whatever your EBS volume type , if you are not experiencing the IOPS or throughput you expect in your conﬁguration , ensure that your EC2 instance bandwidth is not the limiting factor .
Another possible cause for not experiencing the expected IOPS is that you are not driving enough I/O to the EBS volumes .
Check the BurstBalance value to determine whether your volume is being throttled for this reason .
The same calculation applies to read operations .
Note If average I/O size is at or near 44 KiB , you may be using an instance or kernel without support for indirect descriptors .
Any Linux kernel 3.8 and above has this support , as well as any currentgeneration instance .
If your I/O latency is higher than you require , check VolumeQueueLength to make sure your application is not trying to drive more IOPS than you have provisioned .
If your application requires a greater number of IOPS than your volume can provide , you should consider using a larger gp2 volume with a higher base performance level or an io1 volume with more provisioned IOPS to achieve faster latencies .
For more information about Amazon EBS I/O characteristics , see the Amazon EBS : Designing for Performance re : Invent presentation on this topic .
Initializing Amazon EBS Volumes New EBS volumes receive their maximum performance the moment that they are available and do not require initialization ( formerly known as pre-warming ) .
For volumes that were restored from snapshots , the storage blocks must be pulled down from Amazon S3 and written to the volume before you can access them .
This preliminary action takes time and can cause a signiﬁcant increase in the latency of I/O operations the ﬁrst time each block is accessed .
Volume performance is achieved after all blocks have been downloaded and written to the volume .
Important While initializing io1 volumes that were restored from snapshots , the performance of the volume may drop below 50 percent of its expected level , which causes the volume to display a warning state in the I/O Performance status check .
This is expected , and you can ignore the warning state on io1 volumes while you are initializing them .
1044 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Performance For most applications , amortizing the initialization cost over the lifetime of the volume is acceptable .
To avoid this initial performance hit in a production environment , you can use one of the following options : • Force the immediate initialization of the entire volume .
• Enable fast snapshot restore on a snapshot to ensure that the EBS volumes created from it are fullyinitialized at creation and instantly deliver all of their provisioned performance .
Initializing Amazon EBS Volumes on Linux New EBS volumes receive their maximum performance the moment that they are available and do not require initialization ( formerly known as pre-warming ) .
For volumes that have been restored from snapshots , use the dd or ﬁo utilities to read from all of the blocks on a volume .
All existing data on the volume will be preserved .
Use the lsblk command to list the block devices on your instance .
Use the dd or ﬁo utilities to read all of the blocks on the device .
The dd command is installed by default on Linux systems , but ﬁo is considerably faster because it allows multi-threaded reads .
Note This step may take several minutes up to several hours , depending on your EC2 instance bandwidth , the IOPS provisioned for the volume , and the size of the volume .
The bs parameter sets the block size of the read operation ; for optimal performance , this should be set to 1 MB .
Be sure to follow precisely the example command below .
Only the if=/dev/xvdf parameter will vary depending on the name of the device you are reading .
The -- filename ( input ﬁle ) parameter should be set to the drive you wish to initialize .
Your volume is now ready for use .
RAID Conﬁguration on Linux With Amazon EBS , you can use any of the standard RAID conﬁgurations that you can use with a traditional bare metal server , as long as that particular RAID conﬁguration is supported by the operating system for your instance .
This is because all RAID is accomplished at the software level .
Amazon EBS volume data is replicated across multiple servers in an Availability Zone to prevent the loss of data from the failure of any single component .
This replication makes Amazon EBS volumes ten times more reliable than typical commodity disk drives .
For more information , see Amazon EBS Availability and Durability in the Amazon EBS product detail pages .
Grub is typically installed on only one device in a RAID array , and if one of the mirrored devices fails , you may be unable to boot the operating system .
If you need to create a RAID array on a Windows instance , see RAID Conﬁguration on Windows in the Amazon EC2 User Guide for Windows Instances .
Conﬁguration Use Advantages Disadvantages RAID 0 When I/O performance is more important than fault tolerance ; for example , as in a heavily used database ( where data replication is already set up separately ) .
If you add a volume , you get the straight addition of throughput and IOPS .
Performance of the stripe is limited to the worst performing volume in the set .
Loss of a single volume results in a complete data loss for the array .
Safer from the standpoint of data durability .
Does not provide a write performance improvement ; requires more Amazon EC2 to Amazon EBS bandwidth than non-RAID conﬁgurations because the 1046 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Performance Conﬁguration Use Advantages Disadvantages data is written to multiple volumes simultaneously .
Important RAID 5 and RAID 6 are not recommended for Amazon EBS because the parity write operations of these RAID modes consume some of the IOPS available to your volumes .
Creating a RAID 0 array allows you to achieve a higher level of performance for a ﬁle system than you can provision on a single Amazon EBS volume .
Before you perform this procedure , you need to decide how large your RAID array should be and how many IOPS you want to provision .
The resulting size of a RAID 0 array is the sum of the sizes of the volumes within it , and the bandwidth is the sum of the available bandwidth of the volumes within it .
The resulting size and bandwidth of a RAID 1 array is equal to the size and bandwidth of the volumes in the array .
This documentation provides basic RAID setup examples .
Creating a RAID Array on Linux Use the following procedure to create the RAID array .
Note that you can get directions for Windows instances from Creating a RAID Array on Windows in the Amazon EC2 User Guide for Windows Instances .
Create the Amazon EBS volumes for your array .
Create volumes with identical size and IOPS performance values for your array .
Make sure you do not create an array that exceeds the available bandwidth of your EC2 instance .
Attach the Amazon EBS volumes to the instance that you want to host the array .
Use the mdadm command to create a logical RAID device from the newly attached Amazon EBS volumes .
Substitute the number of volumes in your array for number_of_volumes and the device names for each volume in the array ( such as /dev/xvdf ) for device_name .
You can also substitute MY_RAID with your own unique name for the array .
Note You can list the devices on your instance with the lsblk command to ﬁnd the device names .
Allow time for the RAID array to initialize and synchronize .
To ensure that the RAID array is reassembled automatically on boot , create a conﬁguration ﬁle to contain the RAID information : 1048 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Performance [ ec2-user ~ ] $ sudo mdadm -- detail -- scan | sudo tee -a /etc/mdadm.conf Note If you are using a Linux distribution other than Amazon Linux , this ﬁle may need to be placed in diﬀerent location .
( Optional ) To mount this Amazon EBS volume on every system reboot , add an entry for the device to the /etc/fstab ﬁle .
Create a backup of your /etc/fstab ﬁle that you can use if you accidentally destroy or delete this ﬁle while you are editing it .
Open the /etc/fstab ﬁle using your favorite text editor , such as nano or vim .
c. Comment out any lines starting with `` UUID= '' and , at the end of the ﬁle , add a new line for your RAID volume using the following format : device_label mount_point file_system_type fs_mntops fs_freq fs_passno The last three ﬁelds on this line are the ﬁle system mount options , the dump frequency of the ﬁle system , and the order of ﬁle system checks done at boot time .
For more information about /etc/fstab entries , see the fstab manual page ( by entering man fstab on the command line ) .
Note If you ever intend to boot your instance without this volume attached ( for example , so this volume could move back and forth between diﬀerent instances ) , you should add the nofail mount option that allows the instance to boot even if there are errors in mounting the volume .
Debian derivatives , such as Ubuntu , must also add the nobootwait mount option .
1049 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Performance [ ec2-user ~ ] $ sudo mount -a If the previous command does not produce an error , then your /etc/fstab ﬁle is OK and your ﬁle system will mount automatically at the next boot .
If the command does produce any errors , examine the errors and try to correct your /etc/fstab .
This is because the snapshots of these volumes are created independently .
To restore EBS volumes in a RAID array from snapshots that are out of sync would degrade the integrity of the array .
You do not have to stop your instance to coordinate between volumes to ensure consistency because snapshots are automatically taken across multiple EBS volumes .
For more information , see the steps for creating multi-volume snapshots under Creating Amazon EBS Snapshots .
Benchmark EBS Volumes You can test the performance of Amazon EBS volumes by simulating I/O workloads .
Conﬁgure and mount the block device .
Delete your volumes and terminate your instance so that you do n't continue to incur charges .
Important Some of the procedures result in the destruction of existing data on the EBS volumes you benchmark .
The benchmarking procedures are intended for use on volumes specially created for testing purposes , not production volumes .
Set Up Your Instance To get optimal performance from EBS volumes , we recommend that you use an EBS-optimized instance .
EBS-optimized instances deliver dedicated bandwidth between Amazon EC2 and Amazon EBS , with speciﬁcations depending on the instance type .
1050 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Performance To create an EBS-optimized instance , choose Launch as an EBS-Optimized instance when launching the instance using the Amazon EC2 console , or specify -- ebs-optimized when using the command line .
Because you are charged by gigabytes provisioned ( and the number of provisioned IOPS for io1 volumes ) , not the number of volumes , there is no additional cost for creating multiple , smaller volumes and using them to create a stripe set .
If you 're using Oracle Orion to benchmark your volumes , it can simulate striping the same way that Oracle ASM does , so we recommend that you let Orion do the striping .
If you are using a diﬀerent benchmarking tool , you need to stripe the volumes yourself .
Use the ﬁle system that meets your requirements .
AWS provides a JSON template for use with AWS CloudFormation that simpliﬁes this setup procedure .
Access the template and save it as a JSON ﬁle .
AWS CloudFormation allows you to conﬁgure your own SSH keys and oﬀers an easier way to set up a performance test environment to evaluate st1 volumes .
Choose Upload a Template to Amazon S3 and select the JSON template you previously obtained .
After the status for your new stack moves from CREATE_IN_PROGRESS to COMPLETE , choose Outputs to get the public DNS entry for your new instance , which will have a 2 TiB st1 volume attached to it .
Connect using SSH to your new stack as user ec2-user , with the hostname obtained from the DNS entry in the previous step .
Install Benchmark Tools The following table lists some of the possible tools you can use to benchmark the performance of EBS volumes .
These benchmarking tools support a wide variety of test parameters .
You should use commands that approximate the workloads your volumes will support .
These commands provided below are intended as examples to help you get started .
Choosing the Volume Queue Length Choosing the best volume queue length based on your workload and volume type .
Queue Length on SSD-backed Volumes To determine the optimal queue length for your workload on SSD-backed volumes , we recommend that you target a queue length of 1 for every 1000 IOPS available ( baseline for gp2 volumes and the provisioned amount for io1 volumes ) .
Then you can monitor your application performance and tune that value based on your application requirements .
Increasing the queue length is beneﬁcial until you achieve the provisioned IOPS , throughput or optimal system queue length value , which is currently set to 32 .
You should experiment with tuning these values up or down to see what performs best for your application .
1052 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS Performance Queue Length on HDD-backed Volumes To determine the optimal queue length for your workload on HDD-backed volumes , we recommend that you target a queue length of at least 4 while performing 1MiB sequential I/Os .
Then you can monitor your application performance and tune that value based on your application requirements .
You should experiment with tuning these values value up or down to see what performs best for your application .
When the core is called on to resume processing , a certain amount of time passes until the core is again fully operational .
This latency can interfere with processor benchmarking routines .
Run the following commands on an EBS-optimized instance with attached EBS volumes .
If the EBS volumes were restored from snapshots , be sure to initialize them before benchmarking .
Benchmarking io1 Volumes Run ﬁo on the stripe set that you created .
To benchmark such a workload , we recommend that you use separate , simultaneous ﬁo jobs for reads and writes , and use the ﬁo offset_increment option to target diﬀerent block device locations for each job .
Multiple ﬁo jobs for direct I/O , even though using sequential read or write operations , can result in lower than expected throughput for st1 and sc1 volumes .
We recommend that you use one direct I/O job and use the iodepth parameter to control the number of concurrent I/O operations .
Amazon CloudWatch Metrics for Amazon EBS CloudWatch metrics are statistical data that you can use to view , analyze , and set alarms on the operational behavior of your volumes .
The following table describes the types of monitoring data available for your Amazon EBS volumes .
Type Description Basic Data is available automatically in 5-minute periods at no charge .
This includes data for the root device volumes for EBS-backed instances .
When you get data from CloudWatch , you can include a Period request parameter to specify the granularity of the returned data .
This is diﬀerent than the period that we use when we collect the data ( 5-minute periods ) .
We recommend that you specify a period in your request that is equal to or larger than the collection period to ensure that the returned data is valid .
You can get the data using either the CloudWatch API or the Amazon EC2 console .
The console takes the raw data from the CloudWatch API and displays a series of graphs based on the data .
Depending on your needs , you might prefer to use either the data from the API or the graphs in the console .
Amazon EBS Metrics Amazon Elastic Block Store ( Amazon EBS ) sends data points to CloudWatch for several metrics .
Data is only reported to CloudWatch when the volume is attached to an instance .
The Sum statistic reports the total number of bytes transferred during the period .
The Average statistic reports the average size of each read operation during the period , except on volumes attached to a Nitro-based instance , where the average represents the average over the speciﬁed period .
The SampleCount statistic reports the total number of read operations during the period , except on volumes attached to a Nitro-based instance , where the sample count represents the number of data points used in the statistical calculation .
For Xen instances , data is reported only when there is read activity on the volume .
The Minimum and Maximum statistics on this metric are supported only by volumes attached to Nitro-based instances .
Units : Bytes VolumeWriteBytes Provides information on the write operations in a speciﬁed period of time .
The Sum statistic reports the total number of bytes transferred during the period .
The Average statistic reports the average size of each write operation during the period , except on volumes attached to a Nitro-based instance , where the average represents the average over the speciﬁed period .
The SampleCount statistic reports the total number of write operations during the period , except on volumes attached to a Nitro-based instance , where the sample count represents the number of data points used in the statistical calculation .
For Xen instances , data is reported only when there is write activity on the volume .
The Minimum and Maximum statistics on this metric are supported only by volumes attached to Nitro-based instances .
Units : Bytes VolumeReadOps The total number of read operations in a speciﬁed period of time .
To calculate the average read operations per second ( read IOPS ) for the period , divide the total read operations in the period by the number of seconds in that period .
The Minimum and Maximum statistics on this metric are supported only by volumes attached to Nitro-based instances .
Units : Count VolumeWriteOps The total number of write operations in a speciﬁed period of time .
To calculate the average write operations per second ( write IOPS ) for the period , divide the total write operations in the period by the number of seconds in that period .
1056 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS CloudWatch Metrics Metric Description The Minimum and Maximum statistics on this metric are supported only by volumes attached to Nitro-based instances .
Units : Count VolumeTotalReadTime Note This metric is not supported with Multi-Attach enabled volumes .
The total number of seconds spent by all read operations that completed in a speciﬁed period of time .
If multiple requests are submitted at the same time , this total could be greater than the length of the period .
For Xen instances , data is reported only when there is read activity on the volume .
The Average statistic on this metric is not relevant for volumes attached to Nitro-based instances .
The Minimum and Maximum statistics on this metric are supported only by volumes attached to Nitro-based instances .
Units : Seconds VolumeTotalWriteTime Note This metric is not supported with Multi-Attach enabled volumes .
The total number of seconds spent by all write operations that completed in a speciﬁed period of time .
If multiple requests are submitted at the same time , this total could be greater than the length of the period .
For Xen instances , data is reported only when there is write activity on the volume .
The Average statistic on this metric is not relevant for volumes attached to Nitro-based instances .
The Minimum and Maximum statistics on this metric are supported only by volumes attached to Nitro-based instances .
Units : Seconds 1057 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS CloudWatch Metrics Metric VolumeIdleTime Description Note This metric is not supported with Multi-Attach enabled volumes .
The total number of seconds in a speciﬁed period of time when no read or write operations were submitted .
The Average statistic on this metric is not relevant for volumes attached to Nitro-based instances .
The Minimum and Maximum statistics on this metric are supported only by volumes attached to Nitro-based instances .
Units : Seconds VolumeQueueLength The number of read and write operation requests waiting to be completed in a speciﬁed period of time .
The Sum statistic on this metric is not relevant for volumes attached to Nitro-based instances .
The Minimum and Maximum statistics on this metric are supported only by volumes attached to Nitro-based instances .
Units : Count VolumeThroughputPercentage Note This metric is not supported with Multi-Attach enabled volumes .
Used with Provisioned IOPS SSD volumes only .
The percentage of I/O operations per second ( IOPS ) delivered of the total IOPS provisioned for an Amazon EBS volume .
Provisioned IOPS SSD volumes deliver their provisioned performance 99.9 percent of the time .
Units : Percent VolumeConsumedReadWriteOps Used with Provisioned IOPS SSD volumes only .
The total amount of read and write operations ( normalized to 256K capacity units ) consumed in a speciﬁed period of time .
Data is reported to CloudWatch only when the volume is active .
If the volume is not attached , no data is reported .
The Sum statistic on this metric is not relevant for volumes attached to Nitro-based instances .
If the baseline performance of the volume exceeds the maximum burst performance , credits are never spent .
Units : Percent Fast Snapshot Restore Metrics Metric Description FastSnapshotRestoreCreditsBucketSize The maximum number of volume create credits that can be accumulated .
This metric is reported per snapshot per Availability Zone .
The most meaningful statistic is Average .
The results for the Minimum and Maximum statistics are the same as for Average and could be used instead .
FastSnapshotRestoreCreditsBalance The number of volume create credits available .
This metric is reported per snapshot per Availability Zone .
The most meaningful statistic is Average .
The results for the Minimum and Maximum statistics are the same as for Average and could be used instead .
Dimensions for Amazon EBS Metrics The supported dimension is the volume ID ( VolumeId ) .
All available statistics are ﬁltered by volume ID .
All available statistics are ﬁltered by volume ID .
Select a volume on the Volumes page in the console and choose Monitoring .
The following table lists the graphs that are displayed .
The column on the right describes how the raw data metrics from the CloudWatch API are used to produce each graph .
1060 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS CloudWatch Events For the average latency graphs and average size graphs , the average is calculated over the total number of operations ( read or write , whichever is applicable to the graph ) that completed during the period .
Amazon CloudWatch Events for Amazon EBS Amazon EBS emits notiﬁcations based on Amazon CloudWatch Events for a variety of volume , snapshot , and encryption status changes .
With CloudWatch Events , you can establish rules that trigger programmatic actions in response to a change in volume , snapshot , or encryption key state .
For example , when a snapshot is created , you can trigger an AWS Lambda function to share the completed snapshot with another account or copy it to another Region for disaster-recovery purposes .
Events in CloudWatch are represented as JSON objects .
The ﬁelds that are unique to the event are contained in the `` detail '' section of the JSON object .
The '' result '' ﬁeld contains the completed status of the action that triggered the event .
For more information , see Event Patterns in CloudWatch Events in the Amazon CloudWatch Events User Guide .
For more information , see Using Events in the Amazon CloudWatch User Guide .
This event can have a result of either available or failed .
Creation will fail if an invalid KMS key was provided , as shown in the examples below .
Event Data The listing below is an example of a JSON object emitted by EBS for a successful createVolume event .
The cause for the failure was a disabled KMS key .
The cause for the failure was a KMS key pending import .
This event has the result deleted .
If the deletion does not complete , the event is never sent .
Event Data 1062 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS CloudWatch Events The listing below is an example of a JSON object emitted by EBS for a successful deleteVolume event .
If you use a KMS key to encrypt an EBS volume and the key becomes invalid , EBS will emit an event if that key is later used to attach or reattach to an instance , as shown in the examples below .
Event Data The listing below is an example of a JSON object emitted by EBS after a failed attachVolume event .
The cause for the failure was a KMS key pending deletion .
Note AWS may attempt to reattach to a volume following routine server maintenance .
The cause for the failure was a KMS key pending deletion .
This event can have a result of either succeeded or failed .
Event Data The listing below is an example of a JSON object emitted by EBS for a successful createSnapshot event .
In the detail section , the source ﬁeld contains the ARN of the source volume .
The StartTime and EndTime ﬁelds indicate when creation of the snapshot started and completed .
This event can have a result of either succeeded or failed .
Event Data The listing below is an example of a JSON object emitted by EBS for a successful createSnapshots event .
In the detail section , the source ﬁeld contains the ARNs of the source volumes of the multivolume snapshot set .
The StartTime and EndTime ﬁelds indicate when creation of the snapshot started and completed .
The cause for the failure was one or more snapshots failed to complete .
The values of snapshot_id are the ARNs of the failed snapshots .
StartTime and EndTime represent when the create-snapshots action started and ended .
This event can have a result of either succeeded or failed .
Event Data The listing below is an example of a JSON object emitted by EBS after a successful copySnapshot event .
The value of snapshot_id is the ARN of the newly created snapshot .
In the detail section , the value of source is the ARN of the source snapshot .
StartTime and EndTime represent when the copysnapshot action started and ended .
The cause for the failure was an invalid source snapshot ID .
The value of snapshot_id is the ARN of the failed snapshot .
In the detail section , the value of source is the ARN of the source snapshot .
StartTime and EndTime represent when the copy-snapshot action started and ended .
Event Data The following is an example of a JSON object emitted by EBS after a completed shareSnapshot event .
In the detail section , the value of source is the AWS account number of the user that shared the snapshot with you .
StartTime and EndTime represent when the share-snapshot action started and ended .
The shareSnapshot event is emitted only when a private snapshot is shared with another user .
The following is example data for this event .
The possible values for message are as follows : Client.InvalidSnapshot.InvalidState - The requested snapshot transitioned to an invalid state ( Error ) A request to enable fast snapshot restore failed and the state transitioned to disabling or disabled .
Fast snapshot restore can not be enabled for this snapshot .
1068 Amazon Elastic Compute Cloud User Guide for Linux Instances EBS CloudWatch Events Client.UserInitiated The state successfully transitioned to enabling or disabling .
Server.InsufficientCapacity - There was insufficient capacity available to satisfy the request A request to enable fast snapshot restore failed due to insuﬃcient capacity , and the state transitioned to disabling or disabled .
Server.InternalError - An internal error caused the operation to fail A request to enable fast snapshot restore failed due to an internal error , and the state transitioned to disabling or disabled .
Using Amazon Lambda To Handle CloudWatch Events You can use Amazon EBS and CloudWatch Events to automate your data-backup workﬂow .
This requires you to create an IAM policy , a AWS Lambda function to handle the event , and an Amazon CloudWatch Events rule that matches incoming events and routes them to the Lambda function .
The following procedure uses the createSnapshot event to automatically copy a completed snapshot to another Region for disaster recovery .
Create an IAM policy , such as the one shown in the following example , to provide permissions to execute a CopySnapshot action and write to the CloudWatch Events log .
Assign the policy to the IAM user that will handle the CloudWatch event .
For more information , see the AWS Lambda Developer Guide .
For Rule target , ﬁnd and choose the sample function that you previously created .
For Lambda function , select the Lambda function that you previously created and choose Conﬁgure details .
On the Conﬁgure rule details page , type values for Name and Description .
Select the State check box to activate the function ( setting it to Enabled ) .
1070 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance Store Your rule should now appear on the Rules tab .
In the example shown , the event that you conﬁgured should be emitted by EBS the next time you copy a snapshot .
Amazon EC2 Instance Store An instance store provides temporary block-level storage for your instance .
This storage is located on disks that are physically attached to the host computer .
Instance store is ideal for temporary storage of information that changes frequently , such as buﬀers , caches , scratch data , and other temporary content , or for data that is replicated across a ﬂeet of instances , such as a load-balanced pool of web servers .
An instance store consists of one or more instance store volumes exposed as block devices .
The size of an instance store as well as the number of devices available varies by instance type .
Instance types that support one instance store volume have ephemeral0 .
You ca n't detach an instance store volume from one instance and attach it to a diﬀerent instance .
1071 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance Store Volumes The data in an instance store persists only during the lifetime of its associated instance .
However , data in the instance store is lost under any of the following circumstances : • The underlying disk drive fails • The instance stops • The instance terminates Therefore , do not rely on instance store for valuable , long-term data .
When you stop or terminate an instance , every block of storage in the instance store is reset .
Therefore , your data can not be accessed through the instance store of another instance .
If you create an AMI from an instance , the data on its instance store volumes is n't preserved and isn't present on the instance store volumes of the instances that you launch from the AMI .
If you change the instance type , an instance store will not be attached to the new instance type .
Instance Store Volumes The instance type determines the size of the instance store available and the type of hardware used for the instance store volumes .
Instance store volumes are included as part of the instance 's usage cost .
You must specify the instance store volumes that you 'd like to use when you launch the instance ( except for NVMe instance store volumes , which are available by default ) .
Then format and mount the instance store volumes before using them .
You ca n't make an instance store volume available after you launch the instance .
This is a good option when you need storage with very low latency , but you do n't need the data to persist when the instance terminates or you can take advantage of fault-tolerant architectures .
The following table provides the quantity , size , type , and performance optimizations of instance store volumes available on each supported instance type .
Add Instance Store Volumes to Your EC2 Instance You specify the EBS volumes and instance store volumes for your instance using a block device mapping .
Each entry in a block device mapping includes a device name and the volume that it maps to .
The default block device mapping is speciﬁed by the AMI you use .
Alternatively , you can specify a block device mapping for the instance when you launch it .
All the NVMe instance store volumes supported by an instance type are automatically enumerated and assigned a device name on instance launch ; including them in the block device mapping for the AMI or the instance has no eﬀect .
A block device mapping always speciﬁes the root volume for the instance .
The root volume is either an Amazon EBS volume or an instance store volume .
The root volume is mounted automatically .
For instances with an instance store volume for the root volume , the size of this volume varies by AMI , but the maximum size is 10 GB .
You can use a block device mapping to specify additional EBS volumes when you launch your instance , or you can attach additional EBS volumes after your instance is running .
You can specify the instance store volumes for your instance only when you launch it .
You ca n't attach instance store volumes to an instance after you 've launched it .
If you change the instance type , an instance store will not be attached to the new instance type .
The number and size of available instance store volumes for your instance varies by instance type .
Some instance types do not support instance store volumes .
If the number of instance store volumes in a block device mapping exceeds the number of instance store volumes available to an instance , the additional volumes are ignored .
If the instance type you choose for your instance supports non-NVMe instance store volumes , you must add them to the block device mapping for the instance when you launch it .
NVMe instance store volumes 1077 Amazon Elastic Compute Cloud User Guide for Linux Instances Add Instance Store Volumes are available by default .
After you launch an instance , you must ensure that the instance store volumes for your instance are formatted and mounted before you can use them .
The root volume of an instance store-backed instance is mounted automatically .
If you launch an instance with an instance type that supports instance store volumes and an AMI that speciﬁes instance store volumes in its block device mapping , the instance includes these instance store volumes .
If the number of instance store volumes in the block device mapping exceeds the number of instance store volumes available to the instance , the additional instance store volumes are ignored .
Considerations • For M3 instances , specify instance store volumes in the block device mapping of the instance , not the AMI .
Amazon EC2 might ignore instance store volumes that are speciﬁed only in the block device mapping of the AMI .
• When you launch an instance , you can omit non-NVMe instance store volumes speciﬁed in the AMI block device mapping or add instance store volumes .
To add instance store volumes to an Amazon EBS-backed AMI using the console 1 .
In the navigation pane , choose Instances and select the instance .
In the Create Image dialog box , type a meaningful name and description for your image .
For each instance store volume to add , choose Add New Volume , from Volume Type select an instance store volume , and from Device select a device name .
The number of available instance store volumes depends on the instance type .
For instances with NVMe instance store volumes , the device mapping of these volumes depends on the order in which the operating system enumerates the volumes .
To add instance store volumes to an AMI using the command line You can use one of the following commands .
If you need additional instance store volumes , you must add them to the instance as you launch it .
You can also omit devices speciﬁed in the AMI block device mapping .
1078 Amazon Elastic Compute Cloud User Guide for Linux Instances Add Instance Store Volumes Considerations • For M3 instances , you might receive instance store volumes even if you do not specify them in the block device mapping for the instance .
• For HS1 instances , no matter how many instance store volumes you specify in the block device mapping of an AMI , the block device mapping for an instance launched from the AMI automatically includes the maximum number of supported instance store volumes .
You must explicitly remove the instance store volumes that you do n't want from the block device mapping for the instance before you launch it .
To update the block device mapping for an instance using the console 1 .
For each instance store volume to add , choose Add New Volume , from Volume Type select an instance store volume , and from Device select a device name .
The number of available instance store volumes depends on the instance type .
Complete the wizard and launch the instance .
( Optional ) To view the instance store volumes available on your instance , run the lsblk command .
To update the block device mapping for an instance using the command line You can use one of the following options commands with the corresponding command .
For Linux instances , the instance type determines which instance store volumes are mounted for you and which are available for you to mount yourself .
For Windows instances , the EC2Conﬁg service mounts the instance store volumes for an instance .
The block device driver for the instance assigns the actual volume name when mounting the volume , and the name assigned can be diﬀerent than the name that Amazon EC2 recommends .
SSD-based instance store volumes that support TRIM instruction are not pre-formatted with any ﬁle system .
However , you can format volumes with the ﬁle system of your choice after you launch your instance .
For Windows instances , the EC2Conﬁg service reformats the instance store volumes with the NTFS ﬁle system .
You can conﬁrm that the instance store devices are available from within the instance itself using instance metadata .
For Windows instances , you can also view the instance store volumes using Windows Disk Management .
For more information , see Listing disks using Windows Disk Management .
1079 Amazon Elastic Compute Cloud User Guide for Linux Instances SSD Instance Store Volumes For Linux instances , you can view and mount the instance store volumes as described in the following procedure .
To make an instance store volume available on Linux 1 .
Connect to the instance using an SSH client .
Use the df -h command to view the volumes that are formatted and mounted .
Use the lsblk to view any volumes that were mapped at launch but not formatted and mounted .
To format and mount an instance store volume that was mapped only , do the following : a .
Create a ﬁle system on the device using the mkfs command .
Create a directory on which to mount the device using the mkdir command .
c. Mount the device on the newly created directory using the mount command .
SSD Instance Store Volumes To ensure the best IOPS performance from your SSD instance store volumes on Linux , we recommend that you use the most recent version of Amazon Linux , or another Linux AMI with a kernel version of 3.8 or later .
If you do not use a Linux AMI with a kernel version of 3.8 or later , your instance wo n't achieve the maximum IOPS performance available for these instance types .
Like other instance store volumes , you must map the SSD instance store volumes for your instance when you launch it .
The data on an SSD instance volume persists only for the life of its associated instance .
The following is example output for an i3.8xlarge instance , which supports four NVMe devices .
You can use the NVMe commands with your NVMe volumes .
With Amazon Linux , you can install the nvme-cli package from the repo using the yum install command .
With other supported versions of Linux , you can download the nvmecli package if it 's not available in the image .
The data on NVMe instance storage is encrypted using an XTS-AES-256 block cipher implemented in a hardware module on the instance .
The encryption keys are generated using the hardware module and are unique to each NVMe instance storage device .
All encryption keys are destroyed when the instance is stopped or terminated and can not be recovered .
You can not disable this encryption and you can not provide your own encryption key .
Instance store volumes that support TRIM are fully trimmed before they are allocated to your instance .
These volumes are not formatted with a ﬁle system when an instance launches , so you must format them before they can be mounted and used .
For faster access to these volumes , you should skip the TRIM operation when you format them .
With instance store volumes that support TRIM , you can use the TRIM command to notify the SSD controller when you no longer need data that you 've written .
This provides the controller with more free space , which can reduce write ampliﬁcation and increase performance .
On Linux , use the fstrim command to enable periodic TRIM .
Instance Store Swap Volumes Swap space in Linux can be used when a system requires more memory than it has been physically allocated .
When swap space is enabled , Linux systems can swap infrequently used memory pages from physical memory to swap space ( either a dedicated partition or a swap ﬁle in an existing ﬁle system ) and free up that space for memory pages that require high-speed access .
1081 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance Store Swap Volumes Note Using swap space for memory paging is not as fast or eﬃcient as using RAM .
If your workload is regularly paging memory into swap space , you should consider migrating to a larger instance type with more RAM .
The c1.medium and m1.small instance types have a limited amount of physical memory to work with , and they are given a 900 MiB swap volume at launch time to act as virtual memory for Linux AMIs .
Although the Linux kernel sees this swap space as a partition on the root device , it is actually a separate instance store volume , regardless of your root device type .
Amazon Linux automatically enables and uses this swap space , but your AMI may require some additional steps to recognize and use this swap space .
To see if your instance is using swap space , you can use the swapon -s command .
If you do n't see a swap volume listed with this command , you may need to enable swap space for the device .
Check your available disks using the lsblk command .
You can enable the swap volume with the swapon command .
Note You must prepend /dev/ to the device name listed by lsblk .
Use the device name for your system in the command below .
[ ec2-user ~ ] $ sudo vim /etc/fstab Append the following line to your /etc/fstab ﬁle ( using the swap device name for your system ) : /dev/xvda3 none swap sw 0 0 1082 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance Store Swap Volumes To use an instance store volume as swap space Any instance store volume can be used as swap space .
Note This procedure applies only to instance types that support instance storage .
List the block devices attached to your instance to get the device name for your instance store volume .
Because this is an Amazon Linux instance , the instance store volume is formatted and mounted at /media/ephemeral0 ; not all Linux operating systems do this automatically .
Set up a Linux swap area on the device with the mkswap command .
Verify that the new swap space is being used .
Optimizing Disk Performance for Instance Store Volumes Because of the way that Amazon EC2 virtualizes disks , the ﬁrst write to any location on some instance store volumes performs more slowly than subsequent writes .
For most applications , amortizing this cost over the lifetime of the instance is acceptable .
However , if you require high disk performance , we recommend that you initialize your drives by writing once to every drive location before production use .
Note Some instance types with direct-attached solid state drives ( SSD ) and TRIM support provide maximum performance at launch time , without initialization .
If you require greater ﬂexibility in latency or throughput , we recommend using Amazon EBS .
Note Make sure to unmount the drive before performing this command .
This compatibility makes cloud ﬁle storage ideal for workloads that rely on shared ﬁle systems and provides simple integration without code changes .
1084 Amazon Elastic Compute Cloud User Guide for Linux Instances Amazon EFS Amazon Elastic File System ( Amazon EFS ) Amazon EFS provides scalable ﬁle storage for use with Amazon EC2 .
You can create an EFS ﬁle system and conﬁgure your instances to mount the ﬁle system .
You can use an EFS ﬁle system as a common data source for workloads and applications running on multiple instances .
For more information , see the Amazon Elastic File System product page .
In this tutorial , you create an EFS ﬁle system and two Linux instances that can share data using the ﬁle system .
Important Amazon EFS is not supported on Windows instances .
• Allow inbound NFS connections to the ﬁle system via the EFS mount target from the EC2 instances that are associated with this security group ( the source is the security group itself ) .
You must specify a key pair when you conﬁgure your instances or you ca n't connect to them .
Step 1 : Create an EFS File System Amazon EFS enables you to create a ﬁle system that multiple instances can mount and access at the same time .
For more information , see Creating Resources for Amazon EFS in the Amazon Elastic File System User Guide .
For VPC , select the VPC to use for your instances .
For Create mount targets , select all the Availability Zones .
On the Conﬁgure ﬁle system settings page , do the following : 1085 Amazon Elastic Compute Cloud User Guide for Linux Instances Amazon EFS a .
On the Conﬁgure client access page , keep the default settings and choose Next Step .
On the Review and create page , choose Create File System .
After the ﬁle system is created , note the ﬁle system ID , as you 'll use it later in this tutorial .
The user data script mounts the ﬁle system to both instances during launch and updates /etc/fstab to ensure that the ﬁle system is remounted after an instance reboot .
Note There are other ways that you can mount the volume ( for example , on an already running instance ) .
For more information , see Mounting File Systems in the Amazon Elastic File System User Guide .
To launch two instances and mount an EFS ﬁle system 1 .
On the Choose an Amazon Machine Image page , select an Amazon Linux AMI with the HVM virtualization type .
On the Choose an Instance Type page , keep the default instance type , t2.micro and choose Next : Conﬁgure Instance Details .
Keep the default VPC and the default value for Subnet to use the default subnet in the Availability Zone that Amazon EC2 chooses for your instances .
Otherwise , your instances do not get public IP addresses or public DNS names .
On the Conﬁgure Security Group page , choose Select an existing security group and select the security group that you created in Prerequisites ( p. 1085 ) , and then choose Review and Launch .
In the Select an existing key pair or create a new key pair dialog box , select Choose an existing key pair and choose your key pair .
Select the acknowledgment check box , and choose Launch Instances .
In the navigation pane , choose Instances to see the status of your instances .
After the status changes to running , your instances are ready for use .
Step 3 : Test the File System You can connect to your instances and verify that the ﬁle system is mounted to the directory that you speciﬁed ( for example , /mnt/efs ) .
From the terminal window for each instance , run the df -T command to verify that the EFS ﬁle system is mounted .
( Optional ) Create a ﬁle in the ﬁle system from one instance , and then verify that you can view the ﬁle from the other instance .
From the second instance , run the following command to view the ﬁle : $ ls /mnt/efs test-file.txt Step 4 : Clean Up When you are ﬁnished with this tutorial , you can terminate the instances and delete the ﬁle system .
Select the ﬁle system to delete .
When prompted for conﬁrmation , type the ID of the ﬁle system and choose Delete File System .
Amazon FSx for Windows File Server Amazon FSx for Windows File Server provides fully managed Windows ﬁle servers , backed by a fully– native Windows ﬁle system with the features , performance , and compatibility to easily lift and shift enterprise applications to AWS .
Amazon FSx supports a broad set of enterprise Windows workloads with fully managed ﬁle storage built on Microsoft Windows Server .
Amazon FSx has native support for Windows ﬁle system features and for the industry-standard Server Message Block ( SMB ) protocol to access ﬁle storage over a network .
Amazon FSx is optimized for enterprise applications in the AWS Cloud , with native Windows compatibility , enterprise performance and features , and consistent sub-millisecond latencies .
With ﬁle storage on Amazon FSx , the code , applications , and tools that Windows developers and administrators use today can continue to work unchanged .
The Windows applications and workloads that are ideal for Amazon FSx include business applications , home directories , web serving , content management , data analytics , software build setups , and media processing workloads .
As a fully managed service , Amazon FSx for Windows File Server eliminates the administrative overhead of setting up and provisioning ﬁle servers and storage volumes .
Additionally , it keeps Windows software up to date , detects and addresses hardware failures , and performs backups .
It also provides rich integration with other AWS services , including AWS Directory Service for Microsoft Active Directory , Amazon WorkSpaces , AWS Key Management Service , and AWS CloudTrail .
1088 Amazon Elastic Compute Cloud User Guide for Linux Instances Amazon S3 For more information , see the Amazon FSx for Windows File Server User Guide .
It is designed to make web-scale computing easier by enabling you to store and retrieve any amount of data , at any time , from within Amazon EC2 or anywhere on the web .
Amazon S3 stores data objects redundantly on multiple devices across multiple facilities and allows concurrent read or write access to these data objects by many separate clients or application threads .
You can use the redundant data stored in Amazon S3 to recover quickly and reliably from instance or application failures .
In case of instance failure , you can use the stored AMI to immediately launch another instance , thereby allowing for fast recovery and business continuity .
You can use snapshots for recovering data quickly and reliably in case of application or system failures .
You can also use snapshots as a baseline to create multiple new data volumes , expand the size of an existing data volume , or move data volumes across multiple Availability Zones , thereby making your data usage highly scalable .
Buckets organize the Amazon S3 namespace at the highest level and identify the account responsible for that storage .
Objects stored in the buckets have a unique key value and are retrieved using a URL .
Amazon S3 and Amazon EC2 Given the beneﬁts of Amazon S3 for storage , you may decide to use this service to store ﬁles and data sets for use with EC2 instances .
There are several ways to move data to and from Amazon S3 to your instances .
In addition to the examples discussed below , there are a variety of tools that people have written that you can use to access your data in Amazon S3 from your computer or your instance .
Some of the common ones are discussed in the AWS forums .
If you have permission , you can copy a ﬁle to or from Amazon S3 and your instance using one of the following methods .
GET or wget The wget utility is an HTTP and FTP client that allows you to download public objects from Amazon S3 .
It is installed by default in Amazon Linux and most other distributions , and available for download on Windows .
To download an Amazon S3 object , use the following command , substituting the URL of the object to download .
If you receive this error , open the Amazon S3 console and change 1089 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance volume limits the permissions of the object to public .
For more information , see the Amazon Simple Storage Service Developer Guide .
AWS Command Line Interface The AWS Command Line Interface ( AWS CLI ) is a uniﬁed tool to manage your AWS services .
The AWS CLI enables users to authenticate themselves and download restricted items from Amazon S3 and also to upload items .
For more information , such as how to install and conﬁgure the tools , see the AWS Command Line Interface detail page .
The aws s3 cp command is similar to the Unix cp command .
You can copy ﬁles from Amazon S3 to your instance , copy ﬁles from your instance to Amazon S3 , and copy ﬁles from one Amazon S3 location to another .
Use the following command to copy an object from Amazon S3 to your instance .
This can be helpful for downloading a data set and keeping the local copy up-to-date with the remote set .
If you have the proper permissions on the Amazon S3 bucket , you can push your local directory back up to the cloud when you are ﬁnished by reversing the source and destination locations in the command .
Use the following command to download an entire Amazon S3 bucket to a local directory on your instance .
For more information , see the Amazon Simple Storage Service Developer Guide .
You can use this API and its examples to help develop your application and integrate it with other APIs and SDKs , such as the boto Python interface .
Instance volume limits The maximum number of volumes that your instance can have depends on the operating system and instance type .
When considering how many volumes to add to your instance , you should consider whether you need increased I/O bandwidth or increased storage capacity .
Every instance has 1090 Amazon Elastic Compute Cloud User Guide for Linux Instances Linux-speciﬁc volume limits at least one network interface attachment .
NVMe instance store volumes are automatically attached .
For example , if you have no additional network interface attachments on an EBS-only instance , you can attach up to 27 EBS volumes to it .
If you have one additional network interface on an instance with 2 NVMe instance store volumes , you can attach 24 EBS volumes to it .
This number includes the root volume , plus any attached instance store volumes and EBS volumes .
If you experience boot problems on an instance with a large number of volumes , stop the instance , detach any volumes that are not essential to the boot process , and then reattach the volumes after the instance is running .
Important Attaching more than 40 volumes to a Linux instance is supported on a best eﬀort basis only and is not guaranteed .
Bandwidth versus capacity For consistent and predictable bandwidth use cases , use EBS-optimized or 10 Gigabit network connectivity instances and General Purpose SSD or Provisioned IOPS SSD volumes .
Follow the guidance in Amazon EBS–optimized instances ( p. 1026 ) to match the IOPS you have provisioned for your volumes to the bandwidth available from your instances for maximum performance .
For RAID conﬁgurations , many administrators ﬁnd that arrays larger than 8 volumes have diminished performance returns due to increased I/O overhead .
Test your individual application performance and tune it as required .
Device Naming on Linux Instances When you attach a volume to your instance , you include a device name for the volume .
The block device driver for the instance assigns the actual volume name when mounting the volume , and the name assigned can be diﬀerent from the name that Amazon EC2 uses .
The number of volumes that your instance can support is determined by the operating system .
1091 Amazon Elastic Compute Cloud User Guide for Linux Instances Available Device Names Available Device Names There are two types of virtualization available for Linux instances : paravirtual ( PV ) and hardware virtual machine ( HVM ) .
The virtualization type of an instance is determined by the AMI used to launch the instance .
All instance types support HVM AMIs .
Some previous generation instance types support PV AMIs .
Be sure to note the virtualization type of your AMI because the recommended and available device names that you can use depend on the virtualization type of your instance .
The following table lists the available device names that you can specify in a block device mapping or when attaching an EBS volume .
The block device driver can assign NVMe device names in a diﬀerent order than you speciﬁed for the volumes in the block device mapping .
** NVMe instance store volumes are automatically enumerated and assigned an NVMe device name .
Device Name Considerations Keep the following in mind when selecting a device name : • Although you can attach your EBS volumes using the device names used to attach instance store volumes , we strongly recommend that you do n't because the behavior can be unpredictable .
• The number of NVMe instance store volumes for an instance depends on the size of the instance .
• Depending on the block device driver of the kernel , the device could be attached with a diﬀerent name than you speciﬁed .
In most cases , the trailing letter remains the same .
In these cases , the trailing letter of each device name is incremented the same number of times .
Amazon Linux creates a symbolic link for the name you speciﬁed to the renamed device .
Other operating systems could behave diﬀerently .
While using /dev/sda2 is possible , we do not recommend using this device mapping with HVM instances .
• When using PV AMIs , you can not attach volumes that share the same device letters both with and without trailing digits .
Block Device Mapping Each instance that you launch has an associated root device volume , either an Amazon EBS volume or an instance store volume .
You can use block device mapping to specify additional EBS volumes or instance store volumes to attach to an instance when it 's launched .
However , the only way to attach instance store volumes to an instance is to use block device mapping to attach them as the instance is launched .
These devices support random access and generally use buﬀered I/O .
A block device can be physically attached to a computer or accessed remotely as if it were physically attached to the computer .
Amazon EC2 supports two types of block devices : • Instance store volumes ( virtual devices whose underlying hardware is physically attached to the host computer for the instance ) • EBS volumes ( remote storage devices ) A block device mapping deﬁnes the block devices ( instance store volumes and EBS volumes ) to attach to an instance .
You can specify a block device mapping as part of creating an AMI so that the mapping is used by all instances launched from the AMI .
Alternatively , you can specify a block device mapping when you launch an instance , so this mapping overrides the one speciﬁed in the AMI from which you launched the instance .
Note that all NVMe instance store volumes supported by an instance type are automatically enumerated and assigned a device name on instance launch ; including them in your block device mapping has no eﬀect .
The block device driver for the instance assigns the actual volume name when mounting the volume .
The name assigned can be diﬀerent from the name that Amazon EC2 recommends .
Note that the number and size of available instance store volumes for your instance varies by instance type .
• [ NVMe instance store volumes ] These volumes are automatically enumerated and assigned a device name ; including them in your block device mapping has no eﬀect .
This value is optional as long as you specify a volume size .
The speciﬁed size must be greater than or equal to the size of the speciﬁed snapshot .
The default value is true for the root device volume and false for attached volumes .
When you create an AMI , its block device mapping inherits this setting from the instance .
When you launch an instance , it inherits this setting from the AMI .
Block Device Mapping Instance Store Caveats There are several caveats to consider when launching instances with AMIs that have instance store volumes in their block device mappings .
• Some instance types include more instance store volumes than others , and some instance types contain no instance store volumes at all .
If your instance type supports one instance store volume , and your AMI has mappings for two instance store volumes , then the instance launches with one instance store volume .
• Instance store volumes can only be mapped at launch time .
You can not stop an instance without instance store volumes ( such as the t2.micro ) , change the instance to a type that supports instance store volumes , and then restart the instance with instance store volumes .
However , you can create an AMI from the instance and launch it on an instance type that supports instance store volumes , and map those instance store volumes to the instance .
• If you launch an instance with instance store volumes mapped , and then stop the instance and change it to an instance type with fewer instance store volumes and restart it , the instance store volume mappings from the initial launch still show up in the instance metadata .
However , only the maximum number of supported instance store volumes for that instance type are available to the instance .
1094 Amazon Elastic Compute Cloud User Guide for Linux Instances Block Device Mapping Concepts Note When an instance is stopped , all data on the instance store volumes is lost .
• Depending on instance store capacity at launch time , M3 instances may ignore AMI instance store block device mappings at launch unless they are speciﬁed at launch .
You should specify instance store block device mappings at launch time , even if the AMI you are launching has the instance store volumes mapped in the AMI , to ensure that the instance store volumes are available when the instance launches .
Example Block Device Mapping This ﬁgure shows an example block device mapping for an EBS-backed instance .
It also shows the EBS volume that is the root device volume , /dev/sda1 .
Note that this example block device mapping is used in the example commands and APIs in this topic .
How Devices Are Made Available in the Operating System Device names like /dev/sdh and xvdh are used by Amazon EC2 to describe block devices .
The block device mapping is used by Amazon EC2 to specify the block devices to attach to an EC2 instance .
After 1095 Amazon Elastic Compute Cloud User Guide for Linux Instances AMI Block Device Mapping a block device is attached to an instance , it must be mounted by the operating system before you can access the storage device .
When a block device is detached from an instance , it is unmounted by the operating system and you can no longer access the storage device .
With a Linux instance , the device names speciﬁed in the block device mapping are mapped to their corresponding block devices when the instance ﬁrst boots .
The instance type determines which instance store volumes are formatted and mounted by default .
You can mount additional instance store volumes at launch , as long as you do n't exceed the number of instance store volumes available for your instance type .
The block device driver for the instance determines which devices are used when the volumes are formatted and mounted .
AMI Block Device Mapping Each AMI has a block device mapping that speciﬁes the block devices to attach to an instance when it is launched from the AMI .
An AMI that Amazon provides includes a root device only .
To add more block devices to an AMI , you must create your own AMI .
Contents • Specifying a Block Device Mapping for an AMI ( p. 1096 ) • Viewing the EBS Volumes in an AMI Block Device Mapping ( p. 1097 ) Specifying a Block Device Mapping for an AMI There are two ways to specify volumes in addition to the root volume when you create an AMI .
If you've already attached volumes to a running instance before you create an AMI from the instance , the block device mapping for the AMI includes those same volumes .
For EBS volumes , the existing data is saved to a new snapshot , and it 's this new snapshot that 's speciﬁed in the block device mapping .
For instance store volumes , the data is not preserved .
For an EBS-backed AMI , you can add EBS volumes and instance store volumes using a block device mapping .
For an instance store-backed AMI , you can add instance store volumes only by modifying the block device mapping entries in the image manifest ﬁle when registering the image .
Note For M3 instances , you must specify instance store volumes in the block device mapping for the instance when you launch it .
When you launch an M3 instance , instance store volumes speciﬁed in the block device mapping for the AMI may be ignored if they are not speciﬁed as part of the instance block device mapping .
To add volumes to an AMI using the console 1 .
In the Create Image dialog box , choose Add New Volume .
Select a volume type from the Type list and a device name from the Device list .
To add volumes to an AMI using the command line Use the create-image AWS CLI command to specify a block device mapping for an EBS-backed AMI .
1096 Amazon Elastic Compute Cloud User Guide for Linux Instances AMI Block Device Mapping Specify the block device mapping using the -- block-device-mappings parameter .
To view the EBS volumes for an AMI using the console 1 .
Choose EBS images from the Filter list to get a list of EBS-backed AMIs .
1097 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance Block Device Mapping 4 .
Select the desired AMI , and look at the Details tab .
To view the EBS volumes for an AMI using the command line Use the describe-images ( AWS CLI ) command or Get-EC2Image ( AWS Tools for Windows PowerShell ) command to enumerate the EBS volumes in the block device mapping for an AMI .
Instance Block Device Mapping By default , an instance that you launch includes any storage devices speciﬁed in the block device mapping of the AMI from which you launched the instance .
You can specify changes to the block device mapping for an instance when you launch it , and these updates overwrite or merge with the block device mapping of the AMI .
Limits • For the root volume , you can only modify the following : volume size , volume type , and the Delete on Termination ﬂag .
Therefore , you must specify a snapshot whose size is equal to or greater than the size of the snapshot speciﬁed in the block device mapping of the AMI .
Note that updating the block device mapping for an instance does n't make a permanent change to the block device mapping of the AMI from which it was launched .
To add volumes to an instance using the console 1 .
On the Choose an Amazon Machine Image ( AMI ) page , select the AMI to use and choose Select .
Follow the wizard to complete the Choose an Instance Type and Conﬁgure Instance Details pages .
1098 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance Block Device Mapping 5 .
On the Add Storage page , you can modify the root volume , EBS volumes , and instance store volumes as follows : • To change the size of the root volume , locate the Root volume under the Type column , and change its Size ﬁeld .
• To suppress an EBS volume speciﬁed by the block device mapping of the AMI used to launch the instance , locate the volume and click its Delete icon .
• To suppress an instance store volume speciﬁed by the block device mapping of the AMI used to launch the instance , locate the volume , and choose its Delete icon .
• To add an instance store volume , choose Add New Volume , select Instance Store from the Type list , and select a device name from Device .
To add volumes to an instance using the command line Use the run-instances AWS CLI command to specify a block device mapping for an instance .
Notice that you do n't need to specify the snapshot ID for /dev/sdh , because specifying the device name is enough to identify the volume .
If the instance type does n't support multiple instance store volumes , this mapping has no eﬀect .
Updating the Block Device Mapping of a Running Instance You can use the following modify-instance-attribute AWS CLI command to update the block device mapping of a running instance .
Note that you do not need to stop the instance before changing this attribute .
Viewing the EBS Volumes in an Instance Block Device Mapping You can easily enumerate the EBS volumes mapped to an instance .
Note For instances launched before the release of the 2009-10-31 API , AWS ca n't display the block device mapping .
You must detach and reattach the volumes so that AWS can display the block device mapping .
To view the EBS volumes for an instance using the console 1 .
In the search bar , type Root Device Type , and then choose EBS .
Select the desired instance and look at the details displayed in the Description tab .
1100 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance Block Device Mapping 5 .
To display additional information about a block device , select its entry next to Block devices .
Viewing the Instance Block Device Mapping for Instance Store Volumes When you view the block device mapping for your instance , you can see only the EBS volumes , not the instance store volumes .
You can use instance metadata to query the non-NVMe instance store volumes in the block device mapping .
NVMe instance store volumes are not included .
From the instance , use this query to get its block device mapping .
ami ephemeral0 root swap 1101 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance Block Device Mapping The ami device is the root device as seen by the instance .
The swap device is for the page ﬁle .
To get details about an individual block device in the block device mapping , append its name to the previous query , as shown here .
If the number of instance store volumes in a block device mapping exceeds the number of instance store volumes available to an instance , the additional volumes are ignored .
To view the instance store volumes for your instance , run the lsblk command .
1102 Amazon Elastic Compute Cloud User Guide for Linux Instances Resource locations Resources and tags Amazon EC2 provides diﬀerent resources that you can create and use .
Some resources can be tagged with values that you deﬁne , to help you organize and identify them .
The following topics describe resources and tags , and how you can work with them .
Resource Type Description AWS account Global You can use the same AWS account in all regions .
Key pairs Global or Regional The key pairs that you create using Amazon EC2 are tied to the Region where you created them .
You can create your own RSA key pair and upload it to the region in which you want to use it ; therefore , you can make your key pair globally available by uploading it to each Region .
Amazon EC2 resource identiﬁers Regional Each resource identiﬁer , such as an AMI ID , instance ID , EBS volume ID , or EBS snapshot ID , is tied to its Region and can be used only in the Region where you created the resource .
User-supplied resource names Regional Each resource name , such as a security group name or key pair name , is tied to its region and can be used only in the Region where you created the resource .
Although you can create resources with the same name in multiple regions , they are n't related to each other .
AMIs Regional An AMI is tied to the Region where its ﬁles are located within Amazon S3 .
You can copy an AMI from one Region to another .
1103 Amazon Elastic Compute Cloud User Guide for Linux Instances Resource IDs Resource Type Description Elastic IP addresses Regional An Elastic IP address is tied to a Region and can be associated only with an instance in the same Region .
Security groups Regional A security group is tied to a Region and can be assigned only to instances in the same Region .
You ca n't enable an instance to communicate with an instance outside its Region using security group rules .
Traﬃc from an instance in another Region is seen as WAN bandwidth .
EBS snapshots Regional An EBS snapshot is tied to its Region and can only be used to create volumes in the same Region .
You can copy a snapshot from one Region to another .
EBS volumes Availability Zone An Amazon EBS volume is tied to its Availability Zone and can be attached only to instances in the same Availability Zone .
Instances Availability Zone An instance is tied to the Availability Zones in which you launched it .
However , its instance ID is tied to the Region .
Resource IDs When resources are created , we assign each resource a unique resource ID .
You can use resource IDs to ﬁnd your resources in the Amazon EC2 console .
If you are using a command line tool or the Amazon EC2 API to work with Amazon EC2 , resource IDs are required for certain commands .
For example , if you are using the stop-instances AWS CLI command to stop an instance , you must specify the instance ID in the command .
Supported resource types have an opt-in period , during which you can choose a resource ID format , and a deadline date , after which the resource defaults to the longer ID format .
After the deadline has passed for a speciﬁc resource type , you can no longer disable the longer ID format for that resource type .
Diﬀerent resource types have diﬀerent opt-in periods and deadline dates .
The following table lists the supported resource types , along with their opt-in periods and deadline dates .
After you've enabled longer IDs for a resource type , any new resources that you create are created with a longer ID .
Therefore , enabling or disabling longer IDs during the opt-in period does not aﬀect your existing resource IDs .
Depending on when you created your AWS account , supported resource types may default to using longer IDs .
However , you can opt out of using longer IDs until the deadline date for that resource type .
After the deadline You can ’ t disable longer IDs for a resource type after its deadline date has passed .
Any new resources that you create are created with a longer ID .
Working with longer IDs You can enable or disable longer IDs per IAM user and IAM role .
By default , an IAM user or role defaults to the same settings as the root user .
To view your longer ID settings using the console 1 .
In the navigation bar at the top of the screen , select the Region for which to view your longer ID settings .
1105 Amazon Elastic Compute Cloud User Guide for Linux Instances Working with longer IDs 4 .
Expand Advanced Resource ID Management to view the resource types that support longer IDs and their deadline dates .
To view your longer ID settings using the command line Use one of the following commands : • describe-id-format ( AWS CLI ) aws ec2 describe-id-format -- region region • Get-EC2IdFormat ( AWS Tools for Windows PowerShell ) Get-EC2IdFormat -Region region To view longer ID settings for a speciﬁc IAM user or IAM role using the command line Use one of the following commands and specify the ARN of an IAM user , IAM role , or root account user in the request .
This command is useful for performing a quick audit to determine whether a speciﬁc Region is fully opted in for longer IDs .
aws ec2 describe-aggregate-id-format -- region region To identify users who have explicitly deﬁned custom longer ID settings Use the describe-principal-id-format AWS CLI command to view the longer ID format settings for the root user and all IAM roles and IAM users that have explicitly speciﬁed a longer ID preference .
This command is useful for identifying IAM users and IAM roles that have overridden the default longer ID settings .
aws ec2 describe-principal-id-format -- region region Modifying longer ID settings You can use the console and command line tools to modify longer ID settings for resource types that are still within their opt-in period .
Note The AWS CLI and AWS Tools for Windows PowerShell commands in this section are per-region only .
They apply to the default Region unless otherwise speciﬁed .
To modify the settings for other regions , include the region parameter in the command .
1106 Amazon Elastic Compute Cloud User Guide for Linux Instances Working with longer IDs To modify longer ID settings using the console 1 .
In the navigation bar at the top of the screen , select the Region for which to modify the longer ID settings .
Do one of the following : • To enable longer IDs for all supported resource types for all IAM users across all regions , choose Switch to longer IDs , Yes , switch to longer IDs .
Important IAM users and IAM roles need the ec2 : ModifyIdentityIdFormat permission to perform this action .
• To modify longer ID settings for a speciﬁc resource type for your IAM user account , expand Advanced Resource ID Management , and then select the corresponding check box in the My IAM Role/User column to enable longer IDs , or clear the check box to disable longer IDs .
• To modify longer ID settings for a speciﬁc resource type for all IAM users , expand Advanced Resource ID Management , and then select the corresponding check box in the All IAM Roles/ Users column to enable longer IDs , or clear the check box to disable longer IDs .
To modify longer ID settings for your IAM user account using the command line Use one of the following commands : Note If you ’ re using these commands as the root user , then changes apply to the entire AWS account , unless an IAM user or role explicitly overrides these settings for themselves .
Edit-EC2IdFormat -Resource all-current -UseLongId boolean To modify longer ID settings for a speciﬁc IAM user or IAM role using the command line Use one of the following commands and specify the ARN of an IAM user , IAM role , or root user in the request .
You can get a list of each type of resource using its corresponding command or API action .
If you have many resources , you can ﬁlter the results to include only the resources that match certain criteria .
The speciﬁc search types available are : • Search by keyword To search by keyword , type or paste what you ’ re looking for in the search box , and then choose Enter .
Select Instance State from the list .
Select Stopped from the list of suggested values .
To further reﬁne your list , select the search box for more search options .
• Advanced search 1109 Amazon Elastic Compute Cloud User Guide for Linux Instances Listing resources using the console You can create advanced queries by adding multiple ﬁlters .
For example , you can search by tags and see instances for the Flying Mountain project running in the Production stack , and then search by attributes to see all t2.micro instances , or all instances in us-west-2a , or both .
• Inverse search You can search for resources that do not match a speciﬁed value .
For example , to list all instances that are not terminated , search by the Instance State ﬁeld , and preﬁx the Terminated value with an exclamation mark ( ! ) .
• Partial search When searching by ﬁeld , you can also enter a partial string to ﬁnd all resources that contain the string in that ﬁeld .
• Regular expression Regular expressions are useful when you need to match the values in a ﬁeld with a speciﬁc pattern .
After you have the precise results of your search , you can bookmark the URL for easy reference .
In situations where you have thousands of instances , ﬁlters and bookmarks can save you a great deal of time ; you don ’ t have to run searches repeatedly .
This is intentional , as the vast majority of ﬁlters would not be logical if they were joined with AND .
In many cases , you can granulate the results by using complementary search terms on diﬀerent key ﬁelds , where the AND rule is automatically applied instead .
To ﬁne-tune your results , simply remove one ﬁlter in the string until the results ﬁt your requirements .
Listing resources using the console You can view the most common Amazon EC2 resource types using the console .
To view additional resources , use the command line interface or the API actions .
In the navigation pane , choose the option that corresponds to the resource , such as AMIs or Instances .
1110 Amazon Elastic Compute Cloud User Guide for Linux Instances Filtering resources using the console 3 .
The page displays all the available resources .
Filtering resources using the console You can perform ﬁltering and sorting of the most common resource types using the Amazon EC2 console .
For example , you can use the search bar on the instances page to sort instances by tags , attributes , or keywords .
You can also use the search ﬁeld on each page to ﬁnd resources with speciﬁc attributes or values .
You can use regular expressions to search on partial or multiple strings .
For example , to ﬁnd all instances that are using the MySG security group , enter MySG in the search ﬁeld .
To limit your results to MySG only , enter \bMySG\b in the search ﬁeld .
Click on the search box , select Attachment Status from the menu , and then select Detached .
( A detached volume is available to be attached to an instance in the same Availability Zone . ) .
Click on the search box again , select State , and then select Available .
1111 Amazon Elastic Compute Cloud User Guide for Linux Instances Listing and ﬁltering using the CLI and API 5 .
Any volumes that meet this criteria are displayed .
In the Filter pane , select Public images , EBS images , and then your Linux distribution from the Filter lists .
Any AMIs that meet this criteria are displayed .
Listing and ﬁltering using the CLI and API Each resource type has a corresponding CLI command or API request that you use to list resources of that type .
The response contains information for all your resources .
The resulting lists of resources can be long , so you might want to ﬁlter the results to include only the resources that match certain criteria .
You can specify multiple ﬁlter values , and you can also specify multiple ﬁlters .
For example , you can list all the instances whose type is either m1.small or m1.large , and that have an attached EBS volume that is set to delete when the instance terminates .
The instance must match all your ﬁlters to be included in the results .
You can also use wildcards with the ﬁlter values .
For example , you can use database as the ﬁlter value to get only the EBS snapshots whose description equals database .
If you specify *database* , then all snapshots whose description includes database are returned .
If you specify database ? , then only the snapshots whose description matches one of the following patterns are returned : equals database or equals database followed by one character .
The number of question marks determines the maximum number of characters to include in results .
? , then only the snapshots whose description equals database followed by up to four characters are returned .
Descriptions with ﬁve or more characters following database are excluded from the search results .
If a resulting list of resources is long , using an exact string ﬁlter may return the response faster .
Your search can include the literal values of the wildcard characters ; you just need to escape them with a backslash before the character .
For a list of supported ﬁlters per Amazon EC2 resource , see the relevant documentation : • For the AWS CLI , see the relevant describe command in the AWS CLI Command Reference .
• For Windows PowerShell , see the relevant Get command in the AWS Tools for PowerShell Cmdlet Reference .
• For the Query API , see the relevant Describe API action in the Amazon EC2 API Reference .
Tagging your Amazon EC2 resources To help you manage your instances , images , and other Amazon EC2 resources , you can optionally assign your own metadata to each resource in the form of tags .
This topic describes tags and shows you how to create them .
1112 Amazon Elastic Compute Cloud User Guide for Linux Instances Tag basics Warning Tag keys and their values are returned by many diﬀerent API calls .
Denying access to DescribeTags doesn ’ t automatically deny access to tags returned by other APIs .
As a best practice , we recommend that you do not include sensitive data in your tags .
Each tag consists of a key and an optional value , both of which you deﬁne .
Tags enable you to categorize your AWS resources in diﬀerent ways , for example , by purpose , owner , or environment .
This is useful when you have many resources of the same type—you can quickly identify a speciﬁc resource based on the tags you 've assigned to it .
For example , you could deﬁne a set of tags for your account 's Amazon EC2 instances that helps you track each instance 's owner and stack level .
The following diagram illustrates how tagging works .
In this example , you 've assigned two tags to each of your instances—one tag with the key Owner and another with the key Stack .
Each tag also has an associated value .
1113 Amazon Elastic Compute Cloud User Guide for Linux Instances Tagging your resources We recommend that you devise a set of tag keys that meets your needs for each resource type .
Using a consistent set of tag keys makes it easier for you to manage your resources .
You can search and ﬁlter the resources based on the tags you add .
For more information about how to implement an eﬀective resource tagging strategy , see the AWS whitepaper Tagging Best Practices .
Tags do n't have any semantic meaning to Amazon EC2 and are interpreted strictly as a string of characters .
Also , tags are not automatically assigned to your resources .
You can edit tag keys and values , and you can remove tags from a resource at any time .
You can set the value of a tag to an empty string , but you ca n't set the value of a tag to null .
If you add a tag that has the same key as an existing tag on that resource , the new value overwrites the old value .
If you delete a resource , any tags for the resource are also deleted .
You can work with tags using the AWS Management Console , the AWS CLI , and the Amazon EC2 API .
If you 're using AWS Identity and Access Management ( IAM ) , you can control which users in your AWS account have permission to create , edit , or delete tags .
Tagging your resources You can tag most Amazon EC2 resources that already exist in your account .
If you 're using the Amazon EC2 console , you can apply tags to resources by using the Tags tab on the relevant resource screen , or you can use the Tags screen .
Some resource screens enable you to specify tags for a resource when you create the resource ; for example , a tag with a key of Name and a value that you specify .
In most cases , the console applies the tags immediately after the resource is created ( rather than during resource creation ) .
The console may organize resources according to the Name tag , but this tag does n't have any semantic meaning to the Amazon EC2 service .
If you 're using the Amazon EC2 API , the AWS CLI , or an AWS SDK , you can use the CreateTags EC2 API action to apply tags to existing resources .
Additionally , some resource-creating actions enable you to specify tags for a resource when the resource is created .
If tags can not be applied during resource creation , we roll back the resource creation process .
This ensures that resources are either created with tags or not created at all , and that no resources are left untagged at any time .
By tagging resources at the time of creation , you can eliminate the need to run custom tagging scripts after resource creation .
The following table describes the Amazon EC2 resources that can be tagged , and the resources that can be tagged on creation using the Amazon EC2 API , the AWS CLI , or an AWS SDK .
You can tag your EBS volumes on creation using the Volumes screen , or EBS snapshots using the Snapshots screen .
You can apply tag-based resource-level permissions in your IAM policies to the Amazon EC2 API actions that support tagging on creation to implement granular control over the users and groups that can tag resources on creation .
Your resources are properly secured from creation—tags are applied immediately to your resources , therefore any tag-based resource-level permissions controlling the use of resources are immediately eﬀective .
Your resources can be tracked and reported on more accurately .
You can enforce the use of tagging on new resources , and control which tag keys and values are set on your resources .
You can also apply resource-level permissions to the CreateTags and DeleteTags Amazon EC2 API actions in your IAM policies to control which tag keys and values are set on your existing resources .
For more information about tagging your resources for billing , see Using Cost Allocation Tags in the AWS Billing and Cost Management User Guide .
Tag restrictions The following basic restrictions apply to tags : • Maximum number of tags per resource – 50 • For each resource , each tag key must be unique , and each tag key can have only one value .
Tags with the aws : preﬁx do not count against your tags per resource limit .
For example , to delete snapshots that you tagged with a tag key called DeleteMe , you must use the DeleteSnapshots action with the resource identiﬁers of the snapshots , such as snap-1234567890abcdef0 .
You can tag public or shared resources , but the tags you assign are available only to your AWS account and not to the other accounts sharing the resource .
Tagging your resources for billing You can use tags to organize your AWS bill to reﬂect your own cost structure .
To do this , sign up to get your AWS account bill with tag key values included .
For more information about setting up a cost allocation report with tags , see The Monthly Cost Allocation Report in AWS Billing and Cost Management User Guide .
To see the cost of your combined resources , you can organize your billing information based on resources that have the same tag key values .
For example , you can tag several resources with a speciﬁc application name , and then organize your billing information to see the total cost of that application across several services .
For more information , see Using Cost Allocation Tags in the AWS Billing and Cost Management User Guide .
Note If you 've just enabled reporting , data for the current month is available for viewing after 24 hours .
Cost allocation tags can indicate which resources are contributing to costs , but deleting or deactivating resources does n't always reduce costs .
For example , snapshot data that is referenced by another snapshot is preserved , even if the snapshot that contains the original data is deleted .
For more information , see Amazon Elastic Block Store Volumes and Snapshots in the AWS Billing and Cost Management User Guide .
Note Elastic IP addresses that are tagged do not appear on your cost allocation report .
Working with tags using the console Using the Amazon EC2 console , you can see which tags are in use across all of your Amazon EC2 resources in the same Region .
You can view tags by resource and by resource type , and you can also view how many items of each resource type are associated with a speciﬁed tag .
You can also use the Amazon EC2 console to apply or remove tags from one or more resources at a time .
For ease of use and best results , use Tag Editor in the AWS Management Console , which provides a central , uniﬁed way to create and manage your tags .
For more information , see Working with Tag Editor in Getting Started with the AWS Management Console .
You can display the tags for an individual resource or for all resources .
When you select a resource from one of these lists ( for example , an instance ) , if the resource supports tags , you can view and manage its tags .
On most resource pages , you can view the tags in the Tags tab on the details pane .
You can add a column to the resource list that displays all values for tags with the same key .
This column enables you to sort and ﬁlter the resource list by the tag .
There are two ways to add a new column to the resource list to display your tags .
Displaying tags for all resources You can display tags across all resources by selecting Tags from the navigation pane in the Amazon EC2 console .
The following image shows the Tags pane , which lists all tags in use by resource type .
1118 Amazon Elastic Compute Cloud User Guide for Linux Instances Working with tags using the console Adding and deleting tags on an individual resource You can manage tags for an individual resource directly from the resource 's page .
From the navigation bar , select the Region that meets your needs .
This choice is important because some Amazon EC2 resources can be shared between Regions , while others ca n't .
In the Add/Edit Tags dialog box , specify the key and value for each tag , and then choose Save .
From the navigation bar , select the Region that meets your needs .
This choice is important because some Amazon EC2 resources can be shared between Regions , while others ca n't .
Select the resource from the resource list and choose Tags .
From the navigation bar , select the Region that meets your needs .
This choice is important because some Amazon EC2 resources can be shared between Regions , while others ca n't .
At the top of the content pane , choose Manage Tags .
In the resources list , select the check box next to each resource to which to add tags .
Under Add Tag , for Key and Value , type the tag key and values , and then choose Add Tag .
Note If you add a new tag with the same tag key as an existing tag , the new tag overwrites the existing tag .
From the navigation bar , select the Region that meets your needs .
This choice is important because some Amazon EC2 resources can be shared between Regions , while others ca n't .
To view the tags in use , select the Show/Hide Columns gear-shaped icon , and in the Show/Hide Columns dialog box , select the tag keys to view and choose Close .
1119 Amazon Elastic Compute Cloud User Guide for Linux Instances Working with tags using the CLI or API 5 .
In the resource list , select the check box next to each resource from which to remove tags .
From the navigation bar , select the Region for the instance .
This choice is important because some Amazon EC2 resources can be shared between Regions , while others ca n't .
Select the Region that meets your needs .
Select the AMI to use and choose Select .
On the Conﬁgure Instance Details page , conﬁgure the instance settings as necessary , and then choose Next : Add Storage .
On the Add Storage page , you can specify additional storage volumes for your instance .
Choose Add another tag to add more than one tag to your instance .
Choose Next : Conﬁgure Security Group when you are done .
On the Conﬁgure Security Group page , you can choose from an existing security group that you own , or let the wizard create a new security group for you .
Choose Review and Launch when you are done .
Select an existing key pair or create a new one , select the acknowledgment check box , and then choose Launch Instances .
Filtering a list of resources by tag You can ﬁlter your list of resources based on one or more tag keys and tag values .
c. Locate the tag in the list and choose Show Column .
Choose the ﬁlter icon in the top right corner of the column for the tag to display the ﬁlter list .
Select the tag values , and then choose Apply Filter to ﬁlter the results list .
Working with tags using the CLI or API Use the following to add , update , list , and delete the tags for your resources .
1120 Amazon Elastic Compute Cloud User Guide for Linux Instances Working with tags using the CLI or API Task AWS CLI AWS Tools for Windows PowerShell API Action Add or overwrite one or more tags .
The following examples demonstrate how to ﬁlter your instances using tags with the describe-instances command .
Note The way you enter JSON-formatted parameters on the command line diﬀers depending on your operating system .
Omit the single quotes when using the commands with the Windows command line .
For more information , see Specifying Parameter Values for the AWS Command Line Interface .
Example 1 : Describe instances with the speciﬁed tag key The following command describes the instances with a Stack tag , regardless of the value of the tag .
The following actions support tagging on creation .
Task AWS CLI AWS Tools for Windows PowerShell API Action Launch one or more instances .
create-volume New-EC2Volume CreateVolume The following examples demonstrate how to apply tags when you create resources .
Example 4 : Launch an instance and apply tags to the instance and volume The following command launches an instance and applies a tag with a key of webserver and value of production to the instance .
The following command launches an instance and applies a tag with a key of cost-center and a value of cc123 to both the instance and any EBS volume that 's created .
For example , there is a limit on the number of instances that you can launch in a Region .
Therefore , when you launch an instance in the US West ( Oregon ) Region , the request must not cause your usage to exceed your current instance limit in that Region .
The Amazon EC2 console provides limit information for the resources managed by the Amazon EC2 and Amazon VPC consoles .
You can request an increase for many of these limits .
Use the limit information that we provide to manage your AWS infrastructure .
Plan to request any limit increases in advance of the time that you 'll need them .
For more information , see Amazon EC2 endpoints and quotas in the Amazon Web Services General Reference .
Viewing your current limits Use the EC2 Limits page in the Amazon EC2 console to view the current limits for resources provided by Amazon EC2 and Amazon VPC , on a per-Region basis .
1123 Amazon Elastic Compute Cloud User Guide for Linux Instances Viewing your current limits 3 .
Locate the resource in the list .
You can use the search ﬁelds to ﬁlter the list by resource name or resource group .
The Current limit column displays the current maximum for the resource for your account .
1124 Amazon Elastic Compute Cloud User Guide for Linux Instances Requesting a limit increase Requesting a limit increase Use the Limits page in the Amazon EC2 console to request an increase in the limits for resources provided by Amazon EC2 or Amazon VPC , on a per-Region basis .
For more information , see Requesting a Quota Increase in the Service Quotas User Guide .
Select the resource in the list , and choose Request limit increase .
Complete the required ﬁelds on the limit increase form .
We 'll respond to you using the contact method that you speciﬁed .
Limits on email sent using port 25 Amazon EC2 restricts traﬃc on port 25 of all instances by default .
You can request that this restriction be removed .
Amazon EC2 usage reports AWS provides a free reporting tool called Cost Explorer that enables you to analyze the cost and usage of your EC2 instances and the usage of your Reserved Instances .
Cost Explorer is a free tool that you can use to view charts of your usage and costs .
You can view data up to the last 13 months , and forecast how much you are likely to spend for the next three months .
You can use Cost Explorer to see patterns in how much you spend on AWS resources over time , identify areas that need further inquiry , and see trends that you can use to understand your costs .
You also can specify time ranges for the data , and view time data by day or by month .
Here 's an example of some of the questions that you can answer when using Cost Explorer : • How much am I spending on instances of each instance type ?
• How is my instance usage distributed across Availability Zones ?
• How is my instance usage distributed across AWS accounts ?
In the navigation pane , choose Reports and select the report to view .
The report opens in Cost Explorer .
It provides a preconﬁgured view , based on ﬁxed ﬁlter settings , that displays information about your usage and cost trends .
1125 Amazon Elastic Compute Cloud User Guide for Linux Instances Usage Reports Note You must enable Cost Explorer in your account before you can use it .
For more information about working with reports in Cost Explorer , including saving reports , see Analyzing Your Costs with Cost Explorer .
1126 Amazon Elastic Compute Cloud User Guide for Linux Instances Troubleshooting launch issues Troubleshooting EC2 instances The following documentation can help you troubleshoot problems that you might have with your instance .
Troubleshooting instance launch issues The following issues prevent you from launching an instance .
Cause If you get an InstanceLimitExceeded error when you try to launch a new instance or restart a stopped instance , you have reached the limit on the number of instances that you can launch in a Region .
When you create your AWS account , we set default limits on the number of instances you can run on a per-Region basis .
1127 Amazon Elastic Compute Cloud User Guide for Linux Instances Insuﬃcient instance capacity Solution You can request an instance limit increase on a per-region basis .
Insuﬃcient instance capacity Description You get the InsufficientInstanceCapacity error when you try to launch a new instance or restart a stopped instance .
Cause If you get an InsufficientInstanceCapacity error when you try to launch an instance or restart a stopped instance , AWS does not currently have enough available On-Demand capacity to service your request .
Solution To resolve the issue , try the following : • Wait a few minutes and then submit your request again ; capacity can shift frequently .
• If you are launching instances into a cluster placement group , you can get an insuﬃcient capacity error .
Instance terminates immediately Description Your instance goes from the pending state to the terminated state immediately after restarting it .
Cause The following are a few reasons why an instance might immediately terminate : • You 've reached your EBS volume limit .
• The root EBS volume is encrypted and you do not have permissions to access the KMS key for decryption .
1128 Amazon Elastic Compute Cloud User Guide for Linux Instances Connecting to your instance Solution You can use the Amazon EC2 console or AWS Command Line Interface to get the termination reason .
In the Description tab , note the reason next to the State transition reason label .
To get the termination reason using the AWS Command Line Interface 1 .
The following code block shows an example of a StateReason response element .
To submit a request to increase your Amazon EBS volume limit , complete the AWS Support Center Create Case form .
• If the reason is Client.InternalError : Client error on launch , that typically indicates that the root volume is encrypted and that you do not have permissions to access the KMS key for decryption .
To get permissions to access the required KMS key , add the appropriate KMS permissions to your IAM user .
For more information , see Using Key Policies in AWS KMS in the AWS Key Management Service Developer Guide .
Troubleshooting connecting to your instance The following are possible problems you may have and error messages you may see while trying to connect to your instance .
Error connecting to your instance : Connection timed out If you try to connect to your instance and get an error message Network error : Connection timed out or Error connecting to [ instance ] , reason : - > Connection timed out : connect , try the following : • Check your security group rules .
You need a security group rule that allows inbound traﬃc from your public IPv4 address on the proper port .
In the Description tab at the bottom of the console page , next to Security groups , select view inbound rules to display the list of rules that are in eﬀect for the selected instance .
If your security group has a rule that allows inbound traﬃc from a single IP address , this address may not be static if your computer is on a corporate network or if you are connecting through an internet service provider ( ISP ) .
Instead , specify the range of IP addresses used by client computers .
If your security group does not have a rule that allows inbound traﬃc as described in the previous step , add a rule to your security group .
For more information about Security Group rules , see Security Group Rules in the Amazon VPC User Guide .
You need a route that sends all traﬃc destined outside the VPC to the internet gateway for the VPC .
In the Description tab , write down the values of VPC ID and Subnet ID .
Verify that there is an internet gateway attached to your VPC .
Otherwise , choose Create Internet Gateway to create an internet gateway .
1130 Amazon Elastic Compute Cloud User Guide for Linux Instances Error connecting to your instance : Connection timed out Select the internet gateway , and then choose Attach to VPC and follow the directions to attach it to your VPC .
On the Route Table tab , verify that there is a route with 0.0.0.0/0 as the destination and the internet gateway for your VPC as the target .
Choose Add route , use 0.0.0.0/0 as the destination and the internet gateway as the target .
The network ACLs must allow inbound and outbound traﬃc from your local IP address on the proper port .
The default network ACL allows all inbound and outbound traﬃc .
In the navigation pane , choose Subnets and select your subnet .
For Inbound Rules , verify that the rules allow traﬃc from your computer .
Otherwise , delete or modify the rule that is blocking traﬃc from your computer .
For Outbound Rules , verify that the rules allow traﬃc to your computer .
Otherwise , delete or modify the rule that is blocking traﬃc to your computer .
• If your computer is on a corporate network , ask your network administrator whether the internal ﬁrewall allows inbound and outbound traﬃc from your computer on port 22 ( for Linux instances ) or port 3389 ( for Windows instances ) .
If not , you can associate an Elastic IP address with your instance .
• Check the CPU load on your instance ; the server may be overloaded .
AWS automatically provides data such as Amazon CloudWatch metrics and instance status , which you can use to see how much CPU load is on your instance and , if necessary , adjust how your loads are handled .
• If your load is variable , you can automatically scale your instances up or down using Auto Scaling and Elastic Load Balancing .
• If you launched your instance from an older AMI , it may not be conﬁgured for DHCPv6 ( IPv6 addresses are not automatically recognized on the network interface ) .
For more information , see Conﬁgure IPv6 on Your Instances in the Amazon VPC User Guide .
1131 Amazon Elastic Compute Cloud User Guide for Linux Instances Error : unable to load key … Expecting : ANY PRIVATE KEY Error : unable to load key … Expecting : ANY PRIVATE KEY If you try to connect to your instance and get the error message , unable to load key .
Expecting : ANY PRIVATE KEY , the ﬁle in which the private key is stored is incorrectly conﬁgured .
If the private key ﬁle ends in .pem , it might still be incorrectly conﬁgured .
A possible cause for an incorrectly conﬁgured private key ﬁle is a missing certiﬁcate .
If the private key ﬁle is incorrectly conﬁgured , follow these steps to resolve the error 1 .
Add the new key pair to your instance .
Connect to your instance using the new key pair .
Error : User key not recognized by server If you use SSH to connect to your instance • Use ssh -vvv to get triple verbose debugging information while connecting : ssh -vvv -i [ your key name ] .pem ec2-user @ [ public DNS address of your instance ] .compute-1.amazonaws.com The following sample output demonstrates what you might see if you were trying to connect to your instance with a key that was not recognized by the server : open/ANT/myusername/.ssh/known_hosts ) .
Note In PuTTYgen , load your private key ﬁle and select Save Private Key rather than Generate .
• Verify that you are connecting with the appropriate user name for your AMI .
Enter the user name in the Host name box in the PuTTY Conﬁguration window .
• Verify that you have an inbound security group rule to allow inbound traﬃc to the appropriate port .
Error : Host key not found , Permission denied ( publickey ) , or Authentication failed , permission denied If you connect to your instance using SSH and get any of the following errors , Host key not found in [ directory ] , Permission denied ( publickey ) , or Authentication failed , permission denied , verify that you are connecting with the appropriate user name for your AMI and that you have speciﬁed the proper private key ( .pem ) ﬁle for your instance .
For example , to use an SSH client to connect to an Amazon Linux instance , use the following command : ssh -i /path/my-key-pair.pem ec2-user @ public-dns-hostname 1133 Amazon Elastic Compute Cloud User Guide for Linux Instances Error : Unprotected private key ﬁle Conﬁrm that you are using the private key ﬁle that corresponds to the key pair that you selected when you launched the instance .
In the Description tab , verify the value of Key pair name .
If you did not specify a key pair when you launched the instance , you can terminate the instance and launch a new instance , ensuring that you specify a key pair .
If this is an instance that you have been using but you no longer have the .pem ﬁle for your key pair , you can replace the key pair with a new one .
If you generated your own key pair , ensure that your key generator is set up to create RSA keys .
If you get a Permission denied ( publickey ) error and none of the above applies ( for example , you were able to connect previously ) , the permissions on the home directory of your instance may have been changed .
Permissions for /home/ec2-user/.ssh/authorized_keys must be limited to the owner only .
Stop your instance and detach the root volume .
Launch a temporary instance in the same Availability Zone as your current instance ( use a similar or the same AMI as you used for your current instance ) , and attach the root volume to the temporary instance .
Connect to the temporary instance , create a mount point , and mount the volume that you attached .
From the temporary instance , check the permissions of the /home/ec2-user/ directory of the attached volume .
Unmount the volume , detach it from the temporary instance , and re-attach it to the original instance .
Ensure that you specify the correct device name for the root volume ; for example , /dev/ xvda .
If you no longer require the temporary instance , you can terminate it .
Error : Unprotected private key ﬁle Your private key ﬁle must be protected from read and write operations from any other users .
If your private key can be read or written to by anyone but you , then SSH ignores your key and you see the following warning message below .
This private key will be ignored .
If you see a similar message when you try to log in to your instance , examine the ﬁrst line of the error message to verify that you are using the correct public key for your instance .
The above example uses the private key .ssh/my_private_key.pem with ﬁle permissions of 0777 , which allow anyone to read or write to this ﬁle .
This permission level is very insecure , and so SSH ignores this key .
To ﬁx the error , execute the following command , substituting the path for your private key ﬁle .
To resolve the error , the private key must be in the PEM format .
Use the following command to create the private key in the PEM format : ssh-keygen -m PEM Error : Server refused our key or No supported authentication methods available If you use PuTTY to connect to your instance and get either of the following errors , Error : Server refused our key or Error : No supported authentication methods available , verify that you are connecting with the appropriate user name for your AMI .
Type the user name in User name in the PuTTY Conﬁguration window .
1135 Amazon Elastic Compute Cloud User Guide for Linux Instances Can not connect using my browser Can not connect using my browser The Amazon EC2 console provides an option to connect to your instances directly from your browser using a Java SSH client .
If your browser does n't support NPAPI , then you get an error message NPAPI deprecation on Chrome when you connect .
However , recent versions of these browsers also do not support NPAPI , so you can not use them to connect to your instance and you must choose a diﬀerent method to connect to your instance .
For more information , see the following resources : • General : NPAPI Wikipedia article • Chrome : NPAPI deprecation article • Firefox : NPAPI deprecation article • Safari : NPAPI deprecation article Can not ping instance The ping command is a type of ICMP traﬃc — if you are unable to ping your instance , ensure that your inbound security group rules allow ICMP traﬃc for the Echo Request message from all sources , or from the computer or instance from which you are issuing the command .
If you are unable to issue a ping command from your instance , ensure that your outbound security group rules allow ICMP traﬃc for the Echo Request message to all destinations , or to the host that you are attempting to ping .
Error : Server unexpectedly closed network connection If you are connecting to your instance with Putty and you receive the error `` Server unexpectedly closed network connection , '' verify that you have enabled keepalives on the Connection page of the Putty Conﬁguration to avoid being disconnected .
Some servers disconnect clients when they do not receive any data within a speciﬁed period of time .
If you still experience issues after enabling keepalives , try to disable Nagle 's algorithm on the Connection page of the Putty Conﬁguration .
Troubleshooting stopping your instance If you have stopped your Amazon EBS-backed instance and it appears stuck in the stopping state , there may be an issue with the underlying host computer .
There is no cost for any instance usage while an instance is not in the running state .
Force the instance to stop using either the console or the AWS CLI .
Creating a replacement instance To attempt to resolve the problem while you are waiting for assistance from the Amazon EC2 forum or the Support Center , create a replacement instance .
Create an AMI of the stuck instance , and launch a new instance using the new AMI .
In the navigation pane , choose Instances and select the stuck instance .
Launch a new instance from the AMI and verify that the new instance is working .
If the instance also gets stuck terminating , Amazon EC2 automatically forces it to terminate within a few hours .
Verify that the new instance is working .
Select each volume and write down its volume ID .
Be sure to note which volume is the root volume .
1137 Amazon Elastic Compute Cloud User Guide for Linux Instances Terminating your instance 3 .
Select the snapshot that you just created , and choose Actions , Create Volume .
Launch an instance with the same operating system as the stuck instance .
Note the volume ID and device name of its root volume .
In the navigation pane , choose Instances , select the instance that you just launched , choose Actions , Instance State , and then choose Stop .
In the navigation pane , choose Volumes , select the root volume of the stopped instance , and choose Actions , Detach Volume .
Select the root volume that you created from the stuck instance , choose Actions , Attach Volume , and attach it to the new instance as its root volume ( using the device name that you wrote down ) .
In the navigation pane , choose Instances and select the replacement instance .
Verify that the instance is working .
If the instance also gets stuck terminating , Amazon EC2 automatically forces it to terminate within a few hours .
Troubleshooting terminating ( shutting down ) your instance You are not billed for any instance usage while an instance is not in the running state .
In other words , when you terminate an instance , you stop incurring charges for that instance as soon as its state changes to shutting-down .
Delayed instance termination If your instance remains in the shutting-down state longer than a few minutes , it might be delayed due to shutdown scripts being run by the instance .
Another possible cause is a problem with the underlying host computer .
If your instance remains in the shutting-down state for several hours , Amazon EC2 treats it as a stuck instance and forcibly terminates it .
If it appears that your instance is stuck terminating and it has been longer than several hours , post a request for help to the Amazon EC2 forum .
To help expedite a resolution , include the instance ID and describe the steps that you 've already taken .
Terminated instance still displayed After you terminate an instance , it remains visible for a short while before being deleted .
If the entry is not deleted after several hours , contact Support .
Automatically launch or terminate instances If you terminate all your instances , you may see that we launch a new instance for you .
If you launch an instance , you may see that we terminate one of your instances .
If you stop an instance , you may see that we terminate the instance and launch a new instance .
Generally , these behaviors mean that you 've used Amazon EC2 Auto Scaling or Elastic Beanstalk to scale your computing resources automatically based on criteria that you 've deﬁned .
For more information , see the Amazon EC2 Auto Scaling User Guide or the AWS Elastic Beanstalk Developer Guide .
1138 Amazon Elastic Compute Cloud User Guide for Linux Instances Failed status checks Troubleshooting instances with failed status checks The following information can help you troubleshoot issues if your instance fails a status check .
First determine whether your applications are exhibiting any problems .
If you verify that the instance is not running your applications as expected , review the status check information and the system logs .
In the details pane , choose Status Checks to see the individual results for all System Status Checks and Instance Status Checks .
If a system status check has failed , you can try one of the following options : 1139 Amazon Elastic Compute Cloud User Guide for Linux Instances Retrieve the system logs • Create an instance recovery alarm .
• If you changed the instance type to an instance built on the Nitro System ( p. 188 ) , status checks fail if you migrated from an instance that does not have the required ENA and NVMe drivers .
• If your instance is in an Auto Scaling group , the Amazon EC2 Auto Scaling service automatically launches a replacement instance .
For more information , see Health Checks for Auto Scaling Instances in the Amazon EC2 Auto Scaling User Guide .
Retrieve the system logs If an instance status check fails , you can reboot the instance and retrieve the system logs .
The logs may reveal an error that can help you troubleshoot the issue .
Rebooting clears unnecessary information from the logs .
To reboot an instance and retrieve the system log 1 .
It may take a few minutes for your instance to reboot .
Verify that the problem still exists ; in some cases , rebooting may resolve the problem .
When the instance is in the running state , choose Actions , Instance Settings , Get System Log .
6. Review the log that appears on the screen , and use the list of known system log error statements below to troubleshoot your issue .
If your experience diﬀers from our check results , or if you are having an issue with your instance that our checks did not detect , choose Submit feedback on the Status Checks tab to help us improve our detection tests .
If your issue is not resolved , you can post your issue to the Amazon EC2 forum .
Troubleshooting system log errors for Linux-based instances For Linux-based instances that have failed an instance status check , such as the instance reachability check , verify that you followed the steps above to retrieve the system log .
The following list contains some common system log errors and suggested actions you can take to resolve the issue for each error .
The problem will probably occur again unless you change the instance type .
• Reboot the instance to return it to an unimpaired status .
The problem will probably occur again unless you change the instance type .
Note It 's good practice to snapshot your Amazon EBS volumes often .
This dramatically decreases the risk of data loss as a result of failure .
Note Data can not be recovered .
Instance 1143 Amazon Elastic Compute Cloud User Guide for Linux Instances I/O ERROR : neither local nor remote disk ( Broken distributed block device ) For this instance type Do this store volumes are directly tied to single host and single disk failures .
Potential causes Instance type Potential cause Amazon EBS-backed A failed Amazon EBS volume Instance store-backed A failed physical drive Suggested action Terminate the instance and launch a new instance .
For an Amazon EBS-backed instance you can recover data from a recent snapshot by creating an image from it .
Any data added after the snapshot can not be recovered .
request_module : runaway loop modprobe ( Looping legacy kernel modprobe on older Linux versions ) This condition is indicated by a system log similar to the one shown below .
Modify the kernel and ramdisk attributes to use a newer kernel .
Potential causes Incompatible kernel and userland Suggested actions For this instance type Do this Amazon EBS-backed Use the following procedure : 1145 Amazon Elastic Compute Cloud User Guide for Linux Instances '' FATAL : Could not load /lib/modules '' or `` BusyBox '' ( Missing kernel modules ) For this instance type Do this 1 .
Gave up waiting for root device .
( initramfs ) Potential causes One or more of the following conditions can cause this problem : • Missing ramdisk • Missing correct modules from ramdisk • Amazon EBS root volume not correctly attached as /dev/sda1 1146 Amazon Elastic Compute Cloud User Guide for Linux Instances ERROR Invalid kernel ( EC2 incompatible kernel ) Suggested actions For this instance type Do this Amazon EBS-backed Use the following procedure : 1 .
Select corrected ramdisk for the Amazon EBS volume .
Detach the volume and repair it .
Attach the volume to the instance .
Modify the AMI to use the corrected ramdisk .
Terminate the instance and launch a new instance with the correct ramdisk .
ERROR Invalid kernel ( EC2 incompatible kernel ) This condition is indicated by a system log similar to the one shown below .
Modify the AMI by correcting the kernel .
Terminate the instance and launch a new instance with the correct kernel .
Create an AMI with the correct kernel .
fsck : No such ﬁle or directory while trying to open .
( File system not found ) This condition is indicated by a system log similar to the one shown below .
*** Dropping you to a shell ; the system will reboot 1148 Amazon Elastic Compute Cloud User Guide for Linux Instances General error mounting ﬁlesystems ( failed mount ) *** when you leave the shell .
The sixth ﬁeld in the fstab deﬁnes availability requirements of the mount – a nonzero value implies that an fsck will be done on that volume and must succeed .
Using this ﬁeld can be problematic in Amazon EC2 because a failure typically results in an interactive console prompt that is not currently available in Amazon EC2 .
Use care with this feature and read the Linux man page for fstab .
Detach any errant Amazon EBS volumes and the reboot instance .
General error mounting ﬁlesystems ( failed mount ) This condition is indicated by a system log similar to the one shown below .
Setting up new root fs no fstab.sys , mounting internal defaults Switching to new root and running init .
1150 Amazon Elastic Compute Cloud User Guide for Linux Instances VFS : Unable to mount root fs on unknownblock ( Root ﬁlesystem mismatch ) For this instance type Do this 5 .
Detach the volume from the known working instance .
Attach the volume to the stopped instance .
VFS : Unable to mount root fs on unknown-block ( Root ﬁlesystem mismatch ) This condition is indicated by a system log similar to the one shown below .
Suggested actions For this instance type Do this Amazon EBS-backed Do one of the following : • Stop and then restart the instance .
1151 Amazon Elastic Compute Cloud User Guide for Linux Instances Error : Unable to determine major/minor number of root device .
• Refer to the documentation for your Linux distribution to check for known update bugs .
Amazon Elastic Compute Cloud User Guide for Linux Instances XENBUS : Device with no driver .
Modify the AMI to address device mapping issues .
Terminate the instance and launch a new instance from the AMI you created .
This condition is indicated by a system log similar to the one shown below .
Modify the AMI to address device mapping issues .
Terminate the instance and launch a new instance using the AMI you created .
days without being checked , check forced ( File system check required ) This condition is indicated by a system log similar to the one shown below .
Checking filesystems Checking all file systems .
A ﬁlesystem check can take a long time depending on the size of the root ﬁlesystem .
( Missing device ) This condition is indicated by a system log similar to the one shown below .
[ 39 ; 49m Potential causes • Ramdisk looking for missing drive • Filesystem consistency check forced • Drive failed or detached 1154 Amazon Elastic Compute Cloud User Guide for Linux Instances GRUB prompt ( grubdom > ) Suggested actions For this instance type Do this Amazon EBS-backed Try one or more of the following to resolve the issue : • Stop the instance , attach the volume to an existing running instance .
Instance store-backed Try one or more of the following to resolve the issue : • Rebundle ramdisk with correct tooling .
• Unsupported ﬁlesystem used to store your GRUB conﬁguration ﬁle ( for example , converting your root ﬁle system to a type that is not supported by an earlier version of GRUB ) .
• Unsupported ﬁlesystem used to store your GRUB conﬁguration ﬁle ( for example , converting your root ﬁle system to a type that is not supported by an earlier version of GRUB ) .
Verify that your version of GRUB supports the underlying ﬁle system type and upgrade GRUB if necessary .
Terminate the instance and launch a new one using the AMI that you created .
Verify that your version of GRUB supports the underlying ﬁle system type and upgrade GRUB if necessary .
Instance store-backed Option 1 : Modify the AMI and relaunch the instance : 1156 For this instance type Amazon Elastic Compute Cloud User Guide for Linux Instances Bringing up interface eth0 : Device eth0 has diﬀerent MAC address than expected , ignoring .
Verify that your version of GRUB supports the underlying ﬁle system type and upgrade GRUB if necessary .
Terminate the instance and launch a new instance using the AMI you created .
Note To recover data from the existing instance , contact AWS Support .
Potential causes There is a hardcoded interface MAC in the AMI conﬁguration Suggested actions For this instance type Do this Amazon EBS-backed Do one of the following : • Modify the AMI to remove the hardcoding and relaunch the instance .
• Modify the instance to remove the hardcoded MAC address .
OR 1157 Amazon Elastic Compute Cloud User Guide for Linux Instances Unable to load SELinux Policy .
Attach the volume to another instance and modify the volume to remove the hardcoded MAC address .
Attach the volume to the original instance .
Instance store-backed Do one of the following : • Modify the instance to remove the hardcoded MAC address .
( SELinux misconﬁguration ) This condition is indicated by a system log similar to the one shown below .
Potential causes SELinux has been enabled in error : • Supplied kernel is not supported by GRUB • Fallback kernel does not exist Suggested actions For this instance type Do this Amazon EBS-backed Use the following procedure : 1 .
Attach the root volume to another running Linux instance ( later referred to as a recovery instance ) .
Connect to the recovery instance and mount the failed instance 's root volume .
1158 Amazon Elastic Compute Cloud User Guide for Linux Instances XENBUS : Timeout connecting to devices ( Xenbus timeout ) For this instance type Do this 5 .
Disable SELinux on the mounted root volume .
Note On some systems , you disable SELinux by setting SELINUX=disabled in the /mount_point/etc/sysconfig/ selinux ﬁle , where mount_point is the location that you mounted the volume on your recovery instance .
Unmount and detach the root volume from the recovery instance and reattach it to the original instance .
XENBUS : Timeout connecting to devices ( Xenbus timeout ) This condition is indicated by a system log similar to the one shown below .
Potential causes • The block device is not connected to the instance • This instance is using an old instance kernel Suggested actions For this instance type Do this Amazon EBS-backed Do one of the following : • Modify the AMI and instance to use a modern kernel and relaunch the instance .
1159 Amazon Elastic Compute Cloud User Guide for Linux Instances Troubleshooting an unreachable instance For this instance type Do this Instance store-backed Do one of the following : • Terminate the instance .
Troubleshooting an unreachable instance You can use the following methods to troubleshoot an unreachable instance .
Warning For Windows instances , this operation performs a hard reboot that might result in data corruption .
Instance console output Console output is a valuable tool for problem diagnosis .
It is especially useful for troubleshooting kernel problems and service conﬁguration issues that could cause an instance to terminate or become unreachable before its SSH daemon can be started .
For Linux/Unix , the instance console output displays the exact console output that would normally be displayed on a physical monitor attached to a computer .
The posted output is not continuously updated ; only when it is likely to be of the most value .
For Windows instances , the instance console output includes the last three system event log errors .
You can optionally retrieve the latest serial console output at any time during the instance lifecycle .
Note Only the most recent 64 KB of posted output is stored , which is available for at least 1 hour after the last posting .
Only the instance owner can access the console output .
You can retrieve the console output for your instances using the console or the command line .
1160 Amazon Elastic Compute Cloud User Guide for Linux Instances Capture a screenshot of an unreachable instance To get console output using the console 1 .
To get console output using the command line You can use one of the following commands .
Capture a screenshot of an unreachable instance If you are unable to reach your instance via SSH or RDP , you can capture a screenshot of your instance and view it as an image .
The image can provide visibility as to the status of the instance , and allows for quicker troubleshooting .
You can generate screenshots while the instance is running or after it has crashed .
There is no data transfer cost for this screenshot .
The image is generated in JPG format and is no larger than 100 kb .
This feature is not supported when the instance is using an NVIDIA GRID driver or on bare metal instances ( instances of type *.metal ) .
1161 Amazon Elastic Compute Cloud User Guide for Linux Instances Instance recovery when a host computer fails 4 .
To capture a screenshot using the command line You can use one of the following commands .
You are notiﬁed of such an event ahead of time by email .
Back up any important data on your instance store volumes to Amazon EBS or Amazon S3 .
Create an AMI from the instance .
Back up important data to Amazon EBS or Amazon S3 .
Restore any important data to the new instance .
Booting from the wrong volume In some situations , you may ﬁnd that a volume other than the volume attached to /dev/xvda or /dev/ sda has become the root volume of your instance .
This can happen when you have attached the root volume of another instance , or a volume created from the snapshot of a root volume , to an instance with an existing root volume .
This is due to how the initial ramdisk in Linux works .
It chooses the volume deﬁned as / in the /etc/ fstab , and in some distributions , this is determined by the label attached to the volume partition .
To solve this , use the same e2label command to change the label of the attached volume that you do not want to boot from .
However , if both volumes come from the same snapshot , or the secondary is created from a snapshot of the primary volume , they share a UUID .
Use the e2label command to change the label of the volume to something other than / .
Verify that the volume has the new label .
Important If you intend to detach the volume with the new label and return it to another instance to use as the root volume , you must perform the above procedure again and change the volume label back to its original value .
Otherwise , the other instance does not boot because the ramdisk is unable to ﬁnd the volume with the label / .
1163 Amazon Elastic Compute Cloud User Guide for Linux Instances EC2Rescue for Linux Using EC2Rescue for Linux EC2Rescue for Linux is an easy-to-use , open-source tool that can be run on an Amazon EC2 Linux instance to diagnose and troubleshoot common issues using its library of over 100 modules .
A few generalized use cases for EC2Rescue for Linux include gathering syslog and package manager logs , collecting resource utilization data , and diagnosing/remediating known problematic kernel parameters and common OpenSSH issues .
( Optional ) Verify the Signature of EC2Rescue for Linux The following is the recommended process of verifying the validity of the EC2Rescue for Linux package for Linux-based operating systems .
When you download an application from the internet , we recommend that you authenticate the identity of the software publisher and check that the application has not been altered or corrupted after it was published .
This protects you from installing a version of the application that contains a virus or other malicious code .
If , after running the steps in this topic , you determine that the software for EC2Rescue for Linux is altered or corrupted , do not run the installation ﬁle .
AWS publishes a public key and signatures that you can use to verify the downloaded EC2Rescue for Linux package .
The ﬁrst step is to establish trust with the software publisher .
Download the public key of the software publisher , check that the owner of the public key is who they claim to be , and then add the public key to your keyring .
After you establish the authenticity of the public key , you can use it to verify the signature of the application .
If the GPG tools are not installed , you see an error stating that the command can not be found .
To install GPG tools on Debian-based Linux • From a terminal , run the following command : 1165 Amazon Elastic Compute Cloud User Guide for Linux Instances ( Optional ) Verify the Signature of EC2Rescue for Linux apt-get install gnupg2 To install GPG tools on Red Hat–based Linux • From a terminal , run the following command : yum install gnupg2 Authenticate and Import the Public Key The next step in the process is to authenticate the EC2Rescue for Linux public key and add it as a trusted key in your GPG keyring .
Verify the signature by running the following command at a command prompt in the directory where you saved ec2rl.tgz.sig and the EC2Rescue for Linux installation ﬁle .
gpg : There is no indication that the signature belongs to the owner .
If the output includes the phrase BAD signature , check whether you performed the procedure correctly .
If you continue to get this response , contact Amazon Web Services and do not run the installation ﬁle that you downloaded previously .
The following are details about the warnings that you might see : • WARNING : This key is not certiﬁed with a trusted signature !
There is no indication that the signature belongs to the owner .
This refers to your personal level of trust in your belief that you possess an authentic public key for EC2Rescue for Linux .
In an ideal world , you would visit an Amazon Web Services oﬃce and receive the key in person .
In this case , the website is an Amazon Web Services website .
This means that the speciﬁc key is not `` ultimately trusted '' by you ( or by other people whom you trust ) .
Working with EC2Rescue for Linux The following are common tasks you can perform to get started using this tool .
Example Example : Run all modules To run all modules , run EC2Rescue for Linux with no options : ./ec2rl run Some modules require root access .
The output of the EC2Rescue for Linux commands should provide the commands that you need to use .
Creating Backups Create a backup for your instance , one or more volumes , or a speciﬁc device ID using the following commands .
Example Example : Display the general help ./ec2rl help Example Example : List the available modules ./ec2rl list Example Example : Display the help for a speciﬁc module ./ec2rl help module_name For example , use the following command to show the help ﬁle for the dig module : ./ec2rl help dig Developing EC2Rescue Modules Modules are written in YAML , a data serialization standard .
Adding Module Attributes The following table lists the available module attributes .
Attribute Description name The name of the module .
The name should be less than or equal to 18 characters in length .
version The version number of the module .
This value should be less than or equal to 50 characters in length .
helptext The extended description of the module .
Each line should be less than or equal to 75 characters in length .
If the module consumes arguments , required or optional , include them in the helptext value .
! str | Collect output from ps for system analysis Consumes -- times= for number of times to repeat Consumes -- period= for time period between repetition placement The stage in which the module should be run .
remediation Indicates whether the module supports remediation .
Supported values are True or False .
The module defaults to False if this is absent , making it an optional attribute for those modules that do not support remediation .
content The entirety of the script code .
constraint The name of the object containing the constraint values .
domain A descriptor of how the module is grouped or classiﬁed .
The set of included modules uses the following domains : • application • net • os • performance class A descriptor of the type of task performed by the module .
The set of included modules uses the following classes : • collect ( collects output from programs ) • diagnose ( pass/fail based on a set of criteria ) • gather ( copies ﬁles and writes to speciﬁc ﬁle ) 1170 Amazon Elastic Compute Cloud User Guide for Linux Instances Developing EC2Rescue Modules Attribute Description distro The list of Linux distributions that this module supports .
The set of included modules uses the following distributions : • alami ( Amazon Linux ) • rhel • ubuntu • suse required The required arguments that the module is consuming from the CLI options .
optional The optional arguments that the module can use .
software The software executables used in the module .
This attribute is intended to specify software that is not installed by default .
The EC2Rescue for Linux logic ensures that these programs are present and executable before running the module .
package The source software package for an executable .
This attribute is intended to provide extended details on the package with the software , including a URL for downloading or getting further information .
sudo Indicates whether root access is required to run the module .
You do not need to implement sudo checks in the module script .
If the value is true , then the EC2Rescue for Linux logic only runs the module when the executing user has root access .
perﬁmpact Indicates whether the module can have signiﬁcant performance impact upon the environment in which it is run .
If the value is true and the -perfimpact=true argument is not present , then the module is skipped .
Adding Environment Variables The following table lists the available environment variables .
This path can be used to locate the lib directory and use vendored Python modules .
The directory where all output is stored .
The root directory for placing gathered module data .
EC2RL_VIRT_TYPE The virtualization type as provided by the instance metadata .
This is generated via the functions.bash and is only available for modules that have sourced it .
• The ! ec2rlcore.module.Module tag tells the YAML parser which constructor to call when creating the object from the data stream .
! str tag tells the YAML parser to not attempt to determine the type of data , and instead interpret the content as a string literal .
This is important for modules because indentation and newline characters are kept .
• The YAML standard indent is two spaces , which can be seen in the following examples .
Ensure that you maintain standard indentation ( for example , four spaces for Python ) for your script and then indent the entire content two spaces inside the module ﬁle .
Incorrect usage could negatively impact your instance .
Sending a diagnostic interrupt to an instance could trigger an instance to crash and reboot , which could lead to the loss of data .
You can send a diagnostic interrupt to an unreachable or unresponsive Linux instance to manually trigger a kernel panic .
Linux operating systems typically crash and reboot when a kernel panic occurs .
The speciﬁc behavior of the operating system depends on its conﬁguration .
A kernel panic can also be used to cause the 1173 Amazon Elastic Compute Cloud User Guide for Linux Instances Supported instance types instance 's operating system kernel to perform tasks , such as generating a crash dump ﬁle .
You can then use the information in the crash dump ﬁle to conduct root cause analysis and debug the instance .
The crash dump data is generated locally by the operating system on the instance itself .
Before sending a diagnostic interrupt to your instance , we recommend that you consult the documentation for your operating system and then make the necessary conﬁguration changes .
This ensures that it performs the actions that you need when a kernel panic occurs .
Conﬁgure the kernel to reserve an appropriate amount of memory for the secondary kernel .
The amount of memory to reserve depends on the total available memory of your instance .
Open the /etc/default/grub ﬁle using your preferred text editor , locate the line that starts with GRUB_CMDLINE_LINUX_DEFAULT , and then add the crashkernel parameter in the following format : crashkernel=memory_to_reserve .
Save the changes and close the grub ﬁle .
You must conﬁgure the kernel to crash when it receives the unknown NMI .
Open the /etc/sysctl.conf ﬁle using your preferred text editor and add the following .
Reboot and reconnect to your instance .
Verify that the kernel has been booted with the correct crashkernel parameter .
Verify that the kdump service is running .
Conﬁgure the kernel to reserve an appropriate amount of memory for the secondary kernel .
The amount of memory to reserve depends on the total available memory of your instance .
You must conﬁgure the kernel to crash when it receives the unknown NMI .
Open the /etc/sysctl.conf ﬁle using your preferred text editor and add the following .
Reboot and reconnect to your instance .
Verify that the kernel has been booted with the correct crashkernel parameter .
1175 Amazon Elastic Compute Cloud User Guide for Linux Instances Sending a diagnostic interrupt $ grep crashkernel /proc/cmdline The following example output indicates successful conﬁguration .
Verify that the kdump service is running .
You must conﬁgure the kernel to crash when it receives the unknown NMI .
Add the following to your conﬁguration ﬁle .
kernel.unknown_nmi_panic=1 Sending a diagnostic interrupt After you have completed the necessary conﬁguration changes , you can send a diagnostic interrupt to your instance using the AWS CLI or Amazon EC2 API .
We also update the documentation frequently to address the feedback that you send us .
Current API version : 2016-11-15 Feature API Version Description Windows Server on Dedicated Hosts 2016-11-15 You can use Windows Server AMIs provided by Amazon to run the latest versions of Windows Server on Dedicated Hosts .
07 April 2020 Self-service option to enable Local Zones 2016-11-15 You can enable Local Zones using the AWS Management Console or the AWS CLI .
14 February 2020 Platform details and billing information associated with an AMI 2016-11-15 You can determine the platform details and billing 6 February information associated with an Amazon Machine 2020 Image ( AMI ) before you launch an On-Demand Instance or Spot Instance , or purchase a Reserved Instance .
Stop and start a Spot Instance 2016-11-15 You can now stop your Spot Instances backed by Amazon EBS and start them at will , instead of relying on the stop interruption behavior .
13 January 2020 Resource tagging 2016-11-15 You can tag egress-only internet gateways , local gateways , local gateway route tables , local gateway virtual interfaces , local gateway virtual interface groups , local gateway route table VPC associations , and local gateway route table virtual interface group associations .
16 December 2019 1177 Release Date Amazon Elastic Compute Cloud User Guide for Linux Instances Feature API Version Description Recommendations for instance types 2016-11-15 AWS Compute Optimizer provides Amazon EC2 instance recommendations to help you improve performance , save money , or both .
For more information , see the AWS Outposts User Guide .
3 December 2019 Dedicated Hosts and host resource groups 2016-11-15 Dedicated Hosts can now be used with host resource groups .
2 December 2019 Default credit speciﬁcation at the account level 2016-11-15 You can set the default credit speciﬁcation per burstable performance instance family at the account level per AWS Region .
21 November 2019 Amazon EBS fast snapshot restore 2016-11-15 You can enable fast snapshot restores on an EBS snapshot to ensure that EBS volumes created from the snapshot are fully-initialized at creation and instantly deliver all of their provisioned performance .
15 November 2019 1178 Release Date Amazon Elastic Compute Cloud User Guide for Linux Instances Feature API Version Description Hibernation support for On-Demand Windows instances 2016-11-15 You can hibernate On-Demand Windows instances .
14 October 2019 Queued purchases of Reserved Instances 2016-11-15 You can queue the purchase of a Reserved Instance up to three years in advance .
14 August 2019 Capacity optimized allocation strategy 2016-11-15 Using EC2 Fleet or Spot Fleet , you can now launch Spot Instances from Spot pools with optimal capacity for the number of instances that are launching .
27 June 2019 1179 Release Date Amazon Elastic Compute Cloud User Guide for Linux Instances Feature API Version Description Host recovery 2016-11-15 Automatically restart your instances on a new 5 June host in the event of an unexpected hardware 2019 failure on a Dedicated Host .
29 May 2019 Amazon EBS encryption by default 2016-11-15 After you enable encryption by default in a Region , all new EBS volumes you create in the Region are encrypted using the default CMK for EBS encryption .
8 May 2019 Elastic Fabric Adapter 2016-11-15 You can attach an Elastic Fabric Adapter to your instances to accelerate High Performance Computing ( HPC ) applications .
13 February 2019 Partition placement groups 2016-11-15 Partition placement groups spread instances across logical partitions , ensuring that instances in one partition do not share underlying hardware with instances in other partitions .
7 December 2018 1180 Release Date Amazon Elastic Compute Cloud User Guide for Linux Instances Feature API Version Description Hibernate EC2 Linux instances 2016-11-15 You can hibernate a Linux instance if it 's enabled 28 for hibernation and it meets the hibernation November prerequisites .
Amazon Elastic Inference Accelerators 2016-11-15 You can attach an Amazon EI accelerator to your instances to add GPU-powered acceleration to reduce the cost of running deep learning inference .
The instant request returns the launched instances in the API response , and takes no further action , enabling you to control if and when instances are launched .
6 November 2018 Spot savings information 2016-11-15 You can view the savings made from using Spot Instances for a single Spot Fleet or for all Spot Instances .
5 November 2018 Console support for optimizing CPU options 2016-11-15 When you launch an instance , you can optimize the CPU options to suit speciﬁc workloads or business needs using the Amazon EC2 console .
31 October 2018 1181 Release Date Amazon Elastic Compute Cloud User Guide for Linux Instances Feature API Version Description Console support for creating a launch template from an instance 2016-11-15 You can create a launch template using an instance as the basis for a new launch template using the Amazon EC2 console .
This allows you to create and manage capacity reservations independently from the billing discounts oﬀered by Reserved Instances ( RI ) .
After you bring the address range to AWS , it appears in your account as an address pool .
You can create an Elastic IP address from your address pool and use it with your AWS resources .
11 October 2018 Dedicated Host tag on create and console support 2016-11-15 You can tag your Dedicated Hosts on creation , and you can manage your Dedicated Host tags using the Amazon EC2 console .
They oﬀer bare metal performance with direct access to host hardware .
25 September 2018 Console support for scheduled scaling for Spot Fleet 2016-11-15 Increase or decrease the current capacity of the ﬂeet based on the date and time .
20 September 2018 T3 instances 2016-11-15 T3 instances are the next generation burstable general-purpose instance type that provide a baseline level of CPU performance with the ability to burst CPU usage at any time for as long as required .
21 August 2018 1182 Release Date Amazon Elastic Compute Cloud User Guide for Linux Instances Feature API Version Description Allocation strategies for EC2 Fleets 2016-11-15 You can specify whether On-Demand capacity is fulﬁlled by price ( lowest price ﬁrst ) or priority ( highest priority ﬁrst ) .
You can specify the number of Spot pools across which to allocate your target Spot capacity .
You can specify the number of Spot pools across which to allocate your target Spot capacity .
These instances come with NVME instance store volumes .
Automate snapshot lifecycle 2016-11-15 You can use Amazon Data Lifecycle Manager to automate creation and deletion of snapshots for your EBS volumes .
12 July 2018 Launch template CPU options 2016-11-15 When you create a launch template using the command line tools , you can optimize the CPU options to suit speciﬁc workloads or business needs .
17 May 2018 Get latest console output 2016-11-15 You can retrieve the latest console output for some instance types when you use the getconsole-output AWS CLI command .
9 May 2018 1183 Release Date Amazon Elastic Compute Cloud User Guide for Linux Instances Feature API Version Description Optimize CPU options 2016-11-15 When you launch an instance , you can optimize the CPU options to suit speciﬁc workloads or business needs .
2 May 2018 On-Demand Instances in Spot Fleets 2016-11-15 You can include a request for On-Demand capacity in your Spot Fleet request to ensure that you always have instance capacity .
Longer resource IDs 2016-11-15 You can enable the longer ID format for more resource types .
9 February 2018 Network performance improvements 2016-11-15 Instances outside of a cluster placement group can now beneﬁt from increased bandwidth when sending or receiving network traﬃc between other instances or Amazon S3 .
13 December 2017 Amazon Time Sync Service 2016-11-15 You can use the Amazon Time Sync Service to keep accurate time on your instance .
29 November 2017 1184 Release Date Amazon Elastic Compute Cloud User Guide for Linux Instances Feature API Version Description Launch templates 2016-11-15 A launch template can contain all or some of the parameters to launch an instance , so that you do n't have to specify them every time you launch an instance .
29 November 2017 Spread placement 2016-11-15 Spread placement groups are recommended for applications that have a small number of critical instances that should be kept separate from each other .
28 November 2017 Spot Instance hibernation 2016-11-15 The Spot service can hibernate Spot Instances in the event of an interruption .
28 November 2017 Spot Fleet target tracking 2016-11-15 You can set up target tracking scaling policies for your Spot Fleet .
17 November 2017 Spot Fleet integrates with Elastic Load Balancing 2016-11-15 You can attach one or more load balancers to a Spot Fleet .
You can also use the modiﬁcation process to split a Convertible Reserved Instance into smaller reservations .
25 October 2017 1185 Release Date Amazon Elastic Compute Cloud User Guide for Linux Instances Feature API Version Description Release Date Modify VPC tenancy 2016-11-15 You can change the instance tenancy attribute of a VPC from dedicated to default .
2 October 2017 Stop on interruption 2016-11-15 You can specify whether Amazon EC2 should stop or terminate Spot Instances when they are interrupted .
31 August 2017 Recover Elastic IP addresses 2016-11-15 If you release an Elastic IP address for use in a VPC , you might be able to recover it .
11 August 2017 Tag Spot Fleet instances 2016-11-15 You can conﬁgure your Spot Fleet to automatically tag the instances that it launches .
19 April 2017 Tag resources during creation 2016-11-15 You can apply tags to instances and volumes during creation .
23 February 2017 1186 Amazon Elastic Compute Cloud User Guide for Linux Instances Feature API Version Perform modiﬁcations on attached EBS volumes 2016-11-15 With most EBS volumes attached to most EC2 instances , you can modify volume size , type , and IOPS without detaching the volume or stopping the instance .
They are intended for applications that need responsiveness , high performance for limited periods of time , and a low cost .
6 September 2016 Automatic scaling for Spot Fleet Description Release Date You can now set up scaling policies for your Spot 1 Fleet .
2016 1187 Amazon Elastic Compute Cloud User Guide for Linux Instances Feature API Version Description Elastic Network Adapter 2016-04-01 You can now use ENA for enhanced networking .
Release Date 28 June 2016 Enhanced support for viewing and modifying longer IDs 2016-04-01 You can now view and modify longer ID settings 23 June for other IAM users , IAM roles , or the root user .
Copy encrypted Amazon EBS snapshots between AWS accounts 2016-04-01 You can now copy encrypted EBS snapshots between AWS accounts .
21 June 2016 Capture a screenshot of an instance console 2015-10-01 You can now obtain additional information when debugging instances that are unreachable .
23 March 2016 CloudWatch metrics for Spot Fleet You can now get CloudWatch metrics for your Spot Fleet .
During the opt-in period , you can enable the longer ID format for supported resource types .
13 January 2016 1188 Amazon Elastic Compute Cloud User Guide for Linux Instances Feature API Version Description Release Date ClassicLink DNS support 2015-10-01 You can enable ClassicLink DNS support for your VPC so that DNS hostnames that are addressed between linked EC2-Classic instances and instances in the VPC resolve to private IP addresses and not public IP addresses .
11 January 2016 New t2.nano instance type 2015-10-01 T2 instances are designed to provide moderate base performance and the capability to burst to signiﬁcantly higher performance as required by your workload .
They are intended for applications that need responsiveness , high performance for limited periods of time , and a low cost .
6 October 2015 Spot Fleet modify request 2015-10-01 You can now modify the target capacity of your Spot Fleet request .
29 September 2015 Spot Fleet diversiﬁed allocation strategy 2015-04-15 You can now allocate Spot Instances in multiple 15 Spot pools using a single Spot Fleet request .
Spot Fleet instance weighting 2015-04-15 You can now deﬁne the capacity units that each instance type contributes to your application's performance , and adjust the amount you are willing to pay for Spot Instances for each Spot pool accordingly .
31 August 2015 New reboot alarm action and new IAM role for use with alarm actions Added the reboot alarm action and new IAM role for use with alarm actions .
23 July 2015 New t2.large instance type T2 instances are designed to provide moderate base performance and the capability to burst to signiﬁcantly higher performance as required by your workload .
They are intended for applications that need responsiveness , high performance for limited periods of time , and a low cost .
16 June 2015 1189 Amazon Elastic Compute Cloud User Guide for Linux Instances Feature Description Release Date The next generation of general-purpose instances that provide a balance of compute , memory , and network resources .
15 May 2015 Importing VMs with multiple disks as AMIs 2015-03-01 The VM Import process now supports importing VMs with multiple disks as AMIs .
23 April 2015 M4 instances API Version New g2.8xlarge instance type The new g2.8xlarge instance is backed by four high-performance NVIDIA GPUs , making it well suited for GPU compute workloads including large scale rendering , transcoding , machine learning , and other server-side workloads that require massive parallel processing power .
7 April 2015 D2 instances Next generation Amazon EC2 dense-storage instances that are optimized for applications requiring sequential access to large amount of data on direct attached instance storage .
1190 Amazon Elastic Compute Cloud User Guide for Linux Instances Feature Automatic recovery for EC2 instances API Version Description Release Date You can create an Amazon CloudWatch alarm that monitors an Amazon EC2 instance and automatically recovers the instance if it becomes impaired due to an underlying hardware failure or a problem that requires AWS involvement to repair .
A recovered instance is identical to the original instance , including the instance ID , IP addresses , and all instance metadata .
ClassicLink Spot Instance termination notices 2014-10-01 ClassicLink enables you to link your EC2-Classic 7 January instance to a VPC in your account .
You can 2015 associate VPC security groups with the EC2-Classic instance , enabling communication between your EC2-Classic instance and instances in your VPC using private IP addresses .
The best way to protect against Spot Instance interruption is to architect your application to be fault tolerant .
In addition , you can take advantage of Spot Instance termination notices , which provide a two-minute warning before Amazon EC2 must terminate your Spot Instance .
DescribeVolumes pagination support 2014-09-01 The DescribeVolumes API call now supports the pagination of results with the MaxResults and NextToken parameters .
1191 23 October 2014 Amazon Elastic Compute Cloud User Guide for Linux Instances Feature API Version T2 instances 2014-06-15 T2 instances are designed to provide moderate base performance and the capability to burst to signiﬁcantly higher performance as required by your workload .
They are intended for applications that need responsiveness , high performance for limited periods of time , and a low cost .
New EC2 Service Limits page Description Use the EC2 Service Limits page in the Amazon EC2 console to view the current limits for resources provided by Amazon EC2 and Amazon VPC , on a per-region basis .
Release Date 30 June 2014 19 June 2014 Amazon EBS General Purpose SSD Volumes 2014-05-01 General Purpose SSD volumes oﬀer costeﬀective storage that is ideal for a broad range of workloads .
General Purpose SSD volumes can range in size from 1 GiB to 1 TiB .
16 June 2014 Amazon EBS encryption 2014-05-01 Amazon EBS encryption oﬀers seamless encryption of EBS data volumes and snapshots , eliminating the need to build and maintain a secure key management infrastructure .
EBS encryption enables data at rest security by encrypting your data using Amazon-managed keys .
The encryption occurs on the servers that host EC2 instances , providing encryption of data as it moves between EC2 instances and EBS storage .
These instances are ideally suited for relational and NoSQL databases , in-memory analytics solutions , scientiﬁc computing , and other memory-intensive applications that can beneﬁt from the high memory per vCPU , high compute performance , and enhanced networking capabilities of R3 instances .
New Amazon Linux AMI release Amazon Linux AMI 2014.03 is released .
1192 27 March 2014 Amazon Elastic Compute Cloud User Guide for Linux Instances Feature Amazon EC2 Usage Reports API Version Description Release Date Amazon EC2 Usage Reports is a set of reports 28 January that shows cost and usage data of your usage of 2014 EC2 .
For more information about the hardware speciﬁcations for each Amazon EC2 instance type , see Amazon EC2 Instance Types .
20 January 2014 I2 instances 2013-10-15 These instances provide very high IOPS and support TRIM on Linux instances for better successive SSD write performance .
19 December 2013 Importing Linux virtual machines 2013-10-15 The VM Import process now supports the importation of Linux instances .
16 December 2013 Resource-level permissions for RunInstances 2013-10-15 You can now create policies in AWS Identity and Access Management to control resource-level permissions for the Amazon EC2 RunInstances API action .
Launching an instance from the AWS Marketplace You can now launch an instance from the AWS Marketplace using the Amazon EC2 launch wizard .
New launch wizard Modifying Instance Types of Amazon EC2 Reserved Instances New Amazon Linux AMI release Description Release Date 4 November 2013 There is a new and redesigned EC2 launch wizard .
1194 19 March 2013 Amazon Elastic Compute Cloud User Guide for Linux Instances Feature API Version Description Copy an AMI from one Region to another 2013-02-01 You can copy an AMI from one Region to another , enabling you to launch consistent instances in more than one AWS Region quickly and easily .
When you launch an instance , we launch it into your default VPC , unless you create a nondefault VPC and specify it when you launch the instance .
20 December 2012 EBS snapshot copy 2012-12-01 You can use snapshot copies to create backups of data , to create new Amazon EBS volumes , or to create Amazon Machine Images ( AMIs ) .
17 December 2012 Updated EBS metrics and status checks for Provisioned IOPS SSD volumes 2012-10-01 Updated the EBS metrics to include two new 20 metrics for Provisioned IOPS SSD volumes .
Also added new status checks for Provisioned IOPS SSD volumes .
For more information about the hardware speciﬁcations for each Amazon EC2 instance type , see Amazon EC2 Instance Types .
31 October 2012 Spot Instance request status 2012-10-01 Spot Instance request status makes it easy to determine the state of your Spot requests .
14 October 2012 1195 Amazon Elastic Compute Cloud User Guide for Linux Instances Feature New Amazon Linux AMI release API Version Description Release Date Amazon Linux AMI 2012.09 is released .
11 October 2012 Amazon EC2 Reserved Instance Marketplace 2012-08-15 The Reserved Instance Marketplace matches 11 sellers who have Amazon EC2 Reserved Instances September that they no longer need with buyers who are 2012 looking to purchase additional capacity .
Reserved Instances bought and sold through the Reserved Instance Marketplace work like any other Reserved Instances , except that they can have less than a full standard term remaining and can be sold at diﬀerent prices .
Provisioned IOPS SSD for Amazon EBS 2012-07-20 Provisioned IOPS SSD volumes deliver predictable , 31 July high performance for I/O intensive workloads , 2012 such as database applications , that rely on consistent and fast response times .
• Granular permissions for applications running on Amazon EC2 instances that make requests to your AWS services .
Spot Instance features that make it easier to get started and handle the potential of interruption .
You can now manage your Spot Instances as follows : 7 June 2012 • Specify the amount you are willing to pay for Spot Instances using Auto Scaling launch conﬁgurations , and set up a schedule for specifying the amount you are willing to pay for Spot Instances .
For more information , see Launching Spot Instances in Your Auto Scaling Group in the Amazon EC2 Auto Scaling User Guide .
• Use AWS CloudFormation templates to launch Spot Instances in a stack with AWS resources .
EC2 instance export and 2012-05-01 Added support for timestamps on instance status timestamps for status and system status to indicate the date and time checks for Amazon EC2 that a status check failed .
1196 25 May 2012 Amazon Elastic Compute Cloud User Guide for Linux Instances Feature API Version Description Release Date EC2 instance export , and timestamps in instance and system status checks for Amazon VPC 2012-05-01 Added support for EC2 instance export to Citrix Xen , Microsoft Hyper-V , and VMware vSphere .
New Linux AMI release Amazon Linux AMI 2012.03 is released .
Added procedures for using the Javabased SSH client to connect to Linux instances .
7 March 2012 Reserved Instance pricing tiers 2011-12-15 Added a new section discussing how to take advantage of the discount pricing that is built into the Reserved Instance pricing tiers .
New oﬀering types for Amazon EC2 Reserved Instances 2011-11-01 You can choose from a variety of Reserved Instance oﬀerings that address your projected use of the instance .
01 December 2011 Amazon EC2 instance status 2011-11-01 You can view additional details about the status of your instances , including scheduled events planned by AWS that might have an impact on your instances .
These operational activities include instance reboots required to apply software updates or security patches , or instance retirements required where there are hardware issues .
1197 14 November 2011 Amazon Elastic Compute Cloud User Guide for Linux Instances Feature New PDX Region and AKIs Spot Instances in Amazon VPC New Linux AMI release Simpliﬁed VM import process for users of the CLI tools API Version Description Release Date Added information about the release of new AKIs for the new US-West 2 Region .
By launching Spot Instances in a VPC , users of Spot Instances can enjoy the beneﬁts of Amazon VPC .
This update removes the beta September tag from the Amazon Linux AMI , supports the 2011 ability to lock the repositories to a speciﬁc version , and provides for notiﬁcation when updates are available to installed packages including security updates .
2011-07-15 The VM Import process is simpliﬁed with the enhanced functionality of ImportInstance and ImportVolume , which now will perform the upload of the images into Amazon EC2 after creating the import task .
In addition , with the introduction of ResumeImport , users can restart an incomplete upload at the point the task stopped .
15 September 2011 Support for importing in VHD ﬁle format VM Import can now import virtual machine image ﬁles in VHD format .
The VHD ﬁle format is compatible with the Citrix Xen and Microsoft Hyper-V virtualization platforms .
24 August 2011 Update to the Amazon EC2 VM Import Connector for VMware vCenter Added information about the 1.1 version of the Amazon EC2 VM Import Connector for VMware vCenter virtual appliance ( Connector ) .
This update includes proxy support for Internet access , better error handling , improved task progress bar accuracy , and several bug ﬁxes .
This version updates the PVGRUB to address launch failures associated with t1.micro Linux instances .
20 June 2011 1198 Amazon Elastic Compute Cloud User Guide for Linux Instances Feature API Version Description Release Date Spot Instances 2011-05-15 Added information about the Spot Instances Availability Zone pricing Availability Zone pricing feature .
In this release , changes we 've added new Availability Zone pricing options as part of the information returned when you query for Spot Instance requests and Spot price history .
These additions make it easier to determine the price required to launch a Spot Instance into a particular Availability Zone .
26 May 2011 AWS Identity and Access Management Added information about AWS Identity and Access Management ( IAM ) , which enables users to specify which Amazon EC2 actions a user can use with Amazon EC2 resources in general .
26 April 2011 Dedicated instances Launched within your Amazon Virtual Private Cloud ( Amazon VPC ) , Dedicated Instances are instances that are physically isolated at the host hardware level .
Dedicated Instances let you take advantage of Amazon VPC and the AWS cloud , with beneﬁts including on-demand elastic provisioning and pay only for what you use , while isolating your Amazon EC2 compute instances at the hardware level .
27 March 2011 Reserved Instances updates to the AWS Management Console Updates to the AWS Management Console make it easier for users to view their Reserved Instances and purchase additional Reserved Instances , including Dedicated Reserved Instances .
27 March 2011 New Amazon Linux reference AMI The new Amazon Linux reference AMI replaces the CentOS reference AMI .
Removed information about the CentOS reference AMI , including the section named Correcting Clock Drift for Cluster Instances on CentOS 5.4 AMI .
1199 11 March 2011 Amazon Elastic Compute Cloud User Guide for Linux Instances Feature API Version Description Release Date Amazon EC2 VM Import Connector for VMware vCenter Added information about the Amazon EC2 VM Import Connector for VMware vCenter virtual appliance ( Connector ) .
The Connector is a plug-in for VMware vCenter that integrates with VMware vSphere Client and provides a graphical user interface that you can use to import your VMware virtual machines to Amazon EC2 .
3 March 2011 Force volume detachment You can now use the AWS Management Console to force the detachment of an Amazon EBS volume from an instance .
23 February 2011 Instance termination protection You can now use the AWS Management Console to prevent an instance from being terminated .
23 February 2011 Correcting Clock Drift for Cluster Instances on CentOS 5.4 AMI Added information about how to correct clock drift for cluster instances running on Amazon's CentOS 5.4 AMI .
For more information about the hardware speciﬁcations for each Amazon EC2 instance type , see Amazon EC2 Instance Types .
12 July 2010 Amazon VPC IP Address Designation 2010-06-15 Amazon VPC users can now specify the IP address to assign an instance launched in a VPC .
12 July 2010 Amazon CloudWatch Monitoring for Amazon EBS Volumes Amazon CloudWatch monitoring is now automatically available for Amazon EBS volumes .
For more information about the hardware speciﬁcations for each Amazon EC2 instance type , see Amazon EC2 Instance Types .